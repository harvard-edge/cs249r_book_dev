<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/ai_for_good/ai_for_good.html" rel="next">
<link href="../../../contents/core/responsible_ai/responsible_ai.html" rel="prev">
<link href="../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ae75ed80ef5b3e74590777de1ac3d8c3.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-0769fbf68cc3e722256a1e1e51d908bf.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script><script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script><script async="" src="https://hypothes.is/embed.js"></script><script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script><script type="module" src="../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script><script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script><script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script><script type="module" src="../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script><script src="../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script><style>
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
.callout-example {
  --color1: #F0F8F6;
  --color2: #148F77;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
.callout-definition {
  --color1: #F0F4F8;
  --color2: #1B4F72;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
</style>
<style>
details.callout-quiz-answer > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
details.callout-example > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-example.png");
}
details.callout-quiz-question > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-code > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-code.png");
}
details.callout-definition > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-definition.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
details.callout-resource-videos > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
</style>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-md " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/images/icons/favicon.png" alt="" class="navbar-logo"></a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link active" href="../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-file-pdf" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/epub" target="_blank"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text">EPUB</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">
<li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
</li>
</ul>
</div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/responsible_ai/responsible_ai.html">Trustworthy Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/sustainable_ai/sustainable_ai.html">Sustainable AI</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav><div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden">
<i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p style="margin: 0 0 12px 0; padding: 8px 12px; background: rgba(255,193,7,0.2); border: 1px solid #ffc107; border-radius: 4px; font-weight: 600;"><i class="bi bi-exclamation-triangle-fill" style="margin-right: 6px; color: #856404;"></i><strong>🚧 DEVELOPMENT PREVIEW</strong> - Built from dev@<code style="background: rgba(0,0,0,0.1); padding: 2px 4px; border-radius: 3px; font-size: 0.9em;">6fb63725</code> • 2025-10-03 00:17 UTC • <a href="https://mlsysbook.ai" style="color: #856404; text-decoration: underline;"><em>Stable version →</em></a></p>
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div>
<i class="bi bi-x-lg quarto-announcement-action" style="display: none;"></i>
</div>
</header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frontiers/frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AGI Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">Glossary</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/glossary/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Glossary</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">References</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Bibliography</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li>
<a href="#sec-sustainable-ai" id="toc-sec-sustainable-ai" class="nav-link active" data-scroll-target="#sec-sustainable-ai">Sustainable AI</a>
  <ul>
<li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose</a></li>
  <li>
<a href="#sec-sustainable-ai-crisis" id="toc-sec-sustainable-ai-crisis" class="nav-link" data-scroll-target="#sec-sustainable-ai-crisis">The Sustainability Crisis in AI</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-impact-scale" id="toc-sec-sustainable-ai-impact-scale" class="nav-link" data-scroll-target="#sec-sustainable-ai-impact-scale">The Scale of Environmental Impact</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-problem-recognition" id="toc-sec-sustainable-ai-problem-recognition" class="nav-link" data-scroll-target="#sec-sustainable-ai-problem-recognition">Part I: Problem Recognition</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-ethical-responsibility-8a78" id="toc-sec-sustainable-ai-ethical-responsibility-8a78" class="nav-link" data-scroll-target="#sec-sustainable-ai-ethical-responsibility-8a78">Ethical Responsibility and Environmental Justice</a></li>
  <li><a href="#sec-sustainable-ai-longterm-viability-5f29" id="toc-sec-sustainable-ai-longterm-viability-5f29" class="nav-link" data-scroll-target="#sec-sustainable-ai-longterm-viability-5f29">The Viability Crisis: Exponential Demand Meets Physical Limits</a></li>
  <li><a href="#sec-sustainable-ai-biological-intelligence-efficiency-7a9c" id="toc-sec-sustainable-ai-biological-intelligence-efficiency-7a9c" class="nav-link" data-scroll-target="#sec-sustainable-ai-biological-intelligence-efficiency-7a9c">Learning from Biological Intelligence</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-measurement-assessment" id="toc-sec-sustainable-ai-measurement-assessment" class="nav-link" data-scroll-target="#sec-sustainable-ai-measurement-assessment">Part II: Measurement and Assessment</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-carbon-footprint-analysis" id="toc-sec-sustainable-ai-carbon-footprint-analysis" class="nav-link" data-scroll-target="#sec-sustainable-ai-carbon-footprint-analysis">Carbon Footprint Analysis</a></li>
  <li>
<a href="#sec-sustainable-ai-case-study-deepminds-energy-efficiency-3362" id="toc-sec-sustainable-ai-case-study-deepminds-energy-efficiency-3362" class="nav-link" data-scroll-target="#sec-sustainable-ai-case-study-deepminds-energy-efficiency-3362">Case Study: DeepMind’s Energy Efficiency</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-lifecycle-phases" id="toc-sec-sustainable-ai-lifecycle-phases" class="nav-link" data-scroll-target="#sec-sustainable-ai-lifecycle-phases">Three-Phase Lifecycle Assessment Framework</a></li>
  <li><a href="#sec-sustainable-ai-optimization-opportunities" id="toc-sec-sustainable-ai-optimization-opportunities" class="nav-link" data-scroll-target="#sec-sustainable-ai-optimization-opportunities">Geographic and Temporal Optimization Opportunities</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-energy-consumption-patterns" id="toc-sec-sustainable-ai-energy-consumption-patterns" class="nav-link" data-scroll-target="#sec-sustainable-ai-energy-consumption-patterns">Energy Consumption Patterns and Infrastructure Impact</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-datacenter-energy-dynamics" id="toc-sec-sustainable-ai-datacenter-energy-dynamics" class="nav-link" data-scroll-target="#sec-sustainable-ai-datacenter-energy-dynamics">Data Center Energy Dynamics and AI Workloads</a></li>
  <li><a href="#sec-sustainable-ai-energy-demands-data-centers-ec7b" id="toc-sec-sustainable-ai-energy-demands-data-centers-ec7b" class="nav-link" data-scroll-target="#sec-sustainable-ai-energy-demands-data-centers-ec7b">Energy Demands in Data Centers</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-distributed-systems-energy-9f3a" id="toc-sec-sustainable-ai-distributed-systems-energy-9f3a" class="nav-link" data-scroll-target="#sec-sustainable-ai-distributed-systems-energy-9f3a">Distributed Systems Energy Optimization</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-ai-vs-industries-f2ba" id="toc-sec-sustainable-ai-ai-vs-industries-f2ba" class="nav-link" data-scroll-target="#sec-sustainable-ai-ai-vs-industries-f2ba">AI vs.&nbsp;Other Industries</a></li>
  </ul>
</li>
  <li><a href="#sec-sustainable-ai-updated-analysis-95ef" id="toc-sec-sustainable-ai-updated-analysis-95ef" class="nav-link" data-scroll-target="#sec-sustainable-ai-updated-analysis-95ef">Updated Analysis</a></li>
  <li><a href="#sec-sustainable-ai-carbon-emission-scopes-lifecycle" id="toc-sec-sustainable-ai-carbon-emission-scopes-lifecycle" class="nav-link" data-scroll-target="#sec-sustainable-ai-carbon-emission-scopes-lifecycle">Carbon Emission Scopes and Lifecycle Analysis</a></li>
  <li>
<a href="#sec-sustainable-ai-training-inference-lifecycle-analysis" id="toc-sec-sustainable-ai-training-inference-lifecycle-analysis" class="nav-link" data-scroll-target="#sec-sustainable-ai-training-inference-lifecycle-analysis">Training vs.&nbsp;Inference: Lifecycle Energy Analysis</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-training-energy-demands-a66b" id="toc-sec-sustainable-ai-training-energy-demands-a66b" class="nav-link" data-scroll-target="#sec-sustainable-ai-training-energy-demands-a66b">Training Energy Demands</a></li>
  <li><a href="#sec-sustainable-ai-inference-energy-costs-bc1e" id="toc-sec-sustainable-ai-inference-energy-costs-bc1e" class="nav-link" data-scroll-target="#sec-sustainable-ai-inference-energy-costs-bc1e">Inference Energy Costs</a></li>
  <li><a href="#sec-sustainable-ai-edge-ai-impact-5edc" id="toc-sec-sustainable-ai-edge-ai-impact-5edc" class="nav-link" data-scroll-target="#sec-sustainable-ai-edge-ai-impact-5edc">Edge AI Impact</a></li>
  </ul>
</li>
  <li><a href="#sec-sustainable-ai-comprehensive-environmental-assessment" id="toc-sec-sustainable-ai-comprehensive-environmental-assessment" class="nav-link" data-scroll-target="#sec-sustainable-ai-comprehensive-environmental-assessment">Comprehensive Environmental Impact Assessment: Beyond Carbon</a></li>
  <li><a href="#sec-sustainable-ai-water-usage-efc6" id="toc-sec-sustainable-ai-water-usage-efc6" class="nav-link" data-scroll-target="#sec-sustainable-ai-water-usage-efc6">Water Usage</a></li>
  <li><a href="#sec-sustainable-ai-hazardous-chemicals-6c4c" id="toc-sec-sustainable-ai-hazardous-chemicals-6c4c" class="nav-link" data-scroll-target="#sec-sustainable-ai-hazardous-chemicals-6c4c">Hazardous Chemicals</a></li>
  <li><a href="#sec-sustainable-ai-resource-depletion-e383" id="toc-sec-sustainable-ai-resource-depletion-e383" class="nav-link" data-scroll-target="#sec-sustainable-ai-resource-depletion-e383">Resource Depletion</a></li>
  <li><a href="#sec-sustainable-ai-waste-generation-e6d9" id="toc-sec-sustainable-ai-waste-generation-e6d9" class="nav-link" data-scroll-target="#sec-sustainable-ai-waste-generation-e6d9">Waste Generation</a></li>
  <li><a href="#sec-sustainable-ai-biodiversity-impact-8f3d" id="toc-sec-sustainable-ai-biodiversity-impact-8f3d" class="nav-link" data-scroll-target="#sec-sustainable-ai-biodiversity-impact-8f3d">Biodiversity Impact</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-semiconductor-life-cycle-5c14" id="toc-sec-sustainable-ai-semiconductor-life-cycle-5c14" class="nav-link" data-scroll-target="#sec-sustainable-ai-semiconductor-life-cycle-5c14">Semiconductor Life Cycle</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-design-phase-8374" id="toc-sec-sustainable-ai-design-phase-8374" class="nav-link" data-scroll-target="#sec-sustainable-ai-design-phase-8374">Design Phase</a></li>
  <li>
<a href="#sec-sustainable-ai-manufacturing-phase-03a1" id="toc-sec-sustainable-ai-manufacturing-phase-03a1" class="nav-link" data-scroll-target="#sec-sustainable-ai-manufacturing-phase-03a1">Manufacturing Phase</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-fabrication-materials-0eb1" id="toc-sec-sustainable-ai-fabrication-materials-0eb1" class="nav-link" data-scroll-target="#sec-sustainable-ai-fabrication-materials-0eb1">Fabrication Materials</a></li>
  <li><a href="#sec-sustainable-ai-manufacturing-energy-consumption-0214" id="toc-sec-sustainable-ai-manufacturing-energy-consumption-0214" class="nav-link" data-scroll-target="#sec-sustainable-ai-manufacturing-energy-consumption-0214">Manufacturing Energy Consumption</a></li>
  <li><a href="#sec-sustainable-ai-hazardous-waste-water-usage-fabs-9140" id="toc-sec-sustainable-ai-hazardous-waste-water-usage-fabs-9140" class="nav-link" data-scroll-target="#sec-sustainable-ai-hazardous-waste-water-usage-fabs-9140">Hazardous Waste and Water Usage in Fabs</a></li>
  <li><a href="#sec-sustainable-ai-sustainable-initiatives-c0e1" id="toc-sec-sustainable-ai-sustainable-initiatives-c0e1" class="nav-link" data-scroll-target="#sec-sustainable-ai-sustainable-initiatives-c0e1">Sustainable Initiatives</a></li>
  </ul>
</li>
  <li><a href="#sec-sustainable-ai-use-phase-a8ad" id="toc-sec-sustainable-ai-use-phase-a8ad" class="nav-link" data-scroll-target="#sec-sustainable-ai-use-phase-a8ad">Use Phase</a></li>
  <li><a href="#sec-sustainable-ai-disposal-phase-17fc" id="toc-sec-sustainable-ai-disposal-phase-17fc" class="nav-link" data-scroll-target="#sec-sustainable-ai-disposal-phase-17fc">Disposal Phase</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-implementation-solutions" id="toc-sec-sustainable-ai-implementation-solutions" class="nav-link" data-scroll-target="#sec-sustainable-ai-implementation-solutions">Part III: Implementation and Solutions</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-strategic-framework" id="toc-sec-sustainable-ai-strategic-framework" class="nav-link" data-scroll-target="#sec-sustainable-ai-strategic-framework">Strategic Framework for Sustainable AI Implementation</a></li>
  <li>
<a href="#sec-sustainable-ai-practical-implementation-framework" id="toc-sec-sustainable-ai-practical-implementation-framework" class="nav-link" data-scroll-target="#sec-sustainable-ai-practical-implementation-framework">Practical Implementation Framework: From Design to Deployment</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-energy-efficient-algorithmic-design" id="toc-sec-sustainable-ai-energy-efficient-algorithmic-design" class="nav-link" data-scroll-target="#sec-sustainable-ai-energy-efficient-algorithmic-design">Energy-Efficient Algorithmic Design</a></li>
  <li><a href="#sec-sustainable-ai-energyefficient-design-8890" id="toc-sec-sustainable-ai-energyefficient-design-8890" class="nav-link" data-scroll-target="#sec-sustainable-ai-energyefficient-design-8890">Energy-Efficient Design</a></li>
  <li><a href="#sec-sustainable-ai-lifecycleaware-systems-66d8" id="toc-sec-sustainable-ai-lifecycleaware-systems-66d8" class="nav-link" data-scroll-target="#sec-sustainable-ai-lifecycleaware-systems-66d8">Lifecycle-Aware Systems</a></li>
  <li><a href="#sec-sustainable-ai-policy-incentives-2814" id="toc-sec-sustainable-ai-policy-incentives-2814" class="nav-link" data-scroll-target="#sec-sustainable-ai-policy-incentives-2814">Policy and Incentives</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-infrastructure-optimization-fddc" id="toc-sec-sustainable-ai-infrastructure-optimization-fddc" class="nav-link" data-scroll-target="#sec-sustainable-ai-infrastructure-optimization-fddc">Infrastructure Optimization</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-green-data-centers-27e7" id="toc-sec-sustainable-ai-green-data-centers-27e7" class="nav-link" data-scroll-target="#sec-sustainable-ai-green-data-centers-27e7">Green Data Centers</a></li>
  <li><a href="#sec-sustainable-ai-carbonaware-scheduling-77d6" id="toc-sec-sustainable-ai-carbonaware-scheduling-77d6" class="nav-link" data-scroll-target="#sec-sustainable-ai-carbonaware-scheduling-77d6">Carbon-Aware Scheduling</a></li>
  <li><a href="#sec-sustainable-ai-aidriven-thermal-optimization-77fe" id="toc-sec-sustainable-ai-aidriven-thermal-optimization-77fe" class="nav-link" data-scroll-target="#sec-sustainable-ai-aidriven-thermal-optimization-77fe">AI-Driven Thermal Optimization</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-addressing-full-environmental-footprint-b7f6" id="toc-sec-sustainable-ai-addressing-full-environmental-footprint-b7f6" class="nav-link" data-scroll-target="#sec-sustainable-ai-addressing-full-environmental-footprint-b7f6">Addressing Full Environmental Footprint</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-revisiting-life-cycle-impact-c29e" id="toc-sec-sustainable-ai-revisiting-life-cycle-impact-c29e" class="nav-link" data-scroll-target="#sec-sustainable-ai-revisiting-life-cycle-impact-c29e">Revisiting Life Cycle Impact</a></li>
  <li><a href="#sec-sustainable-ai-mitigating-supply-chain-impact-786c" id="toc-sec-sustainable-ai-mitigating-supply-chain-impact-786c" class="nav-link" data-scroll-target="#sec-sustainable-ai-mitigating-supply-chain-impact-786c">Mitigating Supply Chain Impact</a></li>
  <li><a href="#sec-sustainable-ai-reducing-water-resource-consumption-94b9" id="toc-sec-sustainable-ai-reducing-water-resource-consumption-94b9" class="nav-link" data-scroll-target="#sec-sustainable-ai-reducing-water-resource-consumption-94b9">Reducing Water and Resource Consumption</a></li>
  <li><a href="#sec-sustainable-ai-systemic-sustainability-approaches-ba04" id="toc-sec-sustainable-ai-systemic-sustainability-approaches-ba04" class="nav-link" data-scroll-target="#sec-sustainable-ai-systemic-sustainability-approaches-ba04">Systemic Sustainability Approaches</a></li>
  </ul>
</li>
  <li><a href="#sec-sustainable-ai-case-study-googles-framework-4923" id="toc-sec-sustainable-ai-case-study-googles-framework-4923" class="nav-link" data-scroll-target="#sec-sustainable-ai-case-study-googles-framework-4923">Case Study: Google’s Framework</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-embedded-ai-ewaste-292b" id="toc-sec-sustainable-ai-embedded-ai-ewaste-292b" class="nav-link" data-scroll-target="#sec-sustainable-ai-embedded-ai-ewaste-292b">Embedded AI and E-Waste</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-ewaste-crisis-d1a4" id="toc-sec-sustainable-ai-ewaste-crisis-d1a4" class="nav-link" data-scroll-target="#sec-sustainable-ai-ewaste-crisis-d1a4">E-Waste Crisis</a></li>
  <li>
<a href="#sec-sustainable-ai-disposable-electronics-cb28" id="toc-sec-sustainable-ai-disposable-electronics-cb28" class="nav-link" data-scroll-target="#sec-sustainable-ai-disposable-electronics-cb28">Disposable Electronics</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-nonreplaceable-batteries-cost-3e8e" id="toc-sec-sustainable-ai-nonreplaceable-batteries-cost-3e8e" class="nav-link" data-scroll-target="#sec-sustainable-ai-nonreplaceable-batteries-cost-3e8e">Non-Replaceable Batteries Cost</a></li>
  <li><a href="#sec-sustainable-ai-recycling-challenges-4554" id="toc-sec-sustainable-ai-recycling-challenges-4554" class="nav-link" data-scroll-target="#sec-sustainable-ai-recycling-challenges-4554">Recycling Challenges</a></li>
  <li><a href="#sec-sustainable-ai-need-sustainable-design-a7e7" id="toc-sec-sustainable-ai-need-sustainable-design-a7e7" class="nav-link" data-scroll-target="#sec-sustainable-ai-need-sustainable-design-a7e7">Need for Sustainable Design</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-ai-hardware-obsolescence-b3e0" id="toc-sec-sustainable-ai-ai-hardware-obsolescence-b3e0" class="nav-link" data-scroll-target="#sec-sustainable-ai-ai-hardware-obsolescence-b3e0">AI Hardware Obsolescence</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-lockin-proprietary-components-6983" id="toc-sec-sustainable-ai-lockin-proprietary-components-6983" class="nav-link" data-scroll-target="#sec-sustainable-ai-lockin-proprietary-components-6983">Lock-In and Proprietary Components</a></li>
  <li><a href="#sec-sustainable-ai-environmental-cost-c458" id="toc-sec-sustainable-ai-environmental-cost-c458" class="nav-link" data-scroll-target="#sec-sustainable-ai-environmental-cost-c458">Environmental Cost</a></li>
  <li><a href="#sec-sustainable-ai-extending-hardware-lifespan-b028" id="toc-sec-sustainable-ai-extending-hardware-lifespan-b028" class="nav-link" data-scroll-target="#sec-sustainable-ai-extending-hardware-lifespan-b028">Extending Hardware Lifespan</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-policy-regulation-9668" id="toc-sec-sustainable-ai-policy-regulation-9668" class="nav-link" data-scroll-target="#sec-sustainable-ai-policy-regulation-9668">Policy and Regulation</a>
  <ul class="collapse">
<li>
<a href="#sec-sustainable-ai-policy-governance-frameworks" id="toc-sec-sustainable-ai-policy-governance-frameworks" class="nav-link" data-scroll-target="#sec-sustainable-ai-policy-governance-frameworks">Policy and Governance Frameworks for Sustainable AI</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-measurement-accountability" id="toc-sec-sustainable-ai-measurement-accountability" class="nav-link" data-scroll-target="#sec-sustainable-ai-measurement-accountability">Measurement and Accountability Mechanisms</a></li>
  </ul>
</li>
  <li><a href="#sec-sustainable-ai-measurement-reporting-798b" id="toc-sec-sustainable-ai-measurement-reporting-798b" class="nav-link" data-scroll-target="#sec-sustainable-ai-measurement-reporting-798b">Measurement and Reporting</a></li>
  <li><a href="#sec-sustainable-ai-restriction-mechanisms-a260" id="toc-sec-sustainable-ai-restriction-mechanisms-a260" class="nav-link" data-scroll-target="#sec-sustainable-ai-restriction-mechanisms-a260">Restriction Mechanisms</a></li>
  <li><a href="#sec-sustainable-ai-government-incentives-face" id="toc-sec-sustainable-ai-government-incentives-face" class="nav-link" data-scroll-target="#sec-sustainable-ai-government-incentives-face">Government Incentives</a></li>
  <li><a href="#sec-sustainable-ai-selfregulation-02df" id="toc-sec-sustainable-ai-selfregulation-02df" class="nav-link" data-scroll-target="#sec-sustainable-ai-selfregulation-02df">Self-Regulation</a></li>
  <li><a href="#sec-sustainable-ai-global-impact-aafd" id="toc-sec-sustainable-ai-global-impact-aafd" class="nav-link" data-scroll-target="#sec-sustainable-ai-global-impact-aafd">Global Impact</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-public-engagement-9850" id="toc-sec-sustainable-ai-public-engagement-9850" class="nav-link" data-scroll-target="#sec-sustainable-ai-public-engagement-9850">Public Engagement</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-ai-awareness-ddcc" id="toc-sec-sustainable-ai-ai-awareness-ddcc" class="nav-link" data-scroll-target="#sec-sustainable-ai-ai-awareness-ddcc">AI Awareness</a></li>
  <li><a href="#sec-sustainable-ai-messaging-discourse-b14b" id="toc-sec-sustainable-ai-messaging-discourse-b14b" class="nav-link" data-scroll-target="#sec-sustainable-ai-messaging-discourse-b14b">Messaging and Discourse</a></li>
  <li><a href="#sec-sustainable-ai-transparency-trust-4d51" id="toc-sec-sustainable-ai-transparency-trust-4d51" class="nav-link" data-scroll-target="#sec-sustainable-ai-transparency-trust-4d51">Transparency and Trust</a></li>
  <li><a href="#sec-sustainable-ai-engagement-awareness-199d" id="toc-sec-sustainable-ai-engagement-awareness-199d" class="nav-link" data-scroll-target="#sec-sustainable-ai-engagement-awareness-199d">Engagement and Awareness</a></li>
  <li><a href="#sec-sustainable-ai-equitable-ai-access-b94f" id="toc-sec-sustainable-ai-equitable-ai-access-b94f" class="nav-link" data-scroll-target="#sec-sustainable-ai-equitable-ai-access-b94f">Equitable AI Access</a></li>
  </ul>
</li>
  <li>
<a href="#sec-sustainable-ai-future-challenges-58e2" id="toc-sec-sustainable-ai-future-challenges-58e2" class="nav-link" data-scroll-target="#sec-sustainable-ai-future-challenges-58e2">Future Challenges</a>
  <ul class="collapse">
<li><a href="#sec-sustainable-ai-future-directions-633b" id="toc-sec-sustainable-ai-future-directions-633b" class="nav-link" data-scroll-target="#sec-sustainable-ai-future-directions-633b">Future Directions</a></li>
  <li><a href="#sec-sustainable-ai-challenges-16ab" id="toc-sec-sustainable-ai-challenges-16ab" class="nav-link" data-scroll-target="#sec-sustainable-ai-challenges-16ab">Challenges</a></li>
  <li><a href="#sec-sustainable-ai-towards-sustainable-ai-96ad" id="toc-sec-sustainable-ai-towards-sustainable-ai-96ad" class="nav-link" data-scroll-target="#sec-sustainable-ai-towards-sustainable-ai-96ad">Towards Sustainable AI</a></li>
  </ul>
</li>
  <li><a href="#fallacies-and-pitfalls" id="toc-fallacies-and-pitfalls" class="nav-link" data-scroll-target="#fallacies-and-pitfalls">Fallacies and Pitfalls</a></li>
  <li><a href="#sec-sustainable-ai-summary-8cec" id="toc-sec-sustainable-ai-summary-8cec" class="nav-link" data-scroll-target="#sec-sustainable-ai-summary-8cec">Summary</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers">Self-Check Answers</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/responsible_ai/responsible_ai.html">Trustworthy Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/sustainable_ai/sustainable_ai.html">Sustainable AI</a></li></ol></nav></header><section id="sec-sustainable-ai" class="level1 page-columns page-full"><h1>Sustainable AI</h1>
<div class="{layout-narrow} page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="">
<p><em>DALL·E 3 Prompt: 3D illustration on a light background of a sustainable AI network interconnected with a myriad of eco-friendly energy sources. The AI actively manages and optimizes its energy from sources like solar arrays, wind turbines, and hydro dams, emphasizing power efficiency and performance. Deep neural networks spread throughout, receiving energy from these sustainable resources.</em></p>
</div></div><p> <img src="images/png/cover_sustainable_ai.png" class="img-fluid"></p>
</div>
<section id="purpose" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="purpose">Purpose</h2>
<p><em>Why does resource efficiency represent a fundamental constraint that determines the viability and scalability of machine learning systems, not merely an environmental consideration?</em></p>
<p>Machine learning systems consume computational resources at scales that challenge practical deployment limits and economic feasibility. Training state-of-the-art language models requires energy equivalent to powering thousands of homes for months, while global inference workloads demand data center capacity that doubles annually, creating resource bottlenecks that constrain system scalability regardless of environmental concerns. These resource demands impose hard engineering constraints: energy costs that can exceed model development budgets, thermal limits that restrict hardware density, and power infrastructure requirements that limit deployment locations. Resource efficiency directly determines system viability, operational costs, and competitive advantage in resource-constrained environments, making sustainability a critical engineering discipline. Understanding resource optimization techniques enables engineers to design systems that operate within practical power, thermal, and economic limits while achieving performance objectives. As computational demands continue growing exponentially, resource efficiency becomes the primary constraint determining which AI applications can scale from research prototypes to deployed systems that serve billions of users worldwide.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Define environmental impacts of AI systems including energy consumption and carbon emissions</p></li>
<li><p>Identify ethical considerations and responsibilities surrounding sustainable AI development</p></li>
<li><p>Analyze strategies for reducing AI carbon footprint across training and deployment phases</p></li>
<li><p>Describe role of energy-efficient design in sustainable AI system architecture</p></li>
<li><p>Discuss importance of policy and regulation frameworks for promoting sustainable AI practices</p></li>
<li><p>Recognize challenges in AI hardware and software lifecycle management and e-waste reduction</p></li>
</ul>
</div>
</div>
</section><section id="sec-sustainable-ai-crisis" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-crisis">The Sustainability Crisis in AI</h2>
<p>AI systems have transformed technological capabilities across industries, but this transformation comes with environmental cost. The computational demands of AI create sustainability challenges that extend beyond energy consumption, encompassing carbon emissions, resource extraction, manufacturing impact, and electronic waste at a scale that threatens long-term technological viability.</p>
<p>This sustainability crisis manifests in three interconnected dimensions that this chapter examines. First, problem recognition examines the scope and urgency of AI’s environmental impact, including ethical responsibilities and long-term viability concerns. Second, measurement and assessment provides frameworks for quantifying carbon footprints, energy consumption, and lifecycle impacts during training and inference phases. Finally, implementation and solutions presents concrete strategies for mitigation through sustainable development practices, infrastructure optimization, and policy frameworks that enable practical environmental responsibility.</p>
<section id="sec-sustainable-ai-impact-scale" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-impact-scale">The Scale of Environmental Impact</h3>
<p>AI systems consume resources at industrial scales that rival traditional heavy industries. Training a single large language model consumes thousands of megawatt-hours of electricity, equivalent to powering hundreds of households for months<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Data centers (including AI workloads) are projected to account for 8% of global power consumption by 2030, surpassing aviation (2.1%) and approaching cement production (4%) <span class="citation" data-cites="oecd2023blueprint">(<a href="#ref-oecd2023blueprint" role="doc-biblioref">OECD 2023</a>)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Computational demands increase 350,000× faster than hardware efficiency improvements, creating an unsustainable exponential growth pattern.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<strong>Household Energy Comparison</strong>: The average U.S. household consumes 10,500 kWh annually (about 875 kWh monthly). Training GPT-4 consumed an estimated 50,000-100,000 MWh (50-100 million kWh), equivalent to 5-10 years of electricity for 10,000 households. This single training run used more energy than entire small cities like Aspen, Colorado (population 7,400) consume annually.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;<strong>AI vs Industrial Emissions</strong>: Data centers (which include AI workloads) are projected to account for 8% of total power consumption by 2030, surpassing aviation (2.1%) and approaching cement production (4%). Current AI emissions already exceed those of Argentina (0.2 billion tons CO₂ annually). Training just the top 10 large language models in 2023 generated emissions equivalent to 40,000 round-trip flights from New York to London.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;<strong>GPU Manufacturing Impact</strong>: Producing a single high-end GPU like the NVIDIA H100 generates 300-500 kg of CO₂ before any computation occurs. Manufacturing requires 2,500+ liters of ultrapure water, 15+ rare earth elements, and energy-intensive processes reaching 1,000°C. TSMC’s advanced 4nm process consumes 40% more energy per wafer than older 7nm nodes, increasing embodied carbon in AI accelerators.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;<strong>E-Waste from Computing</strong>: Global e-waste reached 54 million metric tons in 2019, with computing equipment contributing 15%. AI hardware accelerates this trend—NVIDIA’s GPU sales increased 200% from 2020-2023, with each high-end GPU weighing 2-4 lbs and containing toxic materials requiring specialized disposal. The rapid obsolescence cycle means AI hardware often becomes e-waste within 3-5 years.</p></div></div><p>Beyond direct energy consumption, AI systems drive environmental impact through hardware manufacturing and resource utilization. Training and inference workloads depend on specialized processors that require rare earth metals whose extraction and processing generate pollution<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The growing demand for AI applications accelerates electronic waste production, with global e-waste reaching 54 million metric tons annually <span class="citation" data-cites="Forti2020">(<a href="#ref-Forti2020" role="doc-biblioref">Forti et al. 2020</a>)</span>, as AI hardware rapidly becomes obsolete due to accelerating performance requirements<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p>These environmental challenges require systematic understanding and coordinated response in technical, policy, and ethical dimensions to ensure AI development remains viable and responsible.</p>
</section></section><section id="sec-sustainable-ai-problem-recognition" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-problem-recognition">Part I: Problem Recognition</h2>
<p>Understanding AI’s sustainability crisis requires examining both its technical dimensions and ethical implications. AI’s environmental impact extends beyond technical metrics to questions of equity, justice, and long-term viability that define the urgency of addressing these challenges. As computational requirements grow exponentially and resource consumption intensifies, the field must confront difficult choices about who bears the costs of AI advancement and who reaps its benefits.</p>
<section id="sec-sustainable-ai-ethical-responsibility-8a78" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-ethical-responsibility-8a78">Ethical Responsibility and Environmental Justice</h3>
<p>The environmental impact of AI creates ethical responsibilities that extend beyond technical optimization. The computational resources required for AI development concentrate environmental costs on specific communities while distributing benefits unequally across global populations. Data centers consume large amounts of electricity and water, often in regions where energy grids rely on fossil fuels and water resources face stress from climate change.</p>
<p>This geographic concentration of environmental burden creates questions of environmental justice. Communities hosting AI infrastructure bear disproportionate environmental burdens while having limited access to AI’s economic benefits.</p>
</section><section id="sec-sustainable-ai-longterm-viability-5f29" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-longterm-viability-5f29">The Viability Crisis: Exponential Demand Meets Physical Limits</h3>
<p>Exponential growth in computational demands challenges the long-term sustainability of AI training and deployment. Over the past decade, AI systems have scaled at an unprecedented rate, with compute requirements increasing 350,000× from 2012 to 2019 <span class="citation" data-cites="schwartz2020green">(<a href="#ref-schwartz2020green" role="doc-biblioref">Schwartz et al. 2020</a>)</span><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. This trend continues as machine learning systems prioritize larger models with more parameters, larger training datasets, and higher computational complexity. Sustaining this trajectory poses sustainability challenges, as hardware efficiency gains fail to keep pace with rising AI workload demands.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<strong>AI Compute Explosion</strong>: This 350,000× increase represents a doubling time of approximately 3.4 months—far exceeding Moore’s Law’s 2-year doubling cycle. For comparison, this is equivalent to going from the computational power of a smartphone to that of the world’s largest supercomputer. The trend has only accelerated with large language models: GPT-4’s training is estimated to have required 25× more compute than GPT-3, while models like PaLM-2 and Claude used even more computational resources.</p></div><div id="fn6"><p><sup>6</sup>&nbsp;<strong>Moore’s Law Origins</strong>: Named after Intel co-founder Gordon Moore, who made this observation in a 1965 <em>Electronics</em> magazine article, Moore’s Law has driven the semiconductor industry for nearly 60 years. Moore initially predicted a doubling every year, later revised to two years. The law’s economic impact is staggering: it allowed the $4 trillion global electronics industry and made possible everything from smartphones to supercomputers. However, at 3nm process nodes, individual atoms become the limiting factor.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;<strong>Dennard Scaling</strong>: Rule observed by IBM’s Robert Dennard in 1974 that smaller transistors could run at the same power density by reducing voltage proportionally. Enabled 30 years of “free” performance gains until ~2005 when leakage current and voltage scaling limits ended the trend. Without Dennard scaling, modern CPUs would consume kilowatts instead of ~100W. Its end forced the shift to multi-core processors and specialized accelerators like GPUs for AI workloads.</p></div></div><p>Historically, computational efficiency improved with advances in semiconductor technology. Moore’s Law<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, which predicted that the number of transistors on a chip would double approximately every two years, led to continuous improvements in processing power and energy efficiency. However, Moore’s Law is now reaching core physical limits, making further transistor scaling difficult and costly. Dennard scaling<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, which once ensured that smaller transistors would operate at lower power levels, has also ended, leading to stagnation in energy efficiency improvements per transistor.</p>
<p>While AI models continue to scale in size and capability, the hardware running these models no longer improves at the same exponential rate. This growing divergence between computational demand and hardware efficiency creates an unsustainable trajectory where AI consumes ever-increasing amounts of energy.</p>
<p>The training of complex AI systems like large deep learning models demands high levels of computing power, resulting in significant energy consumption. Consider OpenAI’s language model GPT-3 as an example. This system operates through computational algorithms trained on large datasets<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, with training estimated to require 1,287 megawatt-hours (MWh) of electricity, equivalent to powering 130 U.S. homes for an entire year <span class="citation" data-cites="maslej2023artificial">(<a href="#ref-maslej2023artificial" role="doc-biblioref">Maslej et al. 2023</a>)</span><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. The human brain achieves superior learning capabilities on just 20 watts, highlighting a 10^6 efficiency gap that defines the sustainability challenge facing artificial intelligence.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<strong>Training Process</strong>: The computational process of optimizing model parameters using data. Comprehensive coverage in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>.</p></div><div id="fn9"><p><sup>9</sup>&nbsp;<strong>GPT-3 Energy Consumption</strong>: Training GPT-3 consumed approximately 1,287 MWh of electricity, equivalent to the annual energy consumption of 130 average American homes or the same amount of CO₂ as burning 500,000 pounds of coal. At average US electricity prices, this training run cost roughly $130,000 in electricity alone. GPT-4, with estimated 25× more compute, likely consumed over 30,000 MWh—enough to power a small city for a month. The energy per parameter ratio reveals hardware-software co-design inefficiencies: GPT-3’s 175 billion parameters required 7.4 kWh per billion parameters, while optimized architectures can achieve sub-1 kWh ratios through mixed precision and sparsity techniques.</p></div></div><p>This comparison shows how current AI architectures diverge from energy-efficient biological computation principles. The efficiency gap between artificial and biological intelligence appears throughout our analysis. In recent years, these generative AI models have gained increasing popularity, leading to more models being trained with growing parameter counts.</p>
<p>Research shows that increasing model size, dataset size, and compute used for training improves performance smoothly with no signs of saturation <span class="citation" data-cites="kaplan2020scaling">(<a href="#ref-kaplan2020scaling" role="doc-biblioref">Kaplan et al. 2020</a>)</span>, as evidenced in <a href="#fig-model-scaling" class="quarto-xref">Figure&nbsp;1</a> where test loss decreases as each of these three factors increases. Beyond training, AI-powered applications such as large-scale recommender systems and generative models require continuous inference at scale, consuming energy even after training completes. As AI adoption grows across industries from finance to healthcare to entertainment, the cumulative energy burden of AI workloads continues to rise, raising concerns about the environmental impact of widespread deployment.</p>
<div class="no-row-height column-margin column-container"></div><div id="fig-model-scaling" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-model-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/model_scaling.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Model Scaling Laws: Increasing model size, dataset size, and compute consistently reduces test loss, indicating that performance improvements continue to be achievable with greater resources and without evidence of saturation. These scaling laws suggest that larger models trained on more data with increased compute will likely yield further gains in performance, driving continued investment in these areas. Source: [@kaplan2020scaling]."><img src="images/png/model_scaling.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>Model Scaling Laws</strong>: Increasing model size, dataset size, and compute consistently reduces test loss, indicating that performance improvements continue to be achievable with greater resources and without evidence of saturation. These scaling laws suggest that larger models trained on more data with increased compute will likely yield further gains in performance, driving continued investment in these areas. Source: <span class="citation" data-cites="kaplan2020scaling">(<a href="#ref-kaplan2020scaling" role="doc-biblioref">Kaplan et al. 2020</a>)</span>.
</figcaption><div class="no-row-height column-margin column-container"><div id="ref-kaplan2020scaling" class="csl-entry" role="listitem">
Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. <span>“Scaling Laws for Neural Language Models.”</span> <em>ArXiv Preprint</em> abs/2001.08361 (January). <a href="http://arxiv.org/abs/2001.08361v1">http://arxiv.org/abs/2001.08361v1</a>.
</div></div></figure>
</div>
<p>Beyond electricity consumption, the sustainability challenges of AI extend to hardware resource demands and the energy efficiency limitations of current architectures. High-performance computing (HPC) clusters and AI accelerators rely on specialized hardware with different energy characteristics: Central Processing Units (CPUs) consume approximately 100 picojoules per multiply-accumulate operation (pJ/MAC), Graphics Processing Units (GPUs) achieve 10 pJ/MAC, while specialized Tensor Processing Units (TPUs) reach 1 pJ/MAC<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>, and specialized accelerators approach 0.1 pJ/MAC. These hardware platforms require rare earth metals and complex manufacturing processes with embodied carbon.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;<strong>Energy Metrics</strong>: pJ/MAC (picojoules per multiply-accumulate operation) measures energy efficiency of computational operations across different processor types.</p></div></div><p>The production of AI chips is energy-intensive, involving multiple fabrication steps that contribute significantly to Scope 3 emissions in the overall AI system lifecycle. As model sizes continue to grow, the demand for AI hardware increases, exacerbating the environmental impact of semiconductor production and disposal.</p>
</section><section id="sec-sustainable-ai-biological-intelligence-efficiency-7a9c" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-biological-intelligence-efficiency-7a9c">Learning from Biological Intelligence</h3>
<p>To understand the scale of AI’s energy challenge, it helps to compare current systems with the most efficient intelligence we know: the human brain. The brain performs complex reasoning, learning, and pattern recognition while consuming only about 20 watts of power. This remarkable efficiency provides valuable engineering insights for sustainable AI design. The brain’s computational efficiency reaches approximately 10⁻¹⁶ joules per operation (0.0001 pJ/operation, where pJ = 10⁻¹² joules), roughly 10,000× more efficient than the most advanced AI accelerators at 0.1 pJ/FLOP<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. In contrast, training a single large language model like GPT-3 consumes 1,287 MWh, representing approximately a 10⁶× energy efficiency gap per operation compared to biological neural computation between artificial and biological intelligence.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;<strong>FLOP Comparison</strong>: Floating-Point Operations Per second (FLOPS) measure computational throughput. Brain efficiency comparisons help contextualize AI hardware energy requirements.</p></div><div id="fn12"><p><sup>12</sup>&nbsp;<strong>Action Potentials</strong>: Electrical signals that neurons use to communicate, lasting ~1 millisecond and consuming ~10⁻¹² joules per spike. Unlike digital circuits that consume power continuously, neurons only consume energy when actively firing. This event-driven approach is why your brain uses 20W despite having 86 billion neurons—most are silent at any given moment. Modern neuromorphic chips like Intel’s Loihi mimic this spike-based communication to achieve 1000× energy savings.</p></div></div><p>The brain achieves this efficiency through several key principles that differ from current AI systems. Rather than processing all information continuously like digital computers, biological systems are selective and event-driven. They activate only small portions of the network at any time and consume energy only when actively processing information<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. These design principles suggest opportunities for creating more energy-efficient AI architectures.</p>
<p>The biological efficiency advantage extends beyond energy consumption to learning sample efficiency. Children acquire language capabilities with exposure to roughly 10^8 words by age 18, while large language models require training on 10^12+ tokens, a 10,000× difference in data efficiency. This disparity suggests that current AI architectures are misaligned with efficient learning principles demonstrated by biological systems.</p>
<p>These insights point toward promising research directions for sustainable AI. Neuromorphic computing<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> architectures that implement spiking neural networks<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> can achieve 100-1000× energy reductions for specific tasks by mimicking biological sparse activation patterns <span class="citation" data-cites="prakash2023tinyml">(<a href="#ref-prakash2023tinyml" role="doc-biblioref">Prakash, Stewart, et al. 2023</a>)</span>. Similarly, local learning algorithms and self-supervised learning approaches, inspired by biological development, offer pathways toward more sample-efficient and energy-conscious AI systems. Understanding these biological principles provides a roadmap for developing AI systems that approach biological energy efficiency while maintaining or improving performance.</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;<strong>Neuromorphic Computing</strong>: Hardware architecture inspired by biological neural networks, using analog circuits and event-driven computation instead of traditional digital logic. Introduced by Caltech’s Carver Mead in the 1980s, modern examples include Intel’s Loihi (130,000 artificial neurons), IBM’s TrueNorth (1 million neurons), and BrainChip’s Akida. These chips consume 1000× less power than GPUs for specific AI tasks by only processing information when inputs change, mimicking brain sparsity.</p></div><div id="fn14"><p><sup>14</sup>&nbsp;<strong>Spiking Neural Networks (SNNs)</strong>: Third-generation artificial neural networks that communicate through discrete spikes (like biological neurons) rather than continuous values. Process information asynchronously and temporally, making them naturally suited for event-driven data like audio and video. While more biologically plausible and energy-efficient, SNNs are harder to train than traditional deep networks, requiring specialized learning algorithms and currently achieving lower accuracy on standard benchmarks.</p></div><div id="ref-prakash2023tinyml" class="csl-entry" role="listitem">
Prakash, Shvetank, Matthew Stewart, Colby Banbury, Mark Mazumder, Pete Warden, Brian Plancher, and Vijay Janapa Reddi. 2023. <span>“Is TinyML Sustainable? Assessing the Environmental Impacts of Machine Learning on Microcontrollers.”</span> <em>ArXiv Preprint</em> abs/2301.11899 (January). <a href="http://arxiv.org/abs/2301.11899v3">http://arxiv.org/abs/2301.11899v3</a>.
</div></div><p>Building on these insights, the long-term sustainability of AI requires a shift in how machine learning systems are designed, optimized, and deployed. As compute demands outpace efficiency improvements, addressing AI’s environmental impact will require rethinking system architecture, energy-aware computing, and lifecycle management. Without intervention, the unchecked growth of AI models will continue to place unsustainable pressures on energy grids, data centers, and natural resources, underscoring the need for a more systematic approach to sustainable AI development.</p>
<p>The convergence of exponential computational demands with physical efficiency limits creates an unsustainable trajectory that threatens the long-term viability of AI development. Understanding these constraints provides the foundation for developing measurement frameworks and implementation strategies that can address the sustainability crisis systematically.</p>
<hr></section></section><section id="sec-sustainable-ai-measurement-assessment" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-measurement-assessment">Part II: Measurement and Assessment</h2>
<p>Having established the scope of AI’s environmental impact, we now turn to systematic measurement approaches. Understanding how to quantify and track environmental costs provides the foundation for making informed design decisions and implementing effective sustainability strategies.</p>
<p>Quantifying AI’s environmental impact requires measurement frameworks that capture energy consumption, carbon emissions, and lifecycle impacts across training and deployment phases. Effective sustainability strategies depend on accurate assessment of where environmental costs originate and how different design choices affect overall footprint.</p>
<section id="sec-sustainable-ai-carbon-footprint-analysis" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-carbon-footprint-analysis">Carbon Footprint Analysis</h3>
<p>Quantifying AI’s environmental impact requires systematic analysis of carbon footprint during system development and deployment. As AI systems continue to scale, their energy consumption and resource demands necessitate a proactive approach to sustainability. Developers and companies that build and deploy AI systems must consider not only performance and efficiency but also the environmental consequences of their design choices.</p>
<p>An ethical challenge lies in balancing technological progress with ecological responsibility. The pursuit of increasingly large models often prioritizes accuracy and capability over energy efficiency, leading to environmental costs. While optimizing for sustainability may introduce trade-offs, including increased development time or minor reductions in accuracy, it is an ethical imperative to integrate environmental considerations into AI system design. This requires shifting industry norms toward sustainable computing practices, such as energy-aware training techniques, low-power hardware designs, and carbon-conscious deployment strategies <span class="citation" data-cites="patterson2021carbon">(<a href="#ref-patterson2021carbon" role="doc-biblioref">Patterson et al. 2021</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>This ethical imperative extends beyond sustainability to encompass broader concerns related to transparency, fairness, and accountability. <a href="#fig-ethical-ai" class="quarto-xref">Figure&nbsp;2</a> illustrates the ethical challenges associated with AI development, linking different types of concerns, including inscrutable evidence, unfair outcomes, and traceability, to issues like opacity, bias, and automation bias. These concerns extend to sustainability, as the environmental trade-offs of AI development are often opaque and difficult to quantify. The lack of traceability in energy consumption and carbon emissions can lead to unjustified actions, where companies prioritize performance gains without fully understanding or disclosing the environmental costs.</p>
<div id="fig-ethical-ai" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ethical-ai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="95cf58c52b01572c60a2d924ae955b2ecac8241b.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Ethical AI Concerns: AI systems introduce ethical challenges across transparency, fairness, and sustainability; these concerns interrelate and stem from issues like opacity, bias, and a lack of traceability in resource consumption. addressing these challenges requires proactive design choices that prioritize accountability and minimize negative societal and environmental impacts. Source: COE."><img src="sustainable_ai_files/mediabag/95cf58c52b01572c60a2d924ae955b2ecac8241b.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ethical-ai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <strong>Ethical AI Concerns</strong>: AI systems introduce ethical challenges across transparency, fairness, and sustainability; these concerns interrelate and stem from issues like opacity, bias, and a lack of traceability in resource consumption. addressing these challenges requires proactive design choices that prioritize accountability and minimize negative societal and environmental impacts. Source: <a href="HTTPS://www.coe.int/en/web/bioethics/common-ethical-challenges-in-AI">COE</a>.
</figcaption></figure>
</div>
<p>Addressing these concerns demands greater transparency and accountability from AI companies. Large technology firms operate extensive cloud infrastructures that power modern AI applications, yet their environmental impact remains opaque. Organizations must measure, report, and reduce their carbon footprint throughout the AI lifecycle, from hardware manufacturing to model training and inference. Voluntary self-regulation provides an initial step, but policy interventions and industry-wide standards may be necessary to ensure long-term sustainability. Reported metrics such as energy consumption, carbon emissions, and efficiency benchmarks can hold organizations accountable.</p>
<p>Building on transparency requirements, ethical AI development requires open discourse on environmental trade-offs. Researchers must advocate for sustainability within their institutions and organizations, ensuring that environmental concerns are integrated into AI development priorities. The broader AI community has begun addressing these issues, as exemplified by the <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter advocating a pause on large-scale AI experiments</a>, which highlights concerns about unchecked expansion. Fostering a culture of transparency and ethical responsibility allows the AI industry to align technological advancement with ecological sustainability.</p>
<p>AI has the potential to reshape industries and societies, but its long-term viability depends on responsible development practices. Ethical AI development involves preventing harm to individuals and communities while ensuring that AI-driven innovation does not occur at the cost of environmental degradation. As stewards of these technologies, developers and organizations must integrate sustainability into AI’s future trajectory.</p>
</section><section id="sec-sustainable-ai-case-study-deepminds-energy-efficiency-3362" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-case-study-deepminds-energy-efficiency-3362">Case Study: DeepMind’s Energy Efficiency</h3>
<p>Google’s data centers form the backbone of services such as Search, Gmail, and YouTube, handling billions of queries daily. These data centers consume large amounts of electricity, especially for cooling infrastructure that ensures optimal server performance. Improving data center energy efficiency has long been a priority, but conventional engineering approaches faced diminishing returns due to cooling system complexity and highly dynamic environmental conditions. To address these challenges, Google collaborated with DeepMind to develop a machine learning optimization system that automates and enhances energy management at scale.</p>
<p>Building on more than a decade of efforts to optimize data center design, energy-efficient hardware, and renewable energy integration, DeepMind’s AI approach targeted one of the most energy-intensive aspects of data centers: cooling systems. Traditional cooling relies on manually set heuristics that account for server heat output, external weather conditions, and architectural constraints. These systems exhibit nonlinear interactions, so simple rule-based optimizations often fail to capture the full complexity of their operations. The result was suboptimal cooling efficiency, leading to unnecessary energy waste.</p>
<p>DeepMind’s team trained a neural network model using Google’s historical sensor data, which included real-time temperature readings, power consumption levels, cooling pump activity, and other operational parameters. The model learned the intricate relationships between these factors and could dynamically predict the most efficient cooling configurations. Unlike traditional approaches that relied on human engineers periodically adjusting system settings, the AI model continuously adapted in real time to changing environmental and workload conditions.</p>
<p>The results demonstrated significant efficiency gains. When deployed in live data center environments, DeepMind’s AI-driven cooling system reduced cooling energy consumption by 40%, leading to an overall 15% improvement in Power Usage Effectiveness (PUE)<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>, a metric for data center energy efficiency that measures the ratio of total energy consumption to the energy used purely for computing tasks <span class="citation" data-cites="barroso2019datacenter">(<a href="#ref-barroso2019datacenter" role="doc-biblioref">Barroso, Hölzle, and Ranganathan 2019</a>)</span>. These improvements were achieved without additional hardware modifications, demonstrating the potential of software-driven optimizations to reduce AI’s carbon footprint.</p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;<strong>Power Usage Effectiveness (PUE)</strong>: Industry standard metric calculated as Total Facility Power ÷ IT Equipment Power. Perfect efficiency = 1.0 (impossible), typical data centers = 1.6-2.0, Google’s best facilities achieve 1.08. Each 0.1 PUE improvement saves millions in electricity costs. Facebook’s Prineville data center achieves 1.09 PUE using outside air cooling. Legacy data centers often exceed 2.5 PUE.</p></div></div><p>Beyond a single data center, DeepMind’s AI model provided a generalizable framework adaptable to different facility designs and climate conditions, offering a scalable solution for optimizing power consumption in global data center networks. This case study exemplifies how AI can serve not just as a consumer of computational resources but as a tool for sustainability, driving efficiency improvements in the infrastructure that supports machine learning.</p>
<p>The integration of data-driven decision-making, real-time adaptation, and scalable AI models demonstrates intelligent resource management’s growing role in sustainable AI system design. This breakthrough exemplifies how machine learning can optimize the infrastructure that powers it, ensuring more energy-efficient large-scale AI deployments.</p>
<p>Building on these optimization insights, the carbon footprint of AI systems requires systematic analysis across multiple phases and scopes to capture the full environmental cost. Training typically accounts for 60-80% of total emissions due to parallel computation<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> requirements, while model serving contributes 15-25% of lifecycle emissions. Hardware manufacturing accounts for 5-15% but represents embodied carbon often overlooked in analyses. Understanding these proportions allows targeted optimization strategies that address the most significant sources of environmental impact.</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;<strong>Parallel Computation</strong>: Simultaneous execution of computations across multiple processors, enabling faster processing of large-scale problems. Detailed in <strong>?@sec-ai-training-distributed-systems-8fe8</strong>.</p></div></div><section id="sec-sustainable-ai-lifecycle-phases" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-lifecycle-phases">Three-Phase Lifecycle Assessment Framework</h4>
<p>Effective carbon footprint measurement requires systematic analysis across three distinct phases that collectively determine environmental impact:</p>
<p>The training phase (60-80% of emissions) represents the most carbon-intensive period involving parallel computation for mathematical optimization processes<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>. A single large language model training run can consume 1,287 MWh of electricity, equivalent to powering 130 households for a year. Geographic placement affects emissions: training in Quebec (hydro-powered, 0.01 kg CO₂/kWh) versus West Virginia (coal-powered, 0.75 kg CO₂/kWh) creates a 75× difference in carbon intensity.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;<strong>Optimization Process</strong>: Mathematical procedures for finding optimal model parameters. Gradient descent and related techniques covered in <strong>?@sec-ai-training-optimization-algorithms-506e</strong>.</p></div></div><p>The inference phase (15-25% of emissions) generates ongoing computational costs for model serving and prediction generation. While individual inferences require less computation than training, the cumulative impact scales with deployment breadth and usage frequency. Models serving millions of users generate ongoing emissions that can exceed training costs over extended deployment periods.</p>
<p>The manufacturing phase (5-15% of emissions) contributes embodied carbon from hardware production, including semiconductor fabrication, rare earth mining, and supply chain logistics. Often overlooked but represents irreducible baseline emissions independent of operational efficiency.</p>
</section><section id="sec-sustainable-ai-optimization-opportunities" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-optimization-opportunities">Geographic and Temporal Optimization Opportunities</h4>
<p>Carbon intensity varies across geographic locations and time periods, creating optimization opportunities. Temporal scheduling can reduce emissions by 50-80% by aligning compute workloads with renewable energy availability, such as peak solar generation during daylight hours <span class="citation" data-cites="Patterson2022carbonaware">(<a href="#ref-Patterson2022carbonaware" role="doc-biblioref">Patterson, Gonzalez, Le, et al. 2022</a>)</span>. Carbon-aware scheduling systems can automatically shift non-urgent training jobs to regions and times with lower carbon intensity.</p>
<div class="no-row-height column-margin column-container"></div><p>These geographic and temporal considerations highlight the complexity of quantifying AI’s carbon impact. The assessment depends on multiple factors, including the size of the model, the duration of training, the hardware used, and the energy sources powering data centers. Large-scale AI models, such as GPT-3, require thousands of megawatt-hours (MWh) of electricity, equivalent to the energy consumption of entire communities. The energy required for inference, the phase during which trained models produce outputs, is also large for widely deployed AI services such as real-time translation, image generation, and personalized recommendations. Unlike traditional software, which has a relatively static energy footprint, AI models consume energy continuously, leading to an ongoing sustainability challenge.</p>
<p>Beyond direct energy use, the carbon footprint of AI must also account for indirect emissions from hardware production and supply chains. Manufacturing AI accelerators such as GPUs, TPUs, and custom chips involves energy-intensive fabrication processes that rely on rare earth metals and complex supply chains. The full life cycle emissions of AI systems, which encompass data centers, hardware manufacturing, and global AI deployments, must be considered to develop more sustainable AI practices.</p>
<p>Understanding AI’s carbon footprint requires breaking down where emissions come from, how they are measured, and what strategies can be employed to mitigate them. This analysis encompasses:</p>
<ul>
<li>Carbon emissions and energy consumption trends in AI, which quantify AI’s energy demand and provide real-world comparisons.</li>
<li>Scopes of carbon emissions (Scope 1, 2, and 3), differentiating between direct, indirect, and supply chain-related emissions.</li>
<li>The energy cost of training vs.&nbsp;inference, analyzing how different phases of AI impact sustainability.</li>
</ul>
<p>Analyzing these components enables better assessment of AI systems’ true environmental impact and identifies opportunities to reduce their footprint through more efficient design, energy-conscious deployment, and sustainable infrastructure choices.</p>
<p>Measuring carbon footprint during development requires integrating tracking tools into ML workflows, as shown in <a href="#lst-carbon-tracking" class="quarto-xref">Listing&nbsp;1</a>.</p>
<div id="lst-carbon-tracking" class="listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-carbon-tracking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;1: <strong>Carbon Footprint Tracking</strong>: Example implementation using CodeCarbon library to measure emissions during model training, enabling data-driven sustainability decisions.
</figcaption><div aria-describedby="lst-carbon-tracking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> codecarbon <span class="im">import</span> EmissionsTracker</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize carbon tracking</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>tracker <span class="op">=</span> EmissionsTracker()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>tracker.start()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Your model training code</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> torch.nn.Linear(<span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training step</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> model(data).mean()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Get emissions report</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>emissions <span class="op">=</span> tracker.stop()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training emissions: </span><span class="sc">{</span>emissions<span class="sc">:.4f}</span><span class="ss"> kg CO2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<p>This integration allows engineers to make informed decisions about model complexity versus environmental impact during development.</p>
</section></section><section id="sec-sustainable-ai-energy-consumption-patterns" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-energy-consumption-patterns">Energy Consumption Patterns and Infrastructure Impact</h3>
<p>AI systems represent among the most energy-intensive computational workloads, involving dense operations<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> with consumption patterns that extend across training, inference, data storage, and communication infrastructure. Understanding these patterns reveals where optimization efforts can achieve environmental impact reduction. Energy consumption scales non-linearly with model complexity, creating opportunities for efficiency improvements through targeted architectural and operational optimizations.</p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;<strong>Dense Operations</strong>: Computational patterns requiring extensive mathematical operations. Specific neural network operations covered in <strong>?@sec-ai-training-neural-network-computation-73f5</strong>.</p></div></div><section id="sec-sustainable-ai-datacenter-energy-dynamics" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-datacenter-energy-dynamics">Data Center Energy Dynamics and AI Workloads</h4>
<p>Data centers serve as the primary energy consumers for AI systems, with power demands that reveal both the scale of the challenge and specific optimization opportunities.</p>
<p>At the heart of AI’s energy demands, data centers consume large amounts of electricity to power compute servers, storage, and cooling systems. The energy efficiency of these facilities varies: Power Usage Effectiveness (PUE) ranges from 1.1 in Google’s most efficient facilities to 2.5 in typical enterprise data centers, effectively doubling energy consumption through infrastructure overhead. Geographic location impacts carbon intensity: training the same model in Quebec (hydro-powered) versus West Virginia (coal-powered) differs by 10× in carbon emissions per kilowatt-hour. Without access to renewable energy, these facilities rely heavily on nonrenewable sources such as coal and natural gas, contributing to global carbon emissions. Current estimates suggest that data centers produce up to 2% of total global CO₂ emissions, a figure that approaches the airline industry’s footprint <span class="citation" data-cites="liu2020energy">(<a href="#ref-liu2020energy" role="doc-biblioref">Liu et al. 2020</a>)</span><a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>. The energy burden of AI is expected to grow exponentially due to three factors: increasing data center capacity, rising AI training workloads, and increasing inference demands <span class="citation" data-cites="patterson2022carbon">(<a href="#ref-patterson2022carbon" role="doc-biblioref">Patterson, Gonzalez, Holzle, et al. 2022</a>)</span>. Without intervention, these trends risk making AI’s environmental footprint unsustainably large <span class="citation" data-cites="thompson2023compute">(<a href="#ref-thompson2023compute" role="doc-biblioref">Thompson, Spanuth, and Matthews 2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-liu2020energy" class="csl-entry" role="listitem">
Liu, Yanan, Xiaoxia Wei, Jinyu Xiao, Zhijie Liu, Yang Xu, and Yun Tian. 2020. <span>“Energy Consumption and Emission Mitigation Prediction Based on Data Center Traffic and PUE for Global Data Centers.”</span> <em>Global Energy Interconnection</em> 3 (3): 272–82. <a href="https://doi.org/10.1016/j.gloei.2020.07.008">https://doi.org/10.1016/j.gloei.2020.07.008</a>.
</div><div id="fn19"><p><sup>19</sup>&nbsp;<strong>Data Center Climate Impact</strong>: Data centers consume approximately 1% of global electricity and produce 0.3% of global carbon emissions directly. However, when including embodied carbon from hardware manufacturing, the figure rises to 2%. For perspective, this equals the annual emissions of Argentina (1.8% of global total) and exceeds the aviation industry’s 2.1%. The largest hyperscale data centers consume over 100 MW continuously—equivalent to powering 80,000 homes.</p></div><div id="ref-thompson2023compute" class="csl-entry" role="listitem">
Thompson, Neil, Tobias Spanuth, and Hyrum Anderson Matthews. 2023. <span>“The Computational Limits of Deep Learning and the Future of AI.”</span> <em>Communications of the ACM</em> 66 (3): 48–57. <a href="https://doi.org/10.1145/3580309">https://doi.org/10.1145/3580309</a>.
</div></div></section><section id="sec-sustainable-ai-energy-demands-data-centers-ec7b" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-energy-demands-data-centers-ec7b">Energy Demands in Data Centers</h4>
<p>AI workloads are among the most compute-intensive operations in modern data centers. Companies such as Meta operate hyperscale data centers spanning multiple football fields in size, housing hundreds of thousands of AI-optimized servers<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a>. The training of large language models (LLMs) such as GPT-4 required over 25,000 Nvidia A100 GPUs running continuously for 90 to 100 days <span class="citation" data-cites="semianalysisGPT4">(<a href="#ref-semianalysisGPT4" role="doc-biblioref">Choi and Yoon 2024</a>)</span>, consuming thousands of megawatt-hours (MWh) of electricity. These facilities rely on high-performance AI accelerators like NVIDIA DGX H100 units, each of which can draw up to 10.2 kW at peak power <span class="citation" data-cites="nvidiadgxH100">(<a href="#ref-nvidiadgxH100" role="doc-biblioref">Choquette 2023</a>)</span>. The energy efficiency gap becomes clear when comparing hardware generations: H100 GPUs achieve approximately 4× better performance per watt than A100s, while mixed-precision training reduces energy consumption by 30-50% through reduced computational precision with minimal accuracy impact <span class="citation" data-cites="gholami2021survey">(<a href="#ref-gholami2021survey" role="doc-biblioref">Gholami et al. 2021</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn20"><p><sup>20</sup>&nbsp;<strong>Hyperscale Data Center Scale</strong>: Meta’s Prineville data center spans 2.5 million square feet (57 football fields) and houses 150,000+ servers. Microsoft’s largest Azure data center in Iowa covers 700 acres with power capacity of 300 MW. Google operates 21 hyperscale facilities globally, consuming 12.2 TWh annually—more electricity than entire countries like Lithuania or Sri Lanka.</p></div></div><p>This dramatic energy consumption reflects AI’s rapid adoption across industries. As shown in <a href="#fig-ai-data-center-demand" class="quarto-xref">Figure&nbsp;3</a>, the energy demand of AI workloads is projected to increase total data center energy use, especially after 2024. While efficiency gains have offset rising power needs, these gains are decelerating, amplifying AI’s environmental impact.</p>
<div class="cell page-columns page-full" data-layout-align="center">
<div class="cell-output-display page-columns page-full">
<div id="fig-ai-data-center-demand" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-ai-data-center-demand-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="sustainable_ai_files/figure-html/fig-ai-data-center-demand-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Projected Demand: By 2030, AI workloads will significantly increase power demand in data centers, outpacing efficiency gains seen previously. This emphasizes the growing environmental impact of AI systems. Source: [@masanet2020energy], Cisco, IEA, Goldman Sachs Global Investment Research."><img src="sustainable_ai_files/figure-html/fig-ai-data-center-demand-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-data-center-demand-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>Projected Demand</strong>: By 2030, AI workloads will significantly increase power demand in data centers, outpacing efficiency gains seen previously. This emphasizes the growing environmental impact of AI systems. Source: <span class="citation" data-cites="masanet2020energy">(<a href="#ref-masanet2020energy" role="doc-biblioref">Masanet et al. 2020b</a>)</span>, Cisco, IEA, Goldman Sachs Global Investment Research.
</figcaption><div class="no-row-height column-margin column-container"><div id="ref-masanet2020energy" class="csl-entry" role="listitem">
———. 2020b. <span>“Recalibrating Global Data Center Energy-Use Estimates.”</span> <em>Science</em> 367 (6481): 984–86. <a href="https://doi.org/10.1126/science.aba3758">https://doi.org/10.1126/science.aba3758</a>.
</div></div></figure>
</div>
</div>
</div>
<p>Beyond computational demands, cooling represents another major factor in AI’s energy footprint. Large-scale AI training and inference workloads generate massive amounts of heat, necessitating advanced cooling solutions to prevent hardware failures. Estimates indicate that 30-40% of a data center’s total electricity usage goes into cooling alone <span class="citation" data-cites="dayarathna2015data">(<a href="#ref-dayarathna2015data" role="doc-biblioref">Dayarathna, Wen, and Fan 2016</a>)</span>. Companies have begun adopting alternative cooling methods to reduce this demand. For example, Microsoft’s data center in Ireland uses a nearby fjord, using over half a million gallons of seawater daily to dissipate heat. However, as AI models scale in complexity, cooling demands continue to grow, making sustainable AI infrastructure design a pressing challenge.</p>
<div class="no-row-height column-margin column-container"></div></section></section><section id="sec-sustainable-ai-distributed-systems-energy-9f3a" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-distributed-systems-energy-9f3a">Distributed Systems Energy Optimization</h3>
<p>Large-scale AI training inherently requires distributed systems coordination, creating additional energy overhead that compounds computational demands. Distributed training<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a> introduces network communication costs that can account for 20-40% of total energy consumption in large clusters. Distributed training across thousands of GPUs requires constant synchronization of computational updates and model parameters<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a>, generating data movement between nodes. This communication overhead scales poorly: doubling cluster size can increase networking energy consumption by 4× due to all-to-all communication patterns in gradient aggregation.</p>
<div class="no-row-height column-margin column-container"><div id="fn21"><p><sup>21</sup>&nbsp;<strong>Training Paradigms</strong>: Current approaches to model optimization requiring coordinated computation across distributed systems. Detailed in <strong>?@sec-ai-training-distributed-systems-8fe8</strong>.</p></div><div id="fn22"><p><sup>22</sup>&nbsp;<strong>Distributed Training</strong>: Training models across multiple computing nodes requiring coordination and communication. Detailed in <strong>?@sec-ai-training-distributed-systems-8fe8</strong>.</p></div></div><p>Addressing these communication overheads, cluster-wide energy optimization requires coordinated resource management that extends beyond individual server efficiency. Dynamic workload placement can achieve 15-25% energy savings by consolidating training jobs onto fewer nodes during low-demand periods, allowing unused hardware to enter low-power states. Similarly, intelligent scheduling that coordinates training across multiple data centers can leverage time-zone differences and regional renewable energy availability, reducing carbon intensity by 30-50% through temporal load balancing.</p>
<p>Building on these optimization strategies, infrastructure sharing presents efficiency opportunities often overlooked in sustainability analyses. Multi-tenant training environments, where multiple model training jobs share the same cluster, can improve GPU utilization from typical 40-60% to 80-90%, effectively halving energy consumption per model trained. Resource sharing also enables batch processing optimizations where multiple smaller training jobs are combined to better utilize available compute capacity, reducing the energy overhead of maintaining idle infrastructure.</p>
<section id="sec-sustainable-ai-ai-vs-industries-f2ba" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-ai-vs-industries-f2ba">AI vs.&nbsp;Other Industries</h4>
<p>The environmental impact of AI workloads has emerged as a concern, with carbon emissions approaching levels comparable to established carbon-intensive sectors. Research demonstrates that training a single large AI model generates carbon emissions equivalent to multiple passenger vehicles over their complete lifecycle <span class="citation" data-cites="strubell2019energy">(<a href="#ref-strubell2019energy" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019b</a>)</span>. To contextualize AI’s environmental footprint, <a href="#fig-carbonfootprint" class="quarto-xref">Figure&nbsp;4</a> compares the carbon emissions of large-scale machine learning tasks to transcontinental flights, illustrating the energy demands of training and inference workloads. It shows a comparison from lowest to highest carbon footprints, starting with a roundtrip flight between NY and SF, human life average per year, American life average per year, US car including fuel over a lifetime, and a Transformer model with neural architecture search<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a>, which has the highest footprint. These comparisons underscore the need for more sustainable AI practices to mitigate the industry’s carbon impact.</p>
<div class="no-row-height column-margin column-container"><div id="fn23"><p><sup>23</sup>&nbsp;<strong>Transformer + NAS Environmental Impact</strong>: This 626,000 lbs CO₂ figure represents training one Transformer model while searching for optimal architecture. Includes evaluating 12,800 different model configurations over multiple days. For comparison, this equals the carbon footprint of 312 economy round-trip flights from NYC to London, or the annual emissions of 140 average Americans. Modern efficient NAS techniques have reduced this cost by 1000×.</p></div></div><div id="fig-carbonfootprint" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-carbonfootprint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="fde4b4dd67e33cd890d52e867bb29d56d2848882.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Carbon Footprint Benchmarks: Training large AI models generates carbon emissions, comparable to everyday activities and long-distance travel, emphasizing the environmental impact of increasingly complex machine learning workloads. The comparison to roundtrip flights, average human lifespans, and vehicle lifetimes contextualizes the energy demands of training a transformer model with neural architecture search as high. Source: @strubell2019energy."><img src="sustainable_ai_files/mediabag/fde4b4dd67e33cd890d52e867bb29d56d2848882.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-carbonfootprint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>Carbon Footprint Benchmarks</strong>: Training large AI models generates carbon emissions, comparable to everyday activities and long-distance travel, emphasizing the environmental impact of increasingly complex machine learning workloads. The comparison to roundtrip flights, average human lifespans, and vehicle lifetimes contextualizes the energy demands of training a transformer model with neural architecture search as high. Source: <span class="citation" data-cites="strubell2019energy">Strubell, Ganesh, and McCallum (<a href="#ref-strubell2019energy" role="doc-biblioref">2019b</a>)</span>.
</figcaption><div class="no-row-height column-margin column-container"></div></figure>
</div>
<p>The training phase of large natural language processing models produces carbon dioxide emissions comparable to hundreds of transcontinental flights. When examining the broader industry impact, AI’s aggregate computational carbon footprint is approaching parity with the commercial aviation sector. As AI applications scale to serve billions of users globally, the cumulative emissions from continuous inference operations may ultimately exceed those generated during training.</p>
<p><a href="#fig-meta-analysis" class="quarto-xref">Figure&nbsp;5</a> provides a detailed analysis of carbon emissions across various large-scale machine learning tasks at Meta, illustrating the environmental impact of different AI applications and architectures. This quantitative assessment of AI’s carbon footprint underscores the pressing need to develop more sustainable approaches to machine learning development and deployment. Understanding these environmental costs is important for implementing effective mitigation strategies and advancing the field responsibly.</p>
<div id="fig-meta-analysis" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-meta-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="2213ded9c5bcc9b0a55264491366690dada272bd.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Carbon footprint of large-scale ML tasks. Source: [@wu2022sustainable]."><img src="sustainable_ai_files/mediabag/2213ded9c5bcc9b0a55264491366690dada272bd.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-meta-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Carbon footprint of large-scale ML tasks. Source: <span class="citation" data-cites="wu2022sustainable">(<a href="#ref-wu2022sustainable" role="doc-biblioref">Wu et al. 2022</a>)</span>.
</figcaption><div class="no-row-height column-margin column-container"></div></figure>
</div>
</section></section><section id="sec-sustainable-ai-updated-analysis-95ef" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-updated-analysis-95ef">Updated Analysis</h3>
<p>AI’s impact extends beyond energy consumption during operation. The full lifecycle emissions of AI include hardware manufacturing, supply chain emissions, and end-of-life disposal, making AI a significant contributor to environmental degradation. AI models require electricity to train and infer, and they also depend on a complex infrastructure of semiconductor fabrication, rare earth metal mining, and electronic waste disposal. The next section breaks down AI’s carbon emissions into Scope 1 (direct emissions), Scope 2 (indirect emissions from electricity), and Scope 3 (supply chain and lifecycle emissions) to provide a more detailed view of its environmental impact.</p>
</section><section id="sec-sustainable-ai-carbon-emission-scopes-lifecycle" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-carbon-emission-scopes-lifecycle">Carbon Emission Scopes and Lifecycle Analysis</h3>
<p>Comprehensive carbon footprint assessment requires systematic analysis across the three standard emission scopes that capture direct operations, purchased energy, and supply chain impacts. With AI projected to grow at 37.3% annually through 2030, operational computing energy needs could multiply 1,000-fold by 2030. This exponential scaling necessitates understanding total lifecycle costs across all emission scopes to identify the most impactful sustainability interventions.</p>
<p>Scope 1 emissions (5-15% of total) originate from on-site power generation including backup diesel generators, facility cooling systems, and owned power plants. While many AI data centers primarily use grid electricity, those with fossil-fuel backup systems or owned generation contribute directly to emissions.</p>
<p>Scope 2 emissions (60-75% of total) represent indirect emissions from electricity purchased to power AI infrastructure. This dominant operational emission category varies dramatically by geographic location and grid energy mix. Training the same model in Quebec (hydro-powered) versus West Virginia (coal-powered) creates a 75× difference in carbon intensity.</p>
<p>Scope 3 emissions (15-25% of total) constitute the most complex category, encompassing hardware manufacturing, transportation, and disposal. Semiconductor manufacturing<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a> is carbon-intensive: producing a single high-performance AI accelerator generates emissions equivalent to several years of operational energy use. Often overlooked but represents irreducible baseline emissions independent of operational efficiency.</p>
<div class="no-row-height column-margin column-container"><div id="fn24"><p><sup>24</sup>&nbsp;<strong>EUV Lithography</strong>: Extreme ultraviolet light (13.5nm wavelength) used to print features smaller than 7nm on silicon chips. Each EUV machine costs $200+ million, weighs 180 tons, requires 1 MW of continuous power (enough for 800 homes), and uses 30,000 liters of ultrapure water daily. ASML is the sole global supplier. EUV enables modern AI chips but consumes 10× more energy than older deep-UV lithography systems.</p></div><div id="fn25"><p><sup>25</sup>&nbsp;<strong>Edge Computing for AI</strong>: Processing data near its source rather than in distant cloud data centers. Reduces latency from 100-200ms (cloud) to 1-10ms (edge) for applications like autonomous vehicles. However, edge AI chips consume 5-50W continuously across billions of devices versus occasional cloud bursts. Tesla’s FSD computer consumes 72W while driving; if all 1.4 billion cars had AI, collective power would equal 50 large power plants.</p></div></div><p>Beyond manufacturing, Scope 3 emissions include the downstream impact of AI once deployed. AI services such as search engines, social media platforms, and cloud-based recommendation systems operate at enormous scale, requiring continuous inference across millions or even billions of user interactions. The cumulative electricity demand of inference workloads can ultimately surpass the energy used for training, further amplifying AI’s carbon impact. End-user devices, including smartphones, IoT devices, and edge computing<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a> platforms, also contribute to Scope 3 emissions, as their AI-allowed functionality depends on sustained computation. Companies such as Meta and Google report that Scope 3 emissions from AI-powered services make up the largest share of their total environmental footprint, due to the sheer scale at which AI operates.</p>
<p>These massive facilities provide the infrastructure for training complex neural networks on vast datasets. For instance, based on <a href="https://www.semianalysis.com/p/gpt-4-architecture-infrastructure">leaked information</a>, OpenAI’s language model GPT-4 was trained on Azure data centers packing over 25,000 Nvidia A100 GPUs, used continuously for over 90 to 100 days.</p>
<p>The GHG Protocol framework <span class="citation" data-cites="ghgprotocol2023">(<a href="#ref-ghgprotocol2023" role="doc-biblioref">Institute and Sustainable Development 2023</a>)</span>, illustrated in <a href="#fig-ghg-protocol" class="quarto-xref">Figure&nbsp;6</a>, provides a structured way to visualize the sources of AI-related carbon emissions. Scope 1 emissions arise from direct company operations, such as data center power generation and company-owned infrastructure. Scope 2 covers electricity purchased from the grid, the primary source of emissions for cloud computing workloads. Scope 3 extends beyond an organization’s direct control, including emissions from hardware manufacturing, transportation, and even the end-user energy consumption of AI-powered services. Understanding this breakdown allows for more targeted sustainability strategies, ensuring that efforts to reduce AI’s environmental impact are not solely focused on energy efficiency but also address the broader supply chain and lifecycle emissions that contribute significantly to the industry’s carbon footprint.</p>
<div class="no-row-height column-margin column-container"><div id="ref-ghgprotocol2023" class="csl-entry" role="listitem">
Institute, World Resources, and World Business Council for Sustainable Development. 2023. <span>“Greenhouse Gas Protocol: Corporate Standard.”</span> <a href="https://ghgprotocol.org/corporate-standard">https://ghgprotocol.org/corporate-standard</a>.
</div></div><div id="fig-ghg-protocol" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ghg-protocol-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/ghg_protocol.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: GHG Emission Scopes: Organizations categorize carbon emissions into scope 1 (direct), scope 2 (purchased energy), and scope 3 (value chain) to comprehensively assess their environmental impact and identify targeted reduction strategies for AI systems. Source: Ucircularise."><img src="images/png/ghg_protocol.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ghg-protocol-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>GHG Emission Scopes</strong>: Organizations categorize carbon emissions into scope 1 (direct), scope 2 (purchased energy), and scope 3 (value chain) to comprehensively assess their environmental impact and identify targeted reduction strategies for AI systems. Source: Ucircularise.
</figcaption></figure>
</div>
</section><section id="sec-sustainable-ai-training-inference-lifecycle-analysis" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-training-inference-lifecycle-analysis">Training vs.&nbsp;Inference: Lifecycle Energy Analysis</h3>
<p>Accurate environmental impact assessment requires understanding the distinct energy consumption patterns of training and inference phases. Training represents intensive, one-time computational investments that create reusable model capabilities. Inference involves continuous energy consumption that scales with deployment breadth and usage frequency. For widely deployed AI services, cumulative inference costs often exceed training expenses over extended operational periods.</p>
<p>This lifecycle perspective reveals optimization opportunities across different phases. Training optimizations focus on computational efficiency and hardware utilization, while inference optimizations emphasize latency, throughput, and edge deployment strategies. Understanding these trade-offs enables targeted sustainability interventions that address the dominant energy consumers for specific AI applications.</p>
<section id="sec-sustainable-ai-training-energy-demands-a66b" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-training-energy-demands-a66b">Training Energy Demands</h4>
<p>Training state-of-the-art AI models demands enormous computational resources, requiring extensive computational infrastructure with hundreds of thousands of cores and specialized AI accelerators operating continuously for months within cloud-based data centers. For example, models like GPT-4 were trained using over 25,000 Nvidia A100 GPUs operating continuously for approximately three months within cloud-based data centers <span class="citation" data-cites="semianalysisGPT4">(<a href="#ref-semianalysisGPT4" role="doc-biblioref">Choi and Yoon 2024</a>)</span>. OpenAI’s dedicated supercomputer infrastructure, built specifically for large-scale AI training, contains 285,000 CPU cores, 10,000 GPUs, and network bandwidth exceeding 400 gigabits per second per server, illustrating the vast scale and associated energy consumption of AI training infrastructures <span class="citation" data-cites="patterson2021carbon">(<a href="#ref-patterson2021carbon" role="doc-biblioref">Patterson et al. 2021</a>)</span>. Advanced computational architectures and hardware optimization strategies for training systems require specialized knowledge of AI acceleration techniques, while algorithmic approaches to training efficiency involve complex optimization methods.</p>
<div class="no-row-height column-margin column-container"><div id="ref-semianalysisGPT4" class="csl-entry" role="listitem">
Choi, Sebin, and Sungmin Yoon. 2024. <span>“GPT-Based Data-Driven Urban Building Energy Modeling (GPT-UBEM): Concept, Methodology, and Case Studies.”</span> <em>Energy and Buildings</em> 325 (December): 115042. <a href="https://doi.org/10.1016/j.enbuild.2024.115042">https://doi.org/10.1016/j.enbuild.2024.115042</a>.
</div><div id="ref-nvidiadgxH100" class="csl-entry" role="listitem">
Choquette, Jack. 2023. <span>“NVIDIA Hopper H100 GPU: Scaling Performance.”</span> <em>IEEE Micro</em> 43 (3): 9–17. <a href="https://doi.org/10.1109/mm.2023.3256796">https://doi.org/10.1109/mm.2023.3256796</a>.
</div><div id="ref-dayarathna2015data" class="csl-entry" role="listitem">
Dayarathna, Miyuru, Yonggang Wen, and Rui Fan. 2016. <span>“Data Center Energy Consumption Modeling: A Survey.”</span> <em>IEEE Communications Surveys &amp;Amp; Tutorials</em> 18 (1): 732–94. <a href="https://doi.org/10.1109/comst.2015.2481183">https://doi.org/10.1109/comst.2015.2481183</a>.
</div></div><p>High-performance AI accelerators, such as NVIDIA DGX H100 systems, are specifically designed for these training workloads. Each DGX H100 unit can draw up to 10.2 kW at peak load, with clusters often consisting of thousands of nodes running continuously <span class="citation" data-cites="nvidiadgxH100">(<a href="#ref-nvidiadgxH100" role="doc-biblioref">Choquette 2023</a>)</span>. The intensive computational loads result in heat dissipation, necessitating cooling infrastructure. Cooling alone can account for 30-40% of total data center energy consumption <span class="citation" data-cites="dayarathna2015data">(<a href="#ref-dayarathna2015data" role="doc-biblioref">Dayarathna, Wen, and Fan 2016</a>)</span>.</p>
<p>These energy costs occur once per trained model. The primary sustainability challenge emerges during model deployment, where inference workloads continuously serve millions or billions of users.</p>
</section><section id="sec-sustainable-ai-inference-energy-costs-bc1e" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-inference-energy-costs-bc1e">Inference Energy Costs</h4>
<p>Inference workloads execute every time an AI model responds to queries, classifies images, or makes predictions. Unlike training, inference scales dynamically and continuously across applications such as search engines, recommendation systems, and generative AI models. Although each individual inference request consumes far less energy compared to training, the cumulative energy usage from billions of daily AI interactions quickly surpasses training-related consumption <span class="citation" data-cites="patterson2021carbon">(<a href="#ref-patterson2021carbon" role="doc-biblioref">Patterson et al. 2021</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-patterson2021carbon" class="csl-entry" role="listitem">
Patterson, David, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021. <span>“Carbon Emissions and Large Neural Network Training.”</span> <em>arXiv Preprint arXiv:2104.10350</em>, April. <a href="http://arxiv.org/abs/2104.10350v3">http://arxiv.org/abs/2104.10350v3</a>.
</div></div><p>For example, AI-driven search engines handle billions of queries per day, recommendation systems provide personalized content continuously, and generative AI services such as ChatGPT or DALL-E have substantial per-query computational costs. The inference energy footprint is high in transformer-based models due to high memory and computational bandwidth requirements.</p>
<p>As shown in <a href="#fig-mckinsey_analysis" class="quarto-xref">Figure&nbsp;7</a>, the market for inference workloads in data centers is projected to grow significantly from $4-5 billion in 2017 to $9-10 billion by 2025, more than doubling in size. Similarly, edge inference workloads are expected to increase from less than $0.1 billion to $4-4.5 billion in the same period. This growth substantially outpaces the expansion of training workloads in both environments, highlighting how the economic footprint of inference is rapidly outgrowing that of training operations.</p>
<div id="fig-mckinsey_analysis" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-mckinsey_analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="eec8bb017dd14eb661c59a133ab7850cb03751b7.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: Inference-Training Market Growth: The rapidly expanding market for inference workloads—projected to more than double from 2017 to 2025—outpaces growth in training, reflecting the increasing demand for deploying AI models at scale. This disparity emphasizes that the operational energy footprint of running AI applications is becoming a dominant cost factor compared to model development itself. Source: Umckinsey."><img src="sustainable_ai_files/mediabag/eec8bb017dd14eb661c59a133ab7850cb03751b7.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mckinsey_analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: <strong>Inference-Training Market Growth</strong>: The rapidly expanding market for inference workloads—projected to more than double from 2017 to 2025—outpaces growth in training, reflecting the increasing demand for deploying AI models at scale. This disparity emphasizes that the operational energy footprint of running AI applications is becoming a dominant cost factor compared to model development itself. Source: Umckinsey.
</figcaption></figure>
</div>
<p>Unlike traditional software applications with fixed energy footprints, inference workloads dynamically scale with user demand. AI services like Alexa, Siri, and Google Assistant rely on continuous cloud-based inference, processing millions of voice queries per minute, necessitating uninterrupted operation of energy-intensive data center infrastructure.</p>
</section><section id="sec-sustainable-ai-edge-ai-impact-5edc" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-edge-ai-impact-5edc">Edge AI Impact</h4>
<p>Inference does not always happen in large data centers—edge AI is emerging as a viable alternative to reduce cloud dependency. Instead of routing every AI request to centralized cloud servers, some AI models can be deployed directly on user devices or at edge computing nodes. This approach reduces data transmission energy costs and lowers the dependency on high-power cloud inference.</p>
<p>However, running inference at the edge does not eliminate energy concerns—especially when AI is deployed at scale. Autonomous vehicles, for instance, require millisecond-latency AI inference, meaning cloud processing is impractical. Instead, vehicles are now being equipped with onboard AI accelerators that function as “data centers on wheels <span class="citation" data-cites="sudhakar2023data">(<a href="#ref-sudhakar2023data" role="doc-biblioref">Sudhakar, Sze, and Karaman 2023</a>)</span>. These embedded computing systems process real-time sensor data equivalent to small data centers, consuming significant power even without relying on cloud inference.</p>
<div class="no-row-height column-margin column-container"><div id="ref-sudhakar2023data" class="csl-entry" role="listitem">
Sudhakar, Soumya, Vivienne Sze, and Sertac Karaman. 2023. <span>“Data Centers on Wheels: Emissions from Computing Onboard Autonomous Vehicles.”</span> <em>IEEE Micro</em> 43 (1): 29–39. <a href="https://doi.org/10.1109/mm.2022.3219803">https://doi.org/10.1109/mm.2022.3219803</a>.
</div></div><p>Similarly, consumer devices such as smartphones, wearables, and IoT sensors individually consume relatively little power but collectively contribute significantly to global energy use due to their sheer numbers. Therefore, the efficiency benefits of edge computing must be balanced against the extensive scale of device deployment.</p>
</section></section><section id="sec-sustainable-ai-comprehensive-environmental-assessment" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-comprehensive-environmental-assessment">Comprehensive Environmental Impact Assessment: Beyond Carbon</h3>
<p>Carbon footprint analysis provides a crucial but incomplete picture of AI’s environmental impact. Comprehensive assessment requires measuring additional ecological impacts including water consumption, hazardous chemical usage, rare material extraction, and biodiversity disruption that often receive less attention despite their ecological significance.</p>
<p>Modern semiconductor fabrication plants producing AI chips require millions of gallons of water daily and use over 250 hazardous substances in their processes. In regions already facing water stress, such as Taiwan, Arizona, and Singapore, this intensive usage threatens local ecosystems and communities. Additionally, AI hardware relies heavily on scarce materials like gallium, indium, arsenic, and helium, which face both geopolitical supply risks and depletion concerns.</p>
<p>This comprehensive impact assessment enables organizations to identify environmental hotspots beyond energy consumption and develop targeted mitigation strategies that address the full ecological footprint of AI systems.</p>
</section><section id="sec-sustainable-ai-water-usage-efc6" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-water-usage-efc6">Water Usage</h3>
<p>Semiconductor fabrication is an exceptionally water-intensive process, requiring vast quantities of ultrapure water for cleaning, cooling, and chemical processing. The scale of water consumption in modern fabs is comparable to that of entire urban populations. For example, TSMC’s latest fab in Arizona is projected to consume 8.9 million gallons of water per day <span class="citation" data-cites="tsmc2023water">(<a href="#ref-tsmc2023water" role="doc-biblioref">Company 2023</a>)</span><a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a>, accounting for nearly 3% of the city’s total water production. This demand places significant strain on local water resources, particularly in water-scarce regions such as Taiwan, Arizona, and Singapore, where semiconductor manufacturing is concentrated. Semiconductor companies have recognized this challenge and are actively investing in recycling technologies and more efficient water management practices. STMicroelectronics, for example, recycles and reuses approximately 41% of its water, significantly reducing its environmental footprint. <a href="#fig-water_cycle" class="quarto-xref">Figure&nbsp;8</a> illustrates the typical semiconductor fab water cycle, showing the stages from raw water intake to wastewater treatment and reuse.</p>
<div class="no-row-height column-margin column-container"><div id="ref-tsmc2023water" class="csl-entry" role="listitem">
Company, Taiwan Semiconductor Manufacturing. 2023. <span>“TSMC Arizona Fab 21 Water Usage Impact Assessment.”</span> <em>Environmental Impact Report</em>. <a href="https://www.tsmc.com/english/dedicatedFoundry/manufacturing/arizona">https://www.tsmc.com/english/dedicatedFoundry/manufacturing/arizona</a>.
</div><div id="fn26"><p><sup>26</sup>&nbsp;<strong>Semiconductor Water Consumption Scale</strong>: TSMC’s Arizona facility will consume 3.2 billion gallons annually—equivalent to 37,000 Olympic swimming pools. Each AI chip requires 5-10x more water than traditional processors due to advanced nodes and complex manufacturing. Intel’s Ireland fab uses 1.5 billion gallons annually, while Samsung’s Texas facility is projected to use 6 million gallons daily. Water treatment and purification add 30-50% to total consumption. During peak summer months, the cumulative daily water consumption of major fabs rivals that of cities with populations exceeding half a million people.</p></div></div><div id="fig-water_cycle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-water_cycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/st_water_cycle.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;8: Water Recycling Loop: Semiconductor fabrication relies on extensive water purification and closed-loop recycling to minimize consumption; this diagram details the stages, from raw water intake to wastewater treatment and reuse, highlighting the potential for significant water conservation within a fab facility. Source: ST sustainability report."><img src="images/png/st_water_cycle.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-water_cycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: <strong>Water Recycling Loop</strong>: Semiconductor fabrication relies on extensive water purification and closed-loop recycling to minimize consumption; this diagram details the stages, from raw water intake to wastewater treatment and reuse, highlighting the potential for significant water conservation within a fab facility. Source: ST sustainability report.
</figcaption></figure>
</div>
<p>The primary use of ultrapure water in semiconductor fabrication is for flushing contaminants from wafers at various production stages. Water also serves as a coolant and carrier fluid in thermal oxidation, chemical deposition, and planarization processes. A single 300mm silicon wafer requires over 8,300 liters of water throughout the complete fabrication process, with more than two-thirds of this being ultrapure water <span class="citation" data-cites="cope2009pure">(<a href="#ref-cope2009pure" role="doc-biblioref">Cope 2009</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>The impact of this massive water usage extends beyond consumption. Excessive water withdrawal from local aquifers lowers groundwater levels, leading to issues such as land subsidence and saltwater intrusion. In Hsinchu, Taiwan, one of the world’s largest semiconductor hubs, extensive water extraction by fabs has led to falling water tables and encroaching seawater contamination, affecting both agriculture and drinking water supplies.</p>
<p><a href="#fig-water_footprint" class="quarto-xref">Figure&nbsp;9</a> contextualizes the daily water footprint of data centers compared to other industrial uses, illustrating the immense water demand of high-tech infrastructure.</p>
<div id="fig-water_footprint" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-water_footprint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/water_footprint.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;9: Data Center Water Usage: High-density computing infrastructure, such as data centers, consumes substantial water resources for cooling, exceeding many common industrial and agricultural applications. understanding these water demands is important for designing sustainable AI systems and mitigating potential impacts like saltwater intrusion in water-stressed regions. Source: google’s data center cooling."><img src="images/png/water_footprint.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-water_footprint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: <strong>Data Center Water Usage</strong>: High-density computing infrastructure, such as data centers, consumes substantial water resources for cooling, exceeding many common industrial and agricultural applications. understanding these water demands is important for designing sustainable AI systems and mitigating potential impacts like <em>saltwater intrusion</em> in water-stressed regions. Source: <a href="https://blog.google/outreach-initiatives/sustainability/our-commitment-to-climate-conscious-data-center-cooling/">google’s data center cooling</a>.
</figcaption></figure>
</div>
<p>While some semiconductor manufacturers implement water recycling systems, the effectiveness of these measures varies. Intel reports that 97% of its direct water consumption is attributed to fabrication processes <span class="citation" data-cites="cooper2011semiconductor">(<a href="#ref-cooper2011semiconductor" role="doc-biblioref">Cooper et al. 2011</a>)</span>, and while water reuse is increasing, the sheer scale of water withdrawals remains a important sustainability challenge.</p>
<div class="no-row-height column-margin column-container"><div id="ref-cooper2011semiconductor" class="csl-entry" role="listitem">
Cooper, Tom, Suzanne Fallender, Joyann Pafumi, Jon Dettling, Sebastien Humbert, and Lindsay Lessard. 2011. <span>“A Semiconductor Company’s Examination of Its Water Footprint Approach.”</span> In <em>Proceedings of the 2011 IEEE International Symposium on Sustainable Systems and Technology</em>, 1–6. IEEE; IEEE. <a href="https://doi.org/10.1109/issst.2011.5936865">https://doi.org/10.1109/issst.2011.5936865</a>.
</div></div><p>Beyond depletion, water discharge from semiconductor fabs introduces contamination risks if not properly managed. Wastewater from fabrication contains metals, acids, and chemical residues that must be thoroughly treated before release. Although modern fabs employ advanced purification systems, the extraction of contaminants still generates hazardous byproducts, which, if not carefully disposed of, pose risks to local ecosystems.</p>
<p>The growing demand for semiconductor manufacturing, driven by AI acceleration and computing infrastructure expansion, makes water management a important factor in sustainable AI development. Ensuring the long-term viability of semiconductor production requires not only reducing direct water consumption but also enhancing wastewater treatment and developing alternative cooling technologies that minimize reliance on fresh water sources.</p>
</section><section id="sec-sustainable-ai-hazardous-chemicals-6c4c" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-hazardous-chemicals-6c4c">Hazardous Chemicals</h3>
<p>Semiconductor fabrication is heavily reliant on highly hazardous chemicals, which play an important role in processes such as etching, doping, and wafer cleaning. The manufacturing of AI hardware, including GPUs, TPUs, and other specialized accelerators, requires the use of strong acids, volatile solvents, and toxic gases, all of which pose significant health and environmental risks if not properly managed. The scale of chemical usage in fabs is immense, with thousands of metric tons of hazardous substances consumed annually <span class="citation" data-cites="kim2018chemical">(<a href="#ref-kim2018chemical" role="doc-biblioref">Kim et al. 2018</a>)</span><a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kim2018chemical" class="csl-entry" role="listitem">
Kim, Sunju, Chungsik Yoon, Seunghon Ham, Jihoon Park, Ohun Kwon, Donguk Park, Sangjun Choi, Seungwon Kim, Kwonchul Ha, and Won Kim. 2018. <span>“Chemical Use in the Semiconductor Manufacturing Industry.”</span> <em>International Journal of Occupational and Environmental Health</em> 24 (3-4): 109–18. <a href="https://doi.org/10.1080/10773525.2018.1519957">https://doi.org/10.1080/10773525.2018.1519957</a>.
</div><div id="fn27"><p><sup>27</sup>&nbsp;<strong>Hazardous Chemical Quantities</strong>: A typical large semiconductor fab uses 500+ different chemicals annually, consuming 500-2,000 metric tons of acids, 50-200 metric tons of solvents, and 10-50 tons of toxic gases. Arsine gas is lethal at 3 parts per million over 30 minutes. TSMC’s facilities store over 50,000 tons of chemicals on-site, requiring specialized emergency response teams and $100+ million in safety infrastructure per fab. Any leaks or accidental releases in fabs can lead to severe health hazards for workers and surrounding communities.</p></div></div><p>Among the most important chemical categories used in fabrication are strong acids, which facilitate wafer etching and oxide removal. Hydrofluoric acid, sulfuric acid, nitric acid, and hydrochloric acid are commonly employed in the cleaning and patterning stages of chip production. While effective for these processes, these acids are highly corrosive and toxic, capable of causing severe chemical burns and respiratory damage if mishandled. Large semiconductor fabs require specialized containment, filtration, and neutralization systems to prevent accidental exposure and environmental contamination.</p>
<p>Solvents are another important component in chip manufacturing, primarily used for dissolving photoresists and cleaning wafers. Key solvents include xylene, methanol, and methyl isobutyl ketone (MIBK), which, despite their utility, present air pollution and worker safety risks. These solvents are volatile organic compounds (VOCs) that can evaporate into the atmosphere, contributing to indoor and outdoor air pollution. If not properly contained, VOC exposure can result in neurological damage, respiratory issues, and long-term health effects for workers in semiconductor fabs.</p>
<p>Toxic gases are among the most dangerous substances used in AI chip manufacturing. Gases such as arsine (AsH₃), phosphine (PH₃), diborane (B₂H₆), and germane (GeH₄) are used in doping and chemical vapor deposition processes, important for fine-tuning semiconductor properties. These gases are highly toxic and even fatal at low concentrations, requiring extensive handling precautions, gas scrubbers, and emergency response protocols.</p>
<p>While modern fabs employ strict safety controls, protective equipment, and chemical treatment systems, incidents still occur, leading to chemical spills, gas leaks, and contamination risks. The challenge of effectively managing hazardous chemicals is heightened by the ever-increasing complexity of AI accelerators, which require more advanced fabrication techniques and new chemical formulations.</p>
<p>Beyond direct safety concerns, the long-term environmental impact of hazardous chemical use remains a major sustainability issue. Semiconductor fabs generate large volumes of chemical waste, which, if improperly handled, can contaminate groundwater, soil, and local ecosystems. Regulations in many countries require fabs to neutralize and treat waste before disposal, but compliance and enforcement vary globally, leading to differing levels of environmental protection.</p>
<p>To mitigate these risks, fabs must continue advancing green chemistry initiatives, exploring alternative etchants, solvents, and gas formulations that reduce toxicity while maintaining fabrication efficiency. Additionally, process optimizations that minimize chemical waste, improve containment, and enhance recycling efforts will be important to reducing the environmental footprint of AI hardware production.</p>
</section><section id="sec-sustainable-ai-resource-depletion-e383" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-resource-depletion-e383">Resource Depletion</h3>
<p>While silicon is abundant and readily available, the fabrication of AI accelerators, GPUs, and specialized AI chips depends on scarce and geopolitically sensitive materials that are far more difficult to source. AI hardware manufacturing requires a range of rare metals, noble gases, and semiconductor compounds, many of which face supply constraints, geopolitical risks, and environmental extraction costs. As AI models become larger and more computationally intensive, the demand for these materials continues to rise, raising concerns about long-term availability and sustainability.</p>
<p>Although silicon serves as the primary material for semiconductor devices, high-performance AI chips depend on rare elements such as gallium, indium, and arsenic, which are important for high-speed, low-power electronic components <span class="citation" data-cites="chen2006gallium">(<a href="#ref-chen2006gallium" role="doc-biblioref">Chen 2006</a>)</span>. Gallium and indium, for example, are widely used in compound semiconductors, particularly for 5G communications, optoelectronics, and AI accelerators. The United States Geological Survey (USGS) has classified indium as a important material, with global supplies expected to last fewer than 15 years at the current rate of consumption <span class="citation" data-cites="davies2011endangered">(<a href="#ref-davies2011endangered" role="doc-biblioref">Davies 2011</a>)</span><a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-chen2006gallium" class="csl-entry" role="listitem">
Chen, H.-W. 2006. <span>“Gallium, Indium, and Arsenic Pollution of Groundwater from a Semiconductor Manufacturing Area of Taiwan.”</span> <em>Bulletin of Environmental Contamination and Toxicology</em> 77 (2): 289–96. <a href="https://doi.org/10.1007/s00128-006-1062-3">https://doi.org/10.1007/s00128-006-1062-3</a>.
</div><div id="fn28"><p><sup>28</sup>&nbsp;<strong>Critical Material Scarcity</strong>: Indium production is only 600-800 tons annually worldwide, with China controlling 60% of supply. Prices fluctuate wildly—from $60/kg in 2002 to $1,000/kg in 2005, now around $400/kg. Each smartphone contains 0.3mg of indium; each AI accelerator contains 50-100x more. At current AI hardware growth rates (40% annually), demand will exceed supply by 2035 without recycling breakthroughs. As AI hardware manufacturing scales, the demand for helium will continue to grow, necessitating more sustainable extraction and recycling practices.</p></div></div><p>Another major concern is helium, a noble gas important for semiconductor cooling, plasma etching, and EUV lithography used in next-generation chip production. Helium is unique in that once released into the atmosphere, it escapes Earth’s gravity and is lost forever, making it a non-renewable resource <span class="citation" data-cites="davies2011endangered">(<a href="#ref-davies2011endangered" role="doc-biblioref">Davies 2011</a>)</span>. The semiconductor industry is one of the largest consumers of helium, and supply shortages have already led to price spikes and disruptions in fabrication processes.</p>
<p>Beyond raw material availability, the geopolitical control of rare earth elements poses additional challenges. China currently dominates over 90% of the world’s rare earth element (REE) refining capacity<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a>, including materials important for AI chips, such as neodymium (for high-performance magnets in AI accelerators) and yttrium (for high-temperature superconductors) <span class="citation" data-cites="jha2014rare">(<a href="#ref-jha2014rare" role="doc-biblioref">Jha 2014</a>)</span>. This concentration of supply creates supply chain vulnerabilities, as trade restrictions or geopolitical tensions could severely impact AI hardware production.</p>
<div class="no-row-height column-margin column-container"><div id="fn29"><p><sup>29</sup>&nbsp;<strong>Chinese Rare Earth Dominance</strong>: China produces 85% of rare earth elements and controls 95% of global refining capacity. The 2010 China-Japan diplomatic crisis saw rare earth exports to Japan cut by 40%, causing prices to spike 2,000%. A single NVIDIA H100 contains 17 different rare earth elements totaling 200-300 grams. U.S. strategic reserves contain only 3-month supply, while building alternative supply chains requires 10-15 years and $50+ billion investment.</p></div><div id="ref-jha2014rare" class="csl-entry" role="listitem">
Jha, A. R. 2014. <em>Rare Earth Materials: Properties and Applications</em>. CRC Press. <a href="https://doi.org/10.1201/b17045">https://doi.org/10.1201/b17045</a>.
</div></div><p>The scope of this material dependency challenge is illustrated in <a href="#tbl-material_depletion" class="quarto-xref">Table&nbsp;1</a>, which highlights the key materials important for AI semiconductor manufacturing, their applications, and supply concerns.</p>
<p>The rapid growth of AI and semiconductor demand has accelerated the depletion of these important resources, creating an urgent need for material recycling, substitution strategies, and more sustainable extraction methods. Some efforts are underway to explore alternative semiconductor materials that reduce dependency on rare elements, but these solutions require significant advancement before they become viable alternatives at scale.</p>
<div id="tbl-material_depletion" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-material_depletion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: <strong>Critical Materials for AI Hardware</strong>: Semiconductor manufacturing relies on specific materials—like silicon, neodymium, and yttrium—that face increasing supply constraints and geopolitical risks, potentially impacting AI hardware production and innovation. The table details these materials, their applications in AI systems, and the associated supply vulnerabilities requiring proactive mitigation strategies.
</figcaption><div aria-describedby="tbl-material_depletion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 37%">
<col style="width: 45%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Material</th>
<th style="text-align: left;">Application in AI Semiconductor Manufacturing</th>
<th style="text-align: left;">Supply Concerns</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Silicon (Si)</td>
<td style="text-align: left;">Primary substrate for chips, wafers, transistors</td>
<td style="text-align: left;">Processing constraints; geopolitical risks</td>
</tr>
<tr class="even">
<td style="text-align: left;">Gallium (Ga)</td>
<td style="text-align: left;">GaN-based power amplifiers, high-frequency components</td>
<td style="text-align: left;">Limited availability; byproduct of aluminum and zinc production</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Germanium (Ge)</td>
<td style="text-align: left;">High-speed transistors, photodetectors, optical interconnects</td>
<td style="text-align: left;">Scarcity; geographically concentrated</td>
</tr>
<tr class="even">
<td style="text-align: left;">Indium (In)</td>
<td style="text-align: left;">Indium Tin Oxide (ITO), optoelectronics</td>
<td style="text-align: left;">Limited reserves; recycling dependency</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Tantalum (Ta)</td>
<td style="text-align: left;">Capacitors, stable integrated components</td>
<td style="text-align: left;">Conflict mineral; vulnerable supply chains</td>
</tr>
<tr class="even">
<td style="text-align: left;">Rare Earth Elements (REEs)</td>
<td style="text-align: left;">Magnets, sensors, high-performance electronics</td>
<td style="text-align: left;">High geopolitical risks; environmental extraction concerns</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Cobalt (Co)</td>
<td style="text-align: left;">Batteries for edge computing devices</td>
<td style="text-align: left;">Human rights issues; geographical concentration (Congo)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Tungsten (W)</td>
<td style="text-align: left;">Interconnects, barriers, heat sinks</td>
<td style="text-align: left;">Limited production sites; geopolitical concerns</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Copper (Cu)</td>
<td style="text-align: left;">Interconnects, barriers, heat sinks</td>
<td style="text-align: left;">Limited high-purity sources; geopolitical concerns</td>
</tr>
<tr class="even">
<td style="text-align: left;">Helium (He)</td>
<td style="text-align: left;">Semiconductor cooling, plasma etching, EUV lithography</td>
<td style="text-align: left;">Non-renewable; irretrievable atmospheric loss; limited extraction capacity</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The transition toward optical interconnects in AI infrastructure exemplifies how emerging technologies can compound these resource challenges. Modern AI systems like Google’s TPUs and high-performance interconnect solutions from companies like Mellanox increasingly rely on optical technologies to achieve the bandwidth requirements for distributed training and inference. While optical interconnects offer advantages including higher bandwidth (up to 400 Gbps in the case of TPUv4 <span class="citation" data-cites="jouppi2023tpu">(<a href="#ref-jouppi2023tpu" role="doc-biblioref">Jouppi et al. 2023</a>)</span>), reduced power consumption, and immunity to electromagnetic interference compared to copper-based connections, they introduce additional material dependencies, particularly for germanium used in high-speed photodetectors and optical components. As AI systems increasingly adopt optical interconnection to address data center bandwidth limitations, the demand for germanium-based components will intensify existing supply chain vulnerabilities, highlighting the need for comprehensive material sustainability planning in AI infrastructure development.</p>
<div class="no-row-height column-margin column-container"><div id="ref-jouppi2023tpu" class="csl-entry" role="listitem">
Jouppi, Norm, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan, Lifeng Nai, Nishant Patil, et al. 2023. <span>“TPU V4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings.”</span> In <em>Proceedings of the 50th Annual International Symposium on Computer Architecture</em>, 1–14. ACM. <a href="https://doi.org/10.1145/3579371.3589350">https://doi.org/10.1145/3579371.3589350</a>.
</div></div></section><section id="sec-sustainable-ai-waste-generation-e6d9" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-waste-generation-e6d9">Waste Generation</h3>
<p>Semiconductor fabrication produces significant volumes of hazardous waste, including gaseous emissions, VOCs, chemical-laden wastewater, and solid toxic byproducts. The production of AI accelerators, GPUs, and other high-performance chips involves multiple stages of chemical processing, etching, and cleaning, each generating waste materials that must be carefully treated to prevent environmental contamination.</p>
<p>Fabs release gaseous waste from various processing steps, particularly chemical vapor deposition (CVD), plasma etching, and ion implantation. This includes toxic and corrosive gases such as arsine (AsH₃), phosphine (PH₃), and germane (GeH₄), which require advanced scrubber systems to neutralize before release into the atmosphere. If not properly filtered, these gases pose severe health hazards and contribute to air pollution and acid rain formation <span class="citation" data-cites="grossman2007high">(<a href="#ref-grossman2007high" role="doc-biblioref">Grossman 2007</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-grossman2007high" class="csl-entry" role="listitem">
Grossman, Elizabeth. 2007. <em>High Tech Trash: Digital Devices, Hidden Toxics, and Human Health</em>. Island press.
</div></div><p>VOCs are another major waste category, emitted from photoresist processing, cleaning solvents, and lithographic coatings. Chemicals such as xylene, acetone, and methanol readily evaporate into the air, where they contribute to ground-level ozone formation and indoor air quality hazards for fab workers. In regions where semiconductor production is concentrated, such as Taiwan and South Korea, regulators have imposed strict VOC emission controls to mitigate their environmental impact.</p>
<p>Semiconductor fabs also generate large volumes of spent acids and metal-laden wastewater, requiring extensive treatment before discharge. Strong acids such as sulfuric acid, hydrofluoric acid, and nitric acid are used to etch silicon wafers, removing excess materials during fabrication. When these acids become contaminated with heavy metals, fluorides, and chemical residues, they must undergo neutralization and filtration before disposal. Improper handling of wastewater has led to groundwater contamination incidents, highlighting the importance of robust waste management systems <span class="citation" data-cites="prakash2022cfu">(<a href="#ref-prakash2022cfu" role="doc-biblioref">Prakash, Callahan, et al. 2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>The solid waste produced in AI hardware manufacturing includes sludge, filter cakes, and chemical residues collected from fab exhaust and wastewater treatment systems. These byproducts often contain concentrated heavy metals, rare earth elements, and semiconductor process chemicals, making them hazardous for conventional landfill disposal. In some cases, fabs incinerate toxic waste, generating additional environmental concerns related to airborne pollutants and toxic ash disposal.</p>
<p>Beyond the waste generated during manufacturing, the end-of-life disposal of AI hardware presents another sustainability challenge. AI accelerators, GPUs, and server hardware have short refresh cycles, with data center equipment typically replaced every 3-5 years. This results in millions of tons of e-waste annually, much of which contains toxic heavy metals such as lead, cadmium, and mercury. Despite growing efforts to improve electronics recycling, current systems capture only 17.4% of global e-waste, leaving the majority to be discarded in landfills or improperly processed <span class="citation" data-cites="singh2022disentangling">(<a href="#ref-singh2022disentangling" role="doc-biblioref">Singh and Ogunseitan 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>Addressing the hazardous waste impact of AI requires advancements in both semiconductor manufacturing and e-waste recycling. Companies are exploring closed-loop recycling for rare metals, improved chemical treatment processes, and alternative materials with lower toxicity. However, as AI models continue to drive demand for higher-performance chips and larger-scale computing infrastructure, the industry’s ability to manage its waste footprint will be a key factor in achieving sustainable AI development.</p>
</section><section id="sec-sustainable-ai-biodiversity-impact-8f3d" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-biodiversity-impact-8f3d">Biodiversity Impact</h3>
<p>The environmental footprint of AI hardware extends beyond carbon emissions, resource depletion, and hazardous waste. The construction and operation of semiconductor fabrication facilities (fabs), data centers, and supporting infrastructure directly impact natural ecosystems, contributing to habitat destruction, water stress, and pollution. These environmental changes have far-reaching consequences for wildlife, plant ecosystems, and aquatic biodiversity, highlighting the need for sustainable AI development that considers broader ecological effects.</p>
<p>Semiconductor fabs and data centers require large tracts of land, often leading to deforestation and destruction of natural habitats. These facilities are typically built in industrial parks or near urban centers, but as demand for AI hardware increases, fabs are expanding into previously undeveloped regions, encroaching on forests, wetlands, and agricultural land.</p>
<p>The physical expansion of AI infrastructure disrupts wildlife migration patterns, as roads, pipelines, transmission towers, and supply chains fragment natural landscapes. Species that rely on large, connected ecosystems for survival, including migratory birds, large mammals, and pollinators, face increased barriers to movement, reducing genetic diversity and population stability. In regions with dense semiconductor manufacturing, such as Taiwan and South Korea, habitat loss has already been linked to declining biodiversity in affected areas <span class="citation" data-cites="hsu2016accumulation">(<a href="#ref-hsu2016accumulation" role="doc-biblioref">Hsu et al. 2016</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-hsu2016accumulation" class="csl-entry" role="listitem">
Hsu, Liang-Ching, Ching-Yi Huang, Yen-Hsun Chuang, Ho-Wen Chen, Ya-Ting Chan, Heng Yi Teah, Tsan-Yao Chen, Chiung-Fen Chang, Yu-Ting Liu, and Yu-Min Tzou. 2016. <span>“Accumulation of Heavy Metals and Trace Elements in Fluvial Sediments Received Effluents from Traditional and Semiconductor Industries.”</span> <em>Scientific Reports</em> 6 (1): 34250. <a href="https://doi.org/10.1038/srep34250">https://doi.org/10.1038/srep34250</a>.
</div></div><p>The massive water consumption of semiconductor fabs poses serious risks to aquatic ecosystems, particularly in water-stressed regions. Excessive groundwater extraction for AI chip production can lower water tables, affecting local rivers, lakes, and wetlands. In Hsinchu, Taiwan, where fabs draw millions of gallons of water daily, seawater intrusion has been reported in local aquifers, altering water chemistry and making it unsuitable for native fish species and vegetation.</p>
<p>Beyond depletion, wastewater discharge from fabs introduces chemical contaminants into natural water systems. While many facilities implement advanced filtration and recycling, even trace amounts of heavy metals, fluorides, and solvents can accumulate in water bodies, bioaccumulating in fish and disrupting aquatic ecosystems. Additionally, thermal pollution from data centers, which release heated water back into lakes and rivers, can raise temperatures beyond tolerable levels for native species, affecting oxygen levels and reproductive cycles <span class="citation" data-cites="poff2002aquatic">(<a href="#ref-poff2002aquatic" role="doc-biblioref">LeRoy Poff, Brinson, and Day 2002</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-poff2002aquatic" class="csl-entry" role="listitem">
LeRoy Poff, N, MM Brinson, and JW Day. 2002. <span>“Aquatic Ecosystems &amp; Global Climate Change.”</span> <em>Pew Center on Global Climate Change</em>.
</div></div><p>Semiconductor fabs emit a variety of airborne pollutants, including VOCs, acid mists, and metal particulates, which can travel significant distances before settling in the environment. These emissions contribute to air pollution and acid deposition, which damage plant life, soil quality, and nearby agricultural systems.</p>
<p>Airborne chemical deposition has been linked to tree decline, reduced crop yields, and soil acidification, particularly near industrial semiconductor hubs. In areas with high VOC emissions, plant growth can be stunted by prolonged exposure, affecting ecosystem resilience and food chains. Additionally, accidental chemical spills or gas leaks from fabs pose severe risks to both local wildlife and human populations, requiring strict regulatory enforcement to minimize long-term ecological damage <span class="citation" data-cites="wald1987semiconductor">(<a href="#ref-wald1987semiconductor" role="doc-biblioref">Wald and Jones 1987</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-wald1987semiconductor" class="csl-entry" role="listitem">
Wald, Peter H., and Jeffrey R. Jones. 1987. <span>“Semiconductor Manufacturing: An Introduction to Processes and Hazards.”</span> <em>American Journal of Industrial Medicine</em> 11 (2): 203–21. <a href="https://doi.org/10.1002/ajim.4700110209">https://doi.org/10.1002/ajim.4700110209</a>.
</div></div><p>The environmental consequences of AI hardware manufacturing demonstrate the urgent need for sustainable semiconductor production, including reduced land use, improved water recycling, and stricter emissions controls. Without intervention, the accelerating demand for AI chips could further strain global biodiversity, emphasizing the importance of balancing technological progress with ecological responsibility.</p>
</section></section><section id="sec-sustainable-ai-semiconductor-life-cycle-5c14" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-semiconductor-life-cycle-5c14">Semiconductor Life Cycle</h2>
<p>The environmental footprint of AI systems extends beyond energy consumption during model training and inference. A comprehensive assessment of AI’s sustainability must consider the entire lifecycle—from the extraction of raw materials used in hardware manufacturing to the eventual disposal of obsolete computing infrastructure. Life Cycle Analysis (LCA)<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a> provides a systematic approach to quantifying the cumulative environmental impact of AI across its four key phases: design, manufacture, use, and disposal.</p>
<div class="no-row-height column-margin column-container"><div id="fn30"><p><sup>30</sup>&nbsp;<strong>Life Cycle Assessment (LCA)</strong>: Systematic methodology for evaluating environmental impacts throughout a product’s entire lifespan—from raw material extraction through manufacturing, use, and disposal. Developed in the 1960s, standardized by ISO 14040/14044. For AI systems, LCA reveals that hardware manufacturing often contributes 30-50% of total emissions despite consuming no operational energy. LCA studies identified that a single NVIDIA H100 GPU generates 300-500 kg CO₂ during production—equivalent to driving 1,200 miles—before any computation occurs.</p></div></div><p>By applying LCA to AI systems, researchers and policymakers can pinpoint important intervention points to reduce emissions, improve resource efficiency, and implement sustainable practices. This approach provides a holistic understanding of AI’s ecological costs, extending sustainability considerations beyond operational power consumption to include hardware supply chains and electronic waste management.</p>
<p><a href="#fig-ai_lca" class="quarto-xref">Figure&nbsp;10</a> illustrates the four primary stages of an AI system’s lifecycle, each contributing to its total environmental footprint.</p>
<div id="fig-ai_lca" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ai_lca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="8a34062e03d287c9e86ad278c993e8f70c34aff9.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;10: AI System Lifecycle: Analyzing AI systems across design, manufacture, use, and disposal stages exposes the full environmental impact beyond operational energy consumption, encompassing resource depletion and electronic waste. This lifecycle assessment allows targeted interventions to improve sustainability throughout the entire AI system’s existence."><img src="sustainable_ai_files/mediabag/8a34062e03d287c9e86ad278c993e8f70c34aff9.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai_lca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: <strong>AI System Lifecycle</strong>: Analyzing AI systems across design, manufacture, use, and disposal stages exposes the full environmental impact beyond operational energy consumption, encompassing resource depletion and electronic waste. This lifecycle assessment allows targeted interventions to improve sustainability throughout the entire AI system’s existence.
</figcaption></figure>
</div>
<p>The following sections will analyze each lifecycle phase in detail, exploring its specific environmental impacts and sustainability challenges.</p>
<section id="sec-sustainable-ai-design-phase-8374" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-design-phase-8374">Design Phase</h3>
<p>The design phase of an AI system encompasses the research, development, and optimization of machine learning models before deployment. This stage involves iterating on model architectures, adjusting hyperparameters, and running training experiments to improve performance. These processes are computationally intensive, requiring extensive use of hardware resources and energy. The environmental cost of AI model design is often underestimated, but repeated training runs, algorithm refinements, and exploratory experimentation contribute significantly to the overall sustainability impact of AI systems.</p>
<p>Developing an AI model requires running multiple experiments to determine the most effective architecture. Automated architecture search techniques, for instance, automate the process of selecting the best model structure by evaluating hundreds or even thousands of configurations<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a>, each requiring a separate training cycle. Similarly, hyperparameter tuning involves modifying parameters such as learning rates, batch sizes, and optimization strategies to enhance model performance, often through exhaustive search techniques. Pre-training and fine-tuning further add to the computational demands, as models undergo multiple training iterations on different datasets before deployment. The iterative nature of this process results in high energy consumption, with studies indicating that hyperparameter tuning alone can account for up to 80% of training-related emissions <span class="citation" data-cites="cite_needed">(<a href="#ref-cite_needed" role="doc-biblioref"><strong>cite_needed?</strong></a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn31"><p><sup>31</sup>&nbsp;<strong>Architecture Search</strong>: Automated methods for finding optimal model structures. Neural Architecture Search (NAS) techniques covered in <strong>?@sec-model-optimizations-neural-architecture-search-31c8</strong>.</p></div></div><p>The scale of energy consumption in the design phase becomes evident when examining large AI models. OpenAI’s GPT-3, for example, required an estimated 1,300 megawatt-hours (MWh) of electricity for training, a figure comparable to the energy consumption of 1,450 U.S. homes over an entire month <span class="citation" data-cites="maslej2023artificial">(<a href="#ref-maslej2023artificial" role="doc-biblioref">Maslej et al. 2023</a>)</span>. However, this estimate only reflects the final training run and does not account for the extensive trial-and-error processes that preceded model selection. In deep reinforcement learning applications, such as DeepMind’s AlphaZero, models undergo repeated training cycles to improve decision-making policies, further amplifying energy demands.</p>
<p>The carbon footprint of AI model design varies significantly depending on the computational resources required and the energy sources powering the data centers where training occurs. A widely cited study found that training a single large-scale natural language processing (NLP) model could produce emissions equivalent to the lifetime carbon footprint of five cars <span class="citation" data-cites="strubell2019energy">(<a href="#ref-strubell2019energy" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019b</a>)</span>. The impact is even more pronounced when training is conducted in data centers reliant on fossil fuels. For instance, models trained in coal-powered facilities in Virginia (USA) generate far higher emissions than those trained in regions powered by hydroelectric or nuclear energy. Hardware selection also plays a important role; training on energy-efficient tensor processing units (TPUs) can significantly reduce emissions compared to using traditional graphics processing units (GPUs).</p>
<div class="no-row-height column-margin column-container"><div id="ref-strubell2019energy" class="csl-entry" role="listitem">
———. 2019b. <span>“Energy and Policy Considerations for Deep Learning in NLP.”</span> <em>arXiv Preprint arXiv:1906.02243</em>, June, 3645–50. <a href="https://doi.org/10.18653/v1/p19-1355">https://doi.org/10.18653/v1/p19-1355</a>.
</div></div><p><a href="#tbl-training-emissions" class="quarto-xref">Table&nbsp;2</a> summarizes the estimated carbon emissions associated with training various AI models, illustrating the correlation between model complexity and environmental impact.</p>
<div id="tbl-training-emissions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-training-emissions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: <strong>Model Carbon Footprint</strong>: Training large AI models generates substantial carbon emissions, directly correlating with computational demands measured in flops; for example, training GPT-3 requires energy equivalent to the lifetime emissions of hundreds of cars. Understanding these emissions is important for developing sustainable AI practices and selecting energy-efficient hardware like tpus to minimize environmental impact. Source:
</figcaption><div aria-describedby="tbl-training-emissions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 23%">
<col style="width: 37%">
<col style="width: 25%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">AI Model</th>
<th style="text-align: center;">Training FLOPs</th>
<th style="text-align: center;">Estimated <span class="math inline">\(\textrm{CO}_2\)</span> Emissions (kg)</th>
<th style="text-align: center;">Equivalent Car Mileage</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">GPT-3</td>
<td style="text-align: center;"><span class="math inline">\(3.1 \times 10^{23}\)</span></td>
<td style="text-align: center;">502,000 kg</td>
<td style="text-align: center;">1.2 million miles</td>
</tr>
<tr class="even">
<td style="text-align: left;">T5-11B</td>
<td style="text-align: center;"><span class="math inline">\(2.3 \times 10^{22}\)</span></td>
<td style="text-align: center;">85,000 kg</td>
<td style="text-align: center;">210,000 miles</td>
</tr>
<tr class="odd">
<td style="text-align: left;">BERT (Base)</td>
<td style="text-align: center;"><span class="math inline">\(3.3 \times 10^{18}\)</span></td>
<td style="text-align: center;">650 kg</td>
<td style="text-align: center;">1,500 miles</td>
</tr>
<tr class="even">
<td style="text-align: left;">ResNet-50</td>
<td style="text-align: center;"><span class="math inline">\(2.0 \times 10^{17}\)</span></td>
<td style="text-align: center;">35 kg</td>
<td style="text-align: center;">80 miles</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Addressing the sustainability challenges of the design phase requires innovations in training efficiency and computational resource management. Researchers have explored techniques such as sparse training, low-precision arithmetic, and weight-sharing methods to reduce the number of required computations without sacrificing model performance. The use of pre-trained models has also gained traction as a means of minimizing resource consumption. Instead of training models from scratch, researchers can fine-tune smaller versions of pre-trained networks, leveraging existing knowledge to achieve similar results with lower computational costs.</p>
<p>Optimizing model search algorithms further contributes to sustainability. Traditional neural architecture search methods require evaluating a large number of candidate architectures, but recent advances in energy-aware NAS approaches prioritize efficiency by reducing the number of training iterations needed to identify optimal configurations. Companies have also begun implementing carbon-aware computing strategies by scheduling training jobs during periods of lower grid carbon intensity or shifting workloads to data centers with cleaner energy sources <span class="citation" data-cites="gupta2022">(<a href="#ref-gupta2022" role="doc-biblioref">Gupta et al. 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>The design phase sets the foundation for the entire AI lifecycle, influencing energy demands in both the training and inference stages. As AI models grow in complexity, their development processes must be reevaluated to ensure that sustainability considerations are integrated at every stage. The decisions made during model design not only determine computational efficiency but also shape the long-term environmental footprint of AI technologies.</p>
</section><section id="sec-sustainable-ai-manufacturing-phase-03a1" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-manufacturing-phase-03a1">Manufacturing Phase</h3>
<p>The manufacturing phase of AI systems is one of the most resource-intensive aspects of their lifecycle, involving the fabrication of specialized semiconductor hardware such as GPUs, TPUs, FPGAs, and other AI accelerators. The production of these chips requires large-scale industrial processes, including raw material extraction, wafer fabrication, lithography, doping, and packaging—all of which contribute significantly to environmental impact <span class="citation" data-cites="nakano2021geopolitics">(<a href="#ref-nakano2021geopolitics" role="doc-biblioref">Bhamra et al. 2024</a>)</span>. This phase not only involves high energy consumption but also generates hazardous waste, relies on scarce materials, and has long-term consequences for resource depletion.</p>
<div class="no-row-height column-margin column-container"></div><section id="sec-sustainable-ai-fabrication-materials-0eb1" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-fabrication-materials-0eb1">Fabrication Materials</h4>
<p>The foundation of AI hardware lies in semiconductors, primarily silicon-based integrated circuits that power AI accelerators. However, modern AI chips rely on more than just silicon; they require specialty materials such as gallium, indium, arsenic, and helium, each of which carries unique environmental extraction costs. These materials are often classified as important elements due to their scarcity, geopolitical sensitivity, and high energy costs associated with mining and refining <span class="citation" data-cites="nakano2021geopolitics">(<a href="#ref-nakano2021geopolitics" role="doc-biblioref">Bhamra et al. 2024</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-nakano2021geopolitics" class="csl-entry" role="listitem">
Bhamra, Ran, Adrian Small, Christian Hicks, and Olimpia Pilch. 2024. <span>“Impact Pathways: Geopolitics, Risk and&nbsp;Ethics in Critical Minerals Supply Chains.”</span> <em>International Journal of Operations &amp;Amp; Production Management</em> 45 (5): 985–94. <a href="https://doi.org/10.1108/ijopm-03-2024-0228">https://doi.org/10.1108/ijopm-03-2024-0228</a>.
</div><div id="ref-cope2009pure" class="csl-entry" role="listitem">
Cope, Gord. 2009. <span>“Pure Water, Semiconductors and the Recession.”</span> <em>Global Water Intelligence</em> 10 (10).
</div></div><p>Silicon itself is abundant, but refining it into high-purity wafers requires extensive energy-intensive processes. The production of a single 300mm silicon wafer requires over 8,300 liters of water, along with strong acids such as hydrofluoric acid, sulfuric acid, and nitric acid used for etching and cleaning <span class="citation" data-cites="cope2009pure">(<a href="#ref-cope2009pure" role="doc-biblioref">Cope 2009</a>)</span>. The demand for ultra-pure water in semiconductor fabrication places a significant burden on local water supplies, with leading fabs consuming millions of gallons per day.</p>
<p>Beyond silicon, gallium and indium are important for high-performance compound semiconductors, such as those used in high-speed AI accelerators and 5G communications. The U.S. Geological Survey has classified indium as a importantly endangered material, with global supplies estimated to last fewer than 15 years at current consumption rates <span class="citation" data-cites="davies2011endangered">(<a href="#ref-davies2011endangered" role="doc-biblioref">Davies 2011</a>)</span>. Meanwhile, helium, a important cooling agent in chip production, is a non-renewable resource that, once released, escapes Earth’s gravity, making it permanently unrecoverable. The continued expansion of AI hardware manufacturing is accelerating the depletion of these important elements, raising concerns about long-term sustainability.</p>
<div class="no-row-height column-margin column-container"><div id="ref-davies2011endangered" class="csl-entry" role="listitem">
Davies, Martin. 2011. <span>“Endangered Elements: Critical Thinking.”</span> In <em>Study Skills for International Postgraduates</em>, 111–30. Macmillan Education UK. <a href="https://doi.org/10.1007/978-0-230-34553-9%5C_8">https://doi.org/10.1007/978-0-230-34553-9\_8</a>.
</div></div><p>The environmental burden of semiconductor fabrication is further amplified by the use of EUV lithography, a process required for manufacturing sub-5nm chips. EUV systems consume massive amounts of energy, requiring high-powered lasers and complex optics. The International Semiconductor Roadmap estimates that each EUV tool consumes approximately one megawatt (MW) of electricity, significantly increasing the carbon footprint of cutting-edge chip production.</p>
</section><section id="sec-sustainable-ai-manufacturing-energy-consumption-0214" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-manufacturing-energy-consumption-0214">Manufacturing Energy Consumption</h4>
<p>The energy required to manufacture AI hardware is substantial, with the total energy cost per chip often exceeding its entire operational lifetime energy use. The manufacturing of a single AI accelerator can emit more carbon than years of continuous use in a data center, making fabrication a key hotspot in AI’s environmental impact.</p>
</section><section id="sec-sustainable-ai-hazardous-waste-water-usage-fabs-9140" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-hazardous-waste-water-usage-fabs-9140">Hazardous Waste and Water Usage in Fabs</h4>
<p>Semiconductor fabrication also generates large volumes of hazardous waste, including gaseous emissions, VOCs, chemical wastewater, and solid byproducts. The acids and solvents used in chip production produce toxic waste streams that require specialized handling to prevent contamination of surrounding ecosystems. Despite advancements in wastewater treatment, trace amounts of metals and chemical residues can still be released into rivers and lakes, affecting aquatic biodiversity and human health <span class="citation" data-cites="prakash2022cfu">(<a href="#ref-prakash2022cfu" role="doc-biblioref">Prakash, Callahan, et al. 2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-prakash2022cfu" class="csl-entry" role="listitem">
Prakash, Shvetank, Tim Callahan, Joseph Bushagour, Colby Banbury, Alan V. Green, Pete Warden, Tim Ansell, and Vijay Janapa Reddi. 2023. <span>“CFU Playground: Full-Stack Open-Source Framework for Tiny Machine Learning (TinyML) Acceleration on FPGAs.”</span> In <em>2023 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</em>, abs/2201.01863:157–67. IEEE. <a href="https://doi.org/10.1109/ispass57527.2023.00024">https://doi.org/10.1109/ispass57527.2023.00024</a>.
</div></div><p>The demand for water in semiconductor fabs has also raised concerns about regional water stress. The TSMC fab in Arizona is projected to consume 8.9 million gallons per day, a figure that accounts for nearly 3% of the city’s water supply. While some fabs have begun investing in water recycling systems, these efforts remain insufficient to offset the growing demand.</p>
</section><section id="sec-sustainable-ai-sustainable-initiatives-c0e1" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-sustainable-initiatives-c0e1">Sustainable Initiatives</h4>
<p>Recognizing the sustainability challenges of semiconductor manufacturing, industry leaders have started implementing initiatives to reduce energy consumption, waste generation, and emissions. Companies like Intel, TSMC, and Samsung have pledged to transition towards carbon-neutral semiconductor fabrication through several key approaches. Many fabs are incorporating renewable energy sources, with facilities in Taiwan and Europe increasingly powered by hydroelectric and wind energy. Water conservation efforts have expanded through closed-loop recycling systems that reduce dependence on local water supplies. Manufacturing processes are being redesigned with eco-friendly etching and lithography techniques that minimize hazardous waste generation. Additionally, companies are developing energy-efficient chip architectures, such as low-power AI accelerators optimized for performance per watt, to reduce the environmental impact of both manufacturing and operation. Despite these efforts, the overall environmental footprint of AI chip manufacturing continues to grow as demand for AI accelerators escalates. Without significant improvements in material efficiency, recycling, and fabrication techniques, the manufacturing phase will remain a major contributor to AI’s sustainability challenges. While this chapter focuses on the environmental costs of manufacturing, the complementary challenge of optimizing hardware architectures for energy efficiency is addressed in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>, operational infrastructure sustainability is covered in <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>, and algorithmic techniques for reducing computational requirements are detailed in <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong>.</p>
<p>The manufacturing phase of AI hardware represents one of the most resource-intensive and environmentally impactful aspects of AI’s lifecycle. The extraction of important materials, high-energy fabrication processes, and hazardous waste generation all contribute to AI’s growing carbon footprint. While industry efforts toward sustainable semiconductor manufacturing are gaining momentum, scaling these initiatives to meet rising AI demand remains a significant challenge.</p>
<p>Addressing the sustainability of AI hardware will require a combination of material innovation, supply chain transparency, and greater investment in circular economy models that emphasize chip recycling and reuse. As AI systems continue to advance, their long-term viability will depend not only on computational efficiency but also on reducing the environmental burden of their underlying hardware infrastructure.</p>
</section></section><section id="sec-sustainable-ai-use-phase-a8ad" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-use-phase-a8ad">Use Phase</h3>
<p>The use phase of AI systems represents one of the most energy-intensive stages in their lifecycle, encompassing both training and inference workloads. As AI adoption grows across industries, the computational requirements for developing and deploying models continue to increase, leading to greater energy consumption and carbon emissions. The operational costs of AI systems extend beyond the direct electricity used in processing; they also include the power demands of data centers, cooling infrastructure, and networking equipment that support large-scale AI workloads. Understanding the sustainability challenges of this phase is important for mitigating AI’s long-term environmental impact.</p>
<p>AI model training is among the most computationally expensive activities in the use phase. Training large-scale models involves running billions or even trillions of mathematical operations across specialized hardware, such as GPUs and TPUs, for extended periods. The energy consumption of training has risen sharply in recent years as AI models have grown in complexity. OpenAI’s GPT-3, for example, required approximately 1,300 megawatt-hours (MWh) of electricity, an amount equivalent to powering 1,450 U.S. homes for a month <span class="citation" data-cites="maslej2023artificial">(<a href="#ref-maslej2023artificial" role="doc-biblioref">Maslej et al. 2023</a>)</span>. The carbon footprint of such training runs depends largely on the energy mix of the data center where they are performed. A model trained in a region relying primarily on fossil fuels, such as coal-powered data centers in Virginia, generates significantly higher emissions than one trained in a facility powered by hydroelectric or nuclear energy.</p>
<div class="no-row-height column-margin column-container"><div id="ref-maslej2023artificial" class="csl-entry" role="listitem">
Maslej, Nestor, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, et al. 2023. <span>“Artificial Intelligence Index Report 2023.”</span> <em>ArXiv Preprint</em> abs/2310.03715 (October). <a href="http://arxiv.org/abs/2310.03715v1">http://arxiv.org/abs/2310.03715v1</a>.
</div><div id="ref-patterson2022carbon" class="csl-entry" role="listitem">
Patterson, David, Joseph Gonzalez, Urs Holzle, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David R. So, Maud Texier, and Jeff Dean. 2022. <span>“The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink.”</span> <em>Computer</em> 55 (7): 18–28. <a href="https://doi.org/10.1109/mc.2022.3148714">https://doi.org/10.1109/mc.2022.3148714</a>.
</div></div><p>Beyond training, the energy demands of AI do not end once a model is developed. The inference phase, where a trained model is used to generate predictions, is responsible for an increasingly large share of AI’s operational carbon footprint. In real-world applications, inference workloads run continuously, handling billions of requests daily across services such as search engines, recommendation systems, language models, and autonomous systems. The cumulative energy impact of inference is substantial, especially in large-scale deployments. While a single training run for a model like GPT-3 is energy-intensive, inference workloads running across millions of users can consume even more power over time. Studies have shown that inference now accounts for more than 60% of total AI-related energy consumption, exceeding the carbon footprint of training in many cases <span class="citation" data-cites="patterson2022carbon">(<a href="#ref-patterson2022carbon" role="doc-biblioref">Patterson, Gonzalez, Holzle, et al. 2022</a>)</span>.</p>
<p>Data centers play a central role in enabling AI, housing the computational infrastructure required for training and inference. These facilities rely on thousands of high-performance servers, each drawing significant power to process AI workloads. The power usage effectiveness of a data center, which measures the efficiency of its energy use, directly influences AI’s carbon footprint. Many modern data centers operate with PUE values between 1.1 and 1.5, meaning that for every unit of power used for computation, an additional 10% to 50% is consumed for cooling, power conversion, and infrastructure overhead <span class="citation" data-cites="barroso2019datacenter">(<a href="#ref-barroso2019datacenter" role="doc-biblioref">Barroso, Hölzle, and Ranganathan 2019</a>)</span>. Cooling systems, in particular, are a major contributor to data center energy consumption, as AI accelerators generate substantial heat during operation.</p>
<div class="no-row-height column-margin column-container"><div id="ref-barroso2019datacenter" class="csl-entry" role="listitem">
Barroso, Luiz André, Urs Hölzle, and Parthasarathy Ranganathan. 2019. <em>The Datacenter as a Computer: Designing Warehouse-Scale Machines</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-01761-2">https://doi.org/10.1007/978-3-031-01761-2</a>.
</div><div id="ref-gupta2022" class="csl-entry" role="listitem">
Gupta, Udit, Mariam Elgamal, Gage Hills, Gu-Yeon Wei, Hsien-Hsin S. Lee, David Brooks, and Carole-Jean Wu. 2022. <span>“ACT: Designing Sustainable Computer Systems with an Architectural Carbon Modeling Tool.”</span> In <em>Proceedings of the 49th Annual International Symposium on Computer Architecture</em>, 784–99. ACM. <a href="https://doi.org/10.1145/3470496.3527408">https://doi.org/10.1145/3470496.3527408</a>.
</div></div><p>The geographic location of data centers has a direct impact on their sustainability. Facilities situated in regions with renewable energy availability can significantly reduce emissions compared to those reliant on fossil fuel-based grids. Companies such as Google and Microsoft have invested in carbon-aware computing strategies, scheduling AI workloads during periods of high renewable energy production to minimize their carbon impact <span class="citation" data-cites="gupta2022">(<a href="#ref-gupta2022" role="doc-biblioref">Gupta et al. 2022</a>)</span>. Google’s DeepMind, for instance, developed an AI-powered cooling optimization system that reduced data center cooling energy consumption by 40%, lowering the overall carbon footprint of AI infrastructure.</p>
<p>The increasing energy demands of AI raise concerns about grid capacity and sustainability trade-offs. AI workloads often compete with other high-energy sectors, such as manufacturing and transportation, for limited electricity supply. In some regions, the rise of AI-driven data centers has led to increased stress on power grids, necessitating new infrastructure investments. The so-called “duck curve” problem, where renewable energy generation fluctuates throughout the day, poses additional challenges for balancing AI’s energy demands with grid availability. The shift toward distributed AI computing and edge processing is emerging as a potential solution to reduce reliance on centralized data centers, shifting some computational tasks closer to end users.</p>
<p>Mitigating the environmental impact of AI’s use phase requires a combination of hardware, software, and infrastructure-level optimizations. Advances in energy-efficient chip architectures, such as low-power AI accelerators and specialized inference hardware, have shown promise in reducing per-query energy consumption. AI models themselves are being optimized for efficiency through techniques such as quantization, pruning, and distillation, which allow for smaller, faster models that maintain high accuracy while requiring fewer computational resources. Meanwhile, ongoing improvements in cooling efficiency, renewable energy integration, and data center operations are important for ensuring that AI’s growing footprint remains sustainable in the long term.</p>
<p>As AI adoption continues to expand, energy efficiency must become a central consideration in model deployment strategies. The use phase will remain a dominant contributor to AI’s environmental footprint, and without significant intervention, the sector’s electricity consumption could grow exponentially. Sustainable AI development requires a coordinated effort across industry, academia, and policymakers to promote responsible AI deployment while ensuring that technological advancements do not come at the expense of long-term environmental sustainability.</p>
</section><section id="sec-sustainable-ai-disposal-phase-17fc" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-disposal-phase-17fc">Disposal Phase</h3>
<p>The disposal phase of AI systems is often overlooked in discussions of sustainability, yet it presents significant environmental challenges. The rapid advancement of AI hardware has led to shorter hardware lifespans, contributing to growing electronic waste (e-waste) and resource depletion. As AI accelerators, GPUs, and high-performance processors become obsolete within a few years, managing their disposal has become a pressing sustainability concern. Unlike traditional computing devices, AI hardware contains complex materials, rare earth elements, and hazardous substances that complicate recycling and waste management efforts. Without effective strategies for repurposing, recycling, or safely disposing of AI hardware, the environmental burden of AI infrastructure will continue to escalate.</p>
<p>The lifespan of AI hardware is relatively short, particularly in data centers where performance efficiency dictates frequent upgrades. On average, GPUs, TPUs, and AI accelerators are replaced every three to five years, as newer, more powerful models enter the market. This rapid turnover results in a constant cycle of hardware disposal, with large-scale AI deployments generating substantial e-waste. Unlike consumer electronics, which may have secondary markets for resale or reuse, AI accelerators often become unviable for commercial use once they are no longer state-of-the-art. The push for ever-faster and more efficient AI models accelerates this cycle, leading to an increasing volume of discarded high-performance computing hardware.</p>
<p>One of the primary environmental concerns with AI hardware disposal is the presence of hazardous materials. AI accelerators contain heavy metals such as lead, cadmium, and mercury, as well as toxic chemical compounds used in semiconductor fabrication. If not properly handled, these materials can leach into soil and water sources, causing long-term environmental and health hazards. The burning of e-waste releases toxic fumes, contributing to air pollution and exposing workers in informal recycling operations to harmful substances. Studies estimate that only 17.4% of global e-waste is properly collected and recycled, leaving the majority to end up in landfills or informal waste processing sites with inadequate environmental protections <span class="citation" data-cites="singh2022disentangling">(<a href="#ref-singh2022disentangling" role="doc-biblioref">Singh and Ogunseitan 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>The complex composition of AI hardware presents significant challenges for recycling. Unlike traditional computing components, which are relatively straightforward to dismantle, AI accelerators incorporate specialized multi-layered circuits, exotic metal alloys, and tightly integrated memory architectures that make material recovery difficult. The disassembly and separation of valuable elements such as gold, palladium, and rare earth metals require advanced recycling technologies that are not widely available. The presence of mixed materials further complicates the process, as some components are chemically bonded or embedded in ways that make extraction inefficient.</p>
<p>Despite these challenges, efforts are being made to develop sustainable disposal solutions for AI hardware. Some manufacturers have begun designing AI accelerators with modular architectures, allowing for easier component replacement and extending the usable lifespan of devices. Research is also underway to improve material recovery processes, making it possible to extract and reuse important elements such as gallium, indium, and tungsten from discarded chips. Emerging techniques such as hydrometallurgical and biometallurgical processing show promise in extracting rare metals with lower environmental impact compared to traditional smelting and refining methods.</p>
<p>The circular economy<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a> model offers a promising approach to mitigating the e-waste crisis associated with AI hardware. Instead of following a linear “use and discard” model, circular economy principles emphasize reuse, refurbishment, and recycling to extend the lifecycle of computing devices. Companies such as Google and Microsoft have launched initiatives to repurpose decommissioned AI hardware for secondary applications, such as running lower-priority machine learning tasks or redistributing functional components to research institutions. These efforts help reduce the overall demand for new semiconductor production while minimizing waste generation.</p>
<div class="no-row-height column-margin column-container"><div id="fn32"><p><sup>32</sup>&nbsp;<strong>Circular Economy</strong>: Economic model that eliminates waste through continual reuse of resources, contrasting with linear “take-make-dispose” models. Popularized by the Ellen MacArthur Foundation in 2010, now embraced by EU policy targeting 65% recycling by 2035. For electronics, this means designing for modularity, repairability, and material recovery. Dell’s Ocean Plastics program and Fairphone’s modular smartphones exemplify circular principles. In AI hardware, circular approaches could extend GPU lifespans from 3-5 years to 8-10 years through component upgrades and secondary use cases.</p></div></div><p>In addition to corporate sustainability initiatives, policy interventions and regulatory frameworks are important in addressing the disposal phase of AI systems. Governments worldwide are beginning to implement extended producer responsibility (EPR) policies, which require technology manufacturers to take accountability for the environmental impact of their products throughout their entire lifecycle. In regions such as the European Union, strict e-waste management regulations mandate that electronic manufacturers participate in certified recycling programs and ensure the safe disposal of hazardous materials. However, enforcement remains inconsistent, and significant gaps exist in global e-waste tracking and management.</p>
<p>The future of AI hardware disposal will depend on advancements in recycling technology, regulatory enforcement, and industry-wide adoption of sustainable design principles. The growing urgency of AI-driven e-waste underscores the need for integrated lifecycle management strategies that account for the full environmental impact of AI infrastructure, from raw material extraction to end-of-life recovery. Without concerted efforts to improve hardware sustainability, the rapid expansion of AI will continue to exert pressure on global resources and waste management systems.</p>
<hr>
<div id="quiz-question-sec-sustainable-ai-semiconductor-life-cycle-5c14" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.1</strong></summary><div>
<ol type="1">
<li>
<p>Which phase of the AI lifecycle is primarily concerned with the computational demands of model training and inference?</p>
<ol type="a">
<li>Design Phase</li>
<li>Manufacturing Phase</li>
<li>Disposal Phase</li>
<li>Use Phase</li>
</ol>
</li>
<li><p>How does Life Cycle Analysis (LCA) help in reducing the environmental impact of AI systems?</p></li>
<li><p>True or False: The manufacturing phase of AI systems has a greater environmental impact than the use phase due to its high energy consumption and waste generation.</p></li>
<li><p>The rapid turnover of AI hardware contributes to growing electronic waste, also known as ____, which poses significant environmental challenges.</p></li>
<li>
<p>Which of the following is a potential strategy to improve the sustainability of AI systems during the use phase?</p>
<ol type="a">
<li>Implementing energy-efficient chip architectures</li>
<li>Utilizing carbon-intensive data centers</li>
<li>Increasing the frequency of hardware upgrades</li>
<li>Extending training times for models</li>
</ol>
</li>
</ol>
<p><a href="#quiz-answer-sec-sustainable-ai-semiconductor-life-cycle-5c14" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section></section><section id="sec-sustainable-ai-implementation-solutions" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-implementation-solutions">Part III: Implementation and Solutions</h2>
<p>Having established the scope of AI’s environmental impact and frameworks for measurement, we turn to concrete strategies for mitigation. Effective sustainable AI requires coordinated action across algorithmic design, infrastructure optimization, policy frameworks, and industry practices. The solutions space spans immediate technical optimizations, medium-term infrastructure changes, and long-term systemic transformations that can reduce AI’s environmental footprint while maintaining technological progress.</p>
<p>Implementation strategies must account for Jevon’s Paradox: efficiency improvements alone may increase overall consumption by making AI more accessible and affordable. Therefore, sustainable AI requires combining technical optimization with usage governance and resource constraints that prevent efficiency gains from being offset by exponential growth in deployment scale.</p>
<section id="sec-sustainable-ai-strategic-framework" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-strategic-framework">Strategic Framework for Sustainable AI Implementation</h3>
<p>Addressing AI’s environmental footprint requires a multi-layered approach that integrates energy-efficient algorithmic design, optimized hardware deployment, sustainable infrastructure operations, and carbon-aware computing strategies. The selection and optimization of AI frameworks themselves play a role in efficiency, involving careful evaluation of computational efficiency and resource utilization patterns. Additionally, AI systems must be designed with lifecycle sustainability in mind, ensuring that models remain efficient throughout their deployment, from training to inference.</p>
<p>A principle that must guide all efforts to mitigate AI’s environmental impact is Jevon’s Paradox<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a>. This paradox, observed by William Stanley Jevons in the 19th century <span class="citation" data-cites="jevons1865coal">(<a href="#ref-jevons1865coal" role="doc-biblioref">Jevons 1865</a>)</span>, states that improvements in technological efficiency can lead to an increase in overall consumption. In the context of AI, even as we develop more energy-efficient models and hardware, the increased accessibility and adoption of AI technologies could lead to a net increase in energy consumption and resource utilization. Therefore, we must approach mitigation strategies with a keen awareness of this potential rebound effect, ensuring that efficiency gains do not inadvertently drive greater consumption. This section explores key strategies for mitigating AI’s environmental impact, beginning with sustainable AI development principles.</p>
<div class="no-row-height column-margin column-container"><div id="fn33"><p><sup>33</sup>&nbsp;<strong>Jevon’s Paradox</strong>: Named after British economist William Stanley Jevons who observed in 1865 that improving coal efficiency actually increased total coal consumption rather than reducing it. Modern examples include LEDs—despite being 85% more efficient than incandescent bulbs, total lighting energy consumption has increased due to expanded usage. In AI, this means that making models 10× more efficient might lead to 100× more AI applications, resulting in net increase in environmental impact.</p></div><div id="ref-jevons1865coal" class="csl-entry" role="listitem">
Jevons, William Stanley. 1865. <em>The Coal Question: An Inquiry Concerning the Progress of the Nation, and the Probable Exhaustion of Our Coal Mines</em>. London: Macmillan; Co. <a href="https://www.econlib.org/library/YPDBooks/Jevons/jvnCQ.html">https://www.econlib.org/library/YPDBooks/Jevons/jvnCQ.html</a>.
</div></div><p>This effect is illustrated in <a href="#fig-jevons-ai" class="quarto-xref">Figure&nbsp;11</a>. As AI systems become more efficient, the cost per unit of computation decreases, whether for language model tokens, computer vision inferences, or recommendation system predictions. In the figure, moving from point A to point B represents a drop in computation cost. However, this price reduction leads to increased usage across all AI applications, as shown by the corresponding shift from point C to point D on the horizontal axis. While there are savings from reduced costs, the total consumption of AI services increases even more rapidly, ultimately resulting in higher overall resource usage and environmental impact. This dynamic highlights the core of Jevon’s Paradox in AI: efficiency alone is not sufficient to guarantee sustainability.</p>
<div id="fig-jevons-ai" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-jevons-ai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="31b86fe8bd59bc321c6290d64caae91e46819dcf.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;11: Jevon’s Paradox: Decreasing computation costs drive increased AI usage, potentially offsetting efficiency gains and leading to higher overall resource consumption; the figure maps this effect, showing how a cost reduction (a to b) fuels demand growth (c to d). This counterintuitive relationship underscores the importance of considering systemic effects when evaluating the environmental impact of AI advancements."><img src="sustainable_ai_files/mediabag/31b86fe8bd59bc321c6290d64caae91e46819dcf.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jevons-ai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: <strong>Jevon’s Paradox</strong>: Decreasing computation costs drive increased AI usage, potentially offsetting efficiency gains and leading to higher overall resource consumption; the figure maps this effect, showing how a cost reduction (a to b) fuels demand growth (c to d). This counterintuitive relationship underscores the importance of considering systemic effects when evaluating the environmental impact of AI advancements.
</figcaption></figure>
</div>
</section><section id="sec-sustainable-ai-practical-implementation-framework" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-practical-implementation-framework">Practical Implementation Framework: From Design to Deployment</h3>
<p>Implementing sustainable AI requires systematic integration of environmental considerations across the entire development lifecycle. This framework spans algorithmic design choices, infrastructure optimization, operational practices, and governance mechanisms that collectively reduce environmental impact while maintaining technical capabilities.</p>
<section id="sec-sustainable-ai-energy-efficient-algorithmic-design" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-energy-efficient-algorithmic-design">Energy-Efficient Algorithmic Design</h4>
<p>Sustainable AI development treats energy efficiency as a design constraint rather than an optimization afterthought. This requires hardware-software co-design approaches that simultaneously optimize algorithmic choices and their hardware implementation for maximum efficiency per unit of computational capability.</p>
</section><section id="sec-sustainable-ai-energyefficient-design-8890" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-energyefficient-design-8890">Energy-Efficient Design</h4>
<p>Many deep learning models rely on billions of parameters, requiring trillions of floating-point operations per second (FLOPS)<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a> during training and inference. While these large models achieve state-of-the-art performance, research indicates that much of their computational complexity is unnecessary. Many parameters contribute little to final predictions, leading to wasteful resource utilization. Effective sustainability requires treating energy efficiency as a design constraint rather than an afterthought, necessitating hardware-software co-design approaches that optimize both algorithmic choices and their hardware implementation simultaneously.</p>
<div class="no-row-height column-margin column-container"><div id="fn34"><p><sup>34</sup>&nbsp;<strong>FLOPS vs FLOPs</strong>: FLOPS (all caps) = Floating-Point Operations Per Second (rate), while FLOPs (mixed case) = total Floating-Point Operations (count). GPT-3 training required 3.1×10²³ FLOPs total, executed on hardware capable of 1.25×10¹⁷ FLOPS. Modern AI accelerators like H100 achieve 2,000 TFLOPS for AI workloads. Each ChatGPT response requires ~10¹² FLOPs—roughly equivalent to your calculator performing one operation per second for 30,000 years. The energy efficiency varies dramatically across hardware: CPUs consume ~100 pJ/FLOP (100 × 10⁻¹² J/FLOP), GPUs achieve ~10 pJ/FLOP, TPUs reach ~1 pJ/FLOP, while specialized AI accelerators approach 0.1 pJ/FLOP—a 1000× efficiency range that defines sustainability opportunities. To mitigate this inefficiency, several optimization techniques have been developed to reduce the computational overhead of AI models while maintaining accuracy.</p></div><div id="fn35"><p><sup>35</sup>&nbsp;<strong>Pruning Technique</strong>: Method for removing unnecessary model components to improve efficiency. Comprehensive coverage in <strong>?@sec-model-optimizations-pruning-2dbe</strong>.</p></div></div><p>One of the most widely used methods for improving energy efficiency is model pruning, an optimization technique that removes unnecessary connections from trained models<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a>. By systematically eliminating redundant weights, pruning reduces both the model size and the number of computations required during inference. Studies show that structured pruning can remove up to 90% of weights in models such as ResNet-50 while maintaining comparable accuracy. This approach allows AI models to operate efficiently on lower-power hardware, making them more suitable for deployment in resource-constrained environments.</p>
<p>Another technique for reducing energy consumption is quantization<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a>, which lowers the numerical precision of computations in AI models. Standard deep learning models typically use 32-bit floating-point precision, but many operations can be performed with 8-bit or even 4-bit integers without significant accuracy loss. The energy efficiency gains from quantization are substantial: 8-bit integer operations consume approximately 16× less energy than 32-bit floating-point operations, while 4-bit operations achieve 64× energy reductions. This hardware-software co-design optimization requires careful coordination between algorithm precision requirements and hardware capabilities. By using lower precision, quantization reduces memory requirements, speeds up inference, and lowers power consumption. For example, NVIDIA’s TensorRT framework applies post-training quantization to deep learning models, achieving a threefold increase in inference speed while maintaining nearly identical accuracy. Similarly, Intel’s Q8BERT demonstrates that quantizing the BERT language model to 8-bit integers can reduce its size by a factor of four with minimal performance degradation <span class="citation" data-cites="zafrir2019q8bert">(<a href="#ref-zafrir2019q8bert" role="doc-biblioref">Zafrir et al. 2019</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn36"><p><sup>36</sup>&nbsp;<strong>Quantization Technique</strong>: Approach for reducing numerical precision in models to improve energy efficiency. Detailed techniques in <strong>?@sec-model-optimizations-numerical-precision-ae60</strong>.</p></div><div id="ref-zafrir2019q8bert" class="csl-entry" role="listitem">
Zafrir, Ofir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. 2019. <span>“Q8BERT: Quantized 8Bit BERT.”</span> In <em>2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS)</em>, 36–39. IEEE; IEEE. <a href="https://doi.org/10.1109/emc2-nips53020.2019.00016">https://doi.org/10.1109/emc2-nips53020.2019.00016</a>.
</div></div><p>A third approach, knowledge distillation, allows large AI models to transfer their learned knowledge to smaller, more efficient models. In this process, a large teacher model trains a smaller student model to approximate its predictions, enabling the student model to achieve competitive performance with significantly fewer parameters. Google’s DistilBERT exemplifies this technique, retaining 97% of the original BERT model’s accuracy while using only 40% of its parameters. Knowledge distillation techniques allow AI practitioners to deploy lightweight models that require less computational power while delivering high-quality predictions.</p>
<p>These optimization techniques represent strategies for sustainable AI development. Comprehensive coverage of these methods requires understanding detailed implementation approaches and performance trade-offs in model optimization techniques and their integration into efficient AI system design.</p>
<p>While these optimization techniques improve efficiency, they also introduce trade-offs. Pruning and quantization can lead to small reductions in model accuracy, requiring fine-tuning to balance performance and sustainability. Knowledge distillation demands additional training cycles, meaning that energy savings are realized during deployment rather than in the training phase. We must consider Jevon’s Paradox: will these efficiency gains lead to a proliferation of AI applications, increasing overall energy consumption? To counteract this, strategies that combine efficiency with limitations on resource usage are necessary. These techniques represent strategies for reducing the energy footprint of AI models without compromising their effectiveness.</p>
</section><section id="sec-sustainable-ai-lifecycleaware-systems-66d8" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-lifecycleaware-systems-66d8">Lifecycle-Aware Systems</h4>
<p>In addition to optimizing individual models, AI systems must be designed with a broader lifecycle-aware perspective. Many AI deployments operate with a short-term mindset, where models are trained, deployed, and then discarded within a few months. This frequent retraining cycle leads to computational waste. By incorporating sustainability considerations into the AI development pipeline, it is possible to extend model lifespan, reduce unnecessary computation, and minimize environmental impact.</p>
<p>An effective way to reduce redundant computation is to limit the frequency of full model retraining. Many production AI systems do not require complete retraining from scratch; instead, they can be updated using incremental learning techniques that adapt existing models to new data. Transfer learning is a widely used approach in which a pre-trained model is fine-tuned on a new dataset, significantly reducing the computational cost compared to training a model from the ground up <span class="citation" data-cites="Raffel2020exploring">(<a href="#ref-Raffel2020exploring" role="doc-biblioref">Narang et al. 2021</a>)</span>. This technique is particularly valuable for domain adaptation, where models trained on large general datasets can be customized for specific applications with minimal retraining. These operational considerations and deployment strategies form core components of the ML operations lifecycle, encompassing systematic approaches to production deployment and maintenance.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Raffel2020exploring" class="csl-entry" role="listitem">
Narang, Sharan, Hyung Won Chung, Yi Tay, Liam Fedus, Thibault Fevry, Michael Matena, Karishma Malkan, et al. 2021. <span>“Do Transformer Modifications Transfer Across Implementations and Applications?”</span> In <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, 21:1–67. 140. Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2021.emnlp-main.465">https://doi.org/10.18653/v1/2021.emnlp-main.465</a>.
</div><div id="ref-Henderson2020towards" class="csl-entry" role="listitem">
Henderson, Peter, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan Jurafsky, and Joelle Pineau. 2020. <span>“Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning.”</span> <em>Journal of Machine Learning Research</em> 21 (248): 1–43. <a href="http://arxiv.org/abs/2002.05651v2">http://arxiv.org/abs/2002.05651v2</a>.
</div></div><p>Another important aspect of lifecycle-aware AI development is the integration of LCA methodologies. LCA provides a systematic framework for quantifying the environmental impact of AI systems at every stage of their lifecycle, from initial training to long-term deployment. Organizations such as MLCommons are actively developing sustainability benchmarks that measure factors such as energy efficiency per inference and carbon emissions per model training cycle <span class="citation" data-cites="Henderson2020towards">(<a href="#ref-Henderson2020towards" role="doc-biblioref">Henderson et al. 2020</a>)</span>. By embedding LCA principles into AI workflows, developers can identify sustainability bottlenecks early in the design process and implement corrective measures before models enter production.</p>
<p>Beyond training efficiency and design evaluation, AI deployment strategies can further enhance sustainability. Cloud-based AI models often rely on centralized data centers, requiring significant energy for data transfer and inference. In contrast, edge computing allows AI models to run directly on end-user devices, reducing the need for constant cloud communication. Deploying AI models on specialized low-power hardware at the edge not only improves latency and privacy but also significantly decreases energy consumption <span class="citation" data-cites="Xu2021edge">(<a href="#ref-Xu2021edge" role="doc-biblioref">Xu et al. 2021</a>)</span>. The technical foundations of these deployment architectures involve complex design principles for efficient edge systems that balance computational requirements with resource constraints.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Xu2021edge" class="csl-entry" role="listitem">
Xu, Xiaolong, Fan Li, Wei Zhang, Liang He, and Ruidong Li. 2021. <span>“Edge Intelligence: Architectures, Challenges, and Applications.”</span> <em>IEEE Internet of Things Journal</em> 8 (6): 4229–49.
</div></div><p>However, Jevon’s Paradox reminds us that optimizing individual stages might not lead to overall sustainability. For example, even if we improve the recyclability of AI hardware, increased production due to greater demand could still lead to resource depletion. Therefore, limiting the production of unneeded hardware is also important. By adopting a lifecycle-aware approach to AI development, practitioners can reduce the environmental impact of AI systems while promoting long-term sustainability.</p>
</section><section id="sec-sustainable-ai-policy-incentives-2814" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-policy-incentives-2814">Policy and Incentives</h4>
<p>While technical optimizations play a important role in mitigating AI’s environmental impact, they must be reinforced by policy incentives and industry-wide commitments to sustainability. Several emerging initiatives aim to integrate sustainability principles into AI development at scale.</p>
<p>One promising approach is carbon-aware AI scheduling, where AI workloads are dynamically allocated based on the availability of renewable energy. Companies such as Google have developed scheduling algorithms that shift AI training jobs to times when wind or solar power is abundant, reducing reliance on fossil fuels <span class="citation" data-cites="Patterson2022carbonaware">(<a href="#ref-Patterson2022carbonaware" role="doc-biblioref">Patterson, Gonzalez, Le, et al. 2022</a>)</span>. These strategies are particularly effective in large-scale data centers, where peak energy demand can be aligned with periods of low-carbon electricity generation.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Patterson2022carbonaware" class="csl-entry" role="listitem">
Patterson, David, Joseph Gonzalez, Quoc Le, Maud Texier, and Jeff Dean. 2022. <span>“Carbon-Aware Computing for Sustainable AI.”</span> <em>Communications of the ACM</em> 65 (11): 50–58.
</div></div><p>Benchmarks and leaderboards focused on sustainability are also gaining traction within the AI community. The <a href="https://ml.energy/leaderboard">ML.ENERGY Leaderboard</a>, for example, ranks AI models based on energy efficiency and carbon footprint, encouraging researchers to optimize models not only for performance but also for sustainability. Similarly, MLCommons is working on standardized benchmarks that evaluate AI efficiency in terms of power consumption per inference, providing a transparent framework for comparing the environmental impact of different models. These sustainability metrics complement traditional performance benchmarks, creating comprehensive evaluation frameworks that account for both capability and environmental impact through systematic measurement approaches.</p>
<p>Regulatory efforts are beginning to shape the future of sustainable AI. The European Union’s Sustainable Digital Markets Act has introduced guidelines for transparent AI energy reporting, requiring tech companies to disclose the carbon footprint of their AI operations. As regulatory frameworks evolve, organizations will face increasing pressure to integrate sustainability considerations into their AI development practices <span class="citation" data-cites="EuropeanCommission2023sustainability">(<a href="#ref-EuropeanCommission2023sustainability" role="doc-biblioref">Commission 2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-EuropeanCommission2023sustainability" class="csl-entry" role="listitem">
Commission, European. 2023. <span>“Sustainable Digital Markets Act: Environmental Transparency in AI.”</span>
</div></div><p>By aligning technical optimizations with industry incentives and policy regulations, AI practitioners can ensure that sustainability becomes an integral component of AI development. The shift toward energy-efficient models, lifecycle-aware design, and transparent environmental reporting will be important in mitigating AI’s ecological impact while continuing to drive innovation.</p>
</section></section><section id="sec-sustainable-ai-infrastructure-optimization-fddc" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-infrastructure-optimization-fddc">Infrastructure Optimization</h3>
<p>The sustainability of AI systems is shaped not only by the efficiency of machine learning models but also by the infrastructure that powers them. While algorithmic improvements such as pruning, quantization, and knowledge distillation reduce computational requirements at the model level, the broader energy footprint of AI is largely dictated by how and where these computations are performed. Large-scale AI workloads are executed in cloud data centers, which house thousands of interconnected servers running continuously to support machine learning training and inference. These facilities consume large amounts of electricity, with some hyperscale data centers drawing over 100 megawatts of power, an amount comparable to the energy demand of a small city <span class="citation" data-cites="Jones2021datacenters">(<a href="#ref-Jones2021datacenters" role="doc-biblioref">Jones, Johnson, and Montgomery 2021</a>)</span>. In addition to direct energy consumption, the cooling requirements of AI infrastructure introduce sustainability challenges. Data centers must dissipate significant amounts of heat generated by AI accelerators, often relying on energy-intensive air conditioning or water-based cooling systems. As AI adoption continues to expand, these infrastructure-level considerations will play an increasingly central role in determining the overall environmental impact of machine learning systems.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Jones2021datacenters" class="csl-entry" role="listitem">
Jones, Nicholas P., Mark Johnson, and Claire Montgomery. 2021. <span>“The Environmental Impact of Data Centers: Challenges and Sustainable Solutions.”</span> <em>Energy Reports</em> 7: 4381–92.
</div></div><p>Addressing these challenges requires a shift toward energy-efficient AI infrastructure. The integration of renewable energy into cloud data centers, the adoption of advanced cooling strategies, and the development of carbon-aware workload scheduling can significantly reduce the carbon footprint of AI operations. By designing AI infrastructure to align with sustainability principles, we can minimize the environmental cost of computation while maintaining the performance required for modern machine learning workloads. This section explores the key approaches to optimizing AI infrastructure, focusing on energy-efficient data centers, dynamic workload scheduling based on carbon intensity, and AI-driven cooling strategies. These advancements offer a pathway toward more sustainable AI deployment, ensuring that the growth of machine learning does not come at the expense of long-term environmental responsibility.</p>
<section id="sec-sustainable-ai-green-data-centers-27e7" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-green-data-centers-27e7">Green Data Centers</h4>
<p>The increasing computational demands of AI have made data centers one of the largest consumers of electricity in the digital economy. Large-scale cloud data centers provide the infrastructure necessary for training and deploying machine learning models, but their energy consumption is substantial. A single hyperscale data center can consume over 100 megawatts of power, a level comparable to the electricity usage of a small city<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a>. Without intervention, the continued growth of AI workloads threatens to push the energy consumption of data centers beyond sustainable levels.</p>
<div class="no-row-height column-margin column-container"><div id="fn37"><p><sup>37</sup>&nbsp;<strong>Power Usage Effectiveness</strong>: Data center efficiency is measured by PUE (Power Usage Effectiveness)—total facility power divided by IT equipment power. Industry average PUE is 1.67 (67% overhead for cooling/infrastructure), but leading hyperscalers achieve 1.1-1.2. Google’s best data centers reach PUE of 1.08, meaning only 8% energy overhead. Each 0.1 PUE improvement saves millions annually in electricity costs. The industry must adopt strategies to optimize power efficiency, integrate renewable energy sources, and improve cooling mechanisms to mitigate the environmental impact of AI infrastructure.</p></div><div id="fn38"><p><sup>38</sup>&nbsp;<strong>Google’s Carbon-Free Commitment</strong>: Google achieved carbon neutrality in 2007 and has been carbon neutral for 15 years, but 24/7 carbon-free energy is more ambitious—requiring real-time matching of energy consumption with clean generation. Currently at 64% carbon-free energy globally. Denmark data centers run on 100% wind power, while others still rely on grid renewables certificates. This requires $15 billion+ investment in clean energy projects worldwide.</p></div></div><p>One of the most promising approaches to reducing data center emissions is the transition to renewable energy. Major cloud providers, including Google, Microsoft, and Amazon Web Services, have committed to powering their data centers with renewable energy, but implementation challenges remain. Unlike fossil fuel plants, which provide consistent electricity output, renewable sources such as wind and solar are intermittent, with generation levels fluctuating throughout the day. To address this variability, AI infrastructure must incorporate energy storage solutions, such as large-scale battery deployments, and implement intelligent scheduling mechanisms that shift AI workloads to times when renewable energy availability is highest. Google, for example, has set a goal to operate its data centers on 24/7 carbon-free energy by 2030<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a>, ensuring that every unit of electricity consumed is matched with renewable generation rather than relying on carbon offsets alone.</p>
<p>Cooling systems represent another major contributor to the energy footprint of data centers, often accounting for 30-40% of total electricity consumption<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a>. Traditional cooling methods rely on air conditioning units and mechanical chillers, both of which require significant power and water resources.</p>
<div class="no-row-height column-margin column-container"><div id="fn39"><p><sup>39</sup>&nbsp;<strong>Data Center Cooling Costs</strong>: Cooling consumes 38% of total data center energy on average. A typical 10 MW data center spends $3.8 million annually on cooling electricity. Google’s machine learning optimization reduced cooling energy by 40%, saving $150+ million globally. Liquid cooling can be 3,000x more efficient than air cooling for high-density AI workloads, reducing cooling energy from 40% to under 10% of total consumption. To improve efficiency, data centers are adopting alternative cooling strategies that reduce energy waste. Liquid cooling, which transfers heat away from AI accelerators using specially designed coolant systems, is significantly more effective than traditional air cooling and is now being deployed in high-density computing clusters. Free-air cooling, which utilizes natural airflow instead of mechanical refrigeration, has also been adopted in temperate climates, where external conditions allow for passive cooling. Microsoft has taken this a step further by deploying underwater data centers that use the surrounding ocean as a natural cooling mechanism, reducing the need for active temperature regulation.</p></div></div><p>Beyond hardware-level optimizations, AI itself is being used to improve the energy efficiency of data center operations. DeepMind has developed machine learning algorithms capable of dynamically adjusting cooling parameters based on real-time sensor data. These AI-powered cooling systems analyze temperature, humidity, and fan speeds, making continuous adjustments to optimize energy efficiency. When deployed in Google’s data centers, DeepMind’s system achieved a 40 percent reduction in cooling energy consumption, demonstrating the potential of AI to enhance the sustainability of the infrastructure that supports machine learning workloads.</p>
<p>However, Jevon’s Paradox suggests that even highly efficient data centers could contribute to increased consumption if they allow a massive expansion of AI-driven services. Optimizing the energy efficiency of data centers is important to reducing the environmental impact of AI, but efficiency alone is not enough. We must also consider strategies for limiting the growth of data center capacity. The integration of renewable energy, the adoption of advanced cooling solutions, and the use of AI-driven optimizations can significantly decrease the carbon footprint of AI infrastructure. As AI continues to scale, these innovations will play a central role in ensuring that machine learning remains aligned with sustainability goals.</p>
</section><section id="sec-sustainable-ai-carbonaware-scheduling-77d6" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-carbonaware-scheduling-77d6">Carbon-Aware Scheduling</h4>
<p>Beyond improvements in hardware and cooling systems, optimizing when and where AI workloads are executed is another important strategy for reducing AI’s environmental impact. The electricity used to power data centers comes from energy grids that fluctuate in carbon intensity based on the mix of power sources available at any given time. Fossil fuel-based power plants supply a significant portion of global electricity, but the share of renewable energy varies by region and time of day. Without optimization, AI workloads may be executed when carbon-intensive energy sources dominate the grid, unnecessarily increasing emissions. By implementing carbon-aware scheduling, AI computations can be dynamically shifted to times and locations where low-carbon energy is available, significantly reducing emissions without sacrificing performance.</p>
<p>Google has pioneered one of the most advanced implementations of carbon-aware computing in its cloud infrastructure. In 2020, the company introduced a scheduling system<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a> that delays non-urgent AI tasks until times when renewable energy sources such as solar or wind power are more abundant. This approach allows AI workloads to align with the natural variability of clean energy availability, reducing reliance on fossil fuels while maintaining high computational efficiency. Google has further extended this strategy by geographically distributing AI workloads, moving computations to data centers in regions where clean energy is more accessible. By shifting large-scale AI training jobs from fossil fuel-heavy grids to low-carbon power sources, the company has demonstrated that significant emissions reductions can be achieved through intelligent workload placement.</p>
<div class="no-row-height column-margin column-container"><div id="fn40"><p><sup>40</sup>&nbsp;<strong>Google Carbon-Aware Scheduling Results</strong>: Google’s carbon-intelligent computing platform achieved 15% reduction in hourly carbon footprint by shifting workloads within regions. Globally shifting workloads between data centers achieved 40% reduction. The system processes 95 billion search queries daily while optimizing for grid carbon intensity. Non-urgent tasks like batch training can shift 70% of workload to lower-carbon time periods, reducing emissions equivalent to taking 50,000 cars off the road annually.</p></div></div><p>The potential for carbon-aware scheduling extends beyond hyperscale cloud providers. Companies that rely on AI infrastructure can integrate carbon intensity metrics into their own computing pipelines, making informed decisions about when to run machine learning jobs. Microsoft’s sustainability-aware cloud computing initiative allows organizations to select carbon-optimized virtual machines, ensuring that workloads are executed with the lowest possible emissions. Research efforts are also underway to develop open-source carbon-aware scheduling frameworks, enabling a broader range of AI practitioners to incorporate sustainability into their computing strategies.</p>
<p>The effectiveness of carbon-aware AI scheduling depends on accurate real-time data about grid emissions. Electricity providers and sustainability organizations have begun publishing grid carbon intensity data through publicly available APIs, allowing AI systems to dynamically respond to changes in energy supply. For instance, the Electricity Maps API provides real-time CO₂ emissions data for power grids worldwide<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a>, enabling AI infrastructure to adjust computational workloads based on carbon availability. As access to grid emissions data improves, carbon-aware computing will become a scalable and widely adoptable solution for reducing the environmental impact of AI operations.</p>
<div class="no-row-height column-margin column-container"><div id="fn41"><p><sup>41</sup>&nbsp;<strong>Real-Time Grid Carbon Intensity</strong>: Grid carbon intensity varies dramatically—from 50g CO₂/kWh in nuclear-heavy France to 820g/kWh in coal-dependent Poland. In Texas, intensity fluctuates 10x daily (150-1,500g/kWh) based on wind generation. The Electricity Maps API serves 50+ million requests daily to allow carbon-aware computing. WattTime API provides marginal emissions data showing which power plants turn on/off next, allowing 2-5x better carbon optimization than average intensity.</p></div></div><p>By shifting AI computations to times and places with cleaner energy sources, carbon-aware scheduling represents a powerful tool for making AI infrastructure more sustainable. Unlike hardware-based optimizations that require physical upgrades, scheduling improvements can be implemented through software, offering an immediate and cost-effective pathway to emissions reductions. As more organizations integrate carbon-aware scheduling into their AI workflows, the cumulative impact on reducing global AI-related carbon emissions could be substantial.</p>
<p>While these strategies apply broadly to AI workloads, inference operations present unique sustainability challenges and opportunities. Unlike training, which represents a one-time energy cost, inference constitutes an ongoing and growing energy demand as AI applications scale worldwide. Cloud providers are increasingly adopting carbon-aware scheduling specifically for inference workloads, dynamically shifting these operations to regions powered by abundant renewable energy <span class="citation" data-cites="radovanovic2022carbon">(<a href="#ref-radovanovic2022carbon" role="doc-biblioref">Alvim et al. 2022</a>)</span>. However, as shown in <a href="#fig-europe_energy_grid" class="quarto-xref">Figure&nbsp;12</a>, the variability of renewable energy production presents significant challenges. The European grid data illustrates how renewable sources fluctuate throughout the day—solar energy peaks at midday, while wind energy shows distinct peaks in mornings and evenings. Currently, fossil and coal-based generation methods supplement energy needs when renewables fall short.</p>
<div class="no-row-height column-margin column-container"><div id="ref-radovanovic2022carbon" class="csl-entry" role="listitem">
Alvim, Mário S., Konstantinos Chatzikokolakis, Yusuke Kawamoto, and Catuscia Palamidessi. 2022. <span>“Information Leakage Games: Exploring Information as a Utility Function.”</span> <em>ACM Transactions on Privacy and Security</em> 25 (3): 1–36. <a href="https://doi.org/10.1145/3517330">https://doi.org/10.1145/3517330</a>.
</div></div><div id="fig-europe_energy_grid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-europe_energy_grid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/europe_energy_grid.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;12: European Energy Mix: Renewable energy sources exhibit significant temporal variability, necessitating fossil fuel supplementation to meet consistent demand. Understanding this fluctuation is important for effectively scheduling AI workloads to periods of high renewable energy availability and minimizing carbon emissions. Source: Uenergy charts."><img src="images/png/europe_energy_grid.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-europe_energy_grid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: <strong>European Energy Mix</strong>: Renewable energy sources exhibit significant temporal variability, necessitating fossil fuel supplementation to meet consistent demand. Understanding this fluctuation is important for effectively scheduling AI workloads to periods of high renewable energy availability and minimizing carbon emissions. Source: Uenergy charts.
</figcaption></figure>
</div>
<p>To fully use carbon-aware scheduling for AI inference workloads, innovation in energy storage solutions is important for consistent renewable energy use. The base energy load is currently met with nuclear energy—a constant source that produces no direct carbon emissions but lacks the flexibility to accommodate renewable energy variability. Tech companies like Microsoft have shown interest in nuclear energy to power their data centers<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a>, as their more constant demand profile (compared to residential use) aligns well with nuclear generation characteristics.</p>
<div class="no-row-height column-margin column-container"><div id="fn42"><p><sup>42</sup>&nbsp;<strong>Nuclear Power for AI Data Centers</strong>: Microsoft partnered with Helion Energy for fusion power by 2028, signing the first commercial fusion agreement. Amazon invested $500M in small modular reactors (SMRs) for data centers. Google is exploring 24/7 nuclear partnerships with Kairos Power. Nuclear provides 20% of U.S. electricity with 12g CO₂/kWh lifecycle emissions versus 820-1,050g for coal. However, new nuclear costs $150-200/MWh versus $20-40 for renewables plus storage.</p></div><div id="ref-gholami2021survey" class="csl-entry" role="listitem">
Gholami, Amir et al. 2021. <span>“A Survey of Quantization Methods for Efficient Neural Network Inference.”</span> <em>IEEE Transactions on Neural Networks and Learning Systems</em> 32 (10): 4562–81. <a href="https://doi.org/10.1109/TNNLS.2021.3088493">https://doi.org/10.1109/TNNLS.2021.3088493</a>.
</div><div id="ref-hinton2015distilling" class="csl-entry" role="listitem">
Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. 2015. <span>“Distilling the Knowledge in a Neural Network.”</span> <em>arXiv Preprint arXiv:1503.02531</em>, March. <a href="http://arxiv.org/abs/1503.02531v1">http://arxiv.org/abs/1503.02531v1</a>.
</div></div><p>Beyond scheduling, optimizing inference sustainability requires complementary hardware and software innovations. Model quantization techniques allow lower-precision arithmetic to significantly cut power consumption without sacrificing accuracy <span class="citation" data-cites="gholami2021survey">(<a href="#ref-gholami2021survey" role="doc-biblioref">Gholami et al. 2021</a>)</span>. Knowledge distillation methods allow compact, energy-efficient models to replicate the performance of larger, resource-intensive networks <span class="citation" data-cites="hinton2015distilling">(<a href="#ref-hinton2015distilling" role="doc-biblioref">Hinton, Vinyals, and Dean 2015</a>)</span>. Coupled with specialized inference accelerators like Google’s TPUs, these approaches substantially reduce inference’s environmental impact.</p>
<p>Software frameworks specifically designed for energy efficiency also play a important role. Energy-aware AI frameworks, such as Zeus <span class="citation" data-cites="jie2023zeus">(<a href="#ref-jie2023zeus" role="doc-biblioref">You, Chung, and Chowdhury 2023</a>)</span> and Perseus <span class="citation" data-cites="jaewon2023perseus">(<a href="#ref-jaewon2023perseus" role="doc-biblioref">Chung et al. 2023</a>)</span><a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a>, balance computational speed and power efficiency during both training and inference. These platforms optimize model execution by analyzing trade-offs between speed and energy consumption, facilitating widespread adoption of energy-efficient AI strategies, particularly for inference operations that must run continuously at scale.</p>
<div class="no-row-height column-margin column-container"><div id="ref-jie2023zeus" class="csl-entry" role="listitem">
You, Jie, Jae-Won Chung, and Mosharaf Chowdhury. 2023. <span>“Zeus: Understanding and Optimizing GPU Energy Consumption of DNN Training.”</span> In <em>20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)</em>, 119–39. Boston, MA: USENIX Association. <a href="https://www.usenix.org/conference/nsdi23/presentation/you">https://www.usenix.org/conference/nsdi23/presentation/you</a>.
</div><div id="ref-jaewon2023perseus" class="csl-entry" role="listitem">
Chung, Jae-Won, Yile Gu, Insu Jang, Luoxi Meng, Nikhil Bansal, and Mosharaf Chowdhury. 2023. <span>“Reducing Energy Bloat in Large Model Training.”</span> <em>ArXiv Preprint</em> abs/2312.06902 (December). <a href="http://arxiv.org/abs/2312.06902v3">http://arxiv.org/abs/2312.06902v3</a>.
</div><div id="fn43"><p><sup>43</sup>&nbsp;<strong>Energy-Aware AI Frameworks</strong>: Zeus framework achieves 75% energy savings on BERT training by automatically finding optimal energy-performance trade-offs. Perseus reduces GPU memory usage by 50% through dynamic batching, lowering energy consumption proportionally. CodeCarbon automatically tracks emissions, revealing that training can vary 10-100x in energy usage depending on optimization settings. These tools democratize energy optimization beyond just hyperscale companies.</p></div></div></section><section id="sec-sustainable-ai-aidriven-thermal-optimization-77fe" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-aidriven-thermal-optimization-77fe">AI-Driven Thermal Optimization</h4>
<p>Cooling systems are one of the most energy-intensive components of AI infrastructure, often accounting for 30-40% of total data center electricity consumption. As AI workloads become more computationally demanding, the heat generated by high-performance accelerators, such as GPUs and TPUs, continues to increase. Without efficient cooling solutions, data centers must rely on power-hungry air conditioning systems or water-intensive thermal management strategies, both of which contribute to AI’s overall environmental footprint. To address this challenge, AI-driven cooling optimization has emerged as a powerful strategy for improving energy efficiency while maintaining reliable operations.</p>
<p>DeepMind has demonstrated the potential of AI-driven cooling by deploying machine learning models to optimize temperature control in Google’s data centers. Traditional cooling systems rely on fixed control policies, making adjustments based on predefined thresholds for temperature and airflow. However, these rule-based systems often operate inefficiently, consuming more energy than necessary. By contrast, DeepMind’s AI-powered cooling system continuously analyzes real-time sensor data, including temperature, humidity, cooling pump speeds, and fan activity, to identify the most energy-efficient configuration for a given workload. Using deep reinforcement learning, the system dynamically adjusts cooling settings to minimize energy consumption while ensuring that computing hardware remains within safe operating temperatures.</p>
<p>When deployed in production, DeepMind’s AI-driven cooling system achieved a 40% reduction in cooling energy usage, leading to an overall 15% reduction in total data center power consumption. This level of efficiency improvement demonstrates how AI itself can be used to mitigate the environmental impact of machine learning infrastructure. The success of DeepMind’s system has inspired further research into AI-driven cooling, with other cloud providers exploring similar machine learning-based approaches to dynamically optimize thermal management.</p>
<p>Beyond AI-driven control systems, advances in liquid cooling and immersion cooling are further improving the energy efficiency of AI infrastructure. Unlike traditional air cooling, which relies on the circulation of cooled air through server racks, liquid cooling transfers heat directly away from high-performance AI chips using specially designed coolants. This approach significantly reduces the energy required for heat dissipation, allowing data centers to operate at higher densities with lower power consumption. Some facilities have taken this concept even further with immersion cooling, where entire server racks are submerged in non-conductive liquid coolants. This technique eliminates the need for traditional air-based cooling systems entirely, drastically cutting down on electricity usage and water consumption.</p>
<p>Microsoft has also explored innovative cooling solutions, deploying underwater data centers that take advantage of natural ocean currents to dissipate heat. By placing computing infrastructure in sealed submersible enclosures, Microsoft has demonstrated that ocean-based cooling can reduce power usage while extending hardware lifespan due to the controlled and stable underwater environment. While such approaches are still experimental, they highlight the growing interest in alternative cooling technologies that can make AI infrastructure more sustainable.</p>
<p>AI-driven cooling and thermal management represent an immediate and scalable opportunity for reducing the environmental impact of AI infrastructure. Unlike major hardware upgrades, which require capital-intensive investment, software-based cooling optimizations can be deployed rapidly across existing data centers. By leveraging AI to enhance cooling efficiency, in combination with emerging liquid and immersion cooling technologies, the industry can significantly reduce energy consumption, lower operational costs, and contribute to the long-term sustainability of AI systems.</p>
</section></section><section id="sec-sustainable-ai-addressing-full-environmental-footprint-b7f6" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-addressing-full-environmental-footprint-b7f6">Addressing Full Environmental Footprint</h3>
<p>As AI systems continue to scale, efforts to mitigate their environmental impact have largely focused on improving energy efficiency in model design and optimizing data center infrastructure. While these advancements are important, they only address part of the problem. AI’s environmental impact extends far beyond operational energy use, encompassing everything from the water consumption in semiconductor manufacturing to the growing burden of electronic waste. A truly sustainable AI ecosystem must account for the full life cycle of AI hardware and software, integrating sustainability at every stage—from material sourcing to disposal.</p>
<p>Earlier in this chapter, we explored the LCA of AI systems, highlighting the substantial carbon emissions, water consumption, and material waste associated with AI hardware manufacturing and deployment. Many of these environmental costs are embedded in the supply chain and do not appear in operational energy reports, leading to an incomplete picture of AI’s true sustainability. Moreover, data centers remain water-intensive, with cooling systems consuming millions of gallons per day, and AI accelerators are often refreshed on short life cycles, leading to mounting e-waste.</p>
<p>This section builds on those discussions by examining how AI’s broader environmental footprint can be reduced. We explore strategies to mitigate AI’s supply chain impact, curb water consumption, and extend hardware longevity. Moving beyond optimizing infrastructure, this approach takes a holistic view of AI sustainability, ensuring that improvements are not just localized to energy efficiency but embedded throughout the entire AI ecosystem.</p>
<section id="sec-sustainable-ai-revisiting-life-cycle-impact-c29e" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-revisiting-life-cycle-impact-c29e">Revisiting Life Cycle Impact</h4>
<p>AI’s environmental footprint extends far beyond electricity consumption during model training and inference. The full life cycle of AI systems, including hardware manufacturing and disposal, contributes significantly to global carbon emissions, resource depletion, and electronic waste. Earlier in this chapter, we examined the LCA of AI hardware, which revealed that emissions are not solely driven by power consumption but also by the materials and processes involved in fabricating AI accelerators, storage devices, and networking infrastructure.</p>
<p>One of the most striking findings from LCA studies is the embodied carbon<a href="#fn44" class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a> cost of AI hardware. Unlike operational emissions, which can be reduced by shifting to cleaner energy sources, embodied emissions result from the raw material extraction, semiconductor fabrication, and supply chain logistics that precede an AI accelerator’s deployment.</p>
<div class="no-row-height column-margin column-container"><div id="fn44"><p><sup>44</sup>&nbsp;<strong>Embodied Carbon</strong>: Carbon emissions from manufacturing, transportation, and disposal phases of a product—distinct from operational emissions during use. For AI hardware, embodied carbon includes mining rare earth elements, semiconductor fabrication, packaging, and shipping. A single NVIDIA H100 GPU embodies 300-500 kg CO₂ before first use—equivalent to 1,000-1,600 miles of driving. For comparison, the GPU’s 700W power consumption generates 300 kg CO₂ annually (assuming average U.S. grid), meaning manufacturing emissions equal 1-2 years of operation. Research indicates that manufacturing emissions alone can account for up to 30% of an AI system’s total carbon footprint, with this number potentially growing as data centers improve their reliance on renewable energy sources.</p></div></div><p>Moreover, AI’s water consumption has often been overlooked in sustainability discussions. Semiconductor fabrication plants, in which AI accelerators are produced, are among the most water-intensive industrial facilities in the world, consuming millions of gallons daily for wafer cleaning and chemical processing. Data centers, too, rely on large amounts of water for cooling, with some hyperscale facilities using as much as 450,000 gallons per day—a number that continues to rise as AI workloads become more power-dense. Given that many of the world’s chip manufacturing hubs are located in water-stressed regions, such as Taiwan and Arizona, AI’s dependence on water raises serious sustainability concerns.</p>
<p>Beyond emissions and water use, AI hardware also contributes to a growing e-waste problem. The rapid evolution of AI accelerators has led to short hardware refresh cycles, where GPUs and TPUs are frequently replaced with newer, more efficient versions. While improving efficiency is important, discarding functional hardware after only a few years leads to unnecessary electronic waste and resource depletion. Many AI chips contain rare earth metals and toxic components, which, if not properly recycled, can contribute to environmental pollution.</p>
<p>Mitigating AI’s environmental impact requires addressing these broader challenges—not just through energy efficiency improvements but by rethinking AI’s hardware life cycle, reducing water-intensive processes, and developing sustainable recycling practices. In the following sections, we explore strategies to tackle these issues head-on, ensuring that AI’s progress aligns with long-term sustainability goals.</p>
</section><section id="sec-sustainable-ai-mitigating-supply-chain-impact-786c" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-mitigating-supply-chain-impact-786c">Mitigating Supply Chain Impact</h4>
<p>Addressing AI’s environmental impact requires intervention at the supply chain level, where significant emissions, resource depletion, and waste generation occur before AI hardware even reaches deployment. While much of the discussion around AI sustainability focuses on energy efficiency in data centers, the embodied carbon emissions from semiconductor fabrication, raw material extraction, and hardware transportation represent a substantial and often overlooked portion of AI’s total footprint. These supply chain emissions are difficult to offset, making it important to develop strategies that reduce their impact at the source.</p>
<p>One of the primary concerns is the carbon intensity of semiconductor manufacturing. Fabricating AI accelerators such as GPUs, TPUs, and custom ASICs requires extreme precision and involves processes such as EUV lithography, chemical vapor deposition, and ion implantation, each of which consumes vast amounts of electricity. Since many semiconductor manufacturing hubs operate in regions where grid electricity is still predominantly fossil-fuel-based, the energy demands of chip fabrication contribute significantly to AI’s carbon footprint. Research suggests that semiconductor fabrication alone can account for up to 30% of an AI system’s total emissions, underscoring the need for more sustainable manufacturing processes.</p>
<p>Beyond carbon emissions, AI’s reliance on rare earth elements and important minerals presents additional sustainability challenges. High-performance AI hardware depends on materials such as gallium, neodymium, and cobalt, which are important for producing efficient and powerful computing components. However, extracting these materials is highly resource-intensive and often results in toxic waste, deforestation, and habitat destruction. The environmental cost is compounded by geopolitical factors, as over 90% of the world’s rare earth refining capacity is controlled by China, creating vulnerabilities in AI’s global supply chain. Ensuring responsible sourcing of these materials is important to reducing AI’s ecological and social impact.</p>
<p>Several approaches can mitigate the environmental burden of AI’s supply chain. Reducing the energy intensity of chip manufacturing is one avenue, with some semiconductor manufacturers exploring low-energy fabrication processes and renewable-powered production facilities. Another approach focuses on extending the lifespan of AI hardware, as frequent hardware refresh cycles contribute to unnecessary waste. AI accelerators are often designed for peak training performance but remain viable for inference workloads long after they are retired from high-performance computing clusters. Repurposing older AI chips for less computationally intensive tasks, rather than discarding them outright, could significantly reduce the frequency of hardware replacement.</p>
<p>Recycling and closed-loop supply chains also play a important role in making AI hardware more sustainable. Recovering and refining valuable materials from retired GPUs, TPUs, and ASICs can reduce reliance on virgin resource extraction while minimizing e-waste. Industry-wide recycling initiatives, combined with hardware design that prioritizes recyclability, could significantly improve AI’s long-term sustainability.</p>
<p>Prioritizing supply chain sustainability in AI is not just an environmental necessity but also an opportunity for innovation. By integrating energy-efficient fabrication, responsible material sourcing, and circular hardware design, the AI industry can take meaningful steps toward reducing its environmental impact before these systems ever reach operation. These efforts, combined with continued advances in energy-efficient AI computing, will be important to ensuring that AI’s growth does not come at an unsustainable ecological cost.</p>
</section><section id="sec-sustainable-ai-reducing-water-resource-consumption-94b9" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-reducing-water-resource-consumption-94b9">Reducing Water and Resource Consumption</h4>
<p>Mitigating AI’s environmental impact requires direct action to reduce its water consumption and resource intensity. AI’s reliance on semiconductor fabrication and data centers creates significant strain on water supplies and important materials, particularly in regions already facing resource scarcity. Unlike carbon emissions, which can be offset through renewable energy, water depletion and material extraction have direct, localized consequences, making it important to integrate sustainability measures at the design and operational levels.</p>
<p>One of the most effective strategies for reducing AI’s water footprint is improving water recycling in semiconductor fabrication. Leading manufacturers are implementing closed-loop water systems, which allow fabs to reuse and treat water rather than continuously consuming fresh supplies. Companies such as Intel and TSMC have already developed advanced filtration and reclamation processes that recover over 80% of the water used in chip production. Expanding these efforts across the industry is important for minimizing the impact of AI hardware manufacturing.</p>
<p>Similarly, data centers can reduce water consumption by optimizing cooling systems. Many hyperscale facilities still rely on evaporative cooling, which consumes vast amounts of water. Transitioning to direct-to-chip liquid cooling or air-based cooling technologies can significantly reduce water use. In regions with water scarcity, some operators have begun using wastewater or desalinated water for cooling rather than drawing from potable sources. These methods help mitigate the environmental impact of AI infrastructure while maintaining efficient operation.</p>
<p>On the materials side, reducing AI’s dependency on rare earth metals and important minerals is important for long-term sustainability. While some materials, such as silicon, are abundant, others, including gallium, neodymium, and cobalt, are subject to geopolitical constraints and environmentally damaging extraction methods. Researchers are actively exploring alternative materials and low-waste manufacturing processes to reduce reliance on these limited resources. Additionally, recycling programs for AI accelerators and other computing hardware can recover valuable materials, reducing the need for virgin extraction.</p>
<p>Beyond individual mitigation efforts, industry-wide collaboration is necessary to develop standards for responsible water use, material sourcing, and recycling programs. Governments and regulatory bodies can also incentivize sustainable practices by enforcing water conservation mandates, responsible mining regulations, and e-waste recycling requirements. By prioritizing these mitigation strategies, the AI industry can work toward minimizing its ecological footprint while continuing to advance technological progress.</p>
</section><section id="sec-sustainable-ai-systemic-sustainability-approaches-ba04" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-systemic-sustainability-approaches-ba04">Systemic Sustainability Approaches</h4>
<p>Mitigating AI’s environmental impact requires more than isolated optimizations—it demands a systemic shift toward sustainable AI development. Addressing the long-term sustainability of AI means integrating circular economy principles, establishing regulatory policies, and fostering industry-wide collaboration to ensure that sustainability is embedded into the AI ecosystem from the ground up.</p>
<p>Jevon’s Paradox highlights the limitations of focusing solely on individual efficiency improvements. We need systemic solutions that address the broader drivers of AI consumption. This includes policies that promote sustainable AI practices, incentives for responsible resource usage, and public awareness campaigns that encourage mindful AI consumption.</p>
<p>One of the most effective ways to achieve lasting sustainability is by aligning AI development with circular economy principles. Unlike the traditional linear model of “build, use, discard,” a circular approach prioritizes reuse, refurbishment, and recycling to extend the lifespan of AI hardware <span class="citation" data-cites="Stahel_2016">(<a href="#ref-Stahel_2016" role="doc-biblioref">Stahel 2016</a>)</span>. Manufacturers and cloud providers can adopt modular hardware designs, allowing individual components, including memory and accelerators, to be upgraded without replacing entire servers. In addition, AI hardware should be designed with recyclability in mind, ensuring that valuable materials can be extracted and reused instead of contributing to electronic waste.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Stahel_2016" class="csl-entry" role="listitem">
Stahel, Walter R. 2016. <span>“The Circular Economy.”</span> <em>Nature</em> 531 (7595): 435–38. <a href="https://doi.org/10.1038/531435a">https://doi.org/10.1038/531435a</a>.
</div><div id="ref-Masanet_2020" class="csl-entry" role="listitem">
Masanet, Eric, Arman Shehabi, Nuoa Lei, Sarah Smith, and Jonathan Koomey. 2020a. <span>“Recalibrating Global Data Center Energy-Use Estimates.”</span> <em>Science</em> 367 (6481): 984–86. <a href="https://doi.org/10.1126/science.aba3758">https://doi.org/10.1126/science.aba3758</a>.
</div></div><p>Regulatory frameworks also play a important role in enforcing sustainability standards. Governments can introduce carbon transparency mandates, requiring AI infrastructure providers to report the full lifecycle emissions of their operations, including embodied carbon from manufacturing <span class="citation" data-cites="Masanet_2020">(<a href="#ref-Masanet_2020" role="doc-biblioref">Masanet et al. 2020a</a>)</span>. Additionally, stricter water use regulations for semiconductor fabs and e-waste recycling policies can help mitigate AI’s resource consumption. Some jurisdictions have already implemented extended producer responsibility laws, which hold manufacturers accountable for the end-of-life disposal of their products. Expanding these policies to AI hardware could incentivize more sustainable design practices.</p>
<p>At the industry level, collaborative efforts are important for scaling sustainable AI practices. Leading AI companies and research institutions should establish shared sustainability benchmarks that track energy efficiency, carbon footprint, and resource usage. Furthermore, standardized green AI certifications could guide consumers and enterprises toward more sustainable technology choices <span class="citation" data-cites="Strubell_2019">(<a href="#ref-Strubell_2019" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019a</a>)</span>. Cloud providers can also commit to 24/7 carbon-free energy (CFE) goals, ensuring that AI workloads are powered by renewable sources in real-time rather than relying on carbon offsets that fail to drive meaningful emissions reductions.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Strubell_2019" class="csl-entry" role="listitem">
Strubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019a. <span>“Energy and Policy Considerations for Deep Learning in NLP.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 3645–50. Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/p19-1355">https://doi.org/10.18653/v1/p19-1355</a>.
</div></div><p>Achieving systemic change in AI sustainability requires a multi-stakeholder approach. Governments, industry leaders, and researchers must work together to set sustainability standards, invest in greener infrastructure, and transition toward a circular AI economy. By embedding sustainability into the entire AI development pipeline, the industry can move beyond incremental optimizations and build a truly sustainable foundation for future innovation.</p>
</section></section><section id="sec-sustainable-ai-case-study-googles-framework-4923" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-case-study-googles-framework-4923">Case Study: Google’s Framework</h3>
<p>To mitigate emissions from rapidly expanding AI workloads, Google engineers identified four key optimization areas, identified as the ‘4 Ms’, where systematic improvements collectively reduce the carbon footprint of machine learning:</p>
<ul>
<li><p><strong>Model</strong>: The selection of efficient AI architectures reduces computation requirements by 5-10<span class="math inline">\(\times\)</span> without compromising model quality. Google has extensively researched sparse models and neural architecture search methodologies, resulting in efficient architectures such as the Evolved Transformer and Primer.</p></li>
<li><p><strong>Machine</strong>: The implementation of AI-specific hardware offers 2-5<span class="math inline">\(\times\)</span> improvements in performance per watt compared to general-purpose systems. Google’s TPUs demonstrate 5-13<span class="math inline">\(\times\)</span> greater carbon efficiency relative to non-optimized GPUs.</p></li>
<li><p><strong>Mechanization</strong>: The utilization of optimized cloud computing infrastructure with high utilization rates yields 1.4-2<span class="math inline">\(\times\)</span> energy reductions compared to conventional on-premise data centers. Google’s facilities consistently exceed industry standards for PUE.</p></li>
<li><p><strong>Map</strong>: The strategic positioning of data centers in regions with low-carbon electricity supplies reduces gross emissions by 5-10<span class="math inline">\(\times\)</span>. Google maintains real-time monitoring of renewable energy usage across its global infrastructure.</p></li>
</ul>
<p>The combined effect of these practices produces multiplicative efficiency gains. For instance, implementing the optimized Transformer model on TPUs in strategically located data centers reduced energy consumption by a factor of 83 and CO₂ emissions by a factor of 747.</p>
<p>Despite substantial growth in AI deployment across Google’s product ecosystem, systematic efficiency improvements have effectively constrained energy consumption growth. A significant indicator of this progress is the observation that AI workloads have maintained a consistent 10% to 15% proportion of Google’s total energy consumption from 2019 through 2021. As AI functionality expanded across Google’s services, corresponding increases in compute cycles were offset by advancements in algorithms, specialized hardware, infrastructure design, and geographical optimization.</p>
<p>Empirical case studies demonstrate how engineering principles focused on sustainable AI development allow simultaneous improvements in both performance and environmental impact. For example, comparative analysis between GPT-3 (considered state-of-the-art in mid-2020) and Google’s GLaM model reveals improved accuracy metrics alongside reduced training computation requirements and lower-carbon energy sources—resulting in a 14-fold reduction in CO₂ emissions within an 18-month development cycle.</p>
<p>Furthermore, Google’s analysis indicates that previous published estimates overestimated machine learning’s energy requirements by factors ranging from 100 to 100,000<span class="math inline">\(\times\)</span> due to methodological limitations and absence of empirical measurements. Through transparent reporting of optimization metrics, Google provides a factual basis for efficiency initiatives while correcting disproportionate projections regarding machine learning’s environmental impact.</p>
<p>While substantial progress has been achieved in constraining the carbon footprint of AI operations, Google acknowledges that continued efficiency advancements are important for responsible innovation as AI applications proliferate. Their ongoing optimization framework encompasses:</p>
<ol type="1">
<li><p><strong>Life-Cycle Analysis</strong>: Demonstrating that computational investments such as neural architecture search, while initially resource-intensive, generate significant downstream efficiencies that outweigh initial costs. Despite higher energy expenditure during the discovery phase compared to manual engineering approaches, NAS ultimately reduces cumulative emissions by generating optimized architectures applicable across numerous deployments.</p></li>
<li><p><strong>Resource Allocation Prioritization</strong>: Concentrating sustainability initiatives on data center and server-side optimization where energy consumption is most concentrated. While Google continues to enhance inference efficiency on edge devices, primary focus remains on training infrastructure and renewable energy procurement to maximize environmental return on investment.</p></li>
<li><p><strong>Economies of Scale</strong>: Leveraging the efficiency advantages inherent in well-designed cloud infrastructure through workload consolidation. As computation transitions from distributed on-premise environments to centralized providers with robust sustainability frameworks, aggregate emissions reductions accelerate.</p></li>
<li><p><strong>Renewable Energy Integration</strong>: Prioritizing renewable energy procurement, as Google has achieved a 100% match of energy consumption with renewable sources since 2017, to further reduce the environmental impact of computational workloads.</p></li>
</ol>
<p>These integrated approaches indicate that AI efficiency improvements are accelerating rather than plateauing. Google’s multifaceted strategy combining systematic measurement, carbon-aware development methodologies, transparency in reporting, and renewable energy transition establishes a replicable framework for sustainable AI scaling. These empirical results provide a foundation for broader industry adoption of comprehensive sustainability practices.</p>
</section></section><section id="sec-sustainable-ai-embedded-ai-ewaste-292b" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-embedded-ai-ewaste-292b">Embedded AI and E-Waste</h2>
<p>The deployment of AI is rapidly expanding beyond centralized data centers into edge and embedded devices, enabling real-time decision-making without requiring constant cloud connectivity. This shift has led to major efficiency gains, reducing latency, bandwidth consumption, and network congestion while enabling new applications in smart consumer devices, industrial automation, healthcare, and autonomous systems. The architecture and design considerations for these distributed AI systems involve complex trade-offs between computational efficiency, latency requirements, and resource constraints. However, the rise of embedded AI brings new environmental challenges, particularly regarding electronic waste, disposable smart devices, and planned obsolescence.</p>
<p>Unlike high-performance AI accelerators in data centers, which are designed for long-term use and high computational throughput, embedded AI hardware is often small, low-cost, and disposable. Many AI-powered IoT sensors, wearables, and smart appliances are built with short lifespans and limited upgradeability, making them difficult, if not entirely impossible, to repair or recycle <span class="citation" data-cites="Baldé_2017">(<a href="#ref-Bald%C3%A9_2017" role="doc-biblioref">Baldé et al. 2017</a>)</span>. As a result, these devices contribute to a rapidly growing electronic waste crisis, one that remains largely overlooked in discussions on AI sustainability.</p>
<p>The scale of this issue is staggering. As illustrated in <a href="#fig-iot-number" class="quarto-xref">Figure&nbsp;13</a>, the number of Internet of Things (IoT) devices is projected to exceed 30 billion by 2030, with AI-powered chips increasingly embedded into everything from household appliances and medical implants to industrial monitoring systems and agricultural sensors <span class="citation" data-cites="Statista_2022">(<a href="#ref-Statista_2022" role="doc-biblioref">Statista 2022</a>)</span>. This exponential growth in connected devices, utilizing specialized hardware architectures optimized for edge computing requirements, presents a significant environmental challenge, as many of these devices will become obsolete within just a few years, leading to an unprecedented surge in e-waste. Without sustainable design practices and improved lifecycle management, the expansion of AI at the edge risks exacerbating global electronic waste accumulation and straining recycling infrastructure.</p>
<div class="no-row-height column-margin column-container"></div><div id="fig-iot-number" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure page-columns page-full"><div aria-describedby="fig-iot-number-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="dd37b4e99d0e9402c860b7cee239be3077d63194.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure&nbsp;13: IoT Device Growth: Rapid expansion in the number of connected devices amplifies the environmental impact of embedded AI systems, as short device lifecycles contribute to escalating electronic waste. Projections exceeding 30 billion devices by 2030 necessitate sustainable design and improved recycling infrastructure to mitigate the growing e-waste crisis. Source: [@Statista_2022]."><img src="sustainable_ai_files/mediabag/dd37b4e99d0e9402c860b7cee239be3077d63194.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-iot-number-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: <strong>IoT Device Growth</strong>: Rapid expansion in the number of connected devices amplifies the environmental impact of embedded AI systems, as short device lifecycles contribute to escalating electronic waste. Projections exceeding 30 billion devices by 2030 necessitate sustainable design and improved recycling infrastructure to mitigate the growing e-waste crisis. Source: <span class="citation" data-cites="Statista_2022">(<a href="#ref-Statista_2022" role="doc-biblioref">Statista 2022</a>)</span>.
</figcaption><div class="no-row-height column-margin column-container"><div id="ref-Statista_2022" class="csl-entry" role="listitem">
Statista. 2022. <span>“Number of Internet of Things (IoT) Connected Devices Worldwide from 2019 to 2030.”</span> <a href="https://www.statista.com/statistics/802690/worldwide-connected-devices-by-access-technology/">https://www.statista.com/statistics/802690/worldwide-connected-devices-by-access-technology/</a>.
</div></div></figure>
</div>
<p>While AI-powered data centers have been scrutinized for their carbon footprint and energy demands, far less attention has been paid to the environmental cost of embedding AI into billions of short-lived devices. Addressing this challenge requires rethinking how AI hardware is designed, manufactured, and disposed of, ensuring that edge AI systems contribute to technological progress without leaving behind an unsustainable legacy of waste.</p>
<section id="sec-sustainable-ai-ewaste-crisis-d1a4" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-ewaste-crisis-d1a4">E-Waste Crisis</h3>
<p>Electronic waste, or e-waste, is one of the fastest-growing environmental challenges of the digital age. Defined as discarded electronic devices containing batteries, circuit boards, and semiconductor components, e-waste presents severe risks to both human health and the environment. Toxic materials such as lead, mercury, cadmium, and brominated flame retardants, commonly found in AI-allowed hardware, can contaminate soil and groundwater when improperly disposed of. Despite the potential for recycling and material recovery, most e-waste remains improperly handled, leading to hazardous waste accumulation and significant environmental degradation.</p>
<p>The scale of the problem is staggering. Today, global e-waste production exceeds 50 million metric tons annually, with projections indicating that this figure will surpass 75 million tons by 2030 as consumer electronics and AI-powered IoT devices continue to proliferate. According to the United Nations, e-waste generation could reach 120 million tons per year by 2050 if current consumption patterns persist <span class="citation" data-cites="un2019circular">(<a href="#ref-un2019circular" role="doc-biblioref">Un and Forum 2019</a>)</span>. The combination of short product lifespans, rising global demand, and limited recycling infrastructure has accelerated this crisis.</p>
<div class="no-row-height column-margin column-container"></div><p>AI-driven consumer devices, such as smart speakers, fitness trackers, and home automation systems, are among the most significant contributors to e-waste. Unlike modular and serviceable computing systems, many of these devices are designed to be disposable, meaning that when a battery fails or a component malfunctions, the entire product is discarded rather than repaired. This built-in disposability exacerbates the unsustainable cycle of consumption and waste, leading to higher material extraction rates and increased pressure on waste management systems.</p>
<p>Developing nations are disproportionately affected by e-waste dumping, as they often lack the infrastructure to process obsolete electronics safely. In 2019, only 13% to 23% of e-waste in lower-income countries was formally collected for recycling, with the remainder either incinerated, illegally dumped, or manually dismantled in unsafe conditions <span class="citation" data-cites="un2019circular">(<a href="#ref-un2019circular" role="doc-biblioref">Un and Forum 2019</a>)</span>. Many discarded AI-powered devices end up in informal recycling operations, where low-paid workers are exposed to hazardous materials without proper protective equipment. Open-air burning of plastic components and crude metal extraction methods release toxic fumes and heavy metals into the surrounding environment, posing severe health risks.</p>
<div class="no-row-height column-margin column-container"><div id="ref-un2019circular" class="csl-entry" role="listitem">
Un, and World Economic Forum. 2019. <em>A New Circular Vision for Electronics, Time for a Global Reboot</em>. PACE - Platform for Accelerating the Circular Economy. <a href="https://www3.weforum.org/docs/WEF%5C_A%5C_New%5C_Circular%5C_Vision%5C_for%5C_Electronics.pdf">https://www3.weforum.org/docs/WEF\_A\_New\_Circular\_Vision\_for\_Electronics.pdf</a>.
</div><div id="ref-singh2022disentangling" class="csl-entry" role="listitem">
Singh, Narendra, and Oladele A. Ogunseitan. 2022. <span>“Disentangling the Worldwide Web of e-Waste and Climate Change Co-Benefits.”</span> <em>Circular Economy</em> 1 (2): 100011. <a href="https://doi.org/10.1016/j.cec.2022.100011">https://doi.org/10.1016/j.cec.2022.100011</a>.
</div></div><p>The global recycling rate for e-waste remains alarmingly low, with only 17.4% of all discarded electronics processed through environmentally sound recycling channels <span class="citation" data-cites="singh2022disentangling">(<a href="#ref-singh2022disentangling" role="doc-biblioref">Singh and Ogunseitan 2022</a>)</span>. The remaining 82.6% is either landfilled, incinerated, or dumped illegally, leading to long-term environmental contamination and resource depletion. Without stronger policies, better product design, and expanded e-waste management systems, the rapid growth of AI-powered devices will significantly worsen this crisis.</p>
<p>AI-driven electronics should not become another major contributor to the global e-waste problem. Tackling this challenge requires a multi-pronged approach, including more sustainable design practices, stronger regulatory oversight, and greater investment in global e-waste recycling infrastructure. Without intervention, AI’s environmental impact will extend far beyond its energy consumption, leaving behind a legacy of toxic waste and resource depletion.</p>
</section><section id="sec-sustainable-ai-disposable-electronics-cb28" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-disposable-electronics-cb28">Disposable Electronics</h3>
<p>The rapid proliferation of low-cost AI-powered microcontrollers, smart sensors, and connected devices has transformed various industries, from consumer electronics and healthcare to industrial automation and agriculture. While these embedded AI systems allow greater efficiency and automation, their short lifespans and non-recyclable designs pose a significant sustainability challenge. Many of these devices are treated as disposable electronics, designed with limited durability, non-replaceable batteries, and little to no repairability, making them destined for the waste stream within just a few years of use.</p>
<p>One of the primary drivers of AI-powered device disposability is the falling cost of microelectronics. The miniaturization of computing hardware has allowed manufacturers to embed tiny AI processors and wireless connectivity modules into everyday products, often for under $1 per chip. As a result, AI functionality is increasingly being integrated into single-use and short-lived products, including smart packaging, connected medical devices, wearables, and home appliances. These cost-effective embedded implementations, utilizing advanced optimization techniques for resource-constrained environments, improve convenience and real-time data collection but lack proper end-of-life management strategies, leading to a surge in hard-to-recycle electronic waste <span class="citation" data-cites="Forti2020">(<a href="#ref-Forti2020" role="doc-biblioref">Forti et al. 2020</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Forti2020" class="csl-entry" role="listitem">
Forti, Vanessa, Cornelis P Balde, Ruediger Kuehr, and Garam Bel. 2020. <em>The Global e-Waste Monitor 2020: Quantities, Flows, and Circular Economy Potential</em>. United Nations University, International Telecommunication Union,; International Solid Waste Association. <a href="https://ewastemonitor.info">https://ewastemonitor.info</a>.
</div></div><section id="sec-sustainable-ai-nonreplaceable-batteries-cost-3e8e" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-nonreplaceable-batteries-cost-3e8e">Non-Replaceable Batteries Cost</h4>
<p>Many disposable AI devices incorporate sealed, non-replaceable lithium-ion batteries, making them inherently unsustainable. Smart earbuds, wireless sensors, and even some fitness trackers lose functionality entirely once their batteries degrade, forcing consumers to discard the entire device. Unlike modular electronics with user-serviceable components, most AI-powered wearables and IoT devices are glued or soldered shut, preventing battery replacement or repair.</p>
<p>This issue extends beyond consumer gadgets. Industrial AI sensors and remote monitoring devices, often deployed in agriculture, infrastructure, and environmental monitoring, frequently rely on non-replaceable batteries with a limited lifespan. Once depleted, these sensors, many of which are installed in remote or difficult-to-access locations, become e-waste, requiring costly and environmentally disruptive disposal or replacement <span class="citation" data-cites="Harper2019">(<a href="#ref-Harper2019" role="doc-biblioref">Ciez and Whitacre 2019</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Harper2019" class="csl-entry" role="listitem">
Ciez, Rebecca E., and J. F. Whitacre. 2019. <span>“Examining Different Recycling Processes for Lithium-Ion Batteries.”</span> <em>Nature Sustainability</em> 2 (2): 148–56. <a href="https://doi.org/10.1038/s41893-019-0222-5">https://doi.org/10.1038/s41893-019-0222-5</a>.
</div></div><p>The environmental impact of battery waste is particularly concerning. Lithium mining, important for battery production, is an energy-intensive process that consumes vast amounts of water and generates harmful byproducts. Additionally, the improper disposal of lithium batteries poses fire and explosion risks, particularly in landfills and waste processing facilities. As the demand for AI-powered devices grows, addressing the battery sustainability crisis will be important to mitigating AI’s long-term environmental footprint.</p>
</section><section id="sec-sustainable-ai-recycling-challenges-4554" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-recycling-challenges-4554">Recycling Challenges</h4>
<p>Unlike traditional computing hardware, including desktop computers and enterprise servers, which can be disassembled and refurbished, most AI-allowed consumer electronics are not designed for recycling. Many of these devices contain mixed-material enclosures, embedded circuits, and permanently attached components, making them difficult to dismantle and recover materials from <span class="citation" data-cites="Cucchiella2016">(<a href="#ref-Cucchiella2016" role="doc-biblioref">Patel et al. 2016</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Cucchiella2016" class="csl-entry" role="listitem">
Patel, Paresh D., Absar Lakdawala, Sajan Chourasia, and Rajesh N. Patel. 2016. <span>“Bio Fuels for Compression Ignition Engine: A Review on Engine Performance, Emission and Life Cycle Analysis.”</span> <em>Renewable and Sustainable Energy Reviews</em> 65 (November): 24–43. <a href="https://doi.org/10.1016/j.rser.2016.06.010">https://doi.org/10.1016/j.rser.2016.06.010</a>.
</div></div><p>Additionally, AI-powered IoT devices are often too small to be efficiently recycled using conventional e-waste processing methods. Large-scale electronics, such as laptops and smartphones, have well-established recycling programs that allow for material recovery. In contrast, tiny AI-powered sensors, earbuds, and embedded chips are often too costly and labor-intensive to separate into reusable components. As a result, they frequently end up in landfills or incinerators, contributing to pollution and resource depletion.</p>
<p>The environmental impact of battery waste is particularly concerning. Lithium mining, important for battery production, is an energy-intensive process that consumes vast amounts of water and generates harmful byproducts <span class="citation" data-cites="Kushnir2015">(<a href="#ref-Kushnir2015" role="doc-biblioref">Bouri 2015</a>)</span>. Additionally, the improper disposal of lithium batteries poses fire and explosion risks, particularly in landfills and waste processing facilities. As the demand for AI-powered devices grows, addressing the battery sustainability crisis will be important to mitigating AI’s long-term environmental footprint <span class="citation" data-cites="Gaines2018">(<a href="#ref-Gaines2018" role="doc-biblioref">Zhan, Oldenburg, and Pan 2018</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Kushnir2015" class="csl-entry" role="listitem">
Bouri, Elie. 2015. <span>“A Broadened Causality in Variance Approach to Assess the Risk Dynamics Between Crude Oil Prices and the Jordanian Stock Market.”</span> <em>Energy Policy</em> 85 (October): 271–79. <a href="https://doi.org/10.1016/j.enpol.2015.06.001">https://doi.org/10.1016/j.enpol.2015.06.001</a>.
</div><div id="ref-Gaines2018" class="csl-entry" role="listitem">
Zhan, Ruiting, Zachary Oldenburg, and Lei Pan. 2018. <span>“Recovery of Active Cathode Materials from Lithium-Ion Batteries Using Froth Flotation.”</span> <em>Sustainable Materials and Technologies</em> 17 (September): e00062. <a href="https://doi.org/10.1016/j.susmat.2018.e00062">https://doi.org/10.1016/j.susmat.2018.e00062</a>.
</div></div></section><section id="sec-sustainable-ai-need-sustainable-design-a7e7" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-need-sustainable-design-a7e7">Need for Sustainable Design</h4>
<p>Addressing the sustainability challenges of disposable AI electronics requires a core shift in design philosophy. Instead of prioritizing cost-cutting and short-term functionality, manufacturers must embed sustainability principles into the development of AI-powered devices. This approach aligns with broader responsible AI principles that emphasize ethical development practices, extending ethical considerations to environmental stewardship. This includes:</p>
<ul>
<li>
<strong>Designing for longevity</strong>: AI-powered devices should be built with replaceable components, modular designs, and upgradable software to extend their usability.</li>
<li>
<strong>Enabling battery replacement</strong>: Consumer and industrial AI devices should incorporate easily swappable batteries rather than sealed enclosures that prevent repair.</li>
<li>
<strong>Standardizing repairability</strong>: AI hardware should adopt universal standards for repair, ensuring that components can be serviced rather than discarded.</li>
<li>
<strong>Developing biodegradable or recyclable materials</strong>: Research into eco-friendly circuit boards, biodegradable polymers, and sustainable packaging can help mitigate waste.</li>
</ul>
<p>Incentives and regulations can also encourage manufacturers to prioritize sustainable AI design. Governments and regulatory bodies can implement right-to-repair laws, extended producer responsibility policies, and e-waste take-back programs to ensure that AI-powered devices are disposed of responsibly. Additionally, consumer awareness campaigns can educate users on responsible e-waste disposal and encourage sustainable purchasing decisions.</p>
<p>The future of AI-powered electronics must be circular rather than linear, ensuring that devices are designed with sustainability in mind and do not contribute disproportionately to the global e-waste crisis. By rethinking design, improving recyclability, and promoting responsible disposal, the industry can mitigate the negative environmental impacts of AI at the edge while still enabling technological progress.</p>
</section></section><section id="sec-sustainable-ai-ai-hardware-obsolescence-b3e0" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-ai-hardware-obsolescence-b3e0">AI Hardware Obsolescence</h3>
<p>The concept of planned obsolescence refers to the intentional design of products with artificially limited lifespans, forcing consumers to upgrade or replace them sooner than necessary. While this practice has long been associated with consumer electronics and household appliances, it is increasingly prevalent in AI-powered hardware, from smartphones and wearables to industrial AI sensors and cloud infrastructure. This accelerated replacement cycle not only drives higher consumption and production but also contributes significantly to the growing e-waste crisis <span class="citation" data-cites="slade2006made">(<a href="#ref-slade2006made" role="doc-biblioref">Slade 2007</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-slade2006made" class="csl-entry" role="listitem">
Slade, Giles. 2007. <em>Made to Break: Technology and Obsolescence in America</em>. Harvard University Press. <a href="https://doi.org/10.4159/9780674043756">https://doi.org/10.4159/9780674043756</a>.
</div><div id="ref-fordham2020planned" class="csl-entry" role="listitem">
Luna, William Fernando Martı́nez. 2018a. <span>“CONSUMER PROTECTION AGAINST PLANNED OBSOLESCENCE. AN INTERNATIONAL PRIVATE LAW ANALYSIS.”</span> In <em>Planned Obsolescence and the Rulle of Law</em>, 12:229–80. 3. Universidad del Externado de Colombia. <a href="https://doi.org/10.2307/j.ctv1ddcwvh.9">https://doi.org/10.2307/j.ctv1ddcwvh.9</a>.
</div></div><p>One of the most visible examples of planned obsolescence in AI hardware is the software-driven degradation of device performance. Many manufacturers introduce software updates that, while ostensibly meant to enhance security and functionality, often degrade the performance of older devices. For example, Apple has faced scrutiny for deliberately slowing down older iPhone models via iOS updates <span class="citation" data-cites="fordham2020planned">(<a href="#ref-fordham2020planned" role="doc-biblioref">Luna 2018a</a>)</span>. While the company claimed that these updates were meant to prevent battery-related shutdowns, critics argued that they pushed consumers toward unnecessary upgrades rather than encouraging repair or battery replacement.</p>
<p>This pattern extends to AI-powered consumer electronics, where firmware updates can render older models incompatible with newer features, effectively forcing users to replace their devices. Many smart home systems, connected appliances, and AI assistants suffer from forced obsolescence due to discontinued cloud support or software services, rendering hardware unusable even when physically intact <span class="citation" data-cites="rosenblatt2021disposable">(<a href="#ref-rosenblatt2021disposable" role="doc-biblioref">Luna 2018b</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-rosenblatt2021disposable" class="csl-entry" role="listitem">
———. 2018b. <span>“CONSUMER PROTECTION AGAINST PLANNED OBSOLESCENCE. AN INTERNATIONAL PRIVATE LAW ANALYSIS.”</span> In <em>Planned Obsolescence and the Rulle of Law</em>, 15:229–80. 2. Universidad del Externado de Colombia. <a href="https://doi.org/10.2307/j.ctv1ddcwvh.9">https://doi.org/10.2307/j.ctv1ddcwvh.9</a>.
</div></div><section id="sec-sustainable-ai-lockin-proprietary-components-6983" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-lockin-proprietary-components-6983">Lock-In and Proprietary Components</h4>
<p>Another form of planned obsolescence arises from hardware lock-in, where manufacturers deliberately prevent users from repairing or upgrading their devices. Many AI-powered devices feature proprietary components, making it impossible to swap out batteries, upgrade memory, or replace failing parts. Instead of designing for modularity and longevity, manufacturers prioritize sealed enclosures and soldered components, ensuring that even minor failures lead to complete device replacement <span class="citation" data-cites="johnson2018right">(<a href="#ref-johnson2018right" role="doc-biblioref">Johnson 2018</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-russell2022tech" class="csl-entry" role="listitem">
Russell, Mark. 2022. <span>“Tech Industry Trends in Hardware Lock-in and Their Sustainability Implications.”</span> <em>Sustainable Computing Journal</em> 10 (1): 34–50.
</div></div><p>For example, many AI wearables and smart devices integrate non-replaceable batteries, meaning that when the battery degrades (often in just two to three years), the entire device becomes e-waste. Similarly, smartphones, laptops, and AI-allowed tablets increasingly use soldered RAM and storage, preventing users from upgrading hardware and extending its lifespan <span class="citation" data-cites="russell2022tech">(<a href="#ref-russell2022tech" role="doc-biblioref">Russell 2022</a>)</span>.</p>
<p>Planned obsolescence also affects industrial AI hardware, including AI-powered cameras, factory sensors, and robotics. Many industrial automation systems rely on vendor-locked software ecosystems, where manufacturers discontinue support for older models to push customers toward newer, more expensive replacements. This creates a cycle of forced upgrades, where companies must frequently replace otherwise functional AI hardware simply to maintain software compatibility <span class="citation" data-cites="sharma2020industrial">(<a href="#ref-sharma2020industrial" role="doc-biblioref">Sharma 2020</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-sharma2020industrial" class="csl-entry" role="listitem">
Sharma, Amit. 2020. <span>“Industrial AI and Vendor Lock-in: The Hidden Costs of Proprietary Ecosystems.”</span> <em>AI and Industry Review</em> 8 (3): 55–70.
</div></div></section><section id="sec-sustainable-ai-environmental-cost-c458" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-environmental-cost-c458">Environmental Cost</h4>
<p>Planned obsolescence is not just a financial burden on consumers—it has severe environmental consequences. By shortening product lifespans and discouraging repairability, manufacturers increase the demand for new electronic components, leading to higher resource extraction, energy consumption, and carbon emissions.</p>
<p>The impact of this cycle is particularly concerning given the high environmental cost of semiconductor manufacturing. Producing AI chips, GPUs, and other advanced computing components requires vast amounts of water, rare earth minerals, and energy. For example, a single 5nm semiconductor fabrication plant consumes millions of gallons of ultrapure water daily and relies on energy-intensive processes that generate significant CO₂ emissions <span class="citation" data-cites="mills1997overview harris2023semiconductor">(<a href="#ref-mills1997overview" role="doc-biblioref">Mills and Le Hunte 1997</a>; <a href="#ref-harris2023semiconductor" role="doc-biblioref">Harris 2023</a>)</span>. When AI-powered devices are discarded prematurely, the environmental cost of manufacturing is effectively wasted, amplifying AI’s overall sustainability challenges.</p>
<div class="no-row-height column-margin column-container"><div id="ref-mills1997overview" class="csl-entry" role="listitem">
Mills, Andrew, and Stephen Le Hunte. 1997. <span>“An Overview of Semiconductor Photocatalysis.”</span> <em>Journal of Photochemistry and Photobiology A: Chemistry</em> 108 (1): 1–35. <a href="https://doi.org/10.1016/s1010-6030(97)00118-4">https://doi.org/10.1016/s1010-6030(97)00118-4</a>.
</div><div id="ref-harris2023semiconductor" class="csl-entry" role="listitem">
Harris, Michael. 2023. <span>“The Environmental Cost of Next-Generation AI Chips: Energy, Water, and Carbon Impacts.”</span> <em>Journal of Green Computing</em> 17 (1): 22–38.
</div><div id="ref-puckett2016e-waste" class="csl-entry" role="listitem">
Puckett, Jim. 2016. <em>E-Waste and the Global Environment: The Hidden Cost of Discarded Electronics</em>. MIT Press.
</div></div><p>Additionally, many discarded AI devices contain hazardous materials, including lead, mercury, and brominated flame retardants, which can leach into the environment if not properly recycled <span class="citation" data-cites="puckett2016e-waste">(<a href="#ref-puckett2016e-waste" role="doc-biblioref">Puckett 2016</a>)</span>. The acceleration of AI-powered consumer electronics and industrial hardware turnover will only worsen the global e-waste crisis, further straining waste management and recycling systems.</p>
</section><section id="sec-sustainable-ai-extending-hardware-lifespan-b028" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-extending-hardware-lifespan-b028">Extending Hardware Lifespan</h4>
<p>Addressing planned obsolescence requires a shift in design philosophy, moving toward repairable, upgradable, and longer-lasting AI hardware. Some potential solutions include:</p>
<ul>
<li>
<strong>Right-to-Repair Legislation</strong>: Many governments are considering right-to-repair laws, which would require manufacturers to provide repair manuals, replacement parts, and diagnostic tools for AI-powered devices. This would allow consumers and businesses to extend hardware lifespans rather than replacing entire systems <span class="citation" data-cites="johnson2018right">(<a href="#ref-johnson2018right" role="doc-biblioref">Johnson 2018</a>)</span>.</li>
<li>
<strong>Modular AI Hardware</strong>: Designing AI-powered devices with modular components—such as replaceable batteries, upgradeable memory, and standardized ports—can significantly reduce electronic waste while improving cost-effectiveness for consumers <span class="citation" data-cites="framework2022modular">(<a href="#ref-framework2022modular" role="doc-biblioref">Incorporated 2022</a>)</span>.</li>
<li>
<strong>Extended Software Support</strong>: Companies should commit to longer software support cycles, ensuring that older AI-powered devices remain functional rather than being rendered obsolete due to artificial compatibility constraints <span class="citation" data-cites="brown2021longterm">(<a href="#ref-brown2021longterm" role="doc-biblioref">Brown 2021</a>)</span>.</li>
<li>
<strong>Consumer Awareness &amp; Circular Economy</strong>: Encouraging trade-in and recycling programs, along with consumer education on sustainable AI purchasing, can help shift demand toward repairable and long-lasting devices <span class="citation" data-cites="ellenmacarthur2017circular">(<a href="#ref-ellenmacarthur2017circular" role="doc-biblioref">Cheshire 2021</a>)</span>.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="ref-johnson2018right" class="csl-entry" role="listitem">
Johnson, Rebecca. 2018. <span>“The Right to Repair Movement and Its Implications for AI Hardware Longevity.”</span> <em>Technology and Society Review</em> 20 (4): 87–102.
</div><div id="ref-framework2022modular" class="csl-entry" role="listitem">
Incorporated, Framework Computer. 2022. <span>“Modular Laptops: A New Approach to Sustainable Computing.”</span>
</div><div id="ref-brown2021longterm" class="csl-entry" role="listitem">
Brown, Samantha. 2021. <span>“Long-Term Software Support: A Key Factor in Sustainable AI Hardware.”</span> <em>Computer Ethics and Sustainability</em> 14 (2): 112–30.
</div><div id="ref-ellenmacarthur2017circular" class="csl-entry" role="listitem">
Cheshire, David. 2021. <span>“Circular Economy and Sustainable AI: Designing Out Waste in the Tech Industry.”</span> In <em>The Handbook to Building a Circular Economy</em>, 48–61. RIBA Publishing. <a href="https://doi.org/10.4324/9781003212775-8">https://doi.org/10.4324/9781003212775-8</a>.
</div></div><p>Several tech companies are already experimenting with more sustainable AI hardware. For example, Framework, a startup focused on modular laptops, offers fully repairable, upgradeable systems that prioritize long-term usability over disposable design. Similar efforts in the smartphone and AI-driven IoT sectors could help reduce the environmental footprint of planned obsolescence.</p>
<p>The widespread adoption of AI-powered devices presents a important opportunity to rethink the lifecycle of electronics. If left unchecked, planned obsolescence will continue to drive wasteful consumption patterns, accelerate e-waste accumulation, and exacerbate the resource extraction crisis. However, with policy interventions, industry innovation, and consumer advocacy, AI hardware can be designed for durability, repairability, and sustainability.</p>
<p>The future of AI should not be disposable. Instead, companies, researchers, and policymakers must prioritize long-term sustainability, ensuring that AI’s environmental footprint is minimized while its benefits are maximized. Addressing planned obsolescence in AI hardware is a key step toward making AI truly sustainable—not just in terms of energy efficiency but in its entire lifecycle, from design to disposal.</p>
<div id="quiz-question-sec-sustainable-ai-embedded-ai-ewaste-292b" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.2</strong></summary><div>
<ol type="1">
<li>
<p>What is a major environmental challenge associated with the proliferation of embedded AI devices?</p>
<ol type="a">
<li>Increased carbon emissions from data centers</li>
<li>Decreased efficiency in AI algorithms</li>
<li>Higher energy consumption in cloud computing</li>
<li>Rapid growth of electronic waste</li>
</ol>
</li>
<li><p>True or False: Embedded AI devices are typically designed for long-term use and easy recyclability.</p></li>
<li><p>Discuss how planned obsolescence in AI-powered devices contributes to the e-waste crisis.</p></li>
<li>
<p>Which of the following strategies can help mitigate the e-waste crisis caused by embedded AI devices?</p>
<ol type="a">
<li>Designing devices with modular components</li>
<li>Increasing the use of proprietary components</li>
<li>Shortening software support cycles</li>
<li>Encouraging single-use designs</li>
</ol>
</li>
</ol>
<p><a href="#quiz-answer-sec-sustainable-ai-embedded-ai-ewaste-292b" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section></section></section><section id="sec-sustainable-ai-policy-regulation-9668" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-policy-regulation-9668">Policy and Regulation</h2>
<p>The sustainability of artificial intelligence extends beyond technical optimization to encompass the broader policy ecosystem that governs its development and deployment. Effective regulation must navigate the tension between enabling innovation and enforcing environmental responsibility, creating frameworks that incentivize sustainable practices without stifling technological progress. This section examines the policy instruments and governance mechanisms emerging to address AI’s environmental footprint, from measurement standards to regulatory restrictions to market-based incentives.</p>
<section id="sec-sustainable-ai-policy-governance-frameworks" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-policy-governance-frameworks">Policy and Governance Frameworks for Sustainable AI</h3>
<p>Effective sustainable AI implementation requires coordinated policy frameworks that balance innovation incentives with environmental responsibility. Regulatory approaches span measurement and reporting mandates, emission restrictions, financial incentives, and industry self-regulation initiatives. The challenge lies in designing policies that drive sustainability improvements without impeding technological progress or creating unequal access to AI capabilities.</p>
<p>Global policy fragmentation creates additional complexity. The European Union leads regulatory efforts through the AI Act<a href="#fn45" class="footnote-ref" id="fnref45" role="doc-noteref"><sup>45</sup></a> and Corporate Sustainability Reporting Directive (CSRD)<a href="#fn46" class="footnote-ref" id="fnref46" role="doc-noteref"><sup>46</sup></a>, while U.S. approaches emphasize voluntary reporting and market-based incentives. China and other nations develop independent frameworks, creating potential barriers to unified global sustainability strategies.</p>
<div class="no-row-height column-margin column-container"><div id="fn45"><p><sup>45</sup>&nbsp;<strong>EU AI Act</strong>: World’s first comprehensive AI regulation, enacted in 2024 after 3+ years of development. Introduces risk-based approach classifying AI systems as minimal, limited, high, or unacceptable risk. High-risk AI systems (including foundation models &gt;10²⁵ FLOPs) must undergo conformity assessments, provide transparency documentation, and report energy consumption. Fines range up to €35 million or 7% of global revenue. Aims to balance innovation with safety, fundamental rights, and environmental protection.</p></div><div id="fn46"><p><sup>46</sup>&nbsp;<strong>Corporate Sustainability Reporting Directive</strong>: EU regulation requiring 50,000+ large companies to disclose environmental, social, and governance (ESG) impacts starting 2024-2028. Replaces previous voluntary guidelines with mandatory, audited sustainability reporting. Covers Scope 1, 2, and 3 emissions, including AI-related energy consumption. Companies must report using European Sustainability Reporting Standards (ESRS), creating standardized ESG data comparable to financial reporting. Estimated compliance costs of €3-8 billion annually across EU.</p></div></div><section id="sec-sustainable-ai-measurement-accountability" class="level4"><h4 class="anchored" data-anchor-id="sec-sustainable-ai-measurement-accountability">Measurement and Accountability Mechanisms</h4>
<p>Transparent measurement and reporting provide the foundation for sustainable AI governance. Without standardized tracking mechanisms, organizations cannot accurately assess environmental impact or identify improvement opportunities.</p>
</section></section><section id="sec-sustainable-ai-measurement-reporting-798b" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-measurement-reporting-798b">Measurement and Reporting</h3>
<p>A important first step toward mitigating AI’s environmental impact is accurate measurement and transparent reporting of energy consumption and carbon emissions. Without standardized tracking mechanisms, it is difficult to assess AI’s true sustainability impact or identify areas for improvement. Government regulations and industry initiatives are beginning to mandate energy audits, emissions disclosures, and standardized efficiency metrics for AI workloads. These policies aim to increase transparency, inform better decision-making, and hold organizations accountable for their environmental footprint.</p>
<p>The lack of universally accepted metrics for assessing AI’s environmental impact has been a significant challenge. Current sustainability evaluations often rely on ad hoc reporting by companies, with inconsistent methodologies for measuring energy consumption and emissions. To address this, policymakers and industry leaders are advocating for formalized sustainability benchmarks that assess AI’s carbon footprint at multiple levels. Computational complexity and model efficiency are key factors, as they determine how much computation is required for a given AI task. Data center efficiency, often measured through power usage effectiveness, plays a important role in evaluating how much of a data center’s power consumption directly supports computation rather than being lost to cooling and infrastructure overhead. The carbon intensity of energy supply is another important consideration, as AI operations running on grids powered primarily by fossil fuels have a far greater environmental impact than those powered by renewable energy sources.</p>
<p>Several industry efforts are working toward standardizing sustainability reporting for AI. The MLCommons benchmarking consortium has begun incorporating energy efficiency as a factor in AI model assessments, recognizing the need for standardized comparisons of model energy consumption. These sustainability metrics complement traditional performance evaluations, creating comprehensive assessment frameworks that balance capability with environmental impact through systematic measurement approaches. Meanwhile, regulatory bodies are pushing for mandatory disclosures. In Europe, the proposed AI Act includes provisions for requiring organizations using AI at scale to report energy consumption and carbon emissions associated with their models. The European Commission has signaled that sustainability reporting requirements for AI may soon be aligned with broader environmental disclosure regulations under the CSRD.</p>
<p>One of the biggest challenges in implementing AI sustainability reporting is balancing transparency with the potential burden on organizations. While greater transparency is important for accountability, requiring detailed reporting for every AI workload could create excessive overhead, particularly for smaller firms and research institutions. To address this, policymakers are exploring scalable approaches that integrate sustainability considerations into existing industry standards without imposing rigid compliance costs. Developing lightweight reporting mechanisms that use existing monitoring tools within data centers and cloud platforms can help ease this burden while still improving visibility into AI’s environmental footprint.</p>
<p>To be most constructive, measurement and reporting policies should focus on enabling continuous refinement rather than imposing simplistic restrictions or rigid caps. Given AI’s rapid evolution, regulations that incorporate flexibility while embedding sustainability into evaluation metrics will be most effective in driving meaningful reductions in energy consumption and emissions. Rather than stifling innovation, well-designed policies can encourage AI developers to prioritize efficiency from the outset, fostering a culture of responsible AI design that aligns with long-term sustainability goals.</p>
</section><section id="sec-sustainable-ai-restriction-mechanisms-a260" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-restriction-mechanisms-a260">Restriction Mechanisms</h3>
<p>Beyond measurement and reporting mandates, direct policy interventions can restrict AI’s environmental impact through regulatory limits on energy consumption, emissions, or model scaling. While AI’s rapid growth has spurred innovation, it has also introduced new sustainability challenges that may require governments to impose guardrails to curb excessive environmental costs. Restrictive mechanisms, such as computational caps, conditional access to public resources, financial incentives, and even outright bans on inefficient AI practices, are all potential tools for reducing AI’s carbon footprint. However, their effectiveness depends on careful policy design that balances sustainability with continued technological advancement.</p>
<p>One potential restriction mechanism involves setting limits on the computational power available for training large AI models. The European Commission’s proposed AI Act has explored this concept by introducing economy-wide constraints on AI training workloads. This approach mirrors emissions trading systems (ETS)<a href="#fn47" class="footnote-ref" id="fnref47" role="doc-noteref"><sup>47</sup></a> in environmental policy, where organizations must either operate within predefined energy budgets or procure additional capacity through regulated exchanges. While such limits could help prevent unnecessary computational waste, they also raise concerns about limiting innovation, particularly for researchers and smaller companies that may struggle to access high-performance computing resources <span class="citation" data-cites="schwartz2020green">(<a href="#ref-schwartz2020green" role="doc-biblioref">Schwartz et al. 2020</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn47"><p><sup>47</sup>&nbsp;<strong>Emissions Trading Systems (ETS)</strong>: Market-based mechanisms where governments set total emission limits (cap) and distribute tradeable allowances to companies. EU ETS, launched in 2005, is world’s largest carbon market covering 40% of EU’s greenhouse gas emissions across 10,000+ installations. Companies exceeding their allowances must buy credits (~€85/ton CO₂ in 2023), while efficient companies can sell excess allowances. California’s cap-and-trade program covers 85% of state emissions. Similar systems could theoretically limit AI compute consumption, creating markets for “computational carbon credits.”</p></div><div id="ref-schwartz2020green" class="csl-entry" role="listitem">
Schwartz, Roy, Jesse Dodge, Noah A. Smith, and Oren Etzioni. 2020. <span>“Green AI.”</span> <em>Communications of the ACM</em> 63 (12): 54–63. <a href="https://doi.org/10.1145/3381831">https://doi.org/10.1145/3381831</a>.
</div></div><p>Another policy tool involves conditioning access to public datasets and government-funded computing infrastructure based on model efficiency. AI researchers and developers increasingly rely on large-scale public datasets and subsidized cloud resources to train models. Some have proposed that governments could restrict these resources to AI projects that meet strict energy efficiency criteria. For instance, the MLCommons benchmarking consortium could integrate sustainability metrics into its standardized performance leaderboards, incentivizing organizations to optimize for efficiency alongside accuracy. However, while conditioned access could promote sustainable AI practices, it also risks creating disparities by limiting access to computational resources for those unable to meet predefined efficiency thresholds.</p>
<p>Financial incentives and disincentives represent another regulatory mechanism for driving sustainable AI. Carbon taxes on AI-related compute consumption could discourage excessive model scaling while generating funds for efficiency-focused research. Similar to existing environmental regulations, organizations could be required to pay fees based on the emissions associated with their AI workloads, encouraging them to optimize for lower energy consumption. Conversely, tax credits could reward companies developing efficient AI techniques, fostering investment in greener computing technologies. While financial mechanisms can effectively guide market behavior, they must be carefully calibrated to avoid disproportionately burdening smaller AI developers or discouraging productive use cases.</p>
<p>In extreme cases, outright bans on particularly wasteful AI applications may be considered. If measurement data consistently pinpoints certain AI practices as disproportionately harmful with no feasible path to remediation, governments may choose to prohibit these activities altogether. However, defining harmful AI use cases is challenging due to AI’s dual-use nature, where the same technology can have both beneficial and detrimental applications. Policymakers must approach bans cautiously, ensuring that restrictions target clearly unsustainable practices without stifling broader AI innovation.</p>
<p>Ultimately, restriction mechanisms must strike a careful balance between environmental responsibility and economic growth. Well-designed policies should encourage AI efficiency while preserving the flexibility needed for continued technological progress. By integrating restrictions with incentives and reporting mandates, policymakers can create a comprehensive framework for guiding AI toward a more sustainable future.</p>
</section><section id="sec-sustainable-ai-government-incentives-face" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-government-incentives-face">Government Incentives</h3>
<p>In addition to regulatory restrictions, governments can play a proactive role in advancing sustainable AI development through incentives that encourage energy-efficient practices. Financial support, tax benefits, grants, and strategic investments in Green AI research can drive the adoption of environmentally friendly AI technologies. Unlike punitive restrictions, incentives provide positive reinforcement, making sustainability a competitive advantage rather than a regulatory burden.</p>
<p>One common approach to promoting sustainability is through tax incentives. Governments already offer tax credits for adopting renewable energy sources, such as the U.S. <a href="https://www.irs.gov/credits-deductions/residential-clean-energy-credit">Residential Clean Energy Credit</a> and <a href="https://www.energy.gov/eere/buildings/179d-commercial-buildings-energy-efficiency-tax-deduction">commercial energy efficiency deductions</a>. Similar programs could be extended to AI companies that optimize their models and infrastructure for lower energy consumption. AI developers who integrate efficiency-enhancing techniques, such as model pruning, quantization, or adaptive scheduling, could qualify for tax reductions, creating a financial incentive for Green AI development.</p>
<p>Beyond tax incentives, direct government funding for sustainable AI research is an emerging strategy. Spain has already committed <a href="https://www.state.gov/artificial-intelligence-for-accelerating-progress-on-the-sustainable-development-goals-addressing-societys-greatest-challenges/">300 million euros</a> toward AI projects that explicitly focus on sustainability. Such funding can accelerate breakthroughs in energy-efficient AI by supporting research into novel low-power algorithms, specialized AI hardware, and eco-friendly data center designs. Public-private partnerships can further enhance these efforts, allowing AI companies to collaborate with research institutions and government agencies to pioneer sustainable solutions.</p>
<p>Governments can also incentivize sustainability by integrating Green AI criteria into public procurement policies. Many AI companies provide cloud computing, software services, and AI-driven analytics to government agencies. By mandating that vendors meet sustainability benchmarks, including operating on carbon-neutral data centers and using energy-efficient AI models, governments can use their purchasing power to set industry-wide standards. Similar policies have already been applied to green building initiatives, where governments require contractors to meet environmental certifications. Applying the same approach to AI could accelerate the adoption of sustainable practices.</p>
<p>Another innovative policy tool is the introduction of carbon credits specifically tailored for AI workloads. Under this system, AI companies could offset emissions by investing in renewable energy projects or carbon capture technologies. AI firms exceeding predefined emissions thresholds would be required to purchase carbon credits, creating a market-based mechanism that naturally incentivizes efficiency. This concept aligns with broader cap-and-trade programs that have successfully reduced emissions in industries like manufacturing and energy production. However, as seen with the challenges surrounding <a href="https://techcommunity.microsoft.com/t5/green-tech-blog/charting-the-path-towards-sustainable-ai-with-azure-machine/ba-p/2866923">unbundled Energy Attribute Certificates (EACs)</a>, carbon credit programs must be carefully structured to ensure genuine emissions reductions rather than allowing companies to simply “buy their way out” of sustainability commitments.</p>
<p>While government incentives offer powerful mechanisms for promoting Green AI, their design and implementation require careful consideration. Incentives should be structured to drive meaningful change without creating loopholes that allow organizations to claim benefits without genuine improvements in sustainability. Additionally, policies must remain flexible enough to accommodate rapid advancements in AI technology. By strategically combining tax incentives, funding programs, procurement policies, and carbon credit systems, governments can create an ecosystem where sustainability is not just a regulatory requirement but an economic advantage.</p>
</section><section id="sec-sustainable-ai-selfregulation-02df" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-selfregulation-02df">Self-Regulation</h3>
<p>While government policies play a important role in shaping sustainable AI practices, the AI industry itself has the power to drive significant environmental improvements through self-regulation. Many leading AI companies and research organizations have already adopted voluntary commitments to reduce their carbon footprints, improve energy efficiency, and promote sustainable development. These efforts can complement regulatory policies and, in some cases, even set higher standards than those mandated by governments.</p>
<p>One of the most visible self-regulation strategies is the commitment by major AI companies to operate on renewable energy. Companies like Google, Microsoft, Amazon, and Meta have pledged to procure enough clean energy to match 100% of their electricity consumption. Google has gone further by aiming for <a href="https://cloud.google.com/blog/topics/sustainability/google-clouds-clean-energy-portfolio-expands-with-new-24-7-carbon-free-energy/">24/7 Carbon-Free Energy</a> by ensuring that its data centers run exclusively on renewables every hour of every day. These commitments not only reduce operational emissions but also create market demand for renewable energy, accelerating the transition to a greener grid. However, as seen with the use of unbundled EACs, transparency and accountability in renewable energy claims remain important to ensuring genuine decarbonization rather than superficial offsets.</p>
<p>Another form of self-regulation is the internal adoption of carbon pricing models. Some companies implement shadow pricing, where they assign an internal cost to carbon emissions in financial decision-making. By incorporating these costs into budgeting and investment strategies, AI companies can prioritize energy-efficient infrastructure and low-emission AI models. This approach mirrors broader corporate sustainability efforts in industries like aviation and manufacturing, where internal carbon pricing has proven to be an effective tool for driving emissions reductions.</p>
<p>Beyond energy consumption, AI developers can implement voluntary efficiency checklists that guide sustainable design choices. Organizations like the <a href="https://climatechange.ai/">AI Sustainability Coalition</a> have proposed frameworks that outline best practices for model development, hardware selection, and operational energy management. These checklists can serve as practical tools for AI engineers to integrate sustainability into their workflows. Companies that publicly commit to following these guidelines set an example for the broader industry, demonstrating that sustainability is not just an afterthought but a core design principle.</p>
<p>Independent sustainability audits further enhance accountability by providing third-party evaluations of AI companies’ environmental impact. Firms specializing in technology sustainability, such as Carbon Trust and Green Software Foundation, offer audits that assess energy consumption, carbon emissions, and adherence to green computing best practices. AI companies that voluntarily undergo these audits and publish their findings help build trust with consumers, investors, and regulators. Transparency in environmental reporting allows stakeholders to verify whether companies are meeting their sustainability commitments.</p>
<p>Self-regulation in AI sustainability also extends to open-source collaborations. Initiatives like <a href="https://codecarbon.io/">CodeCarbon</a> and <a href="https://mlco2.github.io/impact/#compute">ML <span class="math inline">\(\textrm{CO}_2\)</span> Impact</a> provide tools that allow developers to estimate and track the carbon footprint of their AI models. By integrating these tools into mainstream AI development platforms like TensorFlow and PyTorch, the industry can normalize sustainability tracking as a standard practice. Encouraging developers to measure and optimize their energy consumption fosters a culture of accountability and continuous improvement.</p>
<p>While self-regulation is an important step toward sustainability, it cannot replace government oversight. Voluntary commitments are only as strong as the incentives driving them, and without external accountability, some companies may prioritize profit over sustainability. However, when combined with regulatory frameworks, self-regulation can accelerate progress by allowing industry leaders to set higher standards than those mandated by law. By embedding sustainability into corporate strategy, AI companies can demonstrate that technological advancement and environmental responsibility are not mutually exclusive.</p>
</section><section id="sec-sustainable-ai-global-impact-aafd" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-global-impact-aafd">Global Impact</h3>
<p>While AI sustainability efforts are gaining traction, they remain fragmented across national policies, industry initiatives, and regional energy infrastructures. AI’s environmental footprint is inherently global, spanning supply chains, cloud data centers, and international markets. A lack of coordination between governments and corporations risks inefficiencies, contradictory regulations, and loopholes that allow companies to shift environmental burdens rather than genuinely reduce them. Establishing global frameworks for AI sustainability is therefore important for aligning policies, ensuring accountability, and fostering meaningful progress in mitigating AI’s environmental impact.</p>
<p>One of the primary challenges in global AI sustainability efforts is regulatory divergence. Countries and regions are taking vastly different approaches to AI governance. The European Union’s AI Act, for example, introduces comprehensive risk-based regulations that include provisions for energy efficiency and environmental impact assessments for AI systems. By contrast, the United States has largely adopted a market-driven approach, emphasizing corporate self-regulation and voluntary sustainability commitments rather than enforceable mandates. Meanwhile, China has prioritized AI dominance through heavy government investment, with sustainability playing a secondary role to technological leadership. This regulatory patchwork creates inconsistencies in how AI-related emissions, resource consumption, and energy efficiency are tracked and managed.</p>
<p>One proposed solution to this fragmentation is the standardization of sustainability reporting metrics for AI systems. Organizations such as the OECD, IEEE, and United Nations have pushed for unified environmental impact reporting standards similar to financial disclosure frameworks. This would allow companies to track and compare their carbon footprints, energy usage, and resource consumption using common methodologies. The adoption of LCA standards for AI, as observed in wider environmental accounting practices, would allow more accurate assessments of AI’s total environmental impact, from hardware manufacturing to deployment and decommissioning.</p>
<p>Beyond reporting, energy grid decarbonization remains a important global consideration. The sustainability of AI is heavily influenced by the carbon intensity of electricity in different regions. For example, training a large AI model in a coal-powered region like Poland results in significantly higher carbon emissions than training the same model in hydroelectric-powered Norway. However, market-based energy accounting practices, including the purchase of unbundled Energy Attribute Certificates (EACs), have allowed some companies to claim carbon neutrality despite operating in high-emission grids. This has led to concerns that sustainability claims may not always reflect actual emissions reductions but instead rely on financial instruments that shift carbon responsibility rather than eliminating it. As a response, Google has championed 24/7 Carbon-Free Energy (CFE), which aims to match local energy consumption with renewable sources in real-time rather than relying on distant offsets. If widely adopted, this model could become a global benchmark for AI sustainability accounting.</p>
<p>Another key area of global concern is AI hardware supply chains and electronic waste management. The production of AI accelerators, GPUs, and data center hardware depends on a complex network of raw material extraction, semiconductor fabrication, and electronic assembly spanning multiple continents. The environmental impact of this supply chain, which includes rare-earth mineral mining in Africa, chip manufacturing in Taiwan, and final assembly in China, often falls outside the jurisdiction of AI companies themselves. This underscores the need for international agreements on sustainable semiconductor production, responsible mining practices, and e-waste recycling policies.</p>
<p>The Basel Convention, which regulates hazardous waste exports, could provide a model for addressing AI-related e-waste challenges at a global scale. The convention restricts the transfer of toxic electronic waste from developed nations to developing countries, where unsafe recycling practices can harm workers and pollute local ecosystems. Expanding such agreements to cover AI-specific hardware components, such as GPUs and inference chips, could ensure that end-of-life disposal is handled responsibly rather than outsourced to regions with weaker environmental protections.</p>
<p>International collaboration in AI sustainability is not just about mitigating harm but also leveraging AI as a tool for environmental progress. AI models are already being deployed for climate forecasting, renewable energy optimization, and precision agriculture, demonstrating their potential to contribute to global sustainability goals. These applications represent the intersection of AI capabilities with societal benefit, demonstrating how AI can contribute to positive environmental and social outcomes. Governments, research institutions, and industry leaders must align on best practices for scaling AI solutions that support climate action, ensuring that AI is not merely a sustainability challenge but also a powerful tool for global environmental resilience.</p>
<p>Ultimately, sustainable AI requires a coordinated global approach that integrates regulatory alignment, standardized sustainability reporting, energy decarbonization, supply chain accountability, and responsible e-waste management. Without such collaboration, regional disparities in AI governance could hinder meaningful progress, allowing inefficiencies and externalized environmental costs to persist. As AI continues to evolve, establishing global frameworks that balance technological advancement with environmental responsibility will be important in shaping an AI-driven future that is not only intelligent but also sustainable.</p>
<div id="quiz-question-sec-sustainable-ai-policy-regulation-9668" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.3</strong></summary><div>
<ol type="1">
<li>
<p>Which of the following policy tools is used to encourage AI sustainability by providing positive reinforcement?</p>
<ol type="a">
<li>Financial incentives</li>
<li>Computational caps</li>
<li>Emissions trading systems</li>
<li>Outright bans on inefficient AI practices</li>
</ol>
</li>
<li><p>Discuss the challenges of implementing standardized measurement and reporting for AI’s environmental impact. Why is it important?</p></li>
<li><p>True or False: Policy fragmentation across regions poses a challenge to establishing a unified global AI sustainability strategy.</p></li>
<li><p>Order the following steps in the process of implementing AI sustainability reporting: (1) Mandate energy audits, (2) Develop standardized metrics, (3) Increase transparency, (4) Inform decision-making.</p></li>
</ol>
<p><a href="#quiz-answer-sec-sustainable-ai-policy-regulation-9668" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section></section><section id="sec-sustainable-ai-public-engagement-9850" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-public-engagement-9850">Public Engagement</h2>
<p>As artificial intelligence (AI) becomes increasingly intertwined with efforts to address environmental challenges, public perception plays a pivotal role in shaping its adoption, regulation, and long-term societal impact. While AI is often viewed as a powerful tool for advancing sustainability, through applications including smart energy management, climate modeling, and conservation efforts, it also faces scrutiny over its environmental footprint, ethical concerns, and transparency.</p>
<p>Public discourse surrounding AI and sustainability is often polarized. On one side, AI is heralded as a transformative force capable of accelerating climate action, reducing carbon emissions, and optimizing resource use. On the other, concerns persist about the high energy consumption of AI models, the potential for unintended environmental consequences, and the opaque nature of AI-driven decision-making. These contrasting viewpoints influence policy development, funding priorities, and societal acceptance of AI-driven sustainability initiatives.</p>
<p>Bridging the gap between AI researchers, policymakers, and the public is important for ensuring that AI’s contributions to sustainability are both scientifically grounded and socially responsible. This requires clear communication about AI’s capabilities and limitations, greater transparency in AI decision-making processes, and mechanisms for inclusive public participation. Without informed public engagement, misunderstandings and skepticism could hinder the adoption of AI solutions that have the potential to drive meaningful environmental progress.</p>
<section id="sec-sustainable-ai-ai-awareness-ddcc" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-ai-awareness-ddcc">AI Awareness</h3>
<p>Public understanding of AI and its role in sustainability remains limited, often shaped by media narratives that highlight either its transformative potential or its risks. Surveys such as the Pew Research Center poll <span class="citation" data-cites="pew2023ai">(<a href="#ref-pew2023ai" role="doc-biblioref">Center 2023</a>)</span> found that while a majority of people have heard of AI, their understanding of its specific applications, especially in the context of sustainability, remains shallow. Many associate AI with automation, recommendation systems, or chatbots but may not be aware of its broader implications in climate science, energy optimization, and environmental monitoring. This gap between public perception and technical reality underscores the importance of foundational understanding of AI systems and their practical applications in addressing societal challenges.</p>
<div class="no-row-height column-margin column-container"></div><p>A key factor influencing public perception is the framing of AI’s sustainability contributions. Optimistic portrayals emphasize AI’s ability to enhance renewable energy integration, improve climate modeling accuracy, and allow smart infrastructure for reduced emissions. Organizations such as <a href="https://www.climatechange.ai/">Climate Change AI</a> actively promote AI’s potential in environmental applications, fostering a positive narrative. Conversely, concerns about AI’s energy-intensive training processes, ethical considerations, and potential biases contribute to skepticism. Studies analyzing public discourse on AI sustainability reveal an even split between optimism and caution, with some fearing that AI’s environmental costs may outweigh its benefits.</p>
<p>In many cases, public attitudes toward AI-driven sustainability efforts are shaped by trust in institutions. AI systems deployed by reputable environmental organizations or in collaboration with scientific communities tend to receive more favorable reception. However, corporate-led AI sustainability initiatives often face skepticism, particularly if they are perceived as greenwashing—a practice where companies exaggerate their commitment to environmental responsibility without substantial action.</p>
<p>To foster informed public engagement, increasing AI literacy is important. This involves education on AI’s actual energy consumption, potential for optimization, and real-world applications in sustainability. Universities, research institutions, and industry leaders can play a pivotal role in making AI’s sustainability impact more accessible to the general public through open reports, interactive tools, and clear communication strategies.</p>
</section><section id="sec-sustainable-ai-messaging-discourse-b14b" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-messaging-discourse-b14b">Messaging and Discourse</h3>
<p>How AI is communicated to the public significantly influences perceptions of its role in sustainability. The messaging around AI-driven environmental efforts must balance technical accuracy, realistic expectations, and transparency to ensure constructive discourse.</p>
<p>Optimistic narratives emphasize AI’s potential as a powerful tool for sustainability. Initiatives such as <a href="https://www.climatechange.ai/">Climate Change AI</a> and AI-driven conservation projects highlight applications in wildlife protection, climate modeling, energy efficiency, and pollution monitoring. These examples are often framed as AI augmenting human capabilities, enabling more precise and scalable solutions to environmental challenges. Such positive framing encourages public support and investment in AI-driven sustainability research.</p>
<p>However, skepticism remains, particularly regarding AI’s own environmental footprint. Critical perspectives highlight the massive energy demands of AI model training, particularly for large-scale neural networks. The <a href="https://futureoflife.org/open-letter/ai-principles/">Asilomar AI Principles</a> and other cautionary frameworks stress the need for transparency, ethical guardrails, and energy-conscious AI development. The rise of generative AI models has further amplified concerns about data center energy consumption, supply chain sustainability, and the long-term viability of compute-intensive AI workloads.</p>
<p>A key challenge in AI sustainability messaging is avoiding extremes. Public discourse often falls into two polarized views: one where AI is seen as an indispensable tool for solving climate change, and another where AI is portrayed as an unchecked technology accelerating ecological harm. Neither view fully captures the nuanced reality. AI, like any technology, is a tool whose environmental impact depends on how it is developed, deployed, and governed.</p>
<p>To build public trust and engagement, AI sustainability messaging should prioritize three key aspects. First, it must acknowledge clear trade-offs by presenting both the benefits and limitations of AI for sustainability, including energy consumption, data biases, and real-world deployment challenges. Second, messaging should rely on evidence-based claims, communicating AI’s impact through data-driven assessments, lifecycle analyses, and transparent carbon accounting rather than speculative promises. Third, the framing should remain human-centered, emphasizing collaborative AI systems that work alongside scientists, policymakers and communities rather than fully automated, opaque decision-making systems. Through this balanced, transparent approach, AI can maintain credibility while driving meaningful environmental progress.</p>
<p>Effective public engagement relies on bridging the knowledge gap between AI practitioners and non-experts, ensuring that AI’s role in sustainability is grounded in reality, openly discussed, and continuously evaluated.</p>
</section><section id="sec-sustainable-ai-transparency-trust-4d51" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-transparency-trust-4d51">Transparency and Trust</h3>
<p>As AI systems become more integrated into sustainability efforts, transparency and trust are important for ensuring public confidence in their deployment. The complexity of AI models, particularly those used in environmental monitoring, resource optimization, and emissions tracking, often makes it difficult for stakeholders to understand how decisions are being made. Without clear explanations of how AI systems operate, concerns about bias, accountability, and unintended consequences can undermine public trust.</p>
<p>A key aspect of transparency involves ensuring that AI models used in sustainability applications are explainable and interpretable. The <a href="https://www.nist.gov/">National Institute of Standards and Technology (NIST)</a> Principles for Explainable AI provide a framework for designing systems that offer meaningful and understandable explanations of their outputs. These principles emphasize that AI-generated decisions should be contextually relevant, accurately reflect the model’s logic, and clearly communicate the limitations of the system <span class="citation" data-cites="phillips2020four">(<a href="#ref-phillips2020four" role="doc-biblioref">Phillips et al. 2020</a>)</span>. In sustainability applications, where AI influences environmental policy, conservation strategies, and energy management, interpretability is important for public accountability.</p>
<div class="no-row-height column-margin column-container"><div id="ref-phillips2020four" class="csl-entry" role="listitem">
Phillips, P. Jonathon, Carina A. Hahn, Peter C. Fontana, David A. Broniatowski, and Mark A. Przybocki. 2020. <span>“Four Principles of Explainable Artificial Intelligence.”</span> <em>Gaithersburg, Maryland</em>. National Institute of Standards; Technology (NIST). <a href="https://doi.org/10.6028/nist.ir.8312-draft">https://doi.org/10.6028/nist.ir.8312-draft</a>.
</div></div><p>Transparency is also necessary in AI sustainability claims. Many technology companies promote AI-driven sustainability initiatives, yet without standardized reporting, it is difficult to verify the actual impact. The Montréal Carbon Pledge offers a valuable framework for accountability in this space:</p>
<blockquote class="blockquote">
<p>“As institutional investors, we must act in the best long-term interests of our beneficiaries. In this fiduciary role, long-term investment risks are associated with greenhouse gas emissions, climate change, and carbon regulation. Measuring our carbon footprint is integral to understanding better, quantifying, and managing the carbon and climate change-related impacts, risks, and opportunities in our investments. Therefore, as a first step, we commit to measuring and disclosing the carbon footprint of our investments annually to use this information to develop an engagement strategy and identify and set carbon footprint reduction targets.” — Montréal Carbon Pledge</p>
</blockquote>
<p>This commitment to measuring and disclosing carbon footprints serves as a model for how AI sustainability claims could be validated. A similar commitment for AI, where companies disclose the environmental footprint of training and deploying models, would provide the public with a clearer picture of AI’s sustainability contributions. Without such measures, companies risk accusations of “greenwashing,” where claims of sustainability benefits are exaggerated or misleading.</p>
<p>Beyond corporate accountability, transparency in AI governance ensures that AI systems deployed for sustainability are subject to ethical oversight. The integration of AI into environmental decision-making raises questions about who has control over these technologies and how they align with societal values. Efforts such as the OECD AI Policy Observatory highlight the need for regulatory frameworks that require AI developers to disclose energy consumption, data sources, and model biases when deploying AI in important sustainability applications. Public accessibility to this information would allow greater scrutiny and foster trust in AI-driven solutions.</p>
<p>Building trust in AI for sustainability requires not only clear explanations of how models function but also proactive efforts to include stakeholders in decision-making processes. Transparency mechanisms such as open-access datasets, public AI audits, and participatory model development can enhance accountability. By ensuring that AI applications in sustainability remain understandable, verifiable, and ethically governed, trust can be established, enabling broader public support for AI-driven environmental solutions.</p>
</section><section id="sec-sustainable-ai-engagement-awareness-199d" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-engagement-awareness-199d">Engagement and Awareness</h3>
<p>Public engagement plays a important role in shaping the adoption and effectiveness of AI-driven sustainability efforts. While AI has the potential to drive significant environmental benefits, its success depends on how well the public understands and supports its applications. Widespread misconceptions, limited awareness of AI’s role in sustainability, and concerns about ethical and environmental risks can hinder meaningful engagement. Addressing these issues requires deliberate efforts to educate, involve, and empower diverse communities in discussions about AI’s impact on environmental sustainability.</p>
<p>Surveys indicate that while AI is widely recognized, the specific ways it intersects with sustainability remain unclear to the general public. A study conducted by the Pew Research Center <span class="citation" data-cites="pew2023ai">(<a href="#ref-pew2023ai" role="doc-biblioref">Center 2023</a>)</span> found that while 87% of respondents had some awareness of AI, only a small fraction could explain how it affects energy consumption, emissions, or conservation efforts. This gap in understanding can lead to skepticism, with some viewing AI as a potential contributor to environmental harm due to its high computational demands rather than as a tool for addressing climate challenges. To build public confidence in AI sustainability initiatives, clear communication is important.</p>
<div class="no-row-height column-margin column-container"><div id="ref-pew2023ai" class="csl-entry" role="listitem">
Center, Pew Research. 2023. <span>“What Americans Know about AI, Cybersecurity and Big Tech.”</span><a href="https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/%0A%20%20">https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/ </a>.
</div></div><p>Efforts to improve AI literacy in sustainability contexts can take multiple forms. Educational campaigns highlighting AI’s role in optimizing renewable energy grids, reducing food waste, or monitoring biodiversity can help demystify the technology. Programs such as Climate Change AI and Partnership on AI actively work to bridge this gap by providing accessible research, case studies, and policy recommendations that illustrate AI’s benefits in addressing climate change. Similarly, media representation plays a significant role in shaping perceptions, and responsible reporting on AI’s environmental potential, in conjunction with its challenges, can provide a more balanced narrative.</p>
<p>Beyond education, engagement requires active participation from various stakeholders, including local communities, environmental groups, and policymakers. Many AI-driven sustainability projects focus on data collection and automation but lack mechanisms for involving affected communities in decision-making. For example, AI models used in water conservation or wildfire prediction may rely on data that overlooks the lived experiences of local populations. Creating channels for participatory AI design, in which communities contribute insights, validate model outputs, and influence policy, can lead to more inclusive and context-aware sustainability solutions.</p>
<p>Transparency and public input are particularly important when AI decisions affect resource allocation, environmental justice, or regulatory actions. AI-driven carbon credit markets, for instance, require mechanisms to ensure that communities in developing regions benefit from sustainability initiatives rather than facing unintended harms such as land displacement or exploitation. Public consultations, open-data platforms, and independent AI ethics committees can help integrate societal values into AI-driven sustainability policies.</p>
<p>Ultimately, fostering public engagement and awareness in AI sustainability requires a multi-faceted approach that combines education, communication, and participatory governance. By ensuring that AI systems are accessible, understandable, and responsive to community needs, public trust and support for AI-driven sustainability solutions can be strengthened. This engagement is important to aligning AI innovation with societal priorities and ensuring that environmental AI systems serve the broader public good.</p>
</section><section id="sec-sustainable-ai-equitable-ai-access-b94f" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-equitable-ai-access-b94f">Equitable AI Access</h3>
<p>Ensuring equitable access to AI-driven sustainability solutions is important for fostering global environmental progress. While AI has demonstrated its ability to optimize energy grids, monitor deforestation, and improve climate modeling, access to these technologies remains unevenly distributed. Developing nations, marginalized communities, and small-scale environmental organizations often lack the infrastructure, funding, and expertise necessary to use AI effectively. Addressing these disparities is important to ensuring that the benefits of AI sustainability solutions reach all populations rather than exacerbating existing environmental and socioeconomic inequalities.</p>
<p>One of the primary barriers to equitable AI access is the digital divide. Many AI sustainability applications rely on advanced computing infrastructure, cloud resources, and high-quality datasets, which are predominantly concentrated in high-income regions. A recent OECD report on national AI compute capacity highlighted that many countries lack a strategic roadmap for developing AI infrastructure, leading to a growing gap between AI-rich and AI-poor regions <span class="citation" data-cites="oecd2023blueprint">(<a href="#ref-oecd2023blueprint" role="doc-biblioref">OECD 2023</a>)</span>. Without targeted investment in AI infrastructure, lower-income countries remain excluded from AI-driven sustainability advancements. Expanding access to computing resources, supporting open-source AI frameworks, and providing cloud-based AI solutions for environmental monitoring could help bridge this gap.</p>
<div class="no-row-height column-margin column-container"><div id="ref-oecd2023blueprint" class="csl-entry" role="listitem">
OECD. 2023. <span>“A Blueprint for Building National Compute Capacity for Artificial Intelligence.”</span> 350. Organisation for Economic Co-Operation; Development (OECD). <a href="https://doi.org/10.1787/876367e3-en">https://doi.org/10.1787/876367e3-en</a>.
</div></div><p>In addition to infrastructure limitations, a lack of high-quality, region-specific data poses a significant challenge. AI models trained on datasets from industrialized nations may not generalize well to other geographic and socioeconomic contexts. For example, an AI model optimized for water conservation in North America may be ineffective in regions facing different climate patterns, agricultural practices, or regulatory structures. Efforts to localize AI sustainability applications, through the collection of diverse datasets, partnerships with local organizations, and the integration of indigenous knowledge, can enhance the relevance and impact of AI solutions in underrepresented regions.</p>
<p>Access to AI tools also requires technical literacy and capacity-building initiatives. Many small environmental organizations and community-driven sustainability projects do not have the in-house expertise needed to develop or deploy AI solutions effectively. Capacity-building efforts, such as AI training programs, knowledge-sharing networks, and collaborations between academic institutions and environmental groups, can empower local stakeholders to adopt AI-driven sustainability practices. Organizations like Climate Change AI and the Partnership on AI have taken steps to provide resources and guidance on using AI for environmental applications, but more widespread efforts are needed to democratize access.</p>
<p>Funding mechanisms also play a important role in determining who benefits from AI-driven sustainability. While large corporations and well-funded research institutions can afford to invest in AI-powered environmental solutions, smaller organizations often lack the necessary financial resources. Government grants, philanthropic funding, and international AI-for-good initiatives could help ensure that grassroots sustainability efforts can use AI technologies. For instance, Spain has allocated 300 million euros specifically for AI and sustainability projects, setting a precedent for public investment in environmentally responsible AI innovation. Expanding such funding models globally could foster more inclusive AI adoption.</p>
<p>Beyond technical and financial barriers, policy interventions are necessary to ensure that AI sustainability efforts are equitably distributed. Without regulatory frameworks that prioritize inclusion, AI-driven environmental solutions may disproportionately benefit regions with existing technological advantages while neglecting areas with the most pressing sustainability challenges. Governments and international bodies should establish policies that encourage equitable AI adoption, such as requiring AI sustainability projects to consider social impact assessments or mandating transparent reporting on AI-driven environmental initiatives.</p>
<p>Ensuring equitable access to AI for sustainability is not merely a technical challenge but a core issue of environmental justice. As AI continues to shape global sustainability efforts, proactive measures must be taken to prevent technology from reinforcing existing inequalities. By investing in AI infrastructure, localizing AI applications, supporting capacity-building efforts, and implementing inclusive policies, AI can become a tool that empowers all communities in the fight against climate change and environmental degradation.</p>
<div id="quiz-question-sec-sustainable-ai-public-engagement-9850" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.4</strong></summary><div>
<ol type="1">
<li>
<p>Which of the following factors most significantly influences public perception of AI in sustainability efforts?</p>
<ol type="a">
<li>The cost of AI deployment</li>
<li>Technical accuracy of AI models</li>
<li>Media narratives and framing</li>
<li>The speed of AI development</li>
</ol>
</li>
<li><p>True or False: Public trust in AI sustainability initiatives is generally higher when these initiatives are led by corporate entities.</p></li>
<li><p>Discuss the importance of transparency in AI-driven sustainability initiatives. How does it affect public trust and engagement?</p></li>
<li><p>Order the following steps in fostering public engagement in AI sustainability: (1) Increase AI literacy, (2) Ensure transparency, (3) Involve diverse communities.</p></li>
<li>
<p>What is a potential risk of not addressing the digital divide in AI-driven sustainability solutions?</p>
<ol type="a">
<li>Exacerbation of existing inequalities</li>
<li>Increased environmental degradation</li>
<li>Reduced innovation in AI technologies</li>
<li>Higher costs of AI deployment</li>
</ol>
</li>
</ol>
<p><a href="#quiz-answer-sec-sustainable-ai-public-engagement-9850" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section></section><section id="sec-sustainable-ai-future-challenges-58e2" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-future-challenges-58e2">Future Challenges</h2>
<p>As AI continues to evolve, its role in environmental sustainability is set to expand. Advances in AI have the potential to accelerate progress in renewable energy, climate modeling, biodiversity conservation, and resource efficiency. However, realizing this potential requires addressing significant challenges related to energy efficiency, infrastructure sustainability, data availability, and governance. The future of AI and sustainability hinges on balancing innovation with responsible environmental stewardship, ensuring that AI-driven progress does not come at the cost of increased environmental degradation.</p>
<section id="sec-sustainable-ai-future-directions-633b" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-future-directions-633b">Future Directions</h3>
<p>A major priority in AI sustainability is the development of more energy-efficient models and algorithms. Optimizing deep learning models to minimize computational cost is a key research direction, with techniques such as model pruning, quantization, and low-precision numerics demonstrating significant potential for reducing energy consumption without compromising performance. These strategies aim to improve the efficiency of AI workloads while leveraging specialized hardware accelerators to maximize computational throughput with minimal energy expenditure. The continued development of non-von Neumann computing<a href="#fn48" class="footnote-ref" id="fnref48" role="doc-noteref"><sup>48</sup></a> paradigms, such as neuromorphic computing and in-memory computing, presents another avenue for energy-efficient AI architectures, through specialized hardware designs.</p>
<div class="no-row-height column-margin column-container"><div id="fn48"><p><sup>48</sup>&nbsp;<strong>Von Neumann Architecture</strong>: Traditional computing model where processing unit and memory are separate, requiring constant data movement between CPU and RAM. Proposed by John von Neumann in 1945, dominates modern computers but creates the “von Neumann bottleneck”—energy-intensive data shuttling that consumes 60-80% of system power. Non-von Neumann approaches like neuromorphic chips, in-memory computing, and dataflow architectures eliminate this bottleneck by processing data where it’s stored, potentially reducing AI energy consumption by 100-1000×.</p></div></div><p>Another important direction involves the integration of renewable energy into AI infrastructure. Given that data centers are among the largest contributors to AI’s carbon footprint, shifting towards clean energy sources like solar, wind, and hydroelectric power is imperative. The feasibility of this transition depends on advancements in sustainable energy storage technologies, such as those being developed by companies like <a href="https://ambri.com/">Ambri</a>, an MIT spinoff working on liquid metal battery solutions. These innovations could allow data centers to operate on renewable energy with greater reliability, reducing dependency on fossil fuel-based grid power. However, achieving this transition at scale requires collaborative efforts between AI companies, energy providers, and policymakers to develop grid-aware AI scheduling and carbon-aware workload management strategies, ensuring that compute-intensive AI tasks are performed when renewable energy availability is at its peak.</p>
<p>Beyond energy efficiency, AI sustainability will also benefit from intelligent resource allocation and waste reduction strategies. Improving the utilization of computing resources, reducing redundant model training cycles, and implementing efficient data sampling techniques can substantially decrease energy consumption. A key challenge in AI model development is the trade-off between experimentation and efficiency—techniques such as neural architecture search and hyperparameter optimization can improve model performance but often require vast computational resources. Research into efficient experimentation methodologies could help strike a balance, allowing for model improvements while mitigating the environmental impact of excessive training runs.</p>
</section><section id="sec-sustainable-ai-challenges-16ab" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-challenges-16ab">Challenges</h3>
<p>Despite these promising directions, significant obstacles must be addressed to make AI truly sustainable. One of the most pressing challenges is the lack of standardized measurement and reporting frameworks for evaluating AI’s environmental footprint. Unlike traditional industries, where LCA methodologies are well-established, AI systems require more comprehensive and adaptable approaches that account for the full environmental impact of both hardware (compute infrastructure) and software (model training and inference cycles). While efforts such as <a href="https://mlcommons.org/">MLCommons</a> have begun integrating energy efficiency into benchmarking practices, a broader, globally recognized standard is necessary to ensure consistency in reporting AI-related emissions.</p>
<p>Another important challenge is optimizing AI infrastructure for longevity and sustainability. AI accelerators and data center hardware must be designed with maximized utilization, extended operational lifespans, and minimal environmental impact in mind. Unlike conventional hardware refresh cycles, which often prioritize performance gains over sustainability, future AI infrastructure must prioritize reusability, modular design, and circular economy principles to minimize electronic waste and reduce reliance on rare earth materials.</p>
<p>From a software perspective, minimizing redundant computation is important to reducing energy-intensive workloads. The practice of training larger models on increasingly vast datasets, while beneficial for accuracy, comes with diminishing returns in sustainability. A data-centric approach to AI model development, as highlighted in recent work <span class="citation" data-cites="wu2022sustainable">(<a href="#ref-wu2022sustainable" role="doc-biblioref">Wu et al. 2022</a>)</span>, suggests that the predictive value of data decays over time, making it important to identify and filter the most relevant data subsets. Smarter data sampling strategies can optimize training processes, ensuring that only the most informative data is used to refine models, reducing the energy footprint without sacrificing model quality.</p>
<div class="no-row-height column-margin column-container"><div id="ref-wu2022sustainable" class="csl-entry" role="listitem">
Wu, Carole-Jean, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, et al. 2022. <span>“Sustainable Ai: Environmental Implications, Challenges and Opportunities.”</span> <em>Proceedings of Machine Learning and Systems</em> 4: 795–813.
</div></div><p>A further challenge lies in data accessibility and transparency. Many AI sustainability efforts rely on corporate and governmental disclosures of energy usage, carbon emissions, and environmental impact data. However, data gaps and inconsistencies hinder efforts to accurately assess AI’s footprint. Greater transparency from AI companies regarding their sustainability initiatives, coupled with open-access datasets for environmental impact research, would allow more rigorous analysis and inform best practices for sustainable AI development.</p>
<p>Finally, the rapid pace of AI innovation poses challenges for regulation and governance. Policymakers must develop agile, forward-looking policies that promote sustainability while preserving the flexibility needed for AI research and innovation. Regulatory frameworks should encourage efficient AI practices, such as promoting carbon-aware computing, incentivizing energy-efficient AI model development, and ensuring that AI-driven environmental applications align with broader sustainability goals. Achieving this requires close collaboration between AI researchers, environmental scientists, energy sector stakeholders, and policymakers to develop a regulatory landscape that fosters responsible AI growth while minimizing ecological harm.</p>
</section><section id="sec-sustainable-ai-towards-sustainable-ai-96ad" class="level3"><h3 class="anchored" data-anchor-id="sec-sustainable-ai-towards-sustainable-ai-96ad">Towards Sustainable AI</h3>
<p>The future of AI in sustainability is both promising and fraught with challenges. To harness AI’s full potential while mitigating its environmental impact, the field must embrace energy-efficient model development, renewable energy integration, hardware and software optimizations, and transparent environmental reporting. Addressing these challenges will require multidisciplinary collaboration across technical, industrial, and policy domains, ensuring that AI’s trajectory aligns with global sustainability efforts.</p>
<p>By embedding sustainability principles into AI system design, optimizing compute infrastructure, and establishing clear accountability mechanisms, AI can serve as a catalyst for environmental progress rather than a contributor to ecological degradation. The coming years will be pivotal in shaping AI’s role in sustainability, determining whether it amplifies existing challenges or emerges as a key tool in the fight against climate change and resource depletion.</p>
<div id="quiz-question-sec-sustainable-ai-future-challenges-58e2" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.5</strong></summary><div>
<ol type="1">
<li>
<p>Which of the following strategies is crucial for reducing the energy consumption of AI models without compromising performance?</p>
<ol type="a">
<li>Increasing dataset size</li>
<li>Using more GPUs</li>
<li>Model pruning and quantization</li>
<li>Increasing model complexity</li>
</ol>
</li>
<li><p>Discuss the role of renewable energy integration in AI infrastructure. What are the key challenges associated with this transition?</p></li>
<li><p>True or False: A significant challenge in AI sustainability is the lack of standardized measurement and reporting frameworks for evaluating environmental impact.</p></li>
<li><p>AI sustainability efforts can benefit from intelligent resource allocation and ____ reduction strategies.</p></li>
<li><p>How might AI researchers balance the trade-off between experimentation and efficiency in model development?</p></li>
</ol>
<p><a href="#quiz-answer-sec-sustainable-ai-future-challenges-58e2" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section></section><section id="fallacies-and-pitfalls" class="level2"><h2 class="anchored" data-anchor-id="fallacies-and-pitfalls">Fallacies and Pitfalls</h2>
<p>Sustainable AI involves complex trade-offs between computational performance and environmental impact that often challenge conventional assumptions about efficient and responsible system design. The growing scale of AI workloads and the appeal of cloud computing convenience can create misconceptions about the true environmental costs and most effective strategies for reducing ecological impact.</p>
<p><strong>Fallacy:</strong> <em>Cloud computing automatically makes AI systems more environmentally sustainable.</em></p>
<p>This misconception assumes that cloud deployment inherently provides environmental benefits without considering the actual energy sources and utilization patterns of cloud infrastructure. While cloud providers can achieve better resource utilization than individual organizations, they often rely on fossil fuel energy sources and operate data centers in regions with carbon-intensive electricity grids. The convenience of cloud scaling can also enable wasteful resource consumption through over-provisioning and inefficient workload scheduling. True sustainability requires careful provider selection, region-aware deployment, and conscious resource management rather than assuming cloud deployment is inherently green.</p>
<p><strong>Pitfall:</strong> <em>Focusing only on operational energy consumption while ignoring embodied carbon and lifecycle impacts.</em></p>
<p>Many practitioners measure AI sustainability using only training and inference energy consumption without accounting for the full environmental footprint of their systems. Hardware manufacturing, data center construction, cooling infrastructure, and electronic waste disposal contribute significantly to total environmental impact. The embodied carbon in specialized AI accelerators can exceed operational emissions for many workloads. Comprehensive sustainability assessment requires lifecycle analysis that includes manufacturing impacts, infrastructure requirements, and end-of-life disposal rather than focusing solely on operational energy consumption.</p>
<p><strong>Fallacy:</strong> <em>Efficiency improvements automatically translate to reduced environmental impact.</em></p>
<p>This belief assumes that making AI systems more computationally efficient necessarily reduces their environmental footprint. However, efficiency gains often enable increased usage through the rebound effect, where cheaper computation leads to expanded deployment and application scope. A more efficient model might be deployed more widely, potentially increasing total resource consumption despite per-unit improvements. Additionally, efficiency optimizations that require specialized hardware may increase embodied carbon through accelerated hardware replacement cycles. Sustainable AI requires considering both efficiency improvements and their broader deployment implications.</p>
<p><strong>Pitfall:</strong> <em>Treating carbon offsets as a substitute for reducing actual emissions.</em></p>
<p>Organizations often purchase carbon offsets to neutralize their AI system emissions without addressing underlying energy consumption patterns. Many offset programs have questionable additionality, permanence, or verification standards that fail to deliver promised environmental benefits. Relying on offsets can delay necessary transitions to renewable energy sources and efficient computing practices. Sustainable AI development should prioritize actual emissions reduction through renewable energy adoption, efficiency improvements, and conscious resource management, using offsets only as a complement to rather than replacement for emissions reduction strategies.</p>
<p><strong>Pitfall:</strong> <em>Optimizing individual components for sustainability without considering full system lifecycle impacts.</em></p>
<p>Many sustainability efforts focus on optimizing individual system components in isolation without analyzing how these optimizations affect the broader system architecture and lifecycle environmental impact. Reducing training energy consumption through smaller models may increase inference computational requirements if deployed widely, potentially increasing total system emissions. Similarly, extending hardware lifespan through efficient software may be less sustainable than adopting newer, more energy-efficient hardware when considering full lifecycle emissions. Edge deployment to reduce data center energy consumption may increase manufacturing demand for distributed hardware and create complex electronic waste management challenges. Network optimization that reduces bandwidth usage might require additional computational resources for compression or caching. Effective sustainable AI requires holistic lifecycle assessment that considers the environmental implications of system design decisions across hardware procurement, software deployment, operational usage patterns, maintenance requirements, and end-of-life disposal rather than optimizing individual metrics in isolation.</p>
</section><section id="sec-sustainable-ai-summary-8cec" class="level2"><h2 class="anchored" data-anchor-id="sec-sustainable-ai-summary-8cec">Summary</h2>
<p>Sustainable AI represents an intersection where technological advancement must align with environmental responsibility and resource conservation. Machine learning systems consume energy through compute-intensive training, operate energy-hungry inference infrastructure, and drive demand for resource-intensive hardware manufacturing. Yet these same systems offer capabilities for climate modeling, emissions reduction, resource optimization, and biodiversity conservation, creating a complex relationship between environmental impact and environmental benefit that requires careful engineering consideration.</p>
<p>The full lifecycle impact of AI systems extends beyond operational energy consumption to encompass hardware manufacturing, data center infrastructure, cooling systems, and electronic waste management. Green AI practices focus on energy-efficient model architectures, renewable energy integration, carbon-aware computing, and lifecycle-aware development processes. Policy frameworks and measurement standards drive accountability through environmental reporting mandates, efficiency incentives, and governance mechanisms that align technological innovation with sustainability goals.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Key Takeaways">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Takeaways
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>AI systems create environmental impact across their full lifecycle, from hardware manufacturing through training, deployment, and disposal</li>
<li>Sustainable AI requires balancing computational capabilities against environmental costs through efficient architectures and responsible infrastructure choices</li>
<li>Green AI practices encompass energy-aware model design, renewable energy integration, carbon-aware computing, and comprehensive lifecycle assessment</li>
<li>Success demands interdisciplinary collaboration between AI researchers, environmental scientists, policymakers, and industry stakeholders</li>
</ul>
</div>
</div>
<p>The future of sustainable AI depends on choices made today regarding system design, infrastructure deployment, and governance frameworks. Climate applications demonstrate AI’s potential to accelerate environmental solutions, from improving energy grid efficiency to optimizing resource usage and modeling complex ecological systems. However, realizing this potential requires embedding sustainability considerations into every aspect of AI development, creating systems that enhance rather than compromise environmental well-being while advancing technological capabilities.</p>


<div id="quiz-question-sec-sustainable-ai-summary-8cec" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.6</strong></summary><div>
<ol type="1">
<li>
<p>Which of the following is a primary challenge in integrating AI into environmental sustainability efforts?</p>
<ol type="a">
<li>Lack of AI model transparency</li>
<li>High computational costs and energy consumption</li>
<li>Limited data availability</li>
<li>Slow technological advancement</li>
</ol>
</li>
<li><p>Discuss the role of policy and regulatory frameworks in shaping a sustainable AI ecosystem.</p></li>
<li>
<p>What is a potential benefit of AI in environmental sustainability?</p>
<ol type="a">
<li>Enhanced climate modeling capabilities</li>
<li>Increased e-waste production</li>
<li>Reduced need for renewable energy</li>
<li>Greater reliance on fossil fuels</li>
</ol>
</li>
<li><p>How can AI practitioners balance the trade-off between technological progress and environmental sustainability?</p></li>
</ol>
<p><a href="#quiz-answer-sec-sustainable-ai-summary-8cec" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section><section id="self-check-answers" class="level2"><h2 class="anchored" data-anchor-id="self-check-answers">Self-Check Answers</h2>
<div id="quiz-answer-sec-sustainable-ai-semiconductor-life-cycle-5c14" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.1</strong></summary><div>
<ol type="1">
<li>
<p><strong>Which phase of the AI lifecycle is primarily concerned with the computational demands of model training and inference?</strong></p>
<ol type="a">
<li>Design Phase</li>
<li>Manufacturing Phase</li>
<li>Disposal Phase</li>
<li>Use Phase</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Use Phase. This phase involves the energy-intensive activities of training and inference, making it a significant contributor to AI’s operational carbon footprint.</p>
<p><em>Learning Objective</em>: Understand the energy demands during different phases of the AI lifecycle.</p>
</li>
<li>
<p><strong>How does Life Cycle Analysis (LCA) help in reducing the environmental impact of AI systems?</strong></p>
<p><em>Answer</em>: LCA helps by providing a comprehensive assessment of the environmental impact across all lifecycle stages of AI systems. It identifies key intervention points for reducing emissions and improving resource efficiency. For example, LCA can highlight the benefits of using renewable energy in data centers, thus guiding sustainable practices. This is important because it ensures sustainability considerations are integrated into every stage of AI development.</p>
<p><em>Learning Objective</em>: Explain the role of LCA in promoting sustainable AI practices.</p>
</li>
<li>
<p><strong>True or False: The manufacturing phase of AI systems has a greater environmental impact than the use phase due to its high energy consumption and waste generation.</strong></p>
<p><em>Answer</em>: True. The manufacturing phase involves energy-intensive processes and generates significant waste, often exceeding the environmental impact of the use phase.</p>
<p><em>Learning Objective</em>: Understand the environmental impact of the manufacturing phase in the AI lifecycle.</p>
</li>
<li>
<p><strong>The rapid turnover of AI hardware contributes to growing electronic waste, also known as ____, which poses significant environmental challenges.</strong></p>
<p><em>Answer</em>: e-waste. E-waste includes discarded electronic devices and components, which often contain hazardous materials and require careful disposal to prevent environmental harm.</p>
<p><em>Learning Objective</em>: Identify the environmental challenges associated with AI hardware disposal.</p>
</li>
<li>
<p><strong>Which of the following is a potential strategy to improve the sustainability of AI systems during the use phase?</strong></p>
<ol type="a">
<li>Implementing energy-efficient chip architectures</li>
<li>Utilizing carbon-intensive data centers</li>
<li>Increasing the frequency of hardware upgrades</li>
<li>Extending training times for models</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Implementing energy-efficient chip architectures. This strategy reduces the per-query energy consumption and overall carbon footprint of AI systems.</p>
<p><em>Learning Objective</em>: Explore strategies for improving the sustainability of AI systems during their use phase.</p>
</li>
</ol>
<p><a href="#quiz-question-sec-sustainable-ai-semiconductor-life-cycle-5c14" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-sustainable-ai-embedded-ai-ewaste-292b" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.2</strong></summary><div>
<ol type="1">
<li>
<p><strong>What is a major environmental challenge associated with the proliferation of embedded AI devices?</strong></p>
<ol type="a">
<li>Increased carbon emissions from data centers</li>
<li>Decreased efficiency in AI algorithms</li>
<li>Higher energy consumption in cloud computing</li>
<li>Rapid growth of electronic waste</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Rapid growth of electronic waste. Embedded AI devices often have short lifespans and limited upgradeability, leading to increased e-waste. Other options focus on issues not directly related to embedded AI.</p>
<p><em>Learning Objective</em>: Understand the environmental challenges posed by embedded AI systems.</p>
</li>
<li>
<p><strong>True or False: Embedded AI devices are typically designed for long-term use and easy recyclability.</strong></p>
<p><em>Answer</em>: False. Embedded AI devices are often designed to be low-cost and disposable, with limited repairability and recyclability, contributing to e-waste.</p>
<p><em>Learning Objective</em>: Recognize the design limitations of embedded AI devices and their impact on sustainability.</p>
</li>
<li>
<p><strong>Discuss how planned obsolescence in AI-powered devices contributes to the e-waste crisis.</strong></p>
<p><em>Answer</em>: Planned obsolescence in AI-powered devices leads to shorter product lifespans, forcing consumers to replace devices frequently. This practice increases e-waste as devices become obsolete quickly, exacerbating environmental challenges. For example, non-replaceable batteries and proprietary components prevent repair, leading to disposal rather than reuse.</p>
<p><em>Learning Objective</em>: Analyze the impact of planned obsolescence on electronic waste and sustainability.</p>
</li>
<li>
<p><strong>Which of the following strategies can help mitigate the e-waste crisis caused by embedded AI devices?</strong></p>
<ol type="a">
<li>Designing devices with modular components</li>
<li>Increasing the use of proprietary components</li>
<li>Shortening software support cycles</li>
<li>Encouraging single-use designs</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Designing devices with modular components. Modular designs allow for easier repair and upgrade, reducing the need for frequent replacements and decreasing e-waste.</p>
<p><em>Learning Objective</em>: Identify strategies to improve the sustainability of embedded AI systems.</p>
</li>
</ol>
<p><a href="#quiz-question-sec-sustainable-ai-embedded-ai-ewaste-292b" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-sustainable-ai-policy-regulation-9668" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.3</strong></summary><div>
<ol type="1">
<li>
<p><strong>Which of the following policy tools is used to encourage AI sustainability by providing positive reinforcement?</strong></p>
<ol type="a">
<li>Financial incentives</li>
<li>Computational caps</li>
<li>Emissions trading systems</li>
<li>Outright bans on inefficient AI practices</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Financial incentives. This is correct because financial incentives, such as tax credits and grants, provide positive reinforcement for adopting energy-efficient practices. Other options like computational caps and outright bans are restrictive measures.</p>
<p><em>Learning Objective</em>: Understand the role of financial incentives in promoting AI sustainability.</p>
</li>
<li>
<p><strong>Discuss the challenges of implementing standardized measurement and reporting for AI’s environmental impact. Why is it important?</strong></p>
<p><em>Answer</em>: Standardized measurement and reporting face challenges such as inconsistent methodologies, lack of universally accepted metrics, and potential reporting burdens on smaller firms. It’s important because it increases transparency, informs better decision-making, and holds organizations accountable for their environmental footprint. For example, without standardized metrics, comparing energy efficiency across AI models is difficult, hindering efforts to reduce AI’s carbon footprint.</p>
<p><em>Learning Objective</em>: Analyze the importance and challenges of standardized reporting in AI sustainability.</p>
</li>
<li>
<p><strong>True or False: Policy fragmentation across regions poses a challenge to establishing a unified global AI sustainability strategy.</strong></p>
<p><em>Answer</em>: True. This is true because different regions, such as the EU, US, and China, have varying approaches to AI governance, creating inconsistencies and potential barriers to a unified global strategy.</p>
<p><em>Learning Objective</em>: Recognize the impact of policy fragmentation on global AI sustainability efforts.</p>
</li>
<li>
<p><strong>Order the following steps in the process of implementing AI sustainability reporting: (1) Mandate energy audits, (2) Develop standardized metrics, (3) Increase transparency, (4) Inform decision-making.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Develop standardized metrics, (1) Mandate energy audits, (3) Increase transparency, (4) Inform decision-making. Developing metrics is foundational, followed by audits to collect data, which increases transparency and informs decision-making.</p>
<p><em>Learning Objective</em>: Understand the sequence of steps involved in implementing AI sustainability reporting.</p>
</li>
</ol>
<p><a href="#quiz-question-sec-sustainable-ai-policy-regulation-9668" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-sustainable-ai-public-engagement-9850" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.4</strong></summary><div>
<ol type="1">
<li>
<p><strong>Which of the following factors most significantly influences public perception of AI in sustainability efforts?</strong></p>
<ol type="a">
<li>The cost of AI deployment</li>
<li>Technical accuracy of AI models</li>
<li>Media narratives and framing</li>
<li>The speed of AI development</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Media narratives and framing. This is correct because public perception is often shaped by how AI’s sustainability contributions are portrayed in the media, highlighting either its potential or risks. Other options, while relevant, are not the primary influencers of public perception.</p>
<p><em>Learning Objective</em>: Understand the role of media narratives in shaping public perception of AI in sustainability.</p>
</li>
<li>
<p><strong>True or False: Public trust in AI sustainability initiatives is generally higher when these initiatives are led by corporate entities.</strong></p>
<p><em>Answer</em>: False. Public trust is generally higher when AI sustainability initiatives are led by reputable environmental organizations or in collaboration with scientific communities, as corporate-led initiatives often face skepticism due to perceptions of greenwashing.</p>
<p><em>Learning Objective</em>: Recognize the factors that influence public trust in AI sustainability efforts.</p>
</li>
<li>
<p><strong>Discuss the importance of transparency in AI-driven sustainability initiatives. How does it affect public trust and engagement?</strong></p>
<p><em>Answer</em>: Transparency in AI-driven sustainability initiatives is important because it helps build public trust by providing clear explanations of AI models’ operations and impacts. For example, when companies disclose the environmental footprint of AI models, it allows for public scrutiny and accountability, reducing skepticism. This is important because transparency ensures that AI systems are perceived as credible and ethically governed, fostering broader public support.</p>
<p><em>Learning Objective</em>: Explain the role of transparency in enhancing public trust and engagement in AI sustainability initiatives.</p>
</li>
<li>
<p><strong>Order the following steps in fostering public engagement in AI sustainability: (1) Increase AI literacy, (2) Ensure transparency, (3) Involve diverse communities.</strong></p>
<p><em>Answer</em>: The correct order is: (1) Increase AI literacy, (3) Involve diverse communities, (2) Ensure transparency. Increasing AI literacy provides the foundational knowledge necessary for understanding AI’s role in sustainability. Involving diverse communities ensures that multiple perspectives are considered, and ensuring transparency builds trust and accountability.</p>
<p><em>Learning Objective</em>: Understand the sequential steps necessary for effective public engagement in AI sustainability initiatives.</p>
</li>
<li>
<p><strong>What is a potential risk of not addressing the digital divide in AI-driven sustainability solutions?</strong></p>
<ol type="a">
<li>Exacerbation of existing inequalities</li>
<li>Increased environmental degradation</li>
<li>Reduced innovation in AI technologies</li>
<li>Higher costs of AI deployment</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Exacerbation of existing inequalities. This is correct because without addressing the digital divide, access to AI-driven sustainability solutions remains uneven, potentially widening the gap between AI-rich and AI-poor regions. Other options do not directly relate to the digital divide’s impact on inequalities.</p>
<p><em>Learning Objective</em>: Identify the implications of the digital divide on equitable access to AI sustainability solutions.</p>
</li>
</ol>
<p><a href="#quiz-question-sec-sustainable-ai-public-engagement-9850" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-sustainable-ai-future-challenges-58e2" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.5</strong></summary><div>
<ol type="1">
<li>
<p><strong>Which of the following strategies is crucial for reducing the energy consumption of AI models without compromising performance?</strong></p>
<ol type="a">
<li>Increasing dataset size</li>
<li>Using more GPUs</li>
<li>Model pruning and quantization</li>
<li>Increasing model complexity</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Model pruning and quantization. These techniques help reduce energy consumption by simplifying models while maintaining performance. Increasing dataset size and model complexity typically increase energy demands.</p>
<p><em>Learning Objective</em>: Understand techniques for optimizing AI models for energy efficiency.</p>
</li>
<li>
<p><strong>Discuss the role of renewable energy integration in AI infrastructure. What are the key challenges associated with this transition?</strong></p>
<p><em>Answer</em>: Integrating renewable energy into AI infrastructure reduces carbon footprints by using clean energy sources. Key challenges include developing reliable energy storage technologies and coordinating AI workload scheduling with renewable energy availability. Collaboration between AI companies, energy providers, and policymakers is crucial for successful implementation.</p>
<p><em>Learning Objective</em>: Analyze the benefits and challenges of using renewable energy in AI systems.</p>
</li>
<li>
<p><strong>True or False: A significant challenge in AI sustainability is the lack of standardized measurement and reporting frameworks for evaluating environmental impact.</strong></p>
<p><em>Answer</em>: True. This is true because AI systems require comprehensive approaches to measure their environmental footprint, which are not yet standardized globally.</p>
<p><em>Learning Objective</em>: Recognize the importance of standardized frameworks in assessing AI’s environmental impact.</p>
</li>
<li>
<p><strong>AI sustainability efforts can benefit from intelligent resource allocation and ____ reduction strategies.</strong></p>
<p><em>Answer</em>: waste. Intelligent resource allocation and waste reduction strategies help decrease energy consumption and improve AI sustainability.</p>
<p><em>Learning Objective</em>: Identify strategies that contribute to sustainable AI practices.</p>
</li>
<li>
<p><strong>How might AI researchers balance the trade-off between experimentation and efficiency in model development?</strong></p>
<p><em>Answer</em>: AI researchers can balance experimentation and efficiency by using efficient experimentation methodologies, such as neural architecture search and hyperparameter optimization, while minimizing redundant computations. This approach allows model improvements without excessive energy consumption.</p>
<p><em>Learning Objective</em>: Evaluate strategies for balancing experimentation with energy efficiency in AI model development.</p>
</li>
</ol>
<p><a href="#quiz-question-sec-sustainable-ai-future-challenges-58e2" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-sustainable-ai-summary-8cec" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.6</strong></summary><div>
<ol type="1">
<li>
<p><strong>Which of the following is a primary challenge in integrating AI into environmental sustainability efforts?</strong></p>
<ol type="a">
<li>Lack of AI model transparency</li>
<li>High computational costs and energy consumption</li>
<li>Limited data availability</li>
<li>Slow technological advancement</li>
</ol>
<p><em>Answer</em>: The correct answer is B. High computational costs and energy consumption. This is correct because AI systems often require significant computational resources, leading to increased energy use and environmental impact. Options B, C, and D are challenges but not as directly related to environmental sustainability.</p>
<p><em>Learning Objective</em>: Understand the primary challenges of integrating AI into sustainability efforts.</p>
</li>
<li>
<p><strong>Discuss the role of policy and regulatory frameworks in shaping a sustainable AI ecosystem.</strong></p>
<p><em>Answer</em>: Policy and regulatory frameworks are crucial in shaping a sustainable AI ecosystem by setting standards for energy efficiency, mandating environmental impact reporting, and incentivizing green AI practices. For example, policies can promote the use of renewable energy in data centers. This is important because it aligns AI development with environmental goals, ensuring long-term sustainability.</p>
<p><em>Learning Objective</em>: Analyze the impact of policy on AI sustainability.</p>
</li>
<li>
<p><strong>What is a potential benefit of AI in environmental sustainability?</strong></p>
<ol type="a">
<li>Enhanced climate modeling capabilities</li>
<li>Increased e-waste production</li>
<li>Reduced need for renewable energy</li>
<li>Greater reliance on fossil fuels</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Enhanced climate modeling capabilities. This is correct because AI can process large datasets to improve the accuracy of climate models, aiding in better environmental decision-making. Options A, C, and D are negative or incorrect impacts.</p>
<p><em>Learning Objective</em>: Identify positive impacts of AI on environmental sustainability.</p>
</li>
<li>
<p><strong>How can AI practitioners balance the trade-off between technological progress and environmental sustainability?</strong></p>
<p><em>Answer</em>: AI practitioners can balance technological progress and environmental sustainability by adopting energy-efficient algorithms, utilizing renewable energy sources, and implementing lifecycle-aware development practices. For example, optimizing models for lower energy consumption can reduce environmental impact. This balance is crucial to ensure AI advancements do not exacerbate ecological strain.</p>
<p><em>Learning Objective</em>: Evaluate strategies for balancing AI progress with sustainability.</p>
</li>
</ol>
<p><a href="#quiz-question-sec-sustainable-ai-summary-8cec" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>

</section></section><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="pagination-link" aria-label="Responsible AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Responsible AI</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="pagination-link" aria-label="AI for Good">
        <span class="nav-page-text">AI for Good</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
<li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
</ul>
</div>
  </div>
</footer><script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>


</body></html>