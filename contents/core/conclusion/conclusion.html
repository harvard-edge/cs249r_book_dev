<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/labs/labs.html" rel="next">
<link href="../../../contents/core/frontiers/frontiers.html" rel="prev">
<link href="../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ae75ed80ef5b3e74590777de1ac3d8c3.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-0769fbf68cc3e722256a1e1e51d908bf.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<script src="../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script>
<style>
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-definition {
  --color1: #F0F4F8;
  --color2: #1B4F72;
}
.callout-example {
  --color1: #F0F8F6;
  --color2: #148F77;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
</style>
<style>
details.callout-resource-videos > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
details.callout-code > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-code.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
details.callout-definition > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-definition.png");
}
details.callout-example > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-example.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-quiz-question > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-quiz-answer > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
</style>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-md " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/images/icons/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-file-pdf" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/epub" target="_blank"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text">EPUB</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/frontiers/frontiers.html">Frontiers of ML Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/conclusion/conclusion.html">Conclusion</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden"><i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p style="margin: 0 0 12px 0; padding: 8px 12px; background: rgba(255,193,7,0.2); border: 1px solid #ffc107; border-radius: 4px; font-weight: 600;"><i class="bi bi-exclamation-triangle-fill" style="margin-right: 6px; color: #856404;"></i><strong>🚧 DEVELOPMENT PREVIEW</strong> - Built from dev@<code style="background: rgba(0,0,0,0.1); padding: 2px 4px; border-radius: 3px; font-size: 0.9em;">b7d74ce9</code> • 2025-10-09 22:31 UTC • <a href="https://mlsysbook.ai" style="color: #856404; text-decoration: underline;"><em>Stable version →</em></a></p>
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div><i class="bi bi-x-lg quarto-announcement-action" style="display: none;"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frontiers/frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AGI Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Glossary</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/glossary/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Glossary</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-conclusion" id="toc-sec-conclusion" class="nav-link active" data-scroll-target="#sec-conclusion">Conclusion</a>
  <ul>
  <li><a href="#sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" id="toc-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" class="nav-link" data-scroll-target="#sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244">Synthesizing ML Systems Engineering: From Components to Intelligence</a></li>
  <li><a href="#sec-conclusion-systems-engineering-principles-ml-6501" id="toc-sec-conclusion-systems-engineering-principles-ml-6501" class="nav-link" data-scroll-target="#sec-conclusion-systems-engineering-principles-ml-6501">Systems Engineering Principles for ML</a></li>
  <li><a href="#sec-conclusion-applying-principles-across-three-critical-domains-ca7d" id="toc-sec-conclusion-applying-principles-across-three-critical-domains-ca7d" class="nav-link" data-scroll-target="#sec-conclusion-applying-principles-across-three-critical-domains-ca7d">Applying Principles Across Three Critical Domains</a>
  <ul class="collapse">
  <li><a href="#sec-conclusion-building-technical-foundations-5865" id="toc-sec-conclusion-building-technical-foundations-5865" class="nav-link" data-scroll-target="#sec-conclusion-building-technical-foundations-5865">Building Technical Foundations</a></li>
  </ul></li>
  <li><a href="#sec-conclusion-engineering-performance-scale-a99a" id="toc-sec-conclusion-engineering-performance-scale-a99a" class="nav-link" data-scroll-target="#sec-conclusion-engineering-performance-scale-a99a">Engineering for Performance at Scale</a>
  <ul class="collapse">
  <li><a href="#sec-conclusion-model-architecture-optimization-4e0b" id="toc-sec-conclusion-model-architecture-optimization-4e0b" class="nav-link" data-scroll-target="#sec-conclusion-model-architecture-optimization-4e0b">Model Architecture and Optimization</a></li>
  <li><a href="#sec-conclusion-hardware-acceleration-system-performance-59cc" id="toc-sec-conclusion-hardware-acceleration-system-performance-59cc" class="nav-link" data-scroll-target="#sec-conclusion-hardware-acceleration-system-performance-59cc">Hardware Acceleration and System Performance</a></li>
  </ul></li>
  <li><a href="#sec-conclusion-navigating-production-reality-c406" id="toc-sec-conclusion-navigating-production-reality-c406" class="nav-link" data-scroll-target="#sec-conclusion-navigating-production-reality-c406">Navigating Production Reality</a></li>
  <li><a href="#sec-conclusion-future-directions-emerging-opportunities-0840" id="toc-sec-conclusion-future-directions-emerging-opportunities-0840" class="nav-link" data-scroll-target="#sec-conclusion-future-directions-emerging-opportunities-0840">Future Directions and Emerging Opportunities</a>
  <ul class="collapse">
  <li><a href="#sec-conclusion-applying-principles-emerging-deployment-contexts-e1bb" id="toc-sec-conclusion-applying-principles-emerging-deployment-contexts-e1bb" class="nav-link" data-scroll-target="#sec-conclusion-applying-principles-emerging-deployment-contexts-e1bb">Applying Principles to Emerging Deployment Contexts</a></li>
  <li><a href="#sec-conclusion-building-robust-ai-systems-827c" id="toc-sec-conclusion-building-robust-ai-systems-827c" class="nav-link" data-scroll-target="#sec-conclusion-building-robust-ai-systems-827c">Building Robust AI Systems</a></li>
  <li><a href="#sec-conclusion-ai-societal-benefit-daba" id="toc-sec-conclusion-ai-societal-benefit-daba" class="nav-link" data-scroll-target="#sec-conclusion-ai-societal-benefit-daba">AI for Societal Benefit</a></li>
  <li><a href="#sec-conclusion-path-agi-1c6d" id="toc-sec-conclusion-path-agi-1c6d" class="nav-link" data-scroll-target="#sec-conclusion-path-agi-1c6d">The Path to AGI</a></li>
  </ul></li>
  <li><a href="#sec-conclusion-journey-forward-engineering-intelligence-427d" id="toc-sec-conclusion-journey-forward-engineering-intelligence-427d" class="nav-link" data-scroll-target="#sec-conclusion-journey-forward-engineering-intelligence-427d">Your Journey Forward: Engineering Intelligence</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers">Self-Check Answers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/frontiers/frontiers.html">Frontiers of ML Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/conclusion/conclusion.html">Conclusion</a></li></ol></nav></header>




<section id="sec-conclusion" class="level1 page-columns page-full">
<h1>Conclusion</h1>
<div class="{layout-narrow} page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="">
<p><em>DALL·E 3 Prompt: An image depicting a concluding chapter of an ML systems book, open to a two-page spread. The pages summarize key concepts such as neural networks, model architectures, hardware acceleration, and MLOps. One page features a diagram of a neural network and different model architectures, while the other page shows illustrations of hardware components for acceleration and MLOps workflows. The background includes subtle elements like circuit patterns and data points to reinforce the technological theme. The colors are professional and clean, with an emphasis on clarity and understanding.</em></p>
</div></div><p> <img src="images/png/cover_conclusion.png" class="img-fluid"></p>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Synthesize the six core systems engineering principles that transcend specific ML technologies and provide systematic guidance for engineering decisions</li>
<li>Analyze how the “measure everything” principle manifests across data engineering, benchmarking, and operational monitoring contexts</li>
<li>Apply the “design for 10x scale” principle to evaluate system architectures for cloud, edge, and mobile deployment scenarios</li>
<li>Evaluate bottleneck optimization strategies across the full ML systems stack from data pipelines to inference deployment</li>
<li>Critique failure planning approaches in ML systems by comparing traditional software reliability with ML-specific failure modes</li>
<li>Design cost-conscious ML systems that balance computational performance, operational expenses, and environmental sustainability</li>
<li>Assess hardware-software co-design opportunities across different deployment contexts including cloud, edge, and embedded systems</li>
<li>Create integrated solutions that combine technical excellence with operational maturity, security requirements, and ethical considerations</li>
</ul>
</div>
</div>
<section id="sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244">Synthesizing ML Systems Engineering: From Components to Intelligence</h2>
<p>This chapter synthesizes machine learning systems engineering concepts from the preceding twenty chapters, establishing systems thinking as the fundamental paradigm for artificial intelligence development. Our progression from data engineering principles through model architectures, optimization techniques, and operational infrastructure has constructed a comprehensive knowledge foundation spanning ML systems engineering. This synthesis establishes theoretical and practical frameworks that define professional competency in machine learning systems engineering within computer systems research.</p>
<p>Contemporary artificial intelligence<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> achievements emerge not from isolated algorithmic innovations, but through principled systems integration that unifies computational theory with engineering practice. This systems perspective positions machine learning within computer systems engineering traditions, where transformative capabilities arise from systematic orchestration of interdependent components. The transformer architectures <span class="citation" data-cites="vaswani2017attention">(<a href="#ref-vaswani2017attention" role="doc-biblioref">Vaswani et al. 2017</a>)</span> enabling large language models exemplify this principle: their practical utility derives from integrating mathematical foundations with distributed training infrastructure, algorithmic optimization techniques, and robust operational frameworks rather than architectural innovation alone.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<strong>Artificial Intelligence (Systems Perspective)</strong>: Intelligence emerging from integrated systems rather than individual algorithms. Modern AI applications like GPT-4 combine data pipelines (processing petabytes), distributed training (coordinating thousands of processors), efficient inference (serving millions of requests), security measures (preventing attacks), and governance frameworks (ensuring safety). Success depends on systems engineering excellence across all components.</p></div><div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> <em>Advances in Neural Information Processing Systems</em> 30.
</div></div><p>This chapter addresses three fundamental questions that define machine learning systems engineering boundaries. First, what enduring principles transcend specific technologies and provide systematic guidance for engineering decisions across deployment contexts, from contemporary production systems to anticipated artificial general intelligence architectures? Second, how do these principles manifest across resource-abundant cloud infrastructures, resource-constrained edge devices, and emerging generative systems? Third, how can this knowledge be applied systematically to create systems that satisfy technical requirements while addressing broader societal objectives and ethical considerations?</p>
<p>Our analysis reflects the systems thinking paradigm that has structured this textbook, drawing from established computer systems research and engineering methodology. We systematically derive six fundamental engineering principles from technical concepts established throughout the text: comprehensive measurement, scale-oriented design, bottleneck optimization, systematic failure planning, cost-conscious design, and hardware co-design. These principles constitute a framework for principled decision-making across machine learning systems contexts. We examine their application across three domains that structure contemporary ML systems engineering: establishing technical foundations, engineering for performance at scale, and navigating production deployment realities.</p>
<p>The analysis examines emerging frontiers where these principles confront their most significant challenges. From developing resilient AI systems that manage failure modes gracefully to deploying artificial intelligence for societal benefit across healthcare, education, and climate science, these engineering principles will determine artificial intelligence’s societal impact trajectory. As artificial intelligence systems approach general intelligence capabilities<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, the critical question becomes not feasibility, but whether they will be engineered according to established principles of sound systems design and responsible computing.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;<strong>Artificial General Intelligence (AGI)</strong>: AI systems matching human-level performance across all cognitive tasks. Current estimates suggest AGI would require 10<sup>15-10</sup>17 FLOPS (1000x more than GPT-4), demanding novel distributed architectures, energy-efficient hardware, and infrastructure investments exceeding $1 trillion. The engineering challenge lies not in algorithms but in scaling current ML systems principles to unprecedented computational requirements.</p></div></div><p>The frameworks synthesized in this chapter establish systematic approaches for navigating the rapidly evolving artificial intelligence technology landscape while maintaining focus on fundamental engineering objectives: creating systems that scale effectively, perform reliably under diverse conditions, and address significant societal challenges. Artificial intelligence’s future trajectory will be determined not through isolated research contributions, but through systematic application of systems engineering principles by practitioners who master the integration of technical excellence with operational realities and societal responsibility.</p>
<p>This synthesis establishes systematic theoretical understanding and provides the conceptual foundation for professional application within machine learning systems as a mature engineering discipline.</p>
<div id="quiz-question-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.1</strong></summary><div>
<ol type="1">
<li><p>Which principle is emphasized as crucial for the development of contemporary AI systems according to the overview?</p>
<ol type="a">
<li>Isolated algorithmic innovation</li>
<li>Data collection</li>
<li>Architectural innovation</li>
<li>Systems integration</li>
</ol></li>
<li><p>Explain how the systems thinking paradigm contributes to the development of AI systems.</p></li>
<li><p>What is a key challenge when scaling AI systems towards Artificial General Intelligence (AGI)?</p>
<ol type="a">
<li>Developing new algorithms</li>
<li>Scaling current ML systems principles</li>
<li>Increasing data collection</li>
<li>Improving user interfaces</li>
</ol></li>
<li><p>How might the principles of ML systems engineering be applied to address societal challenges?</p></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-conclusion-systems-engineering-principles-ml-6501" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-systems-engineering-principles-ml-6501">Systems Engineering Principles for ML</h2>
<p>We extract six core principles that unite the concepts explored across twenty chapters. These principles transcend specific technologies and provide enduring guidance for building today’s production systems or tomorrow’s artificial general intelligence.</p>
<p><strong>Principle 1: Measure Everything</strong></p>
<p>The measurement frameworks established in <strong><a href="../benchmarking/benchmarking.html#sec-benchmarking-ai">Chapter 12: Benchmarking AI</a></strong>, complemented by the monitoring systems from <strong><a href="../ops/ops.html#sec-ml-operations">Chapter 13: ML Operations</a></strong>, demonstrate that successful ML systems instrument every component because you cannot optimize what you do not measure. Four analytical frameworks provide enduring measurement foundations that transcend specific technologies.</p>
<p>Roofline analysis<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> identifies computational bottlenecks by plotting operational intensity against peak performance, revealing whether systems are memory bound or compute bound, essential for optimizing everything from training workloads to edge inference.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<strong>Roofline Analysis</strong>: Performance modeling technique developed at UC Berkeley that plots computational intensity (operations per byte) against achievable performance. Reveals whether applications are limited by memory bandwidth or computational throughput, guiding optimization priorities for ML workloads.</p></div></div><p>Cost performance evaluation systematically compares total ownership costs against delivered capabilities, incorporating training expenses, infrastructure requirements, and operational overhead to guide deployment decisions. Systematic benchmarking establishes reproducible measurement protocols that enable fair comparisons across architectures, frameworks, and deployment targets, ensuring optimization efforts target actual rather than perceived bottlenecks. These measurements reveal a critical insight: systems rarely fail at expected loads but when demand exceeds design assumptions by orders of magnitude.</p>
<p><strong>Principle 2: Design for 10x Scale</strong></p>
<p>Systems that work in research rarely survive production traffic, requiring design for an order of magnitude more data, users, and computational demands than currently needed<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Building on concepts from <strong><a href="../ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong>, this principle manifests across deployment contexts: cloud systems must handle traffic spikes from thousands to millions of users, edge systems need redundancy for network partitions, and embedded systems require graceful degradation under resource exhaustion.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;<strong>10x Scale Design</strong>: Engineering principle that systems must handle 10x their expected load to survive real-world deployment. Netflix’s recommendation system scales from handling thousands to millions of concurrent users, while maintaining sub-100ms response times through careful architecture design and predictive scaling.</p></div></div><p>Scale alone, however, provides no value if systems waste resources on non-critical paths.</p>
<p><strong>Principle 3: Optimize the Bottleneck</strong></p>
<p>While <strong><a href="../efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 9: Efficient AI</a></strong> establishes efficiency principles and <strong><a href="../optimizations/optimizations.html#sec-model-optimizations">Chapter 10: Model Optimizations</a></strong> provides optimization techniques, systems analysis reveals that 80% of performance gains come from addressing the primary constraint: memory bandwidth in training workloads, network latency in distributed inference, or energy consumption in mobile deployment.</p>
<p><strong>Principle 4: Plan for Failure</strong></p>
<p>The robustness techniques from <strong><a href="../robust_ai/robust_ai.html#sec-robust-ai">Chapter 16: Robust AI</a></strong>, combined with security frameworks from <strong><a href="../responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 17: Responsible AI</a></strong>, assume systems will fail, requiring redundancy, monitoring, and recovery mechanisms from the start. Production systems experience component failures, network partitions, and adversarial inputs daily, necessitating circuit breakers<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, graceful fallbacks, and automated recovery procedures.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<strong>Circuit Breakers</strong>: Software design pattern that prevents cascading failures by temporarily blocking requests to failing services. When error rates exceed thresholds (typically 50% over 30 seconds), circuit breakers open to prevent additional load, automatically retrying after cooldown periods to detect service recovery.</p></div></div><p><strong>Principle 5: Design Cost-Consciously</strong></p>
<p>From sustainability concerns to operational expenses, every technical decision has economic implications. Optimizing for total cost of ownership<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, not just performance, becomes critical when cloud GPU costs can exceed $30,000/month for large models <span class="citation" data-cites="ben2019cost">(<a href="#ref-ben2019cost" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019b</a>)</span>, making efficiency optimizations worth millions in operational savings over deployment lifetimes.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<strong>Total Cost of Ownership (TCO) for ML</strong>: Comprehensive cost including training ($100K-$10M for large models), infrastructure (3x training costs annually), data preparation (40-60% of project budgets), operations (monitoring, updates, compliance), and failure costs (downtime averaging $5,600/minute for e-commerce). TCO analysis drives architectural decisions from cloud vs.&nbsp;edge deployment to model compression priorities.</p></div><div id="ref-ben2019cost" class="csl-entry" role="listitem">
———. 2019b. <span>“Energy and Policy Considerations for Deep Learning in NLP.”</span> <em>arXiv Preprint arXiv:1906.02243</em>, June. <a href="http://arxiv.org/abs/1906.02243v1">http://arxiv.org/abs/1906.02243v1</a>.
</div></div><p><strong>Principle 6: Co-Design for Hardware</strong></p>
<p>Building on the acceleration techniques from <strong><a href="../hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 11: AI Acceleration</a></strong>, efficient AI systems require algorithm hardware co-optimization, not just individual component excellence. This comprehensive approach encompasses three critical dimensions: algorithm hardware matching ensures computational patterns align with target hardware capabilities (systolic arrays favor dense matrix operations while sparse accelerators require structured pruning patterns), memory hierarchy optimization provides frameworks for analyzing data movement costs and optimizing for cache locality, and energy efficiency modeling incorporates TOPS/W metrics to guide power-conscious design decisions essential for mobile and edge deployment.</p>
<div id="quiz-question-sec-conclusion-systems-engineering-principles-ml-6501" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.2</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the purpose of roofline analysis in ML systems?</p>
<ol type="a">
<li>To determine the memory capacity of a system</li>
<li>To evaluate the cost efficiency of cloud deployments</li>
<li>To identify computational bottlenecks by plotting operational intensity against peak performance</li>
<li>To measure the energy consumption of mobile devices</li>
</ol></li>
<li><p>True or False: Designing for 10x scale means that systems should be optimized for current loads only.</p></li>
<li><p>Explain how the principle of ‘Optimize the Bottleneck’ can be applied to enhance the performance of an ML system.</p></li>
<li><p>What is a critical insight gained from systematic benchmarking in ML systems?</p>
<ol type="a">
<li>Systems always fail at expected loads</li>
<li>Systems rarely fail when demand exceeds design assumptions by orders of magnitude</li>
<li>Benchmarking only measures computational throughput</li>
<li>Benchmarking is unnecessary for cloud-based systems</li>
</ol></li>
<li><p>In a production ML system, why is it important to plan for failure, and how can this be implemented?</p></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-systems-engineering-principles-ml-6501" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-conclusion-applying-principles-across-three-critical-domains-ca7d" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-applying-principles-across-three-critical-domains-ca7d">Applying Principles Across Three Critical Domains</h2>
<p>These six foundational principles apply practically across the ML systems landscape. These principles are not abstract ideals but concrete guides that shaped every technical decision explored throughout our journey. Their manifestation varies by context yet remains consistent in purpose. We examine how they operate across three critical domains that structure ML systems engineering: building robust technical foundations where measurement and co-design establish the groundwork, engineering for performance at scale where optimization and planning enable growth, and navigating production realities where all principles converge under operational constraints.</p>
<section id="sec-conclusion-building-technical-foundations-5865" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-conclusion-building-technical-foundations-5865">Building Technical Foundations</h3>
<p>Machine learning systems engineering rests on solid technical foundations where multiple principles converge.</p>
<p>The foundation begins with data engineering, where <strong><a href="../workflow/workflow.html#sec-ai-workflow">Chapter 5: AI Workflow</a></strong> established that data quality determines system quality. “Data is the new code” <span class="citation" data-cites="karpathy2017software">(<a href="#ref-karpathy2017software" role="doc-biblioref">Karpathy 2017</a>)</span> for neural networks. Production systems require instrumentation for schema evolution, lineage tracking, and quality degradation detection. When data quality degrades, effects cascade through the entire system, making data governance both a technical necessity and ethical imperative. The measurement principle manifests through continuous monitoring of distribution shifts, labeling consistency, and pipeline performance.</p>
<div class="no-row-height column-margin column-container"><div id="ref-karpathy2017software" class="csl-entry" role="listitem">
Karpathy, Andrej. 2017. <span>“Software 2.0.”</span> <em>Medium</em>. <a href="https://karpathy.medium.com/software-2-0-a64152b37c35">https://karpathy.medium.com/software-2-0-a64152b37c35</a>.
</div></div><p>Building on this data foundation, frameworks and training systems embody both scale and co-design principles. The framework ecosystem from <strong><a href="../frameworks/frameworks.html#sec-ai-frameworks">Chapter 7: AI Frameworks</a></strong> introduced you to navigating trade-offs between TensorFlow’s production maturity and PyTorch’s research flexibility. <strong><a href="../training/training.html#sec-ai-training">Chapter 8: AI Training</a></strong> then revealed how these frameworks scale beyond single machines, teaching you data parallelism strategies that transform weeks of training into hours through distributed coordination. Framework selection (<strong><a href="../frameworks/frameworks.html#sec-ai-frameworks">Chapter 7: AI Frameworks</a></strong>) impacts development velocity and deployment constraints. Specialization from TensorFlow Lite for mobile (<strong><a href="../frameworks/frameworks.html#sec-ai-frameworks">Chapter 7: AI Frameworks</a></strong>) to JAX for research (<strong><a href="../frameworks/frameworks.html#sec-ai-frameworks">Chapter 7: AI Frameworks</a></strong>) exemplifies hardware co-design. Distributed training through data and model parallelism, mixed precision techniques, and gradient compression all demonstrate designing for scale beyond current needs while optimizing for hardware capabilities.</p>
<p>Efficiency and Optimization (Principle 3: Optimize the Bottleneck): <strong><a href="../efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 9: Efficient AI</a></strong> demonstrates that efficiency determines whether AI moves beyond laboratories to resource-constrained deployment. Neural compression algorithms (pruning, quantization, and knowledge distillation) systematically address bottlenecks (memory, compute, energy) while maintaining performance. This multidimensional optimization requires identifying the limiting factor and addressing it systematically rather than pursuing isolated improvements.</p>
<div id="quiz-question-sec-conclusion-applying-principles-across-three-critical-domains-ca7d" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.3</strong></summary><div>
<ol type="1">
<li><p>Which principle is highlighted as essential for ensuring that AI systems can move beyond laboratory settings to resource-constrained deployments?</p>
<ol type="a">
<li>Data governance</li>
<li>Optimization of bottlenecks</li>
<li>Co-design</li>
<li>Schema evolution</li>
</ol></li>
<li><p>Explain how data governance acts as both a technical necessity and an ethical imperative in ML systems.</p></li>
<li><p>In ML systems, the principle of ‘Data is the new ____’ emphasizes the critical role of data quality in determining system performance.</p></li>
<li><p>Order the following steps in building a robust ML system foundation: (1) Monitor distribution shifts, (2) Implement data governance, (3) Track schema evolution.</p></li>
<li><p>In a production ML system, what trade-offs might you consider when selecting a framework for deployment?</p></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-applying-principles-across-three-critical-domains-ca7d" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-conclusion-engineering-performance-scale-a99a" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-engineering-performance-scale-a99a">Engineering for Performance at Scale</h2>
<p>The technical foundations we have examined (data engineering, frameworks, and efficiency) provide the substrate for ML systems. Yet foundations alone do not create value. The second pillar of ML systems engineering transforms these foundations into systems that perform reliably at scale, shifting focus from “does it work?” to “does it work efficiently for millions of users?” This transition demands new engineering priorities and systematic application of our scaling and optimization principles.</p>
<section id="sec-conclusion-model-architecture-optimization-4e0b" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-conclusion-model-architecture-optimization-4e0b">Model Architecture and Optimization</h3>
<p><strong><a href="../dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong> traced your journey from understanding simple perceptrons (where you first grasped how weighted inputs produce decisions) through convolutional networks that revealed how hierarchical feature extraction mirrors biological vision, to transformer architectures whose attention mechanisms enabled the language understanding powering today’s AI assistants. However, architectural innovation alone proves insufficient for production deployment. Optimization techniques from <strong><a href="../optimizations/optimizations.html#sec-model-optimizations">Chapter 10: Model Optimizations</a></strong> bridge research architectures and production constraints.</p>
<p>Following the hardware co-design principles outlined earlier, three complementary compression approaches demonstrate systematic bottleneck optimization: pruning removes redundant parameters while maintaining accuracy, quantization reduces precision requirements for 4x memory reduction, and knowledge distillation transfers capabilities to compact networks for resource-constrained deployment.</p>
<p>The Deep Compression pipeline <span class="citation" data-cites="han2015deep">(<a href="#ref-han2015deep" role="doc-biblioref">Han, Mao, and Dally 2015</a>)</span> exemplifies this systematic integration. Pruning, quantization, and coding combine for 10-50x compression ratios<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. Operator fusion (combining conv-batchnorm-relu sequences) reduces memory bandwidth by 3x, demonstrating how algorithmic and systems optimizations compound when guided by the co-design imperative established in our foundational principles.</p>
<div class="no-row-height column-margin column-container"><div id="ref-han2015deep" class="csl-entry" role="listitem">
Han, Song, Huizi Mao, and William J. Dally. 2015. <span>“Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding.”</span> <em>arXiv Preprint arXiv:1510.00149</em>, October. <a href="http://arxiv.org/abs/1510.00149v5">http://arxiv.org/abs/1510.00149v5</a>.
</div><div id="fn7"><p><sup>7</sup>&nbsp;<strong>Efficient Architecture Design</strong>: MobileNets <span class="citation" data-cites="howard2017mobilenets">(<a href="#ref-howard2017mobilenets" role="doc-biblioref">Howard et al. 2017</a>)</span> achieve 8-9x computation reduction through depthwise separable convolutions, enabling real-time inference on mobile devices. These constraint-driven architectures demonstrate how deployment limitations catalyze algorithmic innovation applicable to all contexts.</p><div id="ref-howard2017mobilenets" class="csl-entry" role="listitem">
Howard, Andrew G., Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. <span>“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.”</span> <em>arXiv Preprint arXiv:1704.04861</em>, April. <a href="http://arxiv.org/abs/1704.04861v1">http://arxiv.org/abs/1704.04861v1</a>.
</div></div></div><p>These optimizations validate Principle 3’s core insight: identify the bottleneck (memory, compute, or energy), then optimize systematically rather than pursuing isolated improvements.</p>
</section>
<section id="sec-conclusion-hardware-acceleration-system-performance-59cc" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-conclusion-hardware-acceleration-system-performance-59cc">Hardware Acceleration and System Performance</h3>
<p><strong><a href="../hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 11: AI Acceleration</a></strong> shows how specialized hardware transforms computational bottlenecks into acceleration opportunities. GPUs excel at parallel matrix operations, TPUs<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> optimize for tensor workloads, and FPGAs<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> provide reconfigurable acceleration for specific operators.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<strong>Tensor Processing Unit (TPU)</strong>: Google’s custom ASIC designed specifically for neural network operations, achieving significantly better performance-per-watt than contemporary GPUs for ML workloads. TPU v4 pods deliver 1.1 exaflops of peak performance for large-scale model training.</p></div><div id="fn9"><p><sup>9</sup>&nbsp;<strong>Field-Programmable Gate Array (FPGA)</strong>: Reconfigurable hardware that can be optimized for specific ML operators post-manufacturing. Microsoft’s Brainwave achieves ultra-low latency inference (sub-millisecond) by customizing FPGA configurations for specific neural network architectures.</p></div></div><p>Building on the co-design framework established previously, software optimizations must align with hardware capabilities through kernel fusion, operator scheduling, and precision selection that balances accuracy with throughput.</p>
<p><strong><a href="../benchmarking/benchmarking.html#sec-benchmarking-ai">Chapter 12: Benchmarking AI</a></strong> establishes benchmarking as the essential feedback loop for performance engineering. MLPerf<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> provides standardized metrics across hardware platforms, enabling data-driven decisions about deployment trade-offs.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;<strong>MLPerf</strong>: Industry-standard benchmark suite measuring AI system performance across training and inference workloads. Since 2018, MLPerf <span class="citation" data-cites="mattson2020mlperf">(<a href="#ref-mattson2020mlperf" role="doc-biblioref">Mattson et al. 2020</a>)</span> has driven hardware innovation, with participating systems showing 2-5x performance improvements across various benchmarks over 4 years while maintaining fair comparisons across vendors.</p><div id="ref-mattson2020mlperf" class="csl-entry" role="listitem">
Mattson, Peter, Vijay Janapa Reddi, Christine Cheng, Cody Coleman, Greg Diamos, David Kanter, Paulius Micikevicius, et al. 2020. <span>“MLPerf: An Industry Standard Benchmark Suite for Machine Learning Performance.”</span> <em>IEEE Micro</em> 40 (2): 8–16. <a href="https://doi.org/10.1109/mm.2020.2974843">https://doi.org/10.1109/mm.2020.2974843</a>.
</div></div></div><p>This performance engineering foundation enables new deployment paradigms that extend beyond centralized systems to edge and mobile environments.</p>
<div id="quiz-question-sec-conclusion-engineering-performance-scale-a99a" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.4</strong></summary><div>
<ol type="1">
<li><p>Which of the following is a benefit of using pruning in neural network optimization?</p>
<ol type="a">
<li>Increases the number of parameters</li>
<li>Decreases the model’s inference speed</li>
<li>Maintains accuracy while reducing model size</li>
<li>Increases the precision requirements</li>
</ol></li>
<li><p>Explain how knowledge distillation can be used to deploy models in resource-constrained environments.</p></li>
<li><p>Order the following optimization techniques from the Deep Compression pipeline: (1) Quantization, (2) Pruning, (3) Operator Fusion.</p></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-engineering-performance-scale-a99a" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-conclusion-navigating-production-reality-c406" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-navigating-production-reality-c406">Navigating Production Reality</h2>
<p>The third pillar addresses production deployment realities where all six principles converge under the constraint that systems must serve users reliably, securely, and responsibly.</p>
<p>The operations and deployment landscape demonstrates how MLOps<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> orchestrates the full system lifecycle, from continuous integration pipelines with quality gates to A/B testing frameworks for safe rollout. Edge deployment exemplifies the convergence of multiple principles: balancing privacy benefits against latency constraints while ensuring graceful degradation under network failures.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;<strong>Machine Learning Operations (MLOps)</strong>: Engineering discipline applying DevOps principles to ML systems. Netflix deploys 4,000+ ML model updates daily through automated pipelines, while maintaining 99.99% uptime. MLOps transforms artisanal model development into industrial software engineering, encompassing continuous integration, deployment, monitoring, and governance at production scale.</p></div></div><p>Security and privacy considerations reveal ML’s unique vulnerabilities (model extraction, data poisoning, membership inference) requiring layered defenses. Differential privacy provides mathematical guarantees, federated learning enables secure collaboration, and adversarial training builds robustness against attacks that traditional software never faces.</p>
<p>Beyond technical concerns, responsible AI and sustainability considerations broaden cost consciousness beyond computation. Fairness metrics and explainability requirements shape architectural choices from inception. Environmental impact becomes a design constraint: GPT-3’s 1,287 MWh training cost <span class="citation" data-cites="strubell2019energy">(<a href="#ref-strubell2019energy" role="doc-biblioref">Strubell, Ganesh, and McCallum 2019a</a>)</span> equals powering 120 homes annually, making efficiency improvements on 6+ billion smartphones more impactful than datacenter optimizations.</p>
<div class="no-row-height column-margin column-container"><div id="ref-strubell2019energy" class="csl-entry" role="listitem">
Strubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019a. <span>“Energy and Policy Considerations for Deep Learning in NLP.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 3645–50. Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/p19-1355">https://doi.org/10.18653/v1/p19-1355</a>.
</div></div><p>Production reality validates that isolated technical excellence proves insufficient. Systems must integrate operational maturity, security defenses, ethical frameworks, and environmental responsibility to deliver sustained value.</p>
<div id="quiz-question-sec-conclusion-navigating-production-reality-c406" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.5</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the role of MLOps in the production deployment of ML systems?</p>
<ol type="a">
<li>MLOps focuses solely on the initial deployment of models.</li>
<li>MLOps is primarily about securing ML models against adversarial attacks.</li>
<li>MLOps is concerned with the orchestration of the entire ML system lifecycle.</li>
<li>MLOps involves only the monitoring of deployed models.</li>
</ol></li>
<li><p>True or False: Differential privacy is a technique used to ensure the robustness of ML models against adversarial attacks.</p></li>
<li><p>Explain how federated learning can contribute to secure collaboration in ML systems.</p></li>
<li><p>In ML systems, ____ provides mathematical guarantees to protect individual data privacy.</p></li>
<li><p>What are the ethical and environmental considerations that must be integrated into the design of ML systems for production deployment?</p></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-navigating-production-reality-c406" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-conclusion-future-directions-emerging-opportunities-0840" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-future-directions-emerging-opportunities-0840">Future Directions and Emerging Opportunities</h2>
<p>Having established technical foundations, engineered for performance, and navigated production realities, we examine emerging opportunities where the six principles guide future development.</p>
<p>The convergence of technical foundations, performance engineering, and production reality reveals three emerging frontiers where our established principles face their greatest tests: near-term deployment across diverse contexts, building resilient systems for societal benefit, and engineering the path toward artificial general intelligence.</p>
<section id="sec-conclusion-applying-principles-emerging-deployment-contexts-e1bb" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-conclusion-applying-principles-emerging-deployment-contexts-e1bb">Applying Principles to Emerging Deployment Contexts</h3>
<p>As ML systems move beyond research labs, three deployment paradigms test different combinations of our established principles: resource-abundant cloud environments, resource-constrained edge devices, and emerging generative systems.</p>
<p>Cloud deployment prioritizes throughput and scalability, achieving high GPU utilization through kernel fusion, mixed precision training, and gradient compression techniques explored in <strong><a href="../optimizations/optimizations.html#sec-model-optimizations">Chapter 10: Model Optimizations</a></strong> and <strong><a href="../training/training.html#sec-ai-training">Chapter 8: AI Training</a></strong>. Success requires balancing performance optimization with cost efficiency at scale.</p>
<p>In contrast, mobile and edge systems face stringent power, memory, and latency constraints that demand sophisticated hardware-software co-design. The efficiency techniques from <strong><a href="../efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 9: Efficient AI</a></strong>—depthwise separable convolutions, neural architecture search, and quantization—enable deployment on devices with 100-1000x less computational power than data centers. Edge deployment represents AI’s democratization<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>: systems that cannot run on billions of edge devices cannot achieve global impact.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;<strong>AI Democratization</strong>: Making AI accessible beyond tech giants through efficient systems engineering. Mobile-optimized models enable AI on 6+ billion smartphones worldwide, while cloud APIs serve 50+ million developers. Cost reductions from $100,000 to $100 for training specialized models democratize access, but require systematic optimization across hardware, algorithms, and infrastructure to maintain quality at scale.</p></div></div><p>Generative AI systems exemplify the principles at unprecedented scale, requiring novel approaches to autoregressive computation, dynamic model partitioning, and speculative decoding. These systems demonstrate how the measurement, optimization, and co-design principles from earlier sections apply to emerging technologies pushing infrastructure boundaries.</p>
<p>Operating under even more extreme constraints, TinyML and embedded systems face kilobyte memory budgets, milliwatt power envelopes, and decade-long deployment lifecycles. Success in these contexts validates the full systems engineering approach: careful measurement reveals actual bottlenecks, hardware co-design maximizes efficiency, and planning for failure ensures reliability despite severe resource limitations. Mobile deployment constraints have driven breakthrough techniques like MobileNets and EfficientNets that benefit all AI deployment contexts, demonstrating how systems constraints catalyze algorithmic innovation.</p>
<p>These deployment contexts validate our core thesis: success depends on applying the six systems engineering principles systematically rather than pursuing isolated optimizations.</p>
</section>
<section id="sec-conclusion-building-robust-ai-systems-827c" class="level3">
<h3 class="anchored" data-anchor-id="sec-conclusion-building-robust-ai-systems-827c">Building Robust AI Systems</h3>
<p><strong><a href="../robust_ai/robust_ai.html#sec-robust-ai">Chapter 16: Robust AI</a></strong> demonstrates that robustness requires designing for failure from the ground up, Principle 4’s core mandate. ML systems face unique failure modes: distribution shifts degrade accuracy, adversarial inputs exploit vulnerabilities, and edge cases reveal training data limitations. Resilient systems combine redundant hardware for fault tolerance (<strong><a href="../robust_ai/robust_ai.html#sec-robust-ai">Chapter 16: Robust AI</a></strong>), ensemble methods to reduce single-point failures (<strong><a href="../robust_ai/robust_ai.html#sec-robust-ai">Chapter 16: Robust AI</a></strong>), and uncertainty quantification to enable graceful degradation (<strong><a href="../robust_ai/robust_ai.html#sec-robust-ai">Chapter 16: Robust AI</a></strong>). As AI systems take on increasingly autonomous roles, planning for failure becomes the difference between safe deployment and catastrophic failure.</p>
</section>
<section id="sec-conclusion-ai-societal-benefit-daba" class="level3">
<h3 class="anchored" data-anchor-id="sec-conclusion-ai-societal-benefit-daba">AI for Societal Benefit</h3>
<p><strong><a href="../ai_for_good/ai_for_good.html#sec-ai-good">Chapter 19: AI for Good</a></strong> demonstrates AI’s transformative potential across healthcare, climate science, education, and accessibility, domains where all six principles converge. Climate modeling requires efficient inference (Principle 3: Optimize Bottleneck). Medical AI demands explainable decisions and continuous monitoring (Principle 1: Measure). Educational technology needs privacy-preserving personalization at global scale (Principles 2 &amp; 4: Design for Scale, Plan for Failure). These applications validate that technical excellence alone proves insufficient. Success requires interdisciplinary collaboration among technologists, domain experts, policymakers, and affected communities.</p>
</section>
<section id="sec-conclusion-path-agi-1c6d" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-conclusion-path-agi-1c6d">The Path to AGI</h3>
<p>The compound AI systems<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> framework provides the architectural blueprint for advanced intelligence: modular components that can be updated independently, specialized models optimized for specific tasks, and decomposable architectures that enable interpretability and safety through multiple validation layers.</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;<strong>Compound AI Systems</strong>: Architectures combining multiple specialized models rather than single monolithic systems. Google’s PaLM-2 uses separate models for reasoning, memory, and tool use, enabling independent scaling and debugging. This modular approach reduces training costs by 10x while improving reliability through redundancy and specialization, validating systems engineering principles of modularity and fault isolation.</p></div></div><p>The engineering challenges ahead require mastery across the full stack we have explored, from data engineering (<strong><a href="../workflow/workflow.html#sec-ai-workflow">Chapter 5: AI Workflow</a></strong>) and distributed training (<strong><a href="../training/training.html#sec-ai-training">Chapter 8: AI Training</a></strong>) to model optimization (<strong><a href="../optimizations/optimizations.html#sec-model-optimizations">Chapter 10: Model Optimizations</a></strong>) and operational infrastructure (<strong><a href="../ops/ops.html#sec-ml-operations">Chapter 13: ML Operations</a></strong>). These systems engineering principles, not algorithmic breakthroughs, define the path toward artificial general intelligence.</p>
<div id="quiz-question-sec-conclusion-future-directions-emerging-opportunities-0840" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.6</strong></summary><div>
<ol type="1">
<li><p>Which deployment paradigm emphasizes the need for sophisticated hardware-software co-design due to stringent power, memory, and latency constraints?</p>
<ol type="a">
<li>Cloud environments</li>
<li>Mobile and edge systems</li>
<li>Generative AI systems</li>
<li>TinyML and embedded systems</li>
</ol></li>
<li><p>Explain how the principle of ‘designing for failure’ is crucial in building robust AI systems.</p></li>
<li><p>In the context of AI for societal benefit, which principle is emphasized for medical AI systems?</p>
<ol type="a">
<li>Measure</li>
<li>Optimize Bottleneck</li>
<li>Design for Scale</li>
<li>Plan for Failure</li>
</ol></li>
<li><p>In a production system, what trade-offs might you consider when deploying AI systems across diverse contexts such as cloud, edge, and TinyML?</p></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-future-directions-emerging-opportunities-0840" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-conclusion-journey-forward-engineering-intelligence-427d" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-conclusion-journey-forward-engineering-intelligence-427d">Your Journey Forward: Engineering Intelligence</h2>
<p>Twenty chapters ago, we began with a vision: artificial intelligence (AI) as a transformative force reshaping civilization. You now possess the systems engineering principles to make that vision reality.</p>
<p>Artificial general intelligence will be built by engineers who understand that intelligence is a systems property, emerging from the integration of components rather than any single breakthrough. Consider GPT-4’s success <span class="citation" data-cites="openai2023gpt4">(<a href="#ref-openai2023gpt4" role="doc-biblioref">OpenAI et al. 2023</a>)</span>: it required robust data pipelines processing petabytes of text (<strong><a href="../workflow/workflow.html#sec-ai-workflow">Chapter 5: AI Workflow</a></strong>), distributed training infrastructure<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> coordinating thousands of GPUs (<strong><a href="../training/training.html#sec-ai-training">Chapter 8: AI Training</a></strong>), efficient architectures leveraging attention mechanisms and mixture-of-experts (<strong><a href="../efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 9: Efficient AI</a></strong>), secure deployment preventing prompt injection attacks (<strong><a href="../responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 17: Responsible AI</a></strong>), and responsible governance implementing safety filters and usage policies (<strong><a href="../responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 17: Responsible AI</a></strong>).</p>
<div class="no-row-height column-margin column-container"><div id="ref-openai2023gpt4" class="csl-entry" role="listitem">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, et al. 2023. <span>“GPT-4 Technical Report,”</span> March. <a href="http://arxiv.org/abs/2303.08774v6">http://arxiv.org/abs/2303.08774v6</a>.
</div><div id="fn14"><p><sup>14</sup>&nbsp;<strong>Distributed ML Systems</strong>: Traditional distributed systems principles (consensus, partitioning, replication) extended for ML workloads. GPT-3 training required 1024 A100 GPUs communicating 175 billion parameters, where network topology and gradient synchronization become critical bottlenecks. Unlike stateless web services, ML systems maintain massive shared state, requiring novel approaches like gradient compression and asynchronous updates.</p></div></div><p>Every principle in this text, from measuring everything to co-designing for hardware, represents a tool for building that future.</p>
<p>The six principles you have mastered transcend specific technologies. As frameworks evolve, hardware advances, and new architectures emerge, these foundational concepts remain constant. They will guide you whether optimizing today’s production recommendation systems or architecting tomorrow’s compound AI systems approaching general intelligence. The compound AI framework, edge deployment paradigms, and efficiency optimization techniques you have explored represent current instantiations of enduring systems thinking.</p>
<p>But mastery of technical principles alone proves insufficient. The question confronting our generation is not whether artificial general intelligence will arrive, but whether it will be built well: efficiently enough to democratize access beyond wealthy institutions, securely enough to resist exploitation, sustainably enough to preserve our planet, and responsibly enough to serve all humanity equitably. These challenges demand the full stack of ML systems engineering, technical excellence unified with ethical commitment.</p>
<p>As you apply these principles to your own engineering challenges, remember that ML systems engineering centers on serving users and society. Every architectural decision, every optimization technique, and every operational practice should ultimately make AI more beneficial, accessible, and trustworthy. Measure your success not only in reduced latency or improved accuracy, but in real-world impact: lives improved, problems solved, capabilities democratized.</p>
<p>The intelligent systems that will define the coming century (from climate models predicting extreme weather to medical AI diagnosing rare diseases, from educational systems personalizing learning to assistive technologies empowering billions) await your engineering expertise. You now possess the knowledge to build them: the principles to guide design, the techniques to ensure efficiency, the frameworks to guarantee safety, and the wisdom to deploy responsibly.</p>
<p>Your journey as an ML systems engineer begins now. Take the principles you have mastered. Apply them to challenges that matter. Build systems that scale. Create solutions that endure. Engineer intelligence that serves humanity.</p>
<p>The future of intelligence is not something we will simply witness; it is something we must build. Go build it well.</p>
<p><em>Prof.&nbsp;Vijay Janapa Reddi, Harvard University</em></p>
<!-- This is here to make sure that quizzes are inserted properly before a part begins. -->
<div id="quiz-question-sec-conclusion-journey-forward-engineering-intelligence-427d" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.7</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the role of systems engineering in achieving artificial general intelligence (AGI)?</p>
<ol type="a">
<li>Focusing on a single breakthrough technology.</li>
<li>Prioritizing hardware advancements over software improvements.</li>
<li>Integrating diverse components into a cohesive system.</li>
<li>Relying solely on data quality improvements.</li>
</ol></li>
<li><p>True or False: The success of systems like GPT-4 is solely due to advancements in neural network architectures.</p></li>
<li><p>Explain how ethical considerations should influence the design and deployment of AI systems.</p></li>
<li><p>In the context of ML systems engineering, which principle is crucial for ensuring that AI systems are beneficial and trustworthy?</p>
<ol type="a">
<li>Maximizing computational power.</li>
<li>Reducing model size.</li>
<li>Increasing data collection.</li>
<li>Serving users and society.</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-conclusion-journey-forward-engineering-intelligence-427d" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="self-check-answers" class="level2">
<h2 class="anchored" data-anchor-id="self-check-answers">Self-Check Answers</h2>
<div id="quiz-answer-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.1</strong></summary><div>
<ol type="1">
<li><p><strong>Which principle is emphasized as crucial for the development of contemporary AI systems according to the overview?</strong></p>
<ol type="a">
<li>Isolated algorithmic innovation</li>
<li>Data collection</li>
<li>Architectural innovation</li>
<li>Systems integration</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Systems integration. This is emphasized as crucial because contemporary AI achievements emerge from the integration of computational theory with engineering practice, rather than isolated innovations.</p>
<p><em>Learning Objective</em>: Understand the role of systems integration in the development of AI systems.</p></li>
<li><p><strong>Explain how the systems thinking paradigm contributes to the development of AI systems.</strong></p>
<p><em>Answer</em>: Systems thinking contributes by integrating computational theory with engineering practice, enabling the orchestration of interdependent components. For example, transformer architectures rely on distributed training infrastructure and algorithmic optimization. This is important because it enables scalable and reliable AI systems that address complex challenges.</p>
<p><em>Learning Objective</em>: Analyze the contribution of systems thinking to AI system development.</p></li>
<li><p><strong>What is a key challenge when scaling AI systems towards Artificial General Intelligence (AGI)?</strong></p>
<ol type="a">
<li>Developing new algorithms</li>
<li>Scaling current ML systems principles</li>
<li>Increasing data collection</li>
<li>Improving user interfaces</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Scaling current ML systems principles. The challenge lies in scaling these principles to meet the computational requirements of AGI, which are significantly higher than current systems.</p>
<p><em>Learning Objective</em>: Identify challenges in scaling AI systems towards AGI.</p></li>
<li><p><strong>How might the principles of ML systems engineering be applied to address societal challenges?</strong></p>
<p><em>Answer</em>: ML systems engineering principles can be applied to design AI systems that perform reliably in healthcare, education, and climate science. For example, robust operational frameworks ensure AI’s effective deployment in these fields. This is important because it aligns technical capabilities with societal needs.</p>
<p><em>Learning Objective</em>: Apply ML systems engineering principles to societal challenges.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-synthesizing-ml-systems-engineering-components-intelligence-f244" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-conclusion-systems-engineering-principles-ml-6501" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.2</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the purpose of roofline analysis in ML systems?</strong></p>
<ol type="a">
<li>To determine the memory capacity of a system</li>
<li>To evaluate the cost efficiency of cloud deployments</li>
<li>To identify computational bottlenecks by plotting operational intensity against peak performance</li>
<li>To measure the energy consumption of mobile devices</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Roofline analysis identifies computational bottlenecks by plotting operational intensity against peak performance, revealing whether systems are memory bound or compute bound.</p>
<p><em>Learning Objective</em>: Understand the role of roofline analysis in optimizing ML system performance.</p></li>
<li><p><strong>True or False: Designing for 10x scale means that systems should be optimized for current loads only.</strong></p>
<p><em>Answer</em>: False. Designing for 10x scale means systems must handle an order of magnitude more data, users, and computational demands than currently needed, ensuring robustness under unexpected load increases.</p>
<p><em>Learning Objective</em>: Recognize the importance of designing ML systems to handle significantly higher loads than anticipated.</p></li>
<li><p><strong>Explain how the principle of ‘Optimize the Bottleneck’ can be applied to enhance the performance of an ML system.</strong></p>
<p><em>Answer</em>: Optimizing the bottleneck involves identifying and addressing the primary constraint in a system, such as memory bandwidth in training workloads or network latency in distributed inference. By focusing on the main performance limiting factor, significant efficiency gains can be achieved. For example, optimizing memory usage in a training pipeline can reduce training time and resource consumption, leading to more efficient system operation.</p>
<p><em>Learning Objective</em>: Apply the concept of bottleneck optimization to improve ML system performance.</p></li>
<li><p><strong>What is a critical insight gained from systematic benchmarking in ML systems?</strong></p>
<ol type="a">
<li>Systems always fail at expected loads</li>
<li>Systems rarely fail when demand exceeds design assumptions by orders of magnitude</li>
<li>Benchmarking only measures computational throughput</li>
<li>Benchmarking is unnecessary for cloud-based systems</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Systematic benchmarking reveals that systems rarely fail at expected loads but often fail when demand exceeds design assumptions by orders of magnitude.</p>
<p><em>Learning Objective</em>: Understand the role of benchmarking in identifying potential failure points in ML systems.</p></li>
<li><p><strong>In a production ML system, why is it important to plan for failure, and how can this be implemented?</strong></p>
<p><em>Answer</em>: Planning for failure is crucial because production systems experience component failures, network partitions, and adversarial inputs. Implementing redundancy, monitoring, and recovery mechanisms, such as circuit breakers and automated recovery procedures, ensures system resilience. For example, a circuit breaker can prevent cascading failures by temporarily blocking requests to a failing service, allowing the system to recover gracefully.</p>
<p><em>Learning Objective</em>: Explain the importance of failure planning in ML systems and how it can be practically implemented.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-systems-engineering-principles-ml-6501" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-conclusion-applying-principles-across-three-critical-domains-ca7d" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.3</strong></summary><div>
<ol type="1">
<li><p><strong>Which principle is highlighted as essential for ensuring that AI systems can move beyond laboratory settings to resource-constrained deployments?</strong></p>
<ol type="a">
<li>Data governance</li>
<li>Optimization of bottlenecks</li>
<li>Co-design</li>
<li>Schema evolution</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Optimization of bottlenecks. This principle is crucial for addressing resource constraints in deployments by systematically identifying and addressing limiting factors like memory and compute.</p>
<p><em>Learning Objective</em>: Understand the importance of optimizing bottlenecks for deploying AI systems in resource-constrained environments.</p></li>
<li><p><strong>Explain how data governance acts as both a technical necessity and an ethical imperative in ML systems.</strong></p>
<p><em>Answer</em>: Data governance ensures data quality, which is crucial for system performance. It involves monitoring distribution shifts and labeling consistency. Ethically, it prevents biases and ensures fairness. For example, poor data quality can lead to biased models, making governance essential for ethical AI deployment.</p>
<p><em>Learning Objective</em>: Analyze the dual role of data governance in technical and ethical contexts within ML systems.</p></li>
<li><p><strong>In ML systems, the principle of ‘Data is the new ____’ emphasizes the critical role of data quality in determining system performance.</strong></p>
<p><em>Answer</em>: code. This phrase highlights that data quality is as crucial as code quality in determining the effectiveness of machine learning models.</p>
<p><em>Learning Objective</em>: Recall the importance of data quality in the context of ML system performance.</p></li>
<li><p><strong>Order the following steps in building a robust ML system foundation: (1) Monitor distribution shifts, (2) Implement data governance, (3) Track schema evolution.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Implement data governance, (3) Track schema evolution, (1) Monitor distribution shifts. Data governance sets the groundwork, schema evolution ensures data structure integrity, and monitoring distribution shifts maintains performance.</p>
<p><em>Learning Objective</em>: Understand the sequence of actions required to establish a robust ML system foundation.</p></li>
<li><p><strong>In a production ML system, what trade-offs might you consider when selecting a framework for deployment?</strong></p>
<p><em>Answer</em>: When selecting a framework, consider trade-offs between production maturity and research flexibility. For example, TensorFlow offers robust deployment tools, while PyTorch is favored for research. The choice affects development speed and deployment constraints, impacting overall system efficiency.</p>
<p><em>Learning Objective</em>: Evaluate trade-offs in framework selection for ML system deployment.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-applying-principles-across-three-critical-domains-ca7d" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-conclusion-engineering-performance-scale-a99a" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.4</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following is a benefit of using pruning in neural network optimization?</strong></p>
<ol type="a">
<li>Increases the number of parameters</li>
<li>Decreases the model’s inference speed</li>
<li>Maintains accuracy while reducing model size</li>
<li>Increases the precision requirements</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Maintains accuracy while reducing model size. Pruning removes redundant parameters, which streamlines the model without sacrificing performance. Options A, C, and D are incorrect because pruning reduces parameters, typically increases inference speed, and does not increase precision requirements.</p>
<p><em>Learning Objective</em>: Understand the benefits of pruning in optimizing neural network architectures.</p></li>
<li><p><strong>Explain how knowledge distillation can be used to deploy models in resource-constrained environments.</strong></p>
<p><em>Answer</em>: Knowledge distillation transfers the knowledge from a large model (teacher) to a smaller model (student) by training the student model to mimic the outputs of the teacher. This approach allows the deployment of efficient models that perform well in environments with limited computational resources. For example, a distilled model can run on mobile devices with reduced latency. This is important because it enables the use of advanced models in real-time applications where resources are limited.</p>
<p><em>Learning Objective</em>: Understand the application of knowledge distillation for deploying models in constrained environments.</p></li>
<li><p><strong>Order the following optimization techniques from the Deep Compression pipeline: (1) Quantization, (2) Pruning, (3) Operator Fusion.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Pruning, (1) Quantization, (3) Operator Fusion. Pruning is typically performed first to remove redundant parameters, followed by quantization to reduce precision requirements, and finally, operator fusion to optimize execution efficiency. This sequence ensures systematic optimization of the model for deployment.</p>
<p><em>Learning Objective</em>: Understand the sequential application of optimization techniques in the Deep Compression pipeline.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-engineering-performance-scale-a99a" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-conclusion-navigating-production-reality-c406" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.5</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the role of MLOps in the production deployment of ML systems?</strong></p>
<ol type="a">
<li>MLOps focuses solely on the initial deployment of models.</li>
<li>MLOps is primarily about securing ML models against adversarial attacks.</li>
<li>MLOps is concerned with the orchestration of the entire ML system lifecycle.</li>
<li>MLOps involves only the monitoring of deployed models.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. MLOps is concerned with the orchestration of the entire ML system lifecycle. This includes continuous integration, deployment, monitoring, and governance, transforming artisanal model development into industrial software engineering.</p>
<p><em>Learning Objective</em>: Understand the comprehensive role of MLOps in managing the lifecycle of ML systems in production.</p></li>
<li><p><strong>True or False: Differential privacy is a technique used to ensure the robustness of ML models against adversarial attacks.</strong></p>
<p><em>Answer</em>: False. Differential privacy provides mathematical guarantees to protect individual data privacy, not specifically against adversarial attacks. Adversarial training is used to build robustness against such attacks.</p>
<p><em>Learning Objective</em>: Differentiate between privacy techniques and adversarial robustness methods in ML systems.</p></li>
<li><p><strong>Explain how federated learning can contribute to secure collaboration in ML systems.</strong></p>
<p><em>Answer</em>: Federated learning allows multiple parties to collaboratively train models without sharing raw data, thus enhancing data privacy and security. For example, mobile devices can train a shared model while keeping data local. This is important because it mitigates privacy risks associated with central data storage.</p>
<p><em>Learning Objective</em>: Understand the role of federated learning in enhancing privacy and security in collaborative ML environments.</p></li>
<li><p><strong>In ML systems, ____ provides mathematical guarantees to protect individual data privacy.</strong></p>
<p><em>Answer</em>: differential privacy. Differential privacy ensures that the output of a computation does not compromise the privacy of individual data points.</p>
<p><em>Learning Objective</em>: Recall specific privacy techniques used in ML systems to safeguard individual data.</p></li>
<li><p><strong>What are the ethical and environmental considerations that must be integrated into the design of ML systems for production deployment?</strong></p>
<p><em>Answer</em>: Ethical considerations include fairness, explainability, and responsible AI practices, while environmental considerations involve minimizing energy consumption and carbon footprint. For example, optimizing model efficiency can reduce the environmental impact of large-scale deployments. These considerations are important because they ensure the system’s long-term sustainability and societal acceptability.</p>
<p><em>Learning Objective</em>: Integrate ethical and environmental considerations into the design and deployment of ML systems.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-navigating-production-reality-c406" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-conclusion-future-directions-emerging-opportunities-0840" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.6</strong></summary><div>
<ol type="1">
<li><p><strong>Which deployment paradigm emphasizes the need for sophisticated hardware-software co-design due to stringent power, memory, and latency constraints?</strong></p>
<ol type="a">
<li>Cloud environments</li>
<li>Mobile and edge systems</li>
<li>Generative AI systems</li>
<li>TinyML and embedded systems</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Mobile and edge systems. These systems face stringent constraints, requiring advanced co-design to operate efficiently on limited resources. Cloud environments focus on scalability, while TinyML deals with even more extreme constraints.</p>
<p><em>Learning Objective</em>: Understand the unique challenges and design considerations for mobile and edge system deployments.</p></li>
<li><p><strong>Explain how the principle of ‘designing for failure’ is crucial in building robust AI systems.</strong></p>
<p><em>Answer</em>: Designing for failure is crucial because ML systems face unique failure modes like distribution shifts and adversarial inputs. By planning for failure, systems can incorporate redundancy, ensemble methods, and uncertainty quantification to ensure safe deployment and avoid catastrophic failures. This approach is vital as AI systems become more autonomous.</p>
<p><em>Learning Objective</em>: Analyze the importance of designing for failure in ensuring system robustness and reliability.</p></li>
<li><p><strong>In the context of AI for societal benefit, which principle is emphasized for medical AI systems?</strong></p>
<ol type="a">
<li>Measure</li>
<li>Optimize Bottleneck</li>
<li>Design for Scale</li>
<li>Plan for Failure</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Measure. Medical AI systems require explainable decisions and continuous monitoring, emphasizing the need for precise measurement to ensure accuracy and reliability.</p>
<p><em>Learning Objective</em>: Identify the key principles applied in AI systems designed for societal benefit, particularly in healthcare.</p></li>
<li><p><strong>In a production system, what trade-offs might you consider when deploying AI systems across diverse contexts such as cloud, edge, and TinyML?</strong></p>
<p><em>Answer</em>: Trade-offs include balancing performance and cost in cloud environments, optimizing for power and latency in edge systems, and maximizing efficiency within extreme constraints for TinyML. Each context requires different optimizations, such as kernel fusion for clouds or quantization for edge devices, to ensure system effectiveness and scalability.</p>
<p><em>Learning Objective</em>: Evaluate the trade-offs involved in deploying AI systems across various technological contexts.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-future-directions-emerging-opportunities-0840" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-conclusion-journey-forward-engineering-intelligence-427d" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.7</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the role of systems engineering in achieving artificial general intelligence (AGI)?</strong></p>
<ol type="a">
<li>Focusing on a single breakthrough technology.</li>
<li>Prioritizing hardware advancements over software improvements.</li>
<li>Integrating diverse components into a cohesive system.</li>
<li>Relying solely on data quality improvements.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Integrating diverse components into a cohesive system. This is correct because AGI requires a holistic approach that combines various technologies and principles, rather than focusing on a single breakthrough.</p>
<p><em>Learning Objective</em>: Understand the role of systems engineering in achieving AGI.</p></li>
<li><p><strong>True or False: The success of systems like GPT-4 is solely due to advancements in neural network architectures.</strong></p>
<p><em>Answer</em>: False. This is false because the success of systems like GPT-4 relies on a combination of robust data pipelines, distributed training infrastructure, efficient architectures, and responsible deployment and governance.</p>
<p><em>Learning Objective</em>: Recognize the multifaceted nature of successful AI systems.</p></li>
<li><p><strong>Explain how ethical considerations should influence the design and deployment of AI systems.</strong></p>
<p><em>Answer</em>: Ethical considerations should guide the design and deployment of AI systems to ensure they are secure, sustainable, and equitable. For example, implementing safety filters and usage policies can prevent misuse. This is important because AI systems should serve humanity and democratize access, not exacerbate inequalities.</p>
<p><em>Learning Objective</em>: Understand the importance of ethical considerations in AI system design.</p></li>
<li><p><strong>In the context of ML systems engineering, which principle is crucial for ensuring that AI systems are beneficial and trustworthy?</strong></p>
<ol type="a">
<li>Maximizing computational power.</li>
<li>Reducing model size.</li>
<li>Increasing data collection.</li>
<li>Serving users and society.</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Serving users and society. This is crucial because AI systems should ultimately aim to improve real-world impact, such as improving lives and solving problems, rather than just technical metrics.</p>
<p><em>Learning Objective</em>: Identify key principles that ensure AI systems are beneficial and trustworthy.</p></li>
</ol>
<p><a href="#quiz-question-sec-conclusion-journey-forward-engineering-intelligence-427d" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>



</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/frontiers/frontiers.html" class="pagination-link" aria-label="AGI Systems">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">AGI Systems</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/labs/labs.html" class="pagination-link" aria-label="Getting Started">
        <span class="nav-page-text">Getting Started</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.netlify.com">
<p><img src="https://www.netlify.com/v3/img/components/netlify-color-accent.svg" alt="Deploys by Netlify" style="height: 15px; vertical-align: middle; margin-left: 3px;"></p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>