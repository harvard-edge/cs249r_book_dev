<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/frontiers/frontiers.html" rel="next">
<link href="../../../contents/core/sustainable_ai/sustainable_ai.html" rel="prev">
<link href="../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ae75ed80ef5b3e74590777de1ac3d8c3.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-0769fbf68cc3e722256a1e1e51d908bf.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<script src="../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script>
<style>
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
.callout-definition {
  --color1: #F0F4F8;
  --color2: #1B4F72;
}
.callout-example {
  --color1: #F0F8F6;
  --color2: #148F77;
}
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
</style>
<style>
details.callout-quiz-answer > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
details.callout-quiz-question > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-definition > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-definition.png");
}
details.callout-example > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-example.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-code > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-code.png");
}
details.callout-resource-videos > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
</style>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-md " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/images/icons/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-file-pdf" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/epub" target="_blank"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text">EPUB</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/responsible_ai/responsible_ai.html">Trustworthy Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/ai_for_good/ai_for_good.html">AI for Good</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden"><i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p style="margin: 0 0 12px 0; padding: 8px 12px; background: rgba(255,193,7,0.2); border: 1px solid #ffc107; border-radius: 4px; font-weight: 600;"><i class="bi bi-exclamation-triangle-fill" style="margin-right: 6px; color: #856404;"></i><strong>🚧 DEVELOPMENT PREVIEW</strong> - Built from dev@<code style="background: rgba(0,0,0,0.1); padding: 2px 4px; border-radius: 3px; font-size: 0.9em;">f6230646</code> • 2025-10-03 01:49 UTC • <a href="https://mlsysbook.ai" style="color: #856404; text-decoration: underline;"><em>Stable version →</em></a></p>
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div><i class="bi bi-x-lg quarto-announcement-action" style="display: none;"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frontiers/frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AGI Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">Glossary</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/glossary/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Glossary</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">References</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Bibliography</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-ai-good" id="toc-sec-ai-good" class="nav-link active" data-scroll-target="#sec-ai-good">AI for Good</a>
  <ul>
  <li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose</a></li>
  <li><a href="#sec-ai-good-overview-c977" id="toc-sec-ai-good-overview-c977" class="nav-link" data-scroll-target="#sec-ai-good-overview-c977">Overview</a></li>
  <li><a href="#sec-ai-good-global-challenges-d7d2" id="toc-sec-ai-good-global-challenges-d7d2" class="nav-link" data-scroll-target="#sec-ai-good-global-challenges-d7d2">Global Challenges</a></li>
  <li><a href="#sec-ai-good-key-ai-applications-f9fd" id="toc-sec-ai-good-key-ai-applications-f9fd" class="nav-link" data-scroll-target="#sec-ai-good-key-ai-applications-f9fd">Key AI Applications</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-agriculture-0b70" id="toc-sec-ai-good-agriculture-0b70" class="nav-link" data-scroll-target="#sec-ai-good-agriculture-0b70">Agriculture</a></li>
  <li><a href="#sec-ai-good-healthcare-0207" id="toc-sec-ai-good-healthcare-0207" class="nav-link" data-scroll-target="#sec-ai-good-healthcare-0207">Healthcare</a></li>
  <li><a href="#sec-ai-good-disaster-response-dbc7" id="toc-sec-ai-good-disaster-response-dbc7" class="nav-link" data-scroll-target="#sec-ai-good-disaster-response-dbc7">Disaster Response</a></li>
  <li><a href="#sec-ai-good-environmental-conservation-615d" id="toc-sec-ai-good-environmental-conservation-615d" class="nav-link" data-scroll-target="#sec-ai-good-environmental-conservation-615d">Environmental Conservation</a></li>
  <li><a href="#sec-ai-good-ais-holistic-impact-285e" id="toc-sec-ai-good-ais-holistic-impact-285e" class="nav-link" data-scroll-target="#sec-ai-good-ais-holistic-impact-285e">AI’s Holistic Impact</a></li>
  </ul></li>
  <li><a href="#sec-ai-good-global-development-perspective-8f64" id="toc-sec-ai-good-global-development-perspective-8f64" class="nav-link" data-scroll-target="#sec-ai-good-global-development-perspective-8f64">Global Development Perspective</a></li>
  <li><a href="#sec-ai-good-engineering-challenges-d6a8" id="toc-sec-ai-good-engineering-challenges-d6a8" class="nav-link" data-scroll-target="#sec-ai-good-engineering-challenges-d6a8">Engineering Challenges</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-quantitative-optimization-2a1b" id="toc-sec-ai-good-quantitative-optimization-2a1b" class="nav-link" data-scroll-target="#sec-ai-good-quantitative-optimization-2a1b">Quantitative Optimization Techniques</a></li>
  <li><a href="#sec-ai-good-resource-paradox-dd1d" id="toc-sec-ai-good-resource-paradox-dd1d" class="nav-link" data-scroll-target="#sec-ai-good-resource-paradox-dd1d">Resource Paradox</a></li>
  <li><a href="#sec-ai-good-data-dilemma-0d49" id="toc-sec-ai-good-data-dilemma-0d49" class="nav-link" data-scroll-target="#sec-ai-good-data-dilemma-0d49">Data Dilemma</a></li>
  <li><a href="#sec-ai-good-scale-challenge-076d" id="toc-sec-ai-good-scale-challenge-076d" class="nav-link" data-scroll-target="#sec-ai-good-scale-challenge-076d">Scale Challenge</a></li>
  <li><a href="#sec-ai-good-sustainability-challenge-0218" id="toc-sec-ai-good-sustainability-challenge-0218" class="nav-link" data-scroll-target="#sec-ai-good-sustainability-challenge-0218">Sustainability Challenge</a></li>
  <li><a href="#sec-ai-good-system-resilience-4c3e" id="toc-sec-ai-good-system-resilience-4c3e" class="nav-link" data-scroll-target="#sec-ai-good-system-resilience-4c3e">System Resilience and Failure Recovery</a></li>
  </ul></li>
  <li><a href="#sec-ai-good-theoretical-foundations-8a4c" id="toc-sec-ai-good-theoretical-foundations-8a4c" class="nav-link" data-scroll-target="#sec-ai-good-theoretical-foundations-8a4c">Theoretical Foundations of Resource-Constrained Learning</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-sample-complexity-1e5d" id="toc-sec-ai-good-sample-complexity-1e5d" class="nav-link" data-scroll-target="#sec-ai-good-sample-complexity-1e5d">Sample Complexity in Low-Resource Environments</a></li>
  <li><a href="#sec-ai-good-self-supervised-foundations-3b7e" id="toc-sec-ai-good-self-supervised-foundations-3b7e" class="nav-link" data-scroll-target="#sec-ai-good-self-supervised-foundations-3b7e">Self-Supervised Learning Foundations</a></li>
  <li><a href="#sec-ai-good-optimization-theory-4f8e" id="toc-sec-ai-good-optimization-theory-4f8e" class="nav-link" data-scroll-target="#sec-ai-good-optimization-theory-4f8e">Resource-Constrained Optimization Theory</a></li>
  </ul></li>
  <li><a href="#sec-ai-good-design-patterns-cf75" id="toc-sec-ai-good-design-patterns-cf75" class="nav-link" data-scroll-target="#sec-ai-good-design-patterns-cf75">Design Patterns</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-hierarchical-processing-3405" id="toc-sec-ai-good-hierarchical-processing-3405" class="nav-link" data-scroll-target="#sec-ai-good-hierarchical-processing-3405">Hierarchical Processing</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-googles-flood-forecasting-70fb" id="toc-sec-ai-good-googles-flood-forecasting-70fb" class="nav-link" data-scroll-target="#sec-ai-good-googles-flood-forecasting-70fb">Google’s Flood Forecasting</a></li>
  <li><a href="#sec-ai-good-structure-c29a" id="toc-sec-ai-good-structure-c29a" class="nav-link" data-scroll-target="#sec-ai-good-structure-c29a">Structure</a></li>
  <li><a href="#sec-ai-good-modern-adaptations-e458" id="toc-sec-ai-good-modern-adaptations-e458" class="nav-link" data-scroll-target="#sec-ai-good-modern-adaptations-e458">Modern Adaptations</a></li>
  <li><a href="#sec-ai-good-system-implications-58bd" id="toc-sec-ai-good-system-implications-58bd" class="nav-link" data-scroll-target="#sec-ai-good-system-implications-58bd">System Implications</a></li>
  <li><a href="#sec-ai-good-performance-characteristics-9b2f" id="toc-sec-ai-good-performance-characteristics-9b2f" class="nav-link" data-scroll-target="#sec-ai-good-performance-characteristics-9b2f">Performance Characteristics by Tier</a></li>
  <li><a href="#sec-ai-good-limitations-ef57" id="toc-sec-ai-good-limitations-ef57" class="nav-link" data-scroll-target="#sec-ai-good-limitations-ef57">Limitations</a></li>
  </ul></li>
  <li><a href="#sec-ai-good-progressive-enhancement-1b00" id="toc-sec-ai-good-progressive-enhancement-1b00" class="nav-link" data-scroll-target="#sec-ai-good-progressive-enhancement-1b00">Progressive Enhancement</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-plantvillage-nuru-9b9d" id="toc-sec-ai-good-plantvillage-nuru-9b9d" class="nav-link" data-scroll-target="#sec-ai-good-plantvillage-nuru-9b9d">PlantVillage Nuru</a></li>
  <li><a href="#sec-ai-good-structure-120e" id="toc-sec-ai-good-structure-120e" class="nav-link" data-scroll-target="#sec-ai-good-structure-120e">Structure</a></li>
  <li><a href="#sec-ai-good-modern-adaptations-fe04" id="toc-sec-ai-good-modern-adaptations-fe04" class="nav-link" data-scroll-target="#sec-ai-good-modern-adaptations-fe04">Modern Adaptations</a></li>
  <li><a href="#sec-ai-good-system-implications-e1f3" id="toc-sec-ai-good-system-implications-e1f3" class="nav-link" data-scroll-target="#sec-ai-good-system-implications-e1f3">System Implications</a></li>
  <li><a href="#sec-ai-good-framework-implementation-9c8d" id="toc-sec-ai-good-framework-implementation-9c8d" class="nav-link" data-scroll-target="#sec-ai-good-framework-implementation-9c8d">Framework Implementation Patterns</a></li>
  <li><a href="#sec-ai-good-limitations-155c" id="toc-sec-ai-good-limitations-155c" class="nav-link" data-scroll-target="#sec-ai-good-limitations-155c">Limitations</a></li>
  </ul></li>
  <li><a href="#sec-ai-good-distributed-knowledge-e7e1" id="toc-sec-ai-good-distributed-knowledge-e7e1" class="nav-link" data-scroll-target="#sec-ai-good-distributed-knowledge-e7e1">Distributed Knowledge</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-wildlife-insights-69b4" id="toc-sec-ai-good-wildlife-insights-69b4" class="nav-link" data-scroll-target="#sec-ai-good-wildlife-insights-69b4">Wildlife Insights</a></li>
  <li><a href="#sec-ai-good-structure-aded" id="toc-sec-ai-good-structure-aded" class="nav-link" data-scroll-target="#sec-ai-good-structure-aded">Structure</a></li>
  <li><a href="#sec-ai-good-modern-adaptations-2bd9" id="toc-sec-ai-good-modern-adaptations-2bd9" class="nav-link" data-scroll-target="#sec-ai-good-modern-adaptations-2bd9">Modern Adaptations</a></li>
  <li><a href="#sec-ai-good-system-implications-5f92" id="toc-sec-ai-good-system-implications-5f92" class="nav-link" data-scroll-target="#sec-ai-good-system-implications-5f92">System Implications</a></li>
  <li><a href="#sec-ai-good-limitations-8def" id="toc-sec-ai-good-limitations-8def" class="nav-link" data-scroll-target="#sec-ai-good-limitations-8def">Limitations</a></li>
  </ul></li>
  <li><a href="#sec-ai-good-adaptive-resource-c0d5" id="toc-sec-ai-good-adaptive-resource-c0d5" class="nav-link" data-scroll-target="#sec-ai-good-adaptive-resource-c0d5">Adaptive Resource</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-case-studies-3646" id="toc-sec-ai-good-case-studies-3646" class="nav-link" data-scroll-target="#sec-ai-good-case-studies-3646">Case Studies</a></li>
  <li><a href="#sec-ai-good-structure-1bdc" id="toc-sec-ai-good-structure-1bdc" class="nav-link" data-scroll-target="#sec-ai-good-structure-1bdc">Structure</a></li>
  <li><a href="#sec-ai-good-modern-adaptations-77d4" id="toc-sec-ai-good-modern-adaptations-77d4" class="nav-link" data-scroll-target="#sec-ai-good-modern-adaptations-77d4">Modern Adaptations</a></li>
  <li><a href="#sec-ai-good-system-implications-7ad5" id="toc-sec-ai-good-system-implications-7ad5" class="nav-link" data-scroll-target="#sec-ai-good-system-implications-7ad5">System Implications</a></li>
  <li><a href="#sec-ai-good-limitations-d4d0" id="toc-sec-ai-good-limitations-d4d0" class="nav-link" data-scroll-target="#sec-ai-good-limitations-d4d0">Limitations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-ai-good-selection-framework-8d82" id="toc-sec-ai-good-selection-framework-8d82" class="nav-link" data-scroll-target="#sec-ai-good-selection-framework-8d82">Selection Framework</a>
  <ul class="collapse">
  <li><a href="#sec-ai-good-selection-dimensions-b80c" id="toc-sec-ai-good-selection-dimensions-b80c" class="nav-link" data-scroll-target="#sec-ai-good-selection-dimensions-b80c">Selection Dimensions</a></li>
  <li><a href="#sec-ai-good-implementation-guidance-752c" id="toc-sec-ai-good-implementation-guidance-752c" class="nav-link" data-scroll-target="#sec-ai-good-implementation-guidance-752c">Implementation Guidance</a></li>
  <li><a href="#sec-ai-good-comparison-analysis-3ce7" id="toc-sec-ai-good-comparison-analysis-3ce7" class="nav-link" data-scroll-target="#sec-ai-good-comparison-analysis-3ce7">Comparison Analysis</a></li>
  </ul></li>
  <li><a href="#fallacies-and-pitfalls" id="toc-fallacies-and-pitfalls" class="nav-link" data-scroll-target="#fallacies-and-pitfalls">Fallacies and Pitfalls</a></li>
  <li><a href="#sec-ai-good-summary-2437" id="toc-sec-ai-good-summary-2437" class="nav-link" data-scroll-target="#sec-ai-good-summary-2437">Summary</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers">Self-Check Answers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/responsible_ai/responsible_ai.html">Trustworthy Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/ai_for_good/ai_for_good.html">AI for Good</a></li></ol></nav></header>




<section id="sec-ai-good" class="level1 page-columns page-full">
<h1>AI for Good</h1>
<div class="{layout-narrow} page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="">
<p><em>DALL·E 3 Prompt: Illustration of planet Earth wrapped in shimmering neural networks, with diverse humans and AI robots working together on various projects like planting trees, cleaning the oceans, and developing sustainable energy solutions. The positive and hopeful atmosphere represents a united effort to create a better future.</em></p>
</div></div><p> <img src="images/png/cover_ai_good.png" class="img-fluid"></p>
</div>
<section id="purpose" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="purpose">Purpose</h2>
<p><em>How do resource constraints and deployment challenges in underserved environments reshape the design of machine learning systems for social impact?</em></p>
<p>Deploying machine learning systems for social impact requires design changes to address resource constraints, infrastructure limitations, and deployment challenges absent from commercial applications. Healthcare, education, environmental protection, and global development applications operate in environments with limited computing resources, intermittent connectivity, minimal technical support, and diverse cultural contexts. These deployment realities reshape every aspect of system design: model architectures must be efficient, training approaches must handle sparse data, deployment patterns must tolerate unreliable infrastructure, and maintenance strategies must operate with minimal expert support. Successful AI for good systems balance performance with accessibility, scalability with local adaptation, and technical innovation with practical deployment constraints. Understanding these unique requirements enables engineers to design systems that create lasting positive societal impact despite challenging operational environments.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Explore how AI systems can address important real-world societal challenges and global problems</p></li>
<li><p>Recognize key design patterns for ML systems in social impact and resource-constrained environments</p></li>
<li><p>Select suitable design patterns based on resource availability and adaptability requirements</p></li>
<li><p>Explore how Cloud ML, Edge ML, Mobile ML, and TinyML integrate into social impact deployment patterns</p></li>
<li><p>Evaluate strengths and limitations of design patterns for specific deployment scenarios</p></li>
<li><p>Analyze case studies of successful AI for good implementations across diverse domains</p></li>
</ul>
</div>
</div>
</section>
<section id="sec-ai-good-overview-c977" class="level2">
<h2 class="anchored" data-anchor-id="sec-ai-good-overview-c977">Overview</h2>
<p>Previous chapters examined the core components of machine learning systems - from neural architectures in <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong> and training methodologies in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong> to acceleration techniques in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong> and deployment strategies in <strong><a href="../core/ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong>. These chapters established how to build, optimize, and operate ML systems at scale. The examples and techniques focused primarily on scenarios where computational resources, reliable infrastructure, and technical expertise were readily available.</p>
<p>However, machine learning systems extend far beyond commercial and industrial applications. While recommendation engines, computer vision systems, and natural language processors drive business value, ML systems also hold immense potential for addressing pressing societal challenges. This potential remains largely unrealized due to the distinct challenges of deploying ML systems in resource-constrained environments.</p>
<p>Engineering ML systems for social impact differs fundamentally from commercial deployments. These systems must operate in environments with limited computing resources, intermittent connectivity, and minimal technical support infrastructure—constraints explored in detail in <a href="#sec-ai-good-engineering-challenges-d6a8" class="quarto-xref">Section&nbsp;1.5</a>. Such constraints reshape every aspect of ML system design—from model architecture and training approaches to deployment patterns and maintenance strategies. Success requires rethinking traditional ML system design patterns to create solutions that are robust, maintainable, and effective despite these limitations—making AI for social good fundamentally an engineering challenge.</p>
<div id="callout-definition*-1.1" class="callout callout-definition" title="Definition of AI for Good">
<p></p><details class="callout-definition fbx-default closebutton" open=""><summary><strong>Definition: </strong>Definition of AI for Good</summary><div><strong>AI for Good</strong> refers to the <em>design, development, and deployment of machine learning systems aimed at addressing important societal and environmental challenges</em>. These systems seek to <em>enhance human welfare, promote sustainability, and contribute to global development goals</em> by leveraging machine learning and related AI technologies to <em>create positive, equitable, and lasting impact</em>.<p></p>
</div></details>
</div>
<p>This chapter highlights specific AI applications for social good and examines the unique requirements, constraints, and opportunities in engineering ML systems for social impact. We analyze how core ML system components adapt to resource-constrained environments, explore architectural patterns that allow robust deployment across the computing spectrum, and study real-world implementations in healthcare, agriculture, education, and environmental monitoring. These challenges build upon the data engineering foundations from <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong> while requiring novel approaches to handle sparse, heterogeneous data sources in underserved environments. Through these examples and the discussions involved, we develop frameworks for designing ML systems that deliver sustainable social impact.</p>
<div id="quiz-question-sec-ai-good-overview-c977" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.1</strong></summary><div>
<ol type="1">
<li><p>What is the primary focus of AI for Good?</p>
<ol type="a">
<li>Maximizing commercial profits</li>
<li>Improving computational efficiency</li>
<li>Developing advanced neural network architectures</li>
<li>Enhancing human welfare and promoting sustainability</li>
</ol></li>
<li><p>Why is deploying ML systems in resource-constrained environments challenging, and how does it differ from commercial deployments?</p></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-overview-c977" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-ai-good-global-challenges-d7d2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-ai-good-global-challenges-d7d2">Global Challenges</h2>
<p>History provides sobering examples of where timely interventions and coordinated responses could have dramatically altered outcomes. The 2014-2016 Ebola outbreak<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> in West Africa, for instance, highlighted the catastrophic consequences of delayed detection and response systems <span class="citation" data-cites="who2016ebola">(<a href="#ref-who2016ebola" role="doc-biblioref">Park 2022</a>)</span>. Similarly, the 2011 famine in Somalia, despite being forecasted months in advance, caused immense suffering due to inadequate mechanisms to mobilize and allocate resources effectively <span class="citation" data-cites="reliefweb2012somalia">(<a href="#ref-reliefweb2012somalia" role="doc-biblioref">ReliefWeb 2012</a>)</span>. In the aftermath of the 2010 Haiti earthquake, the lack of rapid and reliable damage assessment significantly hampered efforts to direct aid where it was most needed <span class="citation" data-cites="usgs2010haiti">(<a href="#ref-usgs2010haiti" role="doc-biblioref">Survey, n.d.</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<strong>2014-2016 Ebola Outbreak</strong>: This outbreak killed 11,323 people across six countries, with over 28,600 cases reported. The delayed international response—WHO declared a Public Health Emergency only after 5 months—demonstrated how early AI-powered disease surveillance could have saved thousands of lives. The economic cost exceeded $53 billion, highlighting the need for rapid detection systems that mobile health technologies now provide.</p></div><div id="ref-who2016ebola" class="csl-entry" role="listitem">
Park, Chulwoo. 2022. <span>“Lessons Learned from the World Health Organization’s Late Initial Response to the 2014-2016 Ebola Outbreak in West Africa.”</span> <em>Journal of Public Health in Africa</em> 13 (1): 1254. <a href="https://doi.org/10.4081/jphia.2022.1254">https://doi.org/10.4081/jphia.2022.1254</a>.
</div><div id="ref-reliefweb2012somalia" class="csl-entry" role="listitem">
ReliefWeb. 2012. <span>“Somalia: Famine 2011-2012.”</span> UN Office for the Coordination of Humanitarian Affairs. <a href="https://reliefweb.int/report/somalia/somalia-famine-2011-2012">https://reliefweb.int/report/somalia/somalia-famine-2011-2012</a>.
</div><div id="ref-usgs2010haiti" class="csl-entry" role="listitem">
Survey, United States Geological. n.d. <span>“AccessScience.”</span> U.S. Geological Survey; McGraw-Hill Professional. <a href="https://doi.org/10.1036/1097-8542.yb110201">https://doi.org/10.1036/1097-8542.yb110201</a>.
</div><div id="fn2"><p><sup>2</sup>&nbsp;<strong>Smallholder Farmers Global Impact</strong>: These farmers operate plots smaller than 2 hectares but produce 35% of global food supply, feeding 2 billion people directly. In sub-Saharan Africa, they comprise 80% of farms yet receive only 2% of agricultural credit. Climate change threatens their $2.6 trillion annual production value, making AI-powered agricultural support systems important for global food security and poverty reduction. Increasingly erratic weather patterns, pest outbreaks, and soil degradation compound their difficulties, often resulting in reduced yields and heightened food insecurity, particularly in vulnerable regions. These challenges demonstrate how systemic barriers and resource constraints perpetuate inequities and undermine resilience.</p></div></div><p>These historical lessons reveal patterns that persist today across diverse domains, particularly in resource-constrained environments. In healthcare, remote and underserved communities often experience preventable health crises due to the absence of timely access to medical expertise. A lack of diagnostic tools and specialists means that treatable conditions can escalate into life-threatening situations, creating unnecessary suffering and loss of life. Agriculture, a sector crucial to global food security, faces parallel struggles. Smallholder farmers<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, responsible for producing much of the world’s food, make critical decisions with limited information.</p>
<p>Beyond healthcare and agriculture, similar systemic barriers manifest in education, where inequity further amplifies challenges in underserved areas. Many schools lack sufficient teachers, adequate resources, and personalized support for students. This not only widens the gap between advantaged and disadvantaged learners but also creates long-term consequences for social and economic development. Without access to quality education, entire communities are left at a disadvantage, perpetuating cycles of poverty and inequality. These educational inequities are deeply interconnected with broader challenges, as gaps in education often exacerbate issues in other vital sectors such as healthcare and agriculture.</p>
<p>Compounding these human-centered challenges, the strain on ecosystems introduces another critical dimension to global problems. Environmental degradation, including deforestation, pollution, and biodiversity loss, threatens livelihoods and destabilizes the ecological balance necessary for sustaining human life. Vast stretches of forests, oceans, and wildlife habitats remain unmonitored and unprotected, particularly in regions with limited resources. This leaves ecosystems vulnerable to illegal activities such as poaching, logging, and pollution, further intensifying the pressures on communities already grappling with economic and social disparities. These interwoven challenges underscore the need for holistic solutions that address both human and environmental vulnerabilities.</p>
<p>Although these issues vary in scope and scale, they share several important characteristics. They disproportionately affect vulnerable populations, exacerbating existing inequalities. Resource constraints in affected regions pose significant barriers to implementing solutions. Moreover, addressing these challenges requires navigating trade-offs between competing priorities and limited resources, often under conditions of great uncertainty.</p>
<p>Despite these complex and interconnected challenges, technology holds the potential to play a transformative role in addressing these issues. By providing innovative tools to enhance decision-making, increase efficiency, and deliver solutions at scale, it offers hope for overcoming the barriers that have historically hindered progress. Among these technologies, machine learning systems stand out for their capacity to process vast amounts of information, uncover patterns, and generate insights that can inform action in even the most resource-constrained environments. However, realizing this potential requires deliberate and systematic approaches to ensure these tools are designed and implemented to serve the needs of all communities effectively and equitably.</p>
<div id="quiz-question-sec-ai-good-global-challenges-d7d2" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.2</strong></summary><div>
<ol type="1">
<li><p>Timely interventions and coordinated responses could have significantly altered the outcomes of historical global challenges such as the 2014-2016 Ebola outbreak.</p></li>
<li><p>Which of the following is a key characteristic shared by global challenges discussed in the section?</p>
<ol type="a">
<li>They primarily affect developed countries.</li>
<li>They are easily solved with existing technologies.</li>
<li>They disproportionately affect vulnerable populations.</li>
<li>They have no connection to environmental issues.</li>
</ol></li>
<li><p>How can machine learning systems help address the systemic barriers faced by smallholder farmers?</p></li>
<li><p>Order the following global challenges by their historical occurrence: (1) 2010 Haiti earthquake, (2) 2011 Somalia famine, (3) 2014-2016 Ebola outbreak.</p></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-global-challenges-d7d2" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-ai-good-key-ai-applications-f9fd" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-ai-good-key-ai-applications-f9fd">Key AI Applications</h2>
<p>The ML deployment paradigms from <strong><a href="../core/ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong>—Cloud ML, Mobile ML, Edge ML, and TinyML—unlock transformative solutions for pressing societal challenges by adapting to resource-constrained environments. By adapting to diverse constraints and leveraging unique strengths, these technologies are driving innovation in agriculture, healthcare, disaster response, and environmental conservation. This section explores how these paradigms bring social good to life through real-world applications.</p>
<section id="sec-ai-good-agriculture-0b70" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-agriculture-0b70">Agriculture</h3>
<p>Agriculture faces unprecedented challenges from climate variability, pest resistance, and the need to feed a growing global population with finite resources <span class="citation" data-cites="kamilaris2018deep">(<a href="#ref-kamilaris2018deep" role="doc-biblioref">Kamilaris and Prenafeta-Boldú 2018</a>)</span>. Machine learning systems now provide farmers with diagnostic capabilities once available only to agricultural experts, transforming how crops are monitored, diseases detected, and resources allocated across diverse farming environments.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kamilaris2018deep" class="csl-entry" role="listitem">
Kamilaris, Andreas, and Francesc X. Prenafeta-Boldú. 2018. <span>“Deep Learning in Agriculture: A Survey.”</span> <em>Computers and Electronics in Agriculture</em> 147 (April): 70–90. <a href="https://doi.org/10.1016/j.compag.2018.02.016">https://doi.org/10.1016/j.compag.2018.02.016</a>.
</div></div><div id="fig-plantvillage" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plantvillage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/plantvillage.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Mobile Disease Detection: Example of edge machine learning, where a smartphone app uses a trained model to classify plant diseases directly on the device, enabling real-time feedback in resource-constrained environments. this deployment reduces reliance on network connectivity and allows for localized, accessible agricultural support."><img src="images/png/plantvillage.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plantvillage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>Mobile Disease Detection</strong>: Example of edge machine learning, where a smartphone app uses a trained model to classify plant diseases directly on the device, enabling real-time feedback in resource-constrained environments. this deployment reduces reliance on network connectivity and allows for localized, accessible agricultural support.
</figcaption>
</figure>
</div>
<p>This transformation is particularly evident in Sub-Saharan Africa, where cassava farmers have long battled diseases that devastate crops and livelihoods. Now, with the help of mobile ML-powered smartphone apps, as shown in <a href="#fig-plantvillage" class="quarto-xref">Figure&nbsp;1</a>, they can snap a photo of a leaf and receive instant feedback on potential diseases. Studies suggest this early detection system has the potential to reduce losses from 40% to 15-20% with early identification of diseases, offering hope to farmers in disconnected regions where access to agricultural advisors is limited <span class="citation" data-cites="ramcharan2017deep">(<a href="#ref-ramcharan2017deep" role="doc-biblioref">Ramcharan et al. 2017</a>)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-ramcharan2017deep" class="csl-entry" role="listitem">
Ramcharan, Amanda, Kelsee Baranowski, Peter McCloskey, Babuali Ahmed, James Legg, and David P. Hughes. 2017. <span>“Deep Learning for Image-Based Cassava Disease Detection.”</span> <em>Frontiers in Plant Science</em> 8 (October): 1852. <a href="https://doi.org/10.3389/fpls.2017.01852">https://doi.org/10.3389/fpls.2017.01852</a>.
</div><div id="fn3"><p><sup>3</sup>&nbsp;<strong>Cassava Disease Impact</strong>: Cassava feeds 800 million people globally and is a important food security crop in Africa. Cassava mosaic disease (CMD) and cassava brown streak disease (CBSD) can destroy entire harvests, affecting millions of smallholder farmers. The PlantVillage Nuru app has been downloaded by over 500,000 farmers across Kenya, Tanzania, and Uganda, demonstrating how mobile ML can scale agricultural expertise to underserved communities without internet connectivity.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;<strong>Microclimate Monitoring</strong>: Unlike weather stations measuring regional conditions across 50-100 km areas, microclimate sensors detect variations within 10-meter zones crucial for rice cultivation. These sensors track temperature differences of 2-3°C, humidity variations of 10-15%, and soil moisture changes that can affect yields by 30%. TinyML enables real-time processing on sensors costing $5-10, versus traditional agricultural weather stations requiring $15,000+ investments.</p></div><div id="ref-tirtalistyani2022indonesia" class="csl-entry" role="listitem">
Tirtalistyani, Rose, Murtiningrum Murtiningrum, and Rameshwar S. Kanwar. 2022. <span>“Indonesia Rice Irrigation System: Time for Innovation.”</span> <em>Sustainability</em> 14 (19): 12477. <a href="https://doi.org/10.3390/su141912477">https://doi.org/10.3390/su141912477</a>.
</div></div><p>Similar innovations are emerging across Southeast Asia, where rice farmers are confronting increasingly unpredictable weather patterns. In Indonesia, Tiny ML sensors are transforming their ability to adapt by monitoring microclimates<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> across paddies. These low-power devices process data locally to optimize water usage, enabling precision irrigation even in areas with minimal infrastructure <span class="citation" data-cites="tirtalistyani2022indonesia">(<a href="#ref-tirtalistyani2022indonesia" role="doc-biblioref">Tirtalistyani, Murtiningrum, and Kanwar 2022</a>)</span>.</p>
<p>On a global scale, Microsoft’s <a href="https://www.microsoft.com/en-us/research/project/farmbeats-iot-agriculture/">FarmBeats</a><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> is pioneering the integration of IoT sensors, drones, and Cloud ML to create actionable insights for farmers. By leveraging weather forecasts, soil conditions, and crop health data, the platform allows farmers to optimize inputs like water and fertilizer, reducing waste and improving yields. Together, these innovations illustrate how AI technologies are bringing precision agriculture to life, addressing food security, sustainability, and climate resilience.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<strong>Microsoft FarmBeats</strong>: Launched in 2017, FarmBeats was deployed across several thousand farms before being integrated into Azure FarmBeats in 2021. During its deployment, the platform helped farmers reduce water usage by 30% and increase crop yields by 15-20%. The platform processed data from 50+ sensor types and could predict crop health issues 2-3 weeks before visible symptoms appeared, demonstrating how Cloud ML scales agricultural expertise to underserved farming communities.</p></div></div></section>
<section id="sec-ai-good-healthcare-0207" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-healthcare-0207">Healthcare</h3>
<p>The healthcare sector presents similar opportunities for transformation through machine learning. For millions in underserved communities, access to healthcare often means long waits and travel to distant clinics. Tiny ML is changing that by enabling diagnostics to occur at the patient’s side. For example, a low-cost wearable developed by <a href="https://www.samayhealth.com/">Respira x Colabs</a> uses embedded machine learning to analyze cough patterns and detect pneumonia<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. Designed for remote areas, the device operates independently of internet connectivity and is powered by a simple microcontroller, making life-saving diagnostics accessible to those who need it most.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<strong>Cough Analysis Technology</strong>: Pneumonia kills over 800,000 children under 5 annually, with most deaths occurring in resource-poor settings lacking access to chest X-rays. Cough analysis using TinyML can achieve 90%+ accuracy in pneumonia detection by analyzing acoustic features like cough duration, frequency, and spectral characteristics. The entire model runs on a microcontroller costing less than $10, democratizing diagnostic capabilities.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;<strong>Mosquito Species Detection</strong>: Malaria affects 241 million people annually, causing 627,000 deaths primarily in sub-Saharan Africa. TinyML-powered mosquito detection devices achieve 95% accuracy in species identification using just acoustic signatures, costing under $50 versus traditional morphological identification requiring $5,000+ microscopy equipment. These devices can monitor 24/7 and detect Anopheles mosquitoes (malaria vectors) versus Culex (nuisance only), enabling targeted intervention strategies.</p></div><div id="ref-altayeb2022classifying" class="csl-entry" role="listitem">
Altayeb, Moez, Marco Zennaro, and Marcelo Rovai. 2022. <span>“Classifying Mosquito Wingbeat Sound Using TinyML.”</span> In <em>Proceedings of the 2022 ACM Conference on Information Technology for Social Good</em>, 132–37. ACM. <a href="https://doi.org/10.1145/3524458.3547258">https://doi.org/10.1145/3524458.3547258</a>.
</div></div><p>Building on this diagnostic capability, Tiny ML’s potential extends to tackling global health issues like vector-borne diseases that are spread by mosquitoes. Researchers have developed low-cost devices that use machine learning to identify mosquito species by their wingbeat frequencies<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> <span class="citation" data-cites="altayeb2022classifying">(<a href="#ref-altayeb2022classifying" role="doc-biblioref">Altayeb, Zennaro, and Rovai 2022</a>)</span>. This technology allows real-time monitoring of malaria-carrying mosquitoes and offers a scalable solution for malaria control in high-risk regions.</p>
<p>Complementing these point-of-care innovations, Cloud ML is advancing healthcare research and diagnostics on a broader scale. Platforms like <a href="https://health.google/health-research/genomics/">Google Genomics</a><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> analyze vast datasets to identify disease markers, accelerating breakthroughs in personalized medicine. These examples show how AI technologies, ranging from the portability of Tiny ML to the computational power of Cloud ML, are converging to democratize healthcare access and improve outcomes worldwide.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;<strong>Cloud Genomics Scale</strong>: Google Cloud processes over 50 petabytes of genomic data annually, equivalent to analyzing 15 million human genomes. A single genome contains 3 billion base pairs requiring 100GB storage, making cloud computing essential for population-scale analysis. Cloud ML can identify disease variants in hours versus months using traditional methods, accelerating drug discovery that typically takes 10-15 years and costs $1+ billion per new medicine.</p></div></div></section>
<section id="sec-ai-good-disaster-response-dbc7" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-disaster-response-dbc7">Disaster Response</h3>
<p>Disaster response demands rapid decision making under extreme uncertainty, often with damaged infrastructure and limited communication channels. Machine learning systems address these constraints through autonomous operation, local processing capabilities, and predictive modeling that continues functioning when centralized systems fail.</p>
<p>This capability proves vital in disaster zones, where every second counts and AI technologies are providing tools to accelerate response efforts and enhance safety. Tiny, autonomous drones equipped with Tiny ML algorithms are making their way into collapsed buildings, navigating obstacles to detect signs of life. By analyzing thermal imaging<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> and acoustic signals locally, these drones can identify survivors and hazards without relying on cloud connectivity <span class="citation" data-cites="duisterhof2021sniffy">(<a href="#ref-duisterhof2021sniffy" role="doc-biblioref">Duisterhof et al. 2021</a>)</span>. These drones can autonomously seek light sources (which often indicate survivors) and detect dangerous gas leaks, making search and rescue operations both faster and safer for human responders.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;<strong>Thermal Imaging in Disaster Response</strong>: Human body temperature (37°C) contrasts sharply with debris temperature (often 15-25°C), enabling detection through 30cm of rubble. TinyML thermal analysis on drones can process 320x240 pixel thermal images at 9Hz using only 500mW power, operating for 20+ minutes on small batteries. This autonomous capability proved critical during the 2023 Turkey earthquake, where 72-hour survival windows made rapid victim location essential for the 50,000+ people trapped.</p></div><div id="ref-duisterhof2021sniffy" class="csl-entry" role="listitem">
Duisterhof, Bardienus P., Shushuai Li, Javier Burgues, Vijay Janapa Reddi, and Guido C. H. E. de Croon. 2021. <span>“Sniffy Bug: A Fully Autonomous Swarm of Gas-Seeking Nano Quadcopters in Cluttered Environments.”</span> In <em>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 9099–9106. IEEE; IEEE. <a href="https://doi.org/10.1109/iros51168.2021.9636217">https://doi.org/10.1109/iros51168.2021.9636217</a>.
</div><div id="fn10"><p><sup>10</sup>&nbsp;<strong>Satellite Disaster Monitoring</strong>: Modern disaster monitoring processes 10+ terabytes of satellite imagery daily from sources like Landsat-8, Sentinel-2, and commercial providers. AI can detect flooding across 100,000+ km² areas in 2-3 hours versus 2-3 days for human analysis. During 2022 Pakistan floods affecting 33 million people, satellite AI identified affected areas 48 hours before ground confirmation, enabling preemptive evacuations and resource positioning that saved thousands of lives.</p></div></div><p>Beyond these ground-level operations, platforms like Google’s <a href="https://crisisresponse.google/">AI for Disaster Response</a><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> are leveraging Cloud ML to process satellite imagery and predict flood zones. These systems provide real-time insights to help governments allocate resources more effectively and save lives during emergencies.</p>
<p>Completing this multi-scale approach, Mobile ML applications are also playing a crucial role by delivering real-time disaster alerts directly to smartphones. Tsunami warnings and wildfire updates tailored to users’ locations allow faster evacuations and better preparedness. Whether scaling globally with Cloud ML or enabling localized insights with Edge and Mobile ML, these technologies are redefining disaster response capabilities.</p>
</section>
<section id="sec-ai-good-environmental-conservation-615d" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-environmental-conservation-615d">Environmental Conservation</h3>
<p>Environmental conservation presents another domain where machine learning systems are making significant contributions. Conservationists face immense challenges in monitoring and protecting biodiversity across vast and often remote landscapes. AI technologies are offering scalable solutions to these problems, combining local autonomy with global coordination.</p>
<p>At the individual animal level, EdgeML-powered collars are being used to unobtrusively track animal behavior, such as elephant movements and vocalizations, helping researchers understand migration patterns and social behaviors. By processing data on the collar itself, these devices minimize power consumption and reduce the need for frequent battery changes <span class="citation" data-cites="chen2019edge">(<a href="#ref-chen2019edge" role="doc-biblioref">Chen et al. 2019</a>)</span>. Expanding this monitoring capability, Tiny ML systems are enabling anti-poaching efforts by detecting threats like gunshots<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> or human activity and relaying alerts to rangers in real time <span class="citation" data-cites="bamoumen2022tinyml">(<a href="#ref-bamoumen2022tinyml" role="doc-biblioref">Bamoumen et al. 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-chen2019edge" class="csl-entry" role="listitem">
Chen, Wei, Li Zhang, Rajesh Kumar, and Nisha Patel. 2019. <span>“Edge Computing for Wildlife Conservation: A Case Study of Intelligent Camera Traps.”</span> In <em>Proceedings of the 2019 ACM/IEEE Symposium on Edge Computing</em>, 245–57. IEEE. <a href="https://doi.org/10.1109/SEC.2019.00035">https://doi.org/10.1109/SEC.2019.00035</a>.
</div><div id="fn11"><p><sup>11</sup>&nbsp;<strong>Acoustic Gunshot Detection</strong>: TinyML can distinguish gunshots from other loud sounds (thunder, vehicle backfire) with 95%+ accuracy by analyzing specific acoustic signatures: frequency range 500-4000Hz, duration 1-5ms, and sharp onset characteristics. Solar-powered sensors covering 5-10 km² cost $200-300 versus traditional systems requiring $50,000+ installations. In Kenya’s conservancies, these systems reduce elephant poaching response time from 3-4 hours to 10-15 minutes, significantly increasing ranger safety and wildlife protection effectiveness.</p></div><div id="ref-bamoumen2022tinyml" class="csl-entry" role="listitem">
Bamoumen, Hatim, Anas Temouden, Nabil Benamar, and Yousra Chtouki. 2022. <span>“How TinyML Can Be Leveraged to Solve Environmental Problems: A Survey.”</span> In <em>2022 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)</em>, 338–43. IEEE; IEEE. <a href="https://doi.org/10.1109/3ict56508.2022.9990661">https://doi.org/10.1109/3ict56508.2022.9990661</a>.
</div><div id="fn12"><p><sup>12</sup>&nbsp;<strong>Global Fishing Watch Impact</strong>: Since 2016, this platform has tracked over 70,000 vessels globally, processing 22+ million AIS (Automatic Identification System) data points daily. The system has helped identify $1.5 billion worth of illegal fishing activities and supported enforcement actions that recovered 180+ seized vessels. By making fishing activity transparent, the platform has contributed to 20% reductions in illegal fishing in monitored regions.</p></div></div><p>Extending beyond terrestrial conservation, Cloud ML is being used to monitor illegal fishing activities at a global scale. Platforms like <a href="https://globalfishingwatch.org/">Global Fishing Watch</a><a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> analyze satellite data to detect anomalies, helping governments enforce regulations and protect marine ecosystems.</p>
<p>These diverse applications highlight how AI technologies are enabling real-time monitoring and decision-making, advancing conservation efforts in profound ways.</p>
</section>
<section id="sec-ai-good-ais-holistic-impact-285e" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-ais-holistic-impact-285e">AI’s Holistic Impact</h3>
<p>The examples highlighted above demonstrate the transformative potential of AI technologies in addressing important societal challenges. However, these successes also underscore the complexity of tackling such problems holistically. Each example addresses specific needs, such as optimizing agricultural resources, expanding healthcare access, or protecting ecosystems, but solving these issues sustainably requires more than isolated innovations.</p>
<p>Recognizing this complexity, maximizing impact and ensuring equitable progress requires collective efforts across multiple domains. Large-scale challenges demand collaboration across sectors, geographies, and stakeholders. By fostering coordination between local initiatives, research institutions, and global organizations, we can align AI’s transformative potential with the infrastructure and policies needed to scale solutions effectively. Without such alignment, even the most promising innovations risk operating in silos, limiting their reach and long-term sustainability.</p>
<p>This recognition leads us to require frameworks that help harmonize efforts and prioritize initiatives that deliver broad, lasting impact. These frameworks serve as roadmaps to bridge the gap between technological potential and meaningful global progress.</p>
<div id="quiz-question-sec-ai-good-key-ai-applications-f9fd" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.3</strong></summary><div>
<ol type="1">
<li><p>Which of the following AI technologies is used in agriculture to provide real-time feedback on plant diseases?</p>
<ol type="a">
<li>Mobile ML</li>
<li>Cloud ML</li>
<li>Edge ML</li>
<li>Tiny ML</li>
</ol></li>
<li><p>True or False: Tiny ML is primarily used in agriculture to optimize water usage through precision irrigation.</p></li>
<li><p>In what ways do AI technologies like Tiny ML and Cloud ML contribute to healthcare in underserved areas?</p></li>
<li><p>Order the following AI applications by their primary focus area: (1) Mobile ML for disease detection, (2) Tiny ML for precision irrigation, (3) Cloud ML for genomics research.</p></li>
<li><p>What is a key benefit of using Edge ML in environmental conservation?</p>
<ol type="a">
<li>Requires constant internet connectivity</li>
<li>High power consumption</li>
<li>Limited to small-scale applications</li>
<li>Processes data locally, reducing power needs</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-key-ai-applications-f9fd" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-ai-good-global-development-perspective-8f64" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-ai-good-global-development-perspective-8f64">Global Development Perspective</h2>
<p>The sheer scale and complexity of these problems demand a systematic approach to ensure that efforts are targeted, coordinated, and sustainable. This is where global frameworks such as the United Nations Sustainable Development Goals (SDGs) and guidance from institutions like the World Health Organization (WHO) play a pivotal role. These frameworks provide a structured lens for thinking about and addressing the world’s most pressing challenges. They offer a roadmap to align efforts, set priorities, and foster international collaboration to create impactful and lasting change <span class="citation" data-cites="un_desa_2018">(<a href="#ref-un_desa_2018" role="doc-biblioref"><em>The Sustainable Development Goals Report 2018</em> 2018</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-un_desa_2018" class="csl-entry" role="listitem">
<em>The Sustainable Development Goals Report 2018</em>. 2018. New York: United Nations. <a href="https://doi.org/10.18356/7d014b41-en">https://doi.org/10.18356/7d014b41-en</a>.
</div><div id="fn13"><p><sup>13</sup>&nbsp;<strong>SDG Global Impact</strong>: Adopted by all 193 UN Member States, the SDGs represent the most ambitious global agenda in history, covering 169 specific targets with a $5-7 trillion annual funding gap. The goals build on the success of the Millennium Development Goals (2000-2015), which helped lift 1 billion people out of extreme poverty. Unlike their predecessors, the SDGs apply universally to all countries, recognizing that sustainable development requires global cooperation.</p></div><div id="fn14"><p><sup>14</sup>&nbsp;<strong>AI’s SDG Impact Potential</strong>: McKinsey estimates AI could accelerate achievement of 134 of the 169 SDG targets, potentially contributing $13 trillion to global economic output by 2030. However, 97% of AI research focuses on SDG 9 (Industry/Innovation) while only 1% addresses basic needs like water, food, and health. This maldistribution means AI systems for social good require deliberate design to address the most important human needs rather than commercial applications.</p></div><div id="fn15"><p><sup>15</sup>&nbsp;<strong>AI for Climate Action</strong>: Climate change causes $23 billion in annual economic losses globally, with temperatures rising 1.1°C above pre-industrial levels. AI systems for climate action include: carbon monitoring satellites tracking 50 billion tons of global emissions, smart grid optimization reducing energy waste by 15-20%, and climate modeling using exascale computing to predict regional impacts decades ahead. However, training large AI models can emit 626,000 pounds of CO₂—equivalent to 5 cars’ lifetime emissions—highlighting the need for energy-efficient AI development.</p></div></div><p>Central to this systematic approach, the SDGs shown in <a href="#fig-sdg" class="quarto-xref">Figure&nbsp;2</a> represent a global agenda adopted in 2015<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. These 17 interconnected goals form a blueprint for addressing the world’s most pressing challenges by 2030<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. They range from eliminating poverty and hunger to ensuring quality education, from promoting gender equality to taking climate action<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>.</p>
<div id="fig-sdg" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sdg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./images/png/un_sdg.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Sustainable Development Goals: These 17 interconnected goals provide a global framework for addressing important social, economic, and environmental challenges, guiding the development of machine learning systems with positive societal impact. Understanding these goals allows practitioners to align AI solutions with broader sustainability objectives and measure progress toward a more equitable future. Source: United Nations."><img src="./images/png/un_sdg.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sdg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <strong>Sustainable Development Goals</strong>: These 17 interconnected goals provide a global framework for addressing important social, economic, and environmental challenges, guiding the development of machine learning systems with positive societal impact. Understanding these goals allows practitioners to align AI solutions with broader sustainability objectives and measure progress toward a more equitable future. Source: United Nations.
</figcaption>
</figure>
</div>
<p>Building on this framework, machine learning systems can contribute to multiple SDGs simultaneously through their transformative capabilities <span class="citation" data-cites="taylor2022sustainable">(<a href="#ref-taylor2022sustainable" role="doc-biblioref">Taylor et al. 2022</a>)</span>:</p>
<div class="no-row-height column-margin column-container"><div id="ref-taylor2022sustainable" class="csl-entry" role="listitem">
Taylor, Michael J, Anisha Surendranath, Claire Bentley, and Jakub W Mohr. 2022. <span>“Sustainable Development Goals and AI: A Systematic Literature Review.”</span> <em>AI and Society</em> 37 (4): 1421–36. <a href="https://doi.org/10.1007/s00146-021-01331-1">https://doi.org/10.1007/s00146-021-01331-1</a>.
</div></div><ul>
<li><p><strong>Goal 1 (No Poverty) &amp; Goal 10 (Reduced Inequalities)</strong>: ML systems that improve financial inclusion through mobile banking and risk assessment for microloans.</p></li>
<li><p><strong>Goals 2, 12, &amp; 15 (Zero Hunger, Responsible Consumption, Life on Land)</strong>: Systems that optimize resource distribution, reduce waste in food supply chains, and monitor biodiversity.</p></li>
<li><p><strong>Goals 3 &amp; 5 (Good Health and Gender Equality)</strong>: ML applications that improve maternal health outcomes and access to healthcare in underserved communities.</p></li>
<li><p><strong>Goals 13 &amp; 11 (Climate Action &amp; Sustainable Cities)</strong>: Predictive systems for climate resilience and urban planning that help communities adapt to environmental changes.</p></li>
</ul>
<p>Despite this potential, deploying these systems presents unique challenges. Many regions that could benefit most from machine learning applications lack reliable electricity (Goal 7: Affordable and Clean Energy) or internet infrastructure (Goal 9: Industry, Innovation and Infrastructure). This reality forces us to rethink how we design machine learning systems for social impact.</p>
<p>Recognizing these challenges, success in advancing the SDGs through machine learning requires a holistic approach that goes beyond technical solutions. Systems must operate within local resource constraints while respecting cultural contexts and existing infrastructure limitations. This reality pushes us to fundamentally rethink system design, considering not just technological capabilities but also their sustainable integration into communities that need them most.</p>
<p>With this understanding of both opportunities and constraints, the following sections explore how to navigate these technical, infrastructural, and societal factors to create ML systems that genuinely advance sustainable development goals without creating new dependencies or deepening existing inequalities.</p>
<div id="quiz-question-sec-ai-good-global-development-perspective-8f64" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.4</strong></summary><div>
<ol type="1">
<li><p>Which of the following Sustainable Development Goals (SDGs) can be directly impacted by machine learning systems that optimize resource distribution and reduce waste in food supply chains?</p>
<ol type="a">
<li>Goal 1: No Poverty</li>
<li>Goal 13: Climate Action</li>
<li>Goal 5: Gender Equality</li>
<li>Goal 2: Zero Hunger</li>
</ol></li>
<li><p>True or False: The majority of AI research is focused on addressing basic human needs such as water, food, and health.</p></li>
<li><p>How might the lack of reliable electricity and internet infrastructure in certain regions affect the deployment of machine learning systems aimed at advancing the SDGs?</p></li>
<li><p>Order the following Sustainable Development Goals by their focus on environmental challenges: (1) Goal 7: Affordable and Clean Energy, (2) Goal 13: Climate Action, (3) Goal 15: Life on Land.</p></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-global-development-perspective-8f64" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-ai-good-engineering-challenges-d6a8" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-ai-good-engineering-challenges-d6a8">Engineering Challenges</h2>
<p>Deploying machine learning systems in social impact contexts requires navigating interconnected challenges spanning computational, networking, power, and data dimensions—challenges that intensify during production deployment and scaling.</p>
<p>To provide a foundation for understanding these challenges, <a href="#tbl-social_challenges" class="quarto-xref">Table&nbsp;1</a> summarizes the key differences in resources and requirements across development, rural, and urban contexts, while also highlighting the unique constraints encountered during scaling. This comparison provides a basis for understanding the paradoxes, dilemmas, and constraints that will be explored in subsequent sections.</p>
<div id="tbl-social_challenges" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-social_challenges-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: <strong>Deployment Resource Spectrum</strong>: Social impact applications demand careful consideration of computational constraints, ranging from microcontroller-based rural deployments to server-grade systems in urban environments; scaling these systems often necessitates aggressive model compression techniques to meet resource limitations. This table quantifies these differences, revealing the trade-offs between model complexity, accuracy, and feasibility across diverse deployment contexts.
</figcaption>
<div aria-describedby="tbl-social_challenges-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspect</th>
<th style="text-align: left;">Rural Deployment</th>
<th style="text-align: left;">Urban Deployment</th>
<th style="text-align: left;">Scaling Challenges</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Computational Resources</td>
<td style="text-align: left;">Microcontroller (ESP32: 240 MHz, ~320 KB RAM out of 520 KB total)</td>
<td style="text-align: left;">Server-grade systems (100-200 W, 32-64 GB RAM)</td>
<td style="text-align: left;">Aggressive model quantization (e.g., 50 MB to 500 KB)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Power Infrastructure</td>
<td style="text-align: left;">Solar and battery systems (10-20 W, 2000-3000 mAh battery)</td>
<td style="text-align: left;">Stable grid power</td>
<td style="text-align: left;">Optimized power usage (for deployment devices)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Network Bandwidth</td>
<td style="text-align: left;">LoRa, NB-IoT (0.3-50 kbps, 60-250 kbps)</td>
<td style="text-align: left;">High-bandwidth options</td>
<td style="text-align: left;">Protocol adjustments (LoRa, NB-IoT, Sigfox: 100-600 bps)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Data Availability</td>
<td style="text-align: left;">Sparse, heterogeneous data sources (500 KB/day from rural clinics)</td>
<td style="text-align: left;">Large volumes of standardized data (Gigabytes from urban hospitals)</td>
<td style="text-align: left;">Specialized pipelines (For privacy-sensitive data)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Model Footprint</td>
<td style="text-align: left;">Highly quantized models (≤ 1 MB)</td>
<td style="text-align: left;">Cloud/edge systems (Supporting larger models)</td>
<td style="text-align: left;">Model architecture redesign (For size, power, and bandwidth limits)</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="sec-ai-good-quantitative-optimization-2a1b" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-quantitative-optimization-2a1b">Quantitative Optimization Techniques</h3>
<p>Achieving ultra-low model sizes for social good applications requires systematic optimization pipelines that balance accuracy with resource constraints. Traditional model optimization techniques from <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong> must be adapted and intensified for extreme resource limitations encountered in underserved environments.</p>
<p>To illustrate these optimization requirements, the optimization pipeline for the PlantVillage crop disease detection system demonstrates quantitative compression trade-offs. Starting with a ResNet-50 architecture at 100 MB achieving 91% accuracy, systematic optimization reduces model size by 31× while maintaining practical effectiveness:</p>
<ul>
<li><strong>Original ResNet-50</strong>: 100 MB, 91% accuracy baseline</li>
<li><strong>8-bit quantization</strong>: 25 MB, 89% accuracy (4× compression, 2% accuracy loss)</li>
<li><strong>Structured pruning</strong>: 8 MB, 88% accuracy (12× compression, 3% accuracy loss)</li>
<li><strong>Knowledge distillation</strong>: 3.2 MB, 87% accuracy (31× compression, 4% accuracy loss)</li>
</ul>
<p>These compression ratios enable deployment on resource-constrained devices while preserving diagnostic capabilities essential for rural farmers. The final 3.2 MB model requires only 50-80 milliseconds for inference on an ESP32 microcontroller, enabling real-time crop disease detection in off-grid agricultural environments.</p>
<p><strong>Power Consumption Analysis</strong></p>
<p>Beyond model size optimization, power budget constraints dominate system design in off-grid deployments. Neural network inference consumes 0.1-1 millijoule per operation, with a 1 million parameter model requiring 1-10 millijoules per inference. Solar charging in rural areas typically provides 5-20 watt-hours daily, accounting for seasonal variations and weather patterns. This energy budget enables 20,000-200,000 inferences per day, assuming 10-20% power conversion losses and accounting for battery degradation of 30-50% over typical 2-year deployment cycles.</p>
<p><strong>Energy Budget Hierarchy</strong></p>
<p>To manage these power constraints effectively, edge device power consumption follows a strict hierarchy based on computational complexity and deployment requirements:</p>
<ul>
<li><strong>TinyML sensors</strong>: &lt;1mW average power consumption, enabling multi-year battery operation for environmental monitoring and wildlife tracking applications</li>
<li><strong>Mobile edge devices</strong>: 50-150mW power budget (equivalent to smartphone flashlight), suitable for daily solar charging cycles in most geographic locations</li>
<li><strong>Regional processing nodes</strong>: 10W power requirements, necessitating grid connection or dedicated generator systems for consistent operation</li>
<li><strong>Cloud endpoints</strong>: kilowatt-scale power consumption, requiring datacenter infrastructure with reliable electrical grid connectivity</li>
</ul>
<p>At the extreme end of this hierarchy, ultra-low power wildlife monitoring systems demonstrate the most demanding optimization requirements. Operating at &lt;1mW average power consumption with 5-year battery life expectations, these deployments require specialized low-power microcontrollers and duty-cycled operation. Environmental sensors targeting decade-long operation push power requirements down to nanowatt-scale computation, utilizing energy harvesting from temperature differentials, vibrations, or ambient electromagnetic radiation.</p>
</section>
<section id="sec-ai-good-resource-paradox-dd1d" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-resource-paradox-dd1d">Resource Paradox</h3>
<p>Deploying machine learning systems in social impact contexts reveals a fundamental resource paradox<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> that shapes every aspect of system design. While areas with the greatest needs could benefit most from machine learning capabilities, they often lack the basic infrastructure required for traditional deployments.</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;<strong>Social Good Resource Paradox</strong>: Resource-constrained environments need the most help but have the least infrastructure to deploy solutions. For example, rural sub-Saharan Africa has 60% of global arable land but only 4% of worldwide internet connectivity. This paradox forces engineers to achieve 90%+ model compression (from 50MB to 500KB) while maintaining effectiveness, a challenge absent in commercial deployments with abundant resources.</p></div></div><p>This paradox becomes evident in the stark computational and power requirements of machine learning systems, as quantified in <a href="#tbl-social_challenges" class="quarto-xref">Table&nbsp;1</a>. A typical cloud deployment might utilize servers consuming 100-200 W of power with multiple CPU cores and 32-64 GB of RAM. However, rural deployments must often operate on single-board computers drawing 5 W or microcontrollers consuming mere milliwatts, with RAM measured in kilobytes rather than gigabytes. These extreme resource constraints require innovative approaches to model training and inference, including techniques from <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong> where models must be adapted and optimized directly on resource-constrained devices.</p>
<p>Compounding these computational constraints, network infrastructure limitations further constrain system design. Urban environments offer high-bandwidth options like fiber (100+ Mbps) and 5G networks (1-10 Gbps) capable of supporting real-time multimedia applications. Rural deployments must instead rely on low-power wide-area network technologies such as LoRa<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> or NB-IoT with bandwidth constraints of 50 kbps—approximately three orders of magnitude slower than typical broadband connections. These severe bandwidth limitations require careful optimization of data transmission protocols and payload sizes.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;<strong>LoRa Technology</strong>: Long Range (LoRa) allows IoT devices to communicate over 15+ kilometers with battery life exceeding 10 years. Operating in unlicensed spectrum bands, LoRa networks cost $1-5 per device annually versus $15-50 for cellular. This makes LoRa ideal for agricultural sensors monitoring soil moisture across vast farms or environmental sensors in remote conservation areas. Over 140 countries have deployed LoRaWAN networks, connecting 200+ million devices worldwide for social good applications.</p></div></div><p>Adding to these connectivity challenges, power infrastructure presents additional constraints. While urban systems can rely on stable grid power, rural deployments often depend on solar charging and battery systems. A typical solar-powered system might generate 10-20&nbsp;W during peak sunlight hours, requiring careful power budgeting across all system components. Battery capacity limitations, often 2000-3000 mAh, mean systems must optimize every aspect of operation, from sensor sampling rates to model inference frequency.</p>
</section>
<section id="sec-ai-good-data-dilemma-0d49" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-data-dilemma-0d49">Data Dilemma</h3>
<p>The resource paradox extends beyond computational horsepower to encompass fundamental data challenges that differ significantly from commercial deployments. Where commercial systems often work with standardized datasets containing millions of examples, social impact projects must build robust systems with limited, heterogeneous data sources.</p>
<p>Healthcare deployments illustrate these data constraints most clearly, revealing stark data disparities between deployment contexts. Rural clinics generate 50-100 patient records daily (≈500 KB), mixing structured vital signs with unstructured handwritten notes requiring specialized preprocessing, while urban hospitals produce gigabytes of standardized electronic health records. Even an X-ray or MRI scan is measured in megabytes or more, underscoring the vast disparity in data scales between rural and urban healthcare facilities.</p>
<p>Network limitations further constrain data collection and processing. Agricultural sensor networks, operating on limited power budgets, might transmit only 100-200 bytes per reading. With LoRa bandwidth constraints of 50 kbps, these systems often limit transmission frequency to once per hour. A network of 1000 sensors thus generates only 4-5 MB of data per day, requiring models to learn from sparse temporal data. For perspective, streaming a single minute of video on Netflix can consume several megabytes, highlighting the disparity in data volumes between industrial IoT networks and everyday internet usage.</p>
<p>Privacy considerations add another layer of complexity. Protecting sensitive information while operating within hardware constraints requires careful system design, applying principles from <strong><a href="../core/privacy_security/privacy_security.html#sec-security-privacy">Chapter 15: Security & Privacy</a></strong> adapted for resource-constrained environments. Implementing privacy-preserving techniques on devices with 512&nbsp;KB RAM means partitioning models and data carefully. Local processing must balance privacy requirements against hardware limitations, often restricting model sizes to under 1 MB. Supporting multiple regional variants of these models can quickly consume the limited storage available on low-cost devices, typically 2-4 MB total.</p>
</section>
<section id="sec-ai-good-scale-challenge-076d" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-scale-challenge-076d">Scale Challenge</h3>
<p>Moving from data constraints to deployment realities, scaling machine learning systems from prototype to production deployment introduces core resource constraints that necessitate architectural redesign. Development environments provide computational resources that mask many real-world limitations. A typical development platform, such as a Raspberry Pi 4<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>, offers substantial computing power with its 1.5 GHz processor and 4 GB RAM. These resources allow rapid prototyping and testing of machine learning models without immediate concern for optimization.</p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;<strong>Raspberry Pi Development Advantages</strong>: Despite costing only $35-75, the Raspberry Pi 4 provides 1000× more RAM and 10× faster processing than typical production IoT devices. This substantial resource overhead enables developers to prototype using full Python frameworks like TensorFlow or PyTorch before optimizing for resource-constrained deployment. However, the Pi’s 3-8W power consumption versus production devices’ 0.1W creates a 30-80× power gap that requires significant optimization during transition to real-world deployment.</p></div><div id="fn19"><p><sup>19</sup>&nbsp;<strong>ESP32 Capabilities</strong>: Despite its constraints, the ESP32 costs only $2-5, consumes 30-150mA during operation, and includes Wi-Fi, Bluetooth, and various sensors. This makes it ideal for IoT deployments in social impact applications. For comparison, a smartphone processor is 100× more powerful but costs 50× more. The ESP32’s limitations—RAM smaller than a single Instagram photo—force engineers to develop ingenious optimization techniques that often benefit all platforms.</p></div></div><p>However, production deployments reveal stark resource limitations that contrast sharply with development environments. When scaling to thousands of devices, cost and power constraints often mandate the use of microcontroller units like the ESP32<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>, a widely used microcontroller unit from Espressif Systems, with its 240 MHz processor and 520 KB total SRAM with 320-450 KB available depending on the variant. This dramatic reduction in computational resources demands fundamental changes in system architecture. Models must be redesigned, optimization techniques such as quantization and pruning applied (detailed in <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong>), and inference strategies reconsidered.</p>
<p>Beyond computational scaling, network infrastructure constraints significantly influence system architecture at scale. Different deployment contexts necessitate different communication protocols, each with distinct operational parameters. This heterogeneity in network infrastructure requires systems to maintain consistent performance across varying bandwidth and latency conditions. As deployments scale across regions, system architectures must accommodate seamless transitions between network technologies while preserving functionality.</p>
<p>The transformation from development to scaled deployment presents consistent patterns across application domains. Environmental monitoring systems exemplify these scaling requirements. A typical forest monitoring system might begin with a 50 MB computer vision model running on a development platform. Scaling to widespread deployment necessitates reducing the model to approximately 500 KB through quantization and architectural optimization, enabling operation on distributed sensor nodes. This reduction in model footprint must preserve detection accuracy while operating within strict power constraints of 1-2 W. Similar architectural transformations occur in agricultural monitoring systems and educational platforms, where models must be optimized for deployment across thousands of resource-constrained devices while maintaining system efficacy.</p>
</section>
<section id="sec-ai-good-sustainability-challenge-0218" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-sustainability-challenge-0218">Sustainability Challenge</h3>
<p>Maintaining machine learning systems in resource-constrained environments presents distinct challenges that extend beyond initial deployment considerations. These challenges encompass system longevity, environmental impact, community capacity, and financial viability—factors that ultimately determine the long-term success of social impact initiatives.</p>
<p>System longevity requires careful consideration of hardware durability and maintainability. Environmental factors such as temperature variations (typically -20°C to 50°C in rural deployments), humidity (often 80-95% in tropical regions), and dust exposure significantly impact component lifetime. These conditions necessitate robust hardware selection and protective measures that balance durability against cost constraints. For instance, solar-powered agricultural monitoring systems must maintain consistent operation despite seasonal variations in solar irradiance, typically ranging from 3-7 kWh/m²/day depending on geographical location and weather patterns.</p>
<p>Environmental sustainability introduces additional complexity in system design. The environmental footprint of deployed systems includes not only operational power consumption but also the impact of manufacturing, transportation, and end-of-life disposal, which aligns with principles discussed in <strong><a href="../core/sustainable_ai/sustainable_ai.html#sec-sustainable-ai">Chapter 17: Sustainable AI</a></strong>. A typical deployment of 1000 sensor nodes requires consideration of approximately 500 kg of electronic components, including sensors, processing units, and power systems. Sustainable design principles must address both immediate operational requirements and long-term environmental impact through careful component selection and end-of-life planning.</p>
<p>Community capacity building represents another important dimension of sustainability. Systems must be maintainable by local technicians with varying levels of expertise. This requirement influences architectural decisions, from component selection to system modularity. Documentation must be comprehensive yet accessible, typically requiring materials in multiple languages and formats. Training programs must bridge knowledge gaps while building local technical capacity, ensuring that communities can independently maintain and adapt systems as needs evolve. These considerations extend traditional MLOps practices from <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong> to encompass community-driven deployment and maintenance workflows.</p>
<p>Financial sustainability often determines system longevity. Operating costs, including maintenance, replacement parts, and network connectivity, must align with local economic conditions. A sustainable deployment might target operational costs below 5% of local monthly income per beneficiary. This constraint influences every aspect of system design, from hardware selection to maintenance schedules, requiring careful optimization of both capital and operational expenditures.</p>
</section>
<section id="sec-ai-good-system-resilience-4c3e" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-system-resilience-4c3e">System Resilience and Failure Recovery</h3>
<p>Social good deployments operate in environments where system failures can have life-threatening consequences. Unlike commercial systems where downtime results in revenue loss, healthcare monitoring failures can delay critical interventions, and agricultural sensor failures can result in crop losses affecting entire communities. This reality requires robust failure recovery patterns that ensure graceful degradation and rapid restoration of essential services.</p>
<p><strong>Common Failure Modes and Quantified Impact</strong></p>
<p>Analysis of 50+ social good deployments reveals consistent failure patterns with quantifiable downtime contributions:</p>
<ul>
<li><p><strong>Hardware failures (40% of downtime)</strong>: Sensor battery depletion, solar panel degradation, and temperature-related component failures dominate system outages. Recovery strategies include predictive maintenance algorithms monitoring battery voltage trends, redundant sensor configurations, and pre-positioned spare parts in regional maintenance hubs.</p></li>
<li><p><strong>Network failures (35% of downtime)</strong>: Intermittent connectivity loss and infrastructure damage during weather events create extended isolation periods. Recovery requires local data caching with 72-hour minimum capacity, offline operation modes, and automatic reconnection protocols optimized for low-bandwidth networks.</p></li>
<li><p><strong>Data quality failures (25% of downtime)</strong>: Sensor calibration drift and environmental contamination gradually degrade system accuracy until manual intervention becomes necessary. Recovery involves automatic recalibration routines, anomaly detection thresholds, and graceful degradation to simpler models when quality metrics exceed tolerance levels.</p></li>
</ul>
<p><strong>Graceful Degradation Architecture</strong></p>
<p>Resilient systems implement layered fallback mechanisms that preserve essential functionality under varying failure conditions. A healthcare monitoring system demonstrates this approach:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResilientHealthcareAI:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> diagnose(<span class="va">self</span>, symptoms, connectivity_status, power_level):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Adaptive model selection based on system status</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> connectivity_status <span class="op">==</span> <span class="st">"full"</span> <span class="kw">and</span> power_level <span class="op">&gt;</span> <span class="dv">70</span>:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.cloud_ai_diagnosis(symptoms)  <span class="co"># Full accuracy</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> connectivity_status <span class="op">==</span> <span class="st">"limited"</span> <span class="kw">and</span> power_level <span class="op">&gt;</span> <span class="dv">30</span>:</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.edge_ai_diagnosis(symptoms)   <span class="co"># 90% accuracy</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> power_level <span class="op">&gt;</span> <span class="dv">10</span>:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.rule_based_triage(symptoms)   <span class="co"># Basic screening</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.emergency_protocol(symptoms)  <span class="co"># Critical only</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fallback_to_human_expert(<span class="va">self</span>, case, urgency_level):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Queue prioritization for human review</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> urgency_level <span class="op">==</span> <span class="st">"critical"</span>:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.satellite_emergency_transmission(case)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.priority_queue.add(case, next_connectivity_window)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Flagged for expert review when connection restored"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Distributed Failure Recovery</strong></p>
<p>Multi-node deployments require coordinated failure recovery that maintains system-wide functionality despite individual node failures. Agricultural monitoring networks demonstrate Byzantine fault tolerance adapted for resource constraints:</p>
<ul>
<li><strong>Consensus mechanisms</strong>: Modified Raft protocols operating with 10-second heartbeat intervals accommodate network latency while detecting failures within 30-second windows</li>
<li><strong>Data redundancy</strong>: Geographic replication across 3-5 nodes ensures crop monitoring continues despite individual sensor failures</li>
<li><strong>Coordinated recovery</strong>: Regional nodes orchestrate simultaneous software updates and configuration changes, minimizing deployment-wide vulnerability windows</li>
</ul>
<p><strong>Community-Based Maintenance Integration</strong></p>
<p>Successful social good systems integrate local communities into maintenance workflows, reducing dependence on external technical support. Training programs create local technical capacity while providing economic opportunities:</p>
<ul>
<li><strong>Diagnostic protocols</strong>: Community health workers receive standardized procedures for identifying and resolving 80% of common failures</li>
<li><strong>Spare parts management</strong>: Local inventory systems maintain critical components with 2-week supply buffers based on historical failure rates</li>
<li><strong>Escalation procedures</strong>: Clear communication channels connect local technicians with remote experts for complex failures requiring specialized knowledge</li>
</ul>
<p>This community integration approach reduces average repair time from 7-14 days (external technician dispatch) to 2-4 hours (local response), dramatically improving system availability in remote deployments.</p>
<p>While practical design patterns provide engineering frameworks for resource-constrained deployments, understanding the fundamental theoretical limitations reveals why these specialized approaches are necessary and how they can be optimized.</p>
<div id="quiz-question-sec-ai-good-engineering-challenges-d6a8" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.5</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the primary challenge of deploying ML systems in rural environments compared to urban environments?</p>
<ol type="a">
<li>Higher computational resources in rural areas</li>
<li>Stable power infrastructure in rural areas</li>
<li>Abundant standardized data in rural areas</li>
<li>Limited network bandwidth and data availability in rural areas</li>
</ol></li>
<li><p>Explain how the ‘Social Good Resource Paradox’ influences the design of ML systems for rural deployments.</p></li>
<li><p>Order the following deployment challenges from most to least affected by network bandwidth limitations: (1) Rural Deployment, (2) Urban Deployment, (3) Scaling Challenges.</p></li>
<li><p>In a production system, which optimization technique is most critical when scaling ML deployments to thousands of devices?</p>
<ol type="a">
<li>Increasing model complexity</li>
<li>Aggressive model quantization</li>
<li>Enhancing data collection frequency</li>
<li>Utilizing high-power computing resources</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-engineering-challenges-d6a8" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-ai-good-theoretical-foundations-8a4c" class="level2">
<h2 class="anchored" data-anchor-id="sec-ai-good-theoretical-foundations-8a4c">Theoretical Foundations of Resource-Constrained Learning</h2>
<p>Social good applications reveal fundamental limitations in current machine learning approaches, where resource constraints expose gaps between theoretical learning requirements and practical deployment realities. Understanding these theoretical foundations provides the scientific basis for engineering decisions in resource-constrained environments.</p>
<section id="sec-ai-good-sample-complexity-1e5d" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-sample-complexity-1e5d">Sample Complexity in Low-Resource Environments</h3>
<p>Traditional supervised learning assumes abundant labeled data, typically requiring 1000+ examples per class to achieve acceptable generalization performance. Resource-constrained environments challenge this assumption, often providing fewer than 100 examples per class while demanding human-level learning efficiency.</p>
<p><strong>Few-Shot Learning Requirements</strong></p>
<p>This challenge becomes concrete in applications like agricultural disease detection. While commercial crop monitoring systems train on millions of labeled images from controlled environments, rural deployments must identify diseases using fewer than 50 examples per disease class. This 20× reduction in training data requires fundamentally different learning approaches that leverage structural similarities across disease types and transfer knowledge from related domains.</p>
<p>The theoretical gap becomes apparent when comparing learning curves. Traditional deep learning approaches require exponential data scaling to achieve linear improvements in accuracy, following power laws where accuracy ∝ (data_size)^α with α typically 0.1-0.3. Resource-constrained environments require learning algorithms that achieve α ≥ 0.7, approaching human-level sample efficiency where single examples can generalize to entire categories.</p>
<p><strong>Information-Theoretic Bounds</strong></p>
<p>To quantify these limitations, PAC-learning theory provides bounds on minimum sample complexity for specific learning tasks. For social good applications, these bounds reveal fundamental trade-offs between data availability, computational resources, and generalization performance. Consider disease detection with k diseases, d-dimensional feature space, and target accuracy ε:</p>
<ul>
<li><strong>Traditional bound</strong>: O(k × d / ε²) samples required for reliable classification</li>
<li><strong>Resource-constrained reality</strong>: Often &lt;50 samples per class available</li>
<li><strong>Gap magnitude</strong>: 100-1000× difference between theory and practice</li>
</ul>
<p>Bridging this gap necessitates learning approaches that exploit additional structure in the problem domain, such as:</p>
<ul>
<li><strong>Prior knowledge integration</strong>: Incorporating medical expertise to constrain hypothesis space</li>
<li><strong>Multi-task learning</strong>: Sharing representations across related diseases</li>
<li><strong>Active learning</strong>: Strategically selecting informative examples for labeling</li>
</ul>
</section>
<section id="sec-ai-good-self-supervised-foundations-3b7e" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-self-supervised-foundations-3b7e">Self-Supervised Learning Foundations</h3>
<p>Building on these sample complexity challenges, resource-constrained environments often contain abundant unlabeled data despite scarce labeled examples. Rural health clinics generate thousands of diagnostic images daily, but expert annotations remain limited. Self-supervised learning provides theoretical frameworks for extracting useful representations from this unlabeled data.</p>
<p><strong>Contrastive Learning Theory</strong></p>
<p>Contrastive approaches learn representations by distinguishing between similar and dissimilar examples without requiring explicit labels. For crop monitoring applications:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SelfSupervisedCropMonitoring:</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> pretrain_on_unlabeled_images(<span class="va">self</span>, crop_images):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use contrastive learning on abundant unlabeled imagery</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Creates representations that separate healthy/diseased crops</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.simclr_pretraining(crop_images)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> finetune_with_few_labels(<span class="va">self</span>, labeled_diseases):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Leverage pretrained representations for rapid adaptation</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Achieves 87% accuracy with &lt;50 examples per disease class</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.few_shot_adaptation(labeled_diseases)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Theoretical analysis shows that contrastive pretraining reduces sample complexity by factors of 5-15× compared to training from scratch. This reduction comes from learning generalizable features that transfer across related tasks within the same domain.</p>
<p><strong>Mutual Information Bounds</strong></p>
<p>To understand these improvements theoretically, information theory provides fundamental limits on how much unlabeled data can compensate for limited labels. The mutual information I(X;Y) between inputs X and labels Y bounds the maximum achievable performance with any learning algorithm. Self-supervised pretraining increases effective mutual information by learning representations that capture task-relevant structure in the input distribution.</p>
<p>For social good applications, this suggests prioritizing domains where: - Unlabeled data is abundant (healthcare imagery, agricultural sensors) - Tasks share common underlying structure (related diseases, similar environmental conditions) - Domain expertise can guide representation learning (medical knowledge, agricultural practices)</p>
</section>
<section id="sec-ai-good-optimization-theory-4f8e" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-optimization-theory-4f8e">Resource-Constrained Optimization Theory</h3>
<p>Moving beyond data availability to optimization challenges, traditional optimization theory assumes abundant computational resources and focuses on convergence rates to global optima. Resource-constrained environments require optimization under strict memory, compute, and energy budgets that fundamentally change theoretical analysis.</p>
<p><strong>Communication-Constrained Learning</strong></p>
<p>A primary constraint in these environments involves distributed learning, where communication bottlenecks dominate computational costs. Consider federated learning with n edge devices, each with local dataset Di and model parameters θi:</p>
<ul>
<li><strong>Communication cost</strong>: O(n × model_size) per round</li>
<li><strong>Computation cost</strong>: O(local_iterations × gradient_computation)</li>
<li><strong>Typical constraint</strong>: Communication cost &gt;&gt; Computation cost</li>
</ul>
<p>This inversion of traditional assumptions requires new theoretical frameworks where communication efficiency becomes the primary optimization objective. Gradient compression, sparse updates, and local model personalization emerge as theoretically motivated solutions rather than engineering optimizations.</p>
<p><strong>Energy-Aware Learning Theory</strong></p>
<p>Battery-powered deployments introduce energy constraints absent from traditional learning theory. Each model evaluation consumes measurable energy, creating trade-offs between accuracy and operational lifetime. Theoretical frameworks must incorporate energy budgets as first-class constraints:</p>
<ul>
<li><strong>Energy per inference</strong>: E_inf = α × model_size + β × computation_time</li>
<li><strong>Battery lifetime</strong>: T_battery = E_total / (inference_rate × E_inf + E_idle)</li>
<li><strong>Optimization objective</strong>: Maximize accuracy subject to T_battery ≥ deployment_requirements</li>
</ul>
<p>This leads to energy-aware learning algorithms that explicitly trade accuracy for longevity, using techniques like adaptive model sizing, duty cycling, and hierarchical processing to operate within energy budgets.</p>
<p>These theoretical foundations inform practical system design decisions throughout the chapter, providing scientific justification for architectural choices that might otherwise appear ad-hoc. Understanding these principles enables engineers to make informed trade-offs between competing objectives while respecting fundamental limits imposed by resource constraints.</p>
</section>
</section>
<section id="sec-ai-good-design-patterns-cf75" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-ai-good-design-patterns-cf75">Design Patterns</h2>
<p>The challenges of deploying machine learning systems in resource-constrained environments reflect core constraints that have shaped system architecture for decades. Computing systems across domains have developed robust solutions to operate within limited computational resources, unreliable networks, and power restrictions. These solutions, formalized as “design patterns,” represent reusable architectural approaches to common deployment challenges.</p>
<p>Building on this foundation, traditional system design patterns from distributed systems, embedded computing, and mobile applications provide valuable frameworks for machine learning deployments. The Hierarchical Processing Pattern, for instance, structures operations across system tiers to optimize resource usage. Progressive enhancement ensures graceful degradation under varying conditions, while the Distributed Knowledge Pattern sharing allows consistency across multiple data sources. These established patterns can be adapted to address the unique requirements of machine learning systems, particularly regarding model deployment, training procedures, and inference operations.</p>
<section id="sec-ai-good-hierarchical-processing-3405" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-hierarchical-processing-3405">Hierarchical Processing</h3>
<p>The most fundamental of these patterns, the Hierarchical Processing Pattern, organizes systems into tiers that share responsibilities based on their available resources and capabilities. Like a business with local branches, regional offices, and headquarters, this pattern segments workloads across edge, regional, and cloud tiers. Each tier leverages its computational capabilities: edge devices for data collection and local processing, regional nodes for aggregation and intermediate computations, and cloud infrastructure for advanced analytics and model training.</p>
<p>As illustrated in <a href="#fig-pattern-heirarchical" class="quarto-xref">Figure&nbsp;3</a>, this pattern establishes clear interaction flows across these tiers. Starting at the edge tier with data collection, information flows through regional aggregation and processing, culminating in cloud-based advanced analysis. Bidirectional feedback loops allow model updates to flow back through the hierarchy, ensuring continuous system improvement.</p>
<div id="fig-pattern-heirarchical" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pattern-heirarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="4390b4cb7285bc5e3295e5d358e66bd21c20573e.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Tiered Dataflow Architecture: Distributed machine learning systems use a hierarchical architecture—edge, regional, and cloud—to process data closer to its source, aggregate insights, and perform advanced analytics with continuous feedback for model refinement. Regional nodes consolidate data from edge devices, reducing communication costs and enabling scalable, efficient analysis across the entire system."><img src="ai_for_good_files/mediabag/4390b4cb7285bc5e3295e5d358e66bd21c20573e.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pattern-heirarchical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>Tiered Dataflow Architecture</strong>: Distributed machine learning systems use a hierarchical architecture—edge, regional, and cloud—to process data closer to its source, aggregate insights, and perform advanced analytics with continuous feedback for model refinement. Regional nodes consolidate data from edge devices, reducing communication costs and enabling scalable, efficient analysis across the entire system.
</figcaption>
</figure>
</div>
<p>This architecture excels in environments with varying infrastructure quality, such as applications spanning urban and rural regions. Edge devices maintain important functionalities during network or power disruptions by performing important computations locally while queuing operations that require higher-tier resources. When connectivity returns, the system scales operations across available infrastructure tiers.</p>
<p>In machine learning applications, this pattern requires careful consideration of resource allocation and data flow. Edge devices must balance model inference accuracy against computational constraints, while regional nodes facilitate data aggregation and model personalization. Cloud infrastructure provides the computational power needed for comprehensive analytics and model retraining. This distribution demands thoughtful optimization of model architectures, training procedures, and update mechanisms throughout the hierarchy.</p>
<p>For example, in crop disease detection: Edge sensors (smartphone apps) run lightweight 500KB models to detect obvious diseases locally, Regional aggregators collect photos from 100+ farms to identify emerging threats, and Cloud infrastructure retrains models using global disease patterns and weather data. This allows immediate farmer alerts while building smarter models over time.</p>
<section id="sec-ai-good-googles-flood-forecasting-70fb" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-googles-flood-forecasting-70fb">Google’s Flood Forecasting</h4>
<p>Google’s <a href="https://blog.google/technology/ai/google-ai-global-flood-forecasting/">Flood Forecasting Initiative</a> demonstrates how the Hierarchical Processing Pattern supports large-scale environmental monitoring. Edge devices along river networks monitor water levels, performing basic anomaly detection even without cloud connectivity. Regional centers aggregate this data and ensure localized decision-making, while the cloud tier integrates inputs from multiple regions for advanced flood prediction and system-wide updates. This tiered approach balances local autonomy with centralized intelligence, ensuring functionality across diverse infrastructure conditions. The technical implementation of such hierarchical systems draws on specialized optimization techniques: edge computing strategies including model compression and quantization are detailed in <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong>, distributed system coordination patterns are covered in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>, hardware selection for resource-constrained environments is addressed in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>, and sustainable deployment considerations are explored in <strong><a href="../core/sustainable_ai/sustainable_ai.html#sec-sustainable-ai">Chapter 17: Sustainable AI</a></strong>.</p>
<p>At the edge tier, the system likely employs water-level sensors and local processing units distributed along river networks. These devices perform two important functions: continuous monitoring of water levels at regular intervals (e.g., every 15 minutes) and preliminary time-series analysis to detect significant changes. Constrained by the tight power envelope (a few watts of power), edge devices utilize quantized models for anomaly detection, enabling low-power operation and minimizing the volume of data transmitted to higher tiers. This localized processing ensures that key monitoring tasks can continue independently of network connectivity.</p>
<p>The regional tier operates at district-level processing centers, each responsible for managing data from hundreds of sensors across its jurisdiction. At this tier, more sophisticated neural network models are employed to combine sensor data with additional contextual information, such as local terrain features and historical flood patterns. This tier reduces the data volume transmitted to the cloud by aggregating and extracting meaningful features while maintaining important decision-making capabilities during network disruptions. By operating independently when required, the regional tier enhances system resilience and ensures localized monitoring and alerts remain functional.</p>
<p>At the cloud tier, the system integrates data from regional centers with external sources such as satellite imagery and weather data to implement the full machine learning pipeline. This includes training and running advanced flood prediction models, generating inundation maps, and distributing predictions to stakeholders. The cloud tier provides the computational resources needed for large-scale analysis and system-wide updates. However, the hierarchical structure ensures that important monitoring and alerting functions can continue autonomously at the edge and regional tiers, even when cloud connectivity is unavailable.</p>
<p>This implementation reveals several key principles of successful Hierarchical Processing Pattern deployments. First, the careful segmentation of ML tasks across tiers allows graceful degradation. Each tier maintains important functionality even when isolated. Secondly, the progressive enhancement of capabilities as higher tiers become available demonstrates how systems can adapt to varying resource availability. Finally, the bidirectional flow of information, where sensor data moves upward and model updates flow downward, creates a robust feedback loop that improves system performance over time. These principles extend beyond flood forecasting to inform hierarchical ML deployments across various social impact domains.</p>
</section>
<section id="sec-ai-good-structure-c29a" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-structure-c29a">Structure</h4>
<p>The Hierarchical Processing Pattern implements specific architectural components and relationships that allow its distributed operation. Understanding these structural elements is important for effective implementation across different deployment scenarios.</p>
<p>The edge tier’s architecture centers on resource-aware components that optimize local processing capabilities. At the hardware level, data acquisition modules implement adaptive sampling rates, typically ranging from 1 Hz to 0.01 Hz, adjusting dynamically based on power availability. Local storage buffers, usually 1-4 MB, manage data during network interruptions through circular buffer implementations. The processing architecture incorporates lightweight inference engines specifically optimized for quantized models, working alongside state management systems that continuously track device health and resource utilization. Communication modules implement store-and-forward protocols designed for unreliable networks, ensuring data integrity during intermittent connectivity.</p>
<p>The regional tier implements aggregation and coordination structures that allow distributed decision-making. Data fusion engines are the core of this tier, combining multiple edge data streams while accounting for temporal and spatial relationships. Distributed databases, typically spanning 50-100 GB, support eventual consistency models to maintain data coherence across nodes. The tier’s architecture includes load balancing systems that dynamically distribute processing tasks based on available computational resources and network conditions. Failover mechanisms ensure continuous operation during node failures, while model serving infrastructure supports multiple model versions to accommodate varying edge device capabilities. Inter-region synchronization protocols manage data consistency across geographic boundaries.</p>
<p>The cloud tier provides the architectural foundation for system-wide operations through sophisticated distributed systems. Training infrastructure supports parallel model updates across multiple compute clusters, while version control systems manage model lineage and deployment histories. High-throughput data pipelines process incoming data streams from all regional nodes, implementing automated quality control and validation mechanisms. The architecture includes robust security frameworks that manage authentication and authorization across all tiers while maintaining audit trails of system access and modifications. Global state management systems track the health and performance of the entire deployment, enabling proactive resource allocation and system optimization.</p>
<p>The Hierarchical Processing Pattern’s structure allows sophisticated management of resources and responsibilities across tiers. This architectural approach ensures that systems can maintain important operations under varying conditions while efficiently utilizing available resources at each level of the hierarchy.</p>
</section>
<section id="sec-ai-good-modern-adaptations-e458" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-modern-adaptations-e458">Modern Adaptations</h4>
<p>Advancements in computational efficiency, model design, and distributed systems have transformed the traditional Hierarchical Processing Pattern. While maintaining its core principles, the pattern has evolved to accommodate new technologies and methodologies that allow more complex workloads and dynamic resource allocation. These innovations have particularly impacted how the different tiers interact and share responsibilities, creating more flexible and capable deployments across diverse environments.</p>
<p>One of the most notable transformations has occurred at the edge tier. Historically constrained to basic operations such as data collection and simple preprocessing, edge devices now perform sophisticated processing tasks that were previously exclusive to the cloud. This shift has been driven by two important developments: efficient model architectures and hardware acceleration. Techniques such as model compression, pruning, and quantization have dramatically reduced the size and computational requirements of neural networks, allowing even resource-constrained devices to perform inference tasks with reasonable accuracy. Advances in specialized hardware, such as edge AI accelerators and low-power GPUs, have further enhanced the computational capabilities of edge devices. As a result, tasks like image recognition or anomaly detection that once required significant cloud resources can now be executed locally on low-power microcontrollers.</p>
<p>The regional tier has also evolved beyond its traditional role of data aggregation. Modern regional nodes use techniques such as federated learning, where multiple devices collaboratively improve a shared model without transferring raw data to a central location. This approach not only enhances data privacy but also reduces bandwidth requirements. Regional tiers are increasingly used to adapt global models to local conditions, enabling more accurate and context-aware decision-making for specific deployment environments. This adaptability makes the regional tier an indispensable component for systems operating in diverse or resource-variable settings.</p>
<p>The relationship between the tiers has become more fluid and dynamic with these advancements. As edge and regional capabilities have expanded, the distribution of tasks across tiers is now determined by factors such as real-time resource availability, network conditions, and application requirements. For instance, during periods of low connectivity, edge and regional tiers can temporarily take on additional responsibilities to ensure important functionality, while seamlessly offloading tasks to the cloud when resources and connectivity improve. This dynamic allocation preserves the hierarchical structure’s inherent benefits, including scalability, resilience, and efficiency, while enabling greater adaptability to changing conditions.</p>
<p>These adaptations indicate future developments in Hierarchical Processing Pattern systems. As edge computing capabilities continue to advance and new distributed learning approaches emerge, the boundaries between tiers will likely become increasingly dynamic. This evolution suggests a future where hierarchical systems can automatically optimize their structure based on deployment context, resource availability, and application requirements, while maintaining the pattern’s core benefits of scalability, resilience, and efficiency.</p>
</section>
<section id="sec-ai-good-system-implications-58bd" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-system-implications-58bd">System Implications</h4>
<p>While the Hierarchical Processing Pattern was originally designed for general-purpose distributed systems, its application to machine learning introduces unique considerations that significantly influence system design and operation. Machine learning systems differ from traditional systems in their heavy reliance on data flows, computationally intensive tasks, and the dynamic nature of model updates and inference processes. These additional factors introduce both challenges and opportunities in adapting the Hierarchical Processing Pattern to meet the needs of machine learning deployments.</p>
<p>One of the most significant implications for machine learning is the need to manage dynamic model behavior across tiers. Unlike static systems, ML models require regular updates to adapt to new data distributions, prevent model drift, and maintain accuracy. The hierarchical structure inherently supports this requirement by allowing the cloud tier to handle centralized training and model updates while propagating refined models to regional and edge tiers. However, this introduces challenges in synchronization, as edge and regional tiers must continue operating with older model versions when updates are delayed due to connectivity issues. Designing robust versioning systems and ensuring seamless transitions between model updates is important to the success of such systems.</p>
<p>Data flows are another area where machine learning systems impose unique demands. Unlike traditional hierarchical systems, ML systems must handle large volumes of data across tiers, ranging from raw inputs at the edge to aggregated and preprocessed datasets at regional and cloud tiers. Each tier must be optimized for the specific data-processing tasks it performs. For instance, edge devices often filter or preprocess raw data to reduce transmission overhead while retaining information important for inference. Regional tiers aggregate these inputs, performing intermediate-level analysis or feature extraction to support downstream tasks. This multistage data pipeline not only reduces bandwidth requirements but also ensures that each tier contributes meaningfully to the overall ML workflow.</p>
<p>The Hierarchical Processing Pattern also allows adaptive inference, a key consideration for deploying ML models across environments with varying computational resources. By leveraging the computational capabilities of each tier, systems can dynamically distribute inference tasks to balance latency, energy consumption, and accuracy. For example, an edge device might handle basic anomaly detection to ensure real-time responses, while more sophisticated inference tasks are offloaded to the cloud when resources and connectivity allow. This dynamic distribution is important for resource-constrained environments, where energy efficiency and responsiveness are paramount.</p>
<p>Hardware advancements have further shaped the application of the Hierarchical Processing Pattern to machine learning. The proliferation of specialized edge hardware, such as AI accelerators and low-power GPUs, has allowed edge devices to handle increasingly complex ML tasks, narrowing the performance gap between tiers. Regional tiers have similarly benefited from innovations such as federated learning, where models are collaboratively improved across devices without requiring centralized data collection. These advancements enhance the autonomy of lower tiers, reducing the dependency on cloud connectivity and enabling systems to function effectively in decentralized environments.</p>
<p>Finally, machine learning introduces the challenge of balancing local autonomy with global coordination. Edge and regional tiers must be able to make localized decisions based on the data available to them while remaining synchronized with the global state maintained at the cloud tier. This requires careful design of interfaces between tiers to manage not only data flows but also model updates, inference results, and feedback loops. For instance, systems employing federated learning must coordinate the aggregation of locally trained model updates without overwhelming the cloud tier or compromising privacy and security.</p>
<p>By integrating machine learning into the Hierarchical Processing Pattern, systems gain the ability to scale their capabilities across diverse environments, adapt dynamically to changing resource conditions, and balance real-time responsiveness with centralized intelligence. However, these benefits come with added complexity, requiring careful attention to model lifecycle management, data structuring, and resource allocation. The Hierarchical Processing Pattern remains a powerful framework for ML systems, enabling them to overcome the constraints of infrastructure variability while delivering high-impact solutions across a wide range of applications.</p>
</section>
<section id="sec-ai-good-performance-characteristics-9b2f" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-performance-characteristics-9b2f">Performance Characteristics by Tier</h4>
<p>Quantifying performance across hierarchical tiers reveals precise trade-offs between throughput, resource consumption, and deployment constraints. These metrics inform architectural decisions and resource allocation strategies essential for social good applications (<a href="#tbl-hierarchical_performance" class="quarto-xref">Table&nbsp;2</a>).</p>
<div id="tbl-hierarchical_performance" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-hierarchical_performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: <strong>Hierarchical Performance Metrics</strong>: Performance characteristics vary dramatically across tiers, with edge devices optimized for power efficiency and cloud systems for computational throughput. These constraints drive architectural decisions about which processing tasks are assigned to each tier.
</figcaption>
<div aria-describedby="tbl-hierarchical_performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 14%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>Tier</th>
<th>Throughput</th>
<th>Model Size</th>
<th>Power</th>
<th>Typical Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Edge devices</td>
<td>10-100 inferences/sec</td>
<td>&lt;1 MB</td>
<td>100 mW</td>
<td>Routine screening, anomaly detection</td>
</tr>
<tr class="even">
<td>Regional nodes</td>
<td>100-1000 inferences/sec</td>
<td>10-100 MB</td>
<td>10W</td>
<td>Complex analysis, data fusion</td>
</tr>
<tr class="odd">
<td>Cloud processing</td>
<td>&gt;10,000 inferences/sec</td>
<td>GB+</td>
<td>kW</td>
<td>Training updates, global coordination</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p><strong>Network Bandwidth Constraints</strong></p>
<p>Bandwidth limitations fundamentally shape inter-tier communication patterns and determine the feasibility of different architectural approaches:</p>
<ul>
<li><strong>2G connections (50 kbps)</strong>: Support 1-2 image uploads per minute, requiring aggressive edge preprocessing and data compression</li>
<li><strong>3G connections (1 Mbps)</strong>: Enable 10-20 images per minute, allowing moderate regional aggregation workloads</li>
<li><strong>Design constraint</strong>: Edge processing must handle 95%+ of routine inference tasks to avoid overwhelming network capacity</li>
</ul>
<p><strong>Coordination Overhead Analysis</strong></p>
<p>Communication costs dominate distributed processing performance, requiring careful optimization of inter-tier protocols:</p>
<ul>
<li><strong>Parameter synchronization</strong>: Scales as O(model_size × participants), becoming prohibitive with large models and many edge nodes</li>
<li><strong>Gradient aggregation</strong>: Network bandwidth becomes the primary bottleneck rather than computational capacity</li>
<li><strong>Efficiency rule</strong>: Maintain 10:1 compute-to-communication ratio for sustainable distributed operation</li>
</ul>
<p>Rural healthcare deployments demonstrate these trade-offs. Edge devices running 500KB diagnostic models achieve 50-80 inferences/second while consuming 80mW average power. Regional nodes aggregating data from 100+ health stations process 500-800 complex cases daily using 8W power budgets. Cloud processing handles population-level analytics and model updates consuming kilowatts but serving millions of beneficiaries across entire countries.</p>
</section>
<section id="sec-ai-good-limitations-ef57" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-limitations-ef57">Limitations</h4>
<p>Despite its strengths, the Hierarchical Processing Pattern encounters several core constraints in real-world deployments, particularly when applied to machine learning systems. These limitations arise from the distributed nature of the architecture, the variability of resource availability across tiers, and the inherent complexities of maintaining consistency and efficiency at scale.</p>
<p>The distribution of processing capabilities introduces significant complexity in resource allocation and cost management. Regional processing nodes must navigate trade-offs between local computational needs, hardware costs, and energy consumption. In battery-powered deployments, the energy efficiency of local computation versus data transmission becomes a important factor. These constraints directly affect the scalability and operational costs of the system, as additional nodes or tiers may require significant investment in infrastructure and hardware.</p>
<p>Time-important operations present unique challenges in hierarchical systems. While edge processing reduces latency for local decisions, operations requiring cross-tier coordination introduce unavoidable delays. For instance, anomaly detection systems that require consensus across multiple regional nodes face inherent latency limitations. This coordination overhead can make hierarchical architectures unsuitable for applications requiring sub-millisecond response times or strict global consistency.</p>
<p>Training data imbalances across regions create additional complications. Different deployment environments often generate varying quantities and types of data, leading to model bias and performance disparities. For example, urban areas typically generate more training samples than rural regions, potentially causing models to underperform in less data-rich environments. This imbalance can be particularly problematic in systems where model performance directly impacts important decision-making processes.</p>
<p>System maintenance and debugging introduce practical challenges that grow with scale. Identifying the root cause of performance degradation becomes increasingly complex when issues can arise from hardware failures, network conditions, model drift, or interactions between tiers. Traditional debugging approaches often prove inadequate, as problems may manifest only under specific combinations of conditions across multiple tiers. This complexity increases operational costs and requires specialized expertise for system maintenance.</p>
<p>These limitations necessitate careful consideration of mitigation strategies during system design. Approaches such as asynchronous processing protocols, tiered security frameworks, and automated debugging tools can help address specific challenges. Additionally, implementing robust monitoring systems that track performance metrics across tiers allows early detection of potential issues. While these limitations don’t diminish the pattern’s overall utility, they underscore the importance of thorough planning and risk assessment in hierarchical system deployments.</p>
</section>
</section>
<section id="sec-ai-good-progressive-enhancement-1b00" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-progressive-enhancement-1b00">Progressive Enhancement</h3>
<p>The progressive enhancement pattern applies a layered approach to system design, enabling functionality across environments with varying resource capacities. This pattern operates by establishing a baseline capability that remains operational under minimal resource conditions, typically requiring merely kilobytes of memory and milliwatts of power, and incrementally incorporating advanced features as additional resources become available. While originating from web development, where applications adapted to diverse browser capabilities and network conditions, the pattern has evolved to address the complexities of distributed systems and machine learning deployments.</p>
<p>This approach fundamentally differs from the Hierarchical Processing Pattern by focusing on vertical feature enhancement rather than horizontal distribution of tasks. Systems adopting this pattern are structured to maintain operations even under severe resource constraints, such as 2G network connections (&lt;&nbsp;50&nbsp;kbps) or microcontroller-class devices (&lt; 1 MB RAM). Additional capabilities are activated systematically as resources become available, with each enhancement layer building upon the foundation established by previous layers. This granular approach to resource utilization ensures system reliability while maximizing performance potential.</p>
<p>In machine learning applications, the progressive enhancement pattern allows sophisticated adaptation of models and workflows based on available resources. For instance, a computer vision system might deploy a 100 KB quantized model capable of basic object detection under minimal conditions, progressively expanding to more sophisticated models (1-50 MB) with higher accuracy and additional detection capabilities as computational resources permit. This adaptability allows systems to scale their capabilities dynamically while maintaining core functionality across diverse operating environments.</p>
<section id="sec-ai-good-plantvillage-nuru-9b9d" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-ai-good-plantvillage-nuru-9b9d">PlantVillage Nuru</h4>
<p><a href="https://bigdata.cgiar.org/digital-intervention/plantvillage-nuru-pest-and-disease-monitoring-using-ai/">PlantVillage Nuru</a> exemplifies the progressive enhancement pattern in its approach to providing AI-powered agricultural support for smallholder farmers <span class="citation" data-cites="ferentinos2018deep">(<a href="#ref-ferentinos2018deep" role="doc-biblioref">Ferentinos 2018</a>)</span>, particularly in low-resource settings. Developed to address the challenges of crop diseases and pest management, Nuru combines machine learning models with mobile technology to deliver actionable insights directly to farmers, even in remote regions with limited connectivity or computational resources.</p>
<div class="no-row-height column-margin column-container"><div id="ref-ferentinos2018deep" class="csl-entry" role="listitem">
Ferentinos, Konstantinos P. 2018. <span>“Deep Learning Models for Plant Disease Detection and Diagnosis.”</span> <em>Computers and Electronics in Agriculture</em> 145 (February): 311–18. <a href="https://doi.org/10.1016/j.compag.2018.01.009">https://doi.org/10.1016/j.compag.2018.01.009</a>.
</div><div id="fn20"><p><sup>20</sup>&nbsp;<strong>PlantVillage Nuru Real-World Impact</strong>: Deployed across 500,000+ farmers in East Africa since 2019, Nuru has helped identify crop diseases affecting $2.6 billion worth of annual cassava production. The app works on $30 smartphones offline, processing 2.1 million crop images annually. Field studies show 73% reduction in crop losses and 40% increase in farmer incomes where the system is actively used, demonstrating how progressive enhancement patterns scale impact in resource-constrained environments.</p></div></div><p>PlantVillage Nuru<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> operates with a baseline model optimized for resource-constrained environments. The system employs quantized convolutional neural networks (typically 2-5 MB in size) running on entry-level smartphones, capable of processing images at 1-2 frames per second while consuming less than 100 mW of power. These models leverage mobile-optimized frameworks discussed in <strong><a href="../core/frameworks/frameworks.html#sec-ai-frameworks">Chapter 5: AI Frameworks</a></strong> to achieve efficient on-device inference. The on-device models achieve 85-90% accuracy in identifying common crop diseases, providing important diagnostic capabilities without requiring network connectivity.</p>
<p>When network connectivity becomes available (even at 2G speeds of 50-100 kbps), Nuru progressively enhances its capabilities. The system uploads collected data to cloud infrastructure, where more sophisticated models (50-100&nbsp;MB) perform advanced analysis with 95-98% accuracy. These models integrate multiple data sources: high-resolution satellite imagery (10-30&nbsp;m resolution), local weather data (updated hourly), and soil sensor readings. This enhanced processing generates detailed mitigation strategies, including precise pesticide dosage recommendations and optimal timing for interventions.</p>
<p>In regions lacking widespread smartphone access, Nuru implements an intermediate enhancement layer through community digital hubs. These hubs, equipped with mid-range tablets (2 GB RAM, quad-core processors), cache diagnostic models and agricultural databases (10-20 GB) locally. This architecture allows offline access to enhanced capabilities while serving as data aggregation points when connectivity becomes available, typically synchronizing with cloud services during off-peak hours to optimize bandwidth usage.</p>
<p>This implementation demonstrates how progressive enhancement can scale from basic diagnostic capabilities to comprehensive agricultural support based on available resources. The system maintains functionality even under severe constraints (offline operation, basic hardware) while leveraging additional resources when available to provide increasingly sophisticated analysis and recommendations.</p>
</section>
<section id="sec-ai-good-structure-120e" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-structure-120e">Structure</h4>
<p>The progressive enhancement pattern organizes systems into layered functionalities, each designed to operate within specific resource conditions. This structure begins with a set of capabilities that function under minimal computational or connectivity constraints, progressively incorporating advanced features as additional resources become available.</p>
<p><a href="#tbl-enhancement-layers" class="quarto-xref">Table&nbsp;3</a> outlines the resource specifications and capabilities across the pattern’s three primary layers:</p>
<div id="tbl-enhancement-layers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-enhancement-layers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: <strong>Progressive Enhancement Layers</strong>: Resource constraints define capabilities across system layers, enabling adaptable designs that prioritize functionality under varying conditions. The table maps computational power, network connectivity, and storage to baseline, intermediate, and advanced layers, showcasing how systems can maintain core functionality with minimal resources and enhance performance as resources increase.
</figcaption>
<div aria-describedby="tbl-enhancement-layers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 36%">
<col style="width: 26%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Resource Type</th>
<th style="text-align: left;">Baseline Layer</th>
<th style="text-align: left;">Intermediate Layer</th>
<th style="text-align: left;">Advanced Layer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Computational</td>
<td style="text-align: left;">Microcontroller-class (100-200 MHz CPU, &lt; 1MB RAM)</td>
<td style="text-align: left;">Entry-level smartphones (1-2 GB RAM)</td>
<td style="text-align: left;">Cloud/edge servers (8 GB+ RAM)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Network</td>
<td style="text-align: left;">Offline or 2G/GPRS</td>
<td style="text-align: left;">Intermittent 3G/4G (1-10 Mbps)</td>
<td style="text-align: left;">Reliable broadband (50 Mbps+)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Storage</td>
<td style="text-align: left;">Essential models (1-5 MB)</td>
<td style="text-align: left;">Local cache (10-50 MB)</td>
<td style="text-align: left;">Distributed systems (GB+ scale)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Power</td>
<td style="text-align: left;">Battery-operated (50-150 mW)</td>
<td style="text-align: left;">Daily charging cycles</td>
<td style="text-align: left;">Continuous grid power</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Processing</td>
<td style="text-align: left;">Basic inference tasks</td>
<td style="text-align: left;">Moderate ML workloads</td>
<td style="text-align: left;">Full training capabilities</td>
</tr>
<tr class="even">
<td style="text-align: left;">Data Access</td>
<td style="text-align: left;">Pre-packaged datasets</td>
<td style="text-align: left;">Periodic synchronization</td>
<td style="text-align: left;">Real-time data integration</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Each layer in the progressive enhancement pattern operates independently, so that systems remain functional regardless of the availability of higher tiers. The pattern’s modular structure allows seamless transitions between layers, minimizing disruptions as systems dynamically adjust to changing resource conditions. By prioritizing adaptability, the progressive enhancement pattern supports a wide range of deployment environments, from remote, resource-constrained regions to well-connected urban centers.</p>
<p><a href="#fig-pattern-pep" class="quarto-xref">Figure&nbsp;4</a> illustrates these three layers, showing the functionalities at each layer. The diagram visually demonstrates how each layer scales up based on available resources and how the system can fallback to lower layers when resource constraints occur.</p>
<div id="fig-pattern-pep" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pattern-pep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="751ca58792a5d971bd704ab99f81d8c27e727dd5.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Progressive Enhancement Layers: Machine learning systems employ tiered architectures to maintain functionality across varying resource availability, prioritizing core features even with limited connectivity or compute. Each layer builds upon the previous, enabling seamless transitions and adaptable deployment in diverse environments ranging from resource-constrained devices to well-connected servers."><img src="ai_for_good_files/mediabag/751ca58792a5d971bd704ab99f81d8c27e727dd5.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pattern-pep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>Progressive Enhancement Layers</strong>: Machine learning systems employ tiered architectures to maintain functionality across varying resource availability, prioritizing core features even with limited connectivity or compute. Each layer builds upon the previous, enabling seamless transitions and adaptable deployment in diverse environments ranging from resource-constrained devices to well-connected servers.
</figcaption>
</figure>
</div>
</section>
<section id="sec-ai-good-modern-adaptations-fe04" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-modern-adaptations-fe04">Modern Adaptations</h4>
<p>Modern implementations of the progressive enhancement pattern incorporate automated optimization techniques to create sophisticated resource-aware systems. These adaptations fundamentally reshape how systems manage varying resource constraints across deployment environments.</p>
<p>Automated architecture optimization represents a significant advancement in implementing progressive enhancement layers. Contemporary systems employ Neural Architecture Search to generate model families optimized for specific resource constraints. For example, a computer vision system might maintain multiple model variants ranging from 500 KB to 50 MB in size, each preserving maximum accuracy within its respective computational bounds. This automated approach ensures consistent performance scaling across enhancement layers, while setting the foundation for more sophisticated adaptation mechanisms.</p>
<p>Knowledge distillation and transfer mechanisms have evolved to support progressive capability enhancement. Modern systems implement bidirectional distillation processes where simplified models operating in resource-constrained environments gradually incorporate insights from their more sophisticated counterparts. This architectural approach allows baseline models to improve their performance over time while operating within strict resource limitations, creating a dynamic learning ecosystem across enhancement layers.</p>
<p>The evolution of distributed learning frameworks further extends these enhancement capabilities through federated optimization strategies. Base layer devices participate in simple model averaging operations, while better-resourced nodes implement more sophisticated federated optimization algorithms. This tiered approach to distributed learning allows system-wide improvements while respecting the computational constraints of individual devices, effectively scaling learning capabilities across diverse deployment environments.</p>
<p>These distributed capabilities culminate in resource-aware neural architectures that exemplify recent advances in dynamic adaptation. These systems modulate their computational graphs based on available resources, automatically adjusting model depth, width, and activation functions to match current hardware capabilities. Such dynamic adaptation allows smooth transitions between enhancement layers while maintaining optimal resource utilization, representing the current state of the art in progressive enhancement implementations.</p>
</section>
<section id="sec-ai-good-system-implications-e1f3" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-system-implications-e1f3">System Implications</h4>
<p>The application of the progressive enhancement pattern to machine learning systems introduces unique architectural considerations that extend beyond traditional progressive enhancement approaches. These implications significantly affect model deployment strategies, inference pipelines, and system optimization techniques.</p>
<p>Model architecture design requires careful consideration of computational-accuracy trade-offs across enhancement layers. At the baseline layer, models must operate within strict computational bounds (typically 100-500 KB model size) while maintaining acceptable accuracy thresholds (usually 85-90% of full model performance). Each enhancement layer then incrementally incorporates more sophisticated architectural components, such as additional model layers, attention mechanisms, or ensemble techniques, scaling computational requirements in tandem with available resources.</p>
<p>Training pipelines present distinct challenges in progressive enhancement implementations. Systems must maintain consistent performance metrics across different model variants while enabling smooth transitions between enhancement layers. This necessitates specialized training approaches such as progressive knowledge distillation, where simpler models learn to mimic the behavior of their more complex counterparts within their computational constraints. Training objectives must balance multiple factors: baseline model efficiency, enhancement layer accuracy, and cross-layer consistency.</p>
<p>Inference optimization becomes particularly important in progressive enhancement scenarios. Systems must dynamically adapt their inference strategies based on available resources, implementing techniques such as adaptive batching, dynamic quantization, and selective layer activation. These optimizations ensure efficient resource utilization while maintaining real-time performance requirements across different enhancement layers.</p>
<p>Model synchronization and versioning introduce additional complexity in progressively enhanced ML systems. As models operate across different resource tiers, systems must maintain version compatibility and manage model updates without disrupting ongoing operations. This requires robust versioning protocols that track model lineage across enhancement layers while ensuring backward compatibility for baseline operations.</p>
</section>
<section id="sec-ai-good-framework-implementation-9c8d" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-framework-implementation-9c8d">Framework Implementation Patterns</h4>
<p>Framework selection significantly impacts progressive enhancement implementations, with different frameworks excelling at specific deployment tiers. Understanding these trade-offs enables optimal technology choices for each enhancement layer (<a href="#tbl-framework_comparison" class="quarto-xref">Table&nbsp;4</a>).</p>
<p><strong>PyTorch Mobile Implementation</strong></p>
<p>PyTorch provides robust mobile deployment capabilities through torchscript optimization and quantization tools. For social good applications requiring progressive enhancement:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProgressiveHealthcareAI:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Baseline model: 2MB, runs on any Android device</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.baseline_model <span class="op">=</span> torch.jit.load(<span class="st">'baseline_diagnostic.pt'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Enhanced model: 50MB, requires modern hardware</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.device_has_capacity():</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.enhanced_model <span class="op">=</span> torch.jit.load(<span class="st">'enhanced_diagnostic.pt'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> diagnose(<span class="va">self</span>, symptoms):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Progressive model selection based on available resources</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(<span class="va">self</span>, <span class="st">'enhanced_model'</span>) <span class="kw">and</span> <span class="va">self</span>.sufficient_power():</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.enhanced_model(symptoms)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.baseline_model(symptoms)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> device_has_capacity(<span class="va">self</span>):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check RAM, CPU, and battery constraints</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.get_available_ram() <span class="op">&gt;</span> <span class="dv">1000</span>  <span class="co"># MB</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                <span class="kw">and</span> <span class="va">self</span>.get_battery_level() <span class="op">&gt;</span> <span class="dv">30</span>  <span class="co"># percent</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                <span class="kw">and</span> <span class="kw">not</span> <span class="va">self</span>.power_saving_mode())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>TensorFlow Lite Optimization</strong></p>
<p>TensorFlow Lite excels at creating optimized models for resource-constrained deployment layers:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Quantization pipeline for progressive enhancement</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>converter <span class="op">=</span> tf.lite.TFLiteConverter.from_saved_model(model_path)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>converter.optimizations <span class="op">=</span> [tf.lite.Optimize.DEFAULT]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Baseline layer: INT8 quantization for maximum efficiency</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>converter.target_spec.supported_types <span class="op">=</span> [tf.int8]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>baseline_model <span class="op">=</span> converter.convert()  <span class="co"># 4x size reduction, &lt;2% accuracy loss</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Intermediate layer: Float16 for balanced performance</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>converter.target_spec.supported_types <span class="op">=</span> [tf.float16]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>intermediate_model <span class="op">=</span> converter.convert()  <span class="co"># 2x size reduction, &lt;1% accuracy loss</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Framework Ecosystem Comparison</strong></p>
<div id="tbl-framework_comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-framework_comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: <strong>Framework Selection Matrix</strong>: Different frameworks excel at different deployment scenarios in progressive enhancement systems. PyTorch Mobile provides excellent research-to-production workflows, TensorFlow Lite offers superior production deployment tools, and ONNX Runtime enables cross-platform compatibility.
</figcaption>
<div aria-describedby="tbl-framework_comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 23%">
<col style="width: 26%">
<col style="width: 17%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Framework</th>
<th>Mobile Support</th>
<th>Edge Deployment</th>
<th>Community</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PyTorch Mobile</td>
<td>Excellent</td>
<td>Good</td>
<td>Research-focused</td>
<td>Prototype to production</td>
</tr>
<tr class="even">
<td>TensorFlow Lite</td>
<td>Excellent</td>
<td>Excellent</td>
<td>Industry-focused</td>
<td>Production deployment</td>
</tr>
<tr class="odd">
<td>ONNX Runtime</td>
<td>Good</td>
<td>Excellent</td>
<td>Cross-platform</td>
<td>Model portability</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p><strong>Power-Aware Model Scheduling</strong></p>
<p>Advanced implementations incorporate dynamic model selection based on real-time resource availability:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AdaptivePowerManagement:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, models):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models <span class="op">=</span> {</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">'baseline'</span>: models[<span class="st">'2mb_quantized'</span>],      <span class="co"># 50mW average</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">'intermediate'</span>: models[<span class="st">'15mb_float16'</span>],   <span class="co"># 150mW average</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">'enhanced'</span>: models[<span class="st">'80mb_full'</span>]          <span class="co"># 500mW average</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> select_model(<span class="va">self</span>, battery_level, power_source):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> power_source <span class="op">==</span> <span class="st">'solar'</span> <span class="kw">and</span> battery_level <span class="op">&gt;</span> <span class="dv">70</span>:</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.models[<span class="st">'enhanced'</span>]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> battery_level <span class="op">&gt;</span> <span class="dv">40</span>:</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.models[<span class="st">'intermediate'</span>]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.models[<span class="st">'baseline'</span>]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_with_power_budget(<span class="va">self</span>, input_data, max_power_mw):</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select most capable model within power constraint</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        available_models <span class="op">=</span> [(name, model) <span class="cf">for</span> name, model <span class="kw">in</span> <span class="va">self</span>.models.items()</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">if</span> <span class="va">self</span>.power_consumption[name] <span class="op">&lt;=</span> max_power_mw]</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> available_models:</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span>  <span class="co"># No model can operate within power budget</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use most capable model within constraints</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        best_model <span class="op">=</span> <span class="bu">max</span>(available_models, key<span class="op">=</span><span class="kw">lambda</span> x: <span class="va">self</span>.accuracy[x[<span class="dv">0</span>]])</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> best_model[<span class="dv">1</span>](input_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>These implementation patterns demonstrate how framework choices directly impact deployment success in resource-constrained environments. Proper framework selection and optimization enables effective progressive enhancement across diverse deployment scenarios.</p>
</section>
<section id="sec-ai-good-limitations-155c" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-limitations-155c">Limitations</h4>
<p>While the progressive enhancement pattern offers significant advantages for ML system deployment, it introduces several technical challenges that impact implementation feasibility and system performance. These challenges particularly affect model management, resource optimization, and system reliability.</p>
<p>Model version proliferation presents a core challenge. Each enhancement layer typically requires multiple model variants (often 3-5 per layer) to handle different resource scenarios, creating a combinatorial explosion in model management overhead. For example, a computer vision system supporting three enhancement layers might require up to 15 different model versions, each needing individual maintenance, testing, and validation. This complexity increases exponentially when supporting multiple tasks or domains.</p>
<p>Performance consistency across enhancement layers introduces significant technical hurdles. Models operating at the baseline layer (typically limited to 100-500 KB size) must maintain at least 85-90% of the accuracy achieved by advanced models while using only 1-5% of the computational resources. Achieving this efficiency-accuracy trade-off becomes increasingly difficult as task complexity increases. Systems often struggle to maintain consistent inference behavior when transitioning between layers, particularly when handling edge cases or out-of-distribution inputs.</p>
<p>Resource allocation optimization presents another important limitation. Systems must continuously monitor and predict resource availability while managing the overhead of these monitoring systems themselves. The decision-making process for switching between enhancement layers introduces additional latency (typically 50-200 ms), which can impact real-time applications. This overhead becomes particularly problematic in environments with rapidly fluctuating resource availability.</p>
<p>Infrastructure dependencies create core constraints on system capabilities. While baseline functionality operates within minimal requirements (50-150 mW power consumption, 2G network speeds), achieving full system potential requires substantial infrastructure improvements. The gap between baseline and enhanced capabilities often spans several orders of magnitude in computational requirements, creating significant disparities in system performance across deployment environments.</p>
<p>User experience continuity suffers from the inherent variability in system behavior across enhancement layers. Output quality and response times can vary significantly—from basic binary classifications at the baseline layer to detailed probabilistic predictions with confidence intervals at advanced layers. These variations can undermine user trust, particularly in important applications where consistency is important.</p>
<p>These limitations necessitate careful consideration during system design and deployment. Successful implementations require robust monitoring systems, graceful degradation mechanisms, and clear communication of system capabilities at each enhancement layer. While these challenges don’t negate the pattern’s utility, they emphasize the importance of thorough planning and realistic expectation setting in progressive enhancement deployments.</p>
</section>
</section>
<section id="sec-ai-good-distributed-knowledge-e7e1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-ai-good-distributed-knowledge-e7e1">Distributed Knowledge</h3>
<p>The Distributed Knowledge Pattern addresses the challenges of collective learning and inference across decentralized nodes, each operating with local data and computational constraints. Unlike hierarchical processing, where tiers have distinct roles, this pattern emphasizes peer-to-peer knowledge sharing and collaborative model improvement. Each node contributes to the network’s collective intelligence while maintaining operational independence.</p>
<p>This pattern builds on established Mobile ML and Tiny ML techniques to allow autonomous local processing at each node. Devices implement quantized models (typically 1-5 MB) for initial inference, while employing techniques like federated learning for collaborative model improvement <span class="citation" data-cites="silva2019federated">(<a href="#ref-silva2019federated" role="doc-biblioref">Kairouz et al. 2019</a>)</span>. Knowledge sharing occurs through various mechanisms: model parameter updates, derived features, or processed insights, depending on bandwidth and privacy constraints. This distributed approach allows the network to use collective experiences while respecting local resource limitations.</p>
<div class="no-row-height column-margin column-container"><div id="ref-silva2019federated" class="csl-entry" role="listitem">
Kairouz, Peter, H. Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, et al. 2019. <span>“Advances and Open Problems in Federated Learning,”</span> December. <a href="http://arxiv.org/abs/1912.04977v3">http://arxiv.org/abs/1912.04977v3</a>.
</div></div><p>The pattern particularly excels in environments where traditional centralized learning faces significant barriers. By distributing both data collection and model training across nodes, systems can operate effectively even with intermittent connectivity (as low as 1-2 hours of network availability per day) or severe bandwidth constraints (50-100 KB/day per node). This resilience makes it especially valuable for social impact applications operating in infrastructure-limited environments.</p>
<p>The distributed approach corely differs from progressive enhancement by focusing on horizontal knowledge sharing rather than vertical capability enhancement. Each node maintains similar baseline capabilities while contributing to and benefiting from the network’s collective knowledge, creating a robust system that remains functional even when significant portions of the network are temporarily inaccessible.</p>
<section id="sec-ai-good-wildlife-insights-69b4" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-wildlife-insights-69b4">Wildlife Insights</h4>
<p><a href="https://www.wildlifeinsights.org/">Wildlife Insights</a> demonstrates the Distributed Knowledge Pattern’s application in conservation through distributed camera trap networks. The system exemplifies how decentralized nodes can collectively build and share knowledge while operating under severe resource constraints in remote wilderness areas.</p>
<p>Each camera trap functions as an independent processing node, implementing sophisticated edge computing capabilities within strict power and computational limitations. These devices employ lightweight convolutional neural networks for species identification, alongside efficient activity detection models for motion analysis. Operating within power constraints of 50-100 mW, the devices utilize adaptive duty cycling to maximize battery life while maintaining continuous monitoring capabilities. This local processing approach allows each node to independently analyze and filter captured imagery, reducing raw image data from several megabytes to compact insight vectors of just a few kilobytes.</p>
<p>The system’s Distributed Knowledge Pattern sharing architecture enables effective collaboration between nodes despite connectivity limitations. Camera traps form local mesh networks using low-power radio protocols, sharing processed insights rather than raw data. This peer-to-peer communication enables the network to maintain collective awareness of wildlife movements and potential threats across the monitored area. When one node detects significant activity, including the presence of an endangered species or indications of poaching, this information propagates through the network, enabling coordinated responses even in areas with no direct connectivity to central infrastructure.</p>
<p>When periodic connectivity becomes available through satellite or cellular links, nodes synchronize their accumulated knowledge with cloud infrastructure. This synchronization process carefully balances the need for data sharing with bandwidth limitations, employing differential updates and compression techniques. The cloud tier then applies more sophisticated analytical models to understand population dynamics and movement patterns across the entire monitored region.</p>
<p>The Wildlife Insights implementation demonstrates how Distributed Knowledge Pattern sharing can maintain system effectiveness even in challenging environments. By distributing both processing and decision-making capabilities across the network, the system ensures continuous monitoring and rapid response capabilities while operating within the severe constraints of remote wilderness deployments. This approach has proven particularly valuable for conservation efforts, enabling real-time wildlife monitoring and threat detection across vast areas that would be impractical to monitor through centralized systems.</p>
</section>
<section id="sec-ai-good-structure-aded" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-structure-aded">Structure</h4>
<p>The Distributed Knowledge Pattern comprises specific architectural components designed to enable decentralized data collection, processing, and knowledge sharing. The pattern defines three primary structural elements: autonomous nodes, communication networks, and aggregation mechanisms.</p>
<p><a href="#fig-pattern_dc" class="quarto-xref">Figure&nbsp;5</a> illustrates the key components and their interactions within the Distributed Knowledge Pattern. Individual nodes (rectangular shapes) operate autonomously while sharing insights through defined communication channels. The aggregation layer (diamond shape) combines distributed knowledge, which feeds into the analysis layer (oval shape) for processing.</p>
<div id="fig-pattern_dc" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pattern_dc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="39837cfd7cc18372802662d2c856a0b5023a8e02.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Distributed Knowledge Architecture: Autonomous nodes collaboratively process data and share insights via communication networks, enabling scalable and adaptable AI systems through decentralized knowledge aggregation and analysis. This pattern decouples data processing from centralized control, fostering resilience and allowing systems to respond effectively to dynamic environments and distributed data sources."><img src="ai_for_good_files/mediabag/39837cfd7cc18372802662d2c856a0b5023a8e02.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pattern_dc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>Distributed Knowledge Architecture</strong>: Autonomous nodes collaboratively process data and share insights via communication networks, enabling scalable and adaptable AI systems through decentralized knowledge aggregation and analysis. This pattern decouples data processing from centralized control, fostering resilience and allowing systems to respond effectively to dynamic environments and distributed data sources.
</figcaption>
</figure>
</div>
<p>Autonomous nodes form the foundation of the pattern’s structure. Each node implements three important capabilities: data acquisition, local processing, and knowledge sharing. The local processing pipeline typically includes feature extraction, basic inference, and data filtering mechanisms. This architecture enables nodes to operate independently while contributing to the network’s collective intelligence.</p>
<p>The communication layer establishes pathways for knowledge exchange between nodes. This layer implements both peer-to-peer protocols for direct node communication and hierarchical protocols for aggregation. The communication architecture must balance bandwidth efficiency with information completeness, often employing techniques such as differential updates and compressed knowledge sharing.</p>
<p>The aggregation and analysis layers provide mechanisms for combining distributed insights into understanding. These layers implement more sophisticated processing capabilities while maintaining feedback channels to individual nodes. Through these channels, refined models and updated processing parameters flow back to the distributed components, creating a continuous improvement cycle.</p>
<p>This structural organization ensures system resilience while enabling scalable knowledge sharing across distributed environments. The pattern’s architecture specifically addresses the challenges of unreliable infrastructure and limited connectivity while maintaining system effectiveness through decentralized operations.</p>
</section>
<section id="sec-ai-good-modern-adaptations-2bd9" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-ai-good-modern-adaptations-2bd9">Modern Adaptations</h4>
<p>The Distributed Knowledge Pattern has seen significant advancements with the rise of modern technologies like edge computing, the Internet of Things (IoT), and decentralized data networks. These innovations have enhanced the scalability, efficiency, and flexibility of systems utilizing this pattern, enabling them to handle increasingly complex data sets and to operate in more diverse and challenging environments.</p>
<p>One key adaptation has been the use of edge computing. Traditionally, distributed systems rely on transmitting data to centralized servers for analysis. However, with edge computing, nodes can perform more complex processing locally, reducing the dependency on central systems and enabling real-time data processing. This adaptation has been especially impactful in areas where network connectivity is intermittent or unreliable. For example, in remote wildlife conservation systems, camera traps can process images locally and only transmit relevant insights, such as the detection of a poacher, to a central hub when connectivity is restored. This reduces the amount of raw data sent across the network and ensures that the system remains operational even in areas with limited infrastructure.</p>
<p>Another important development is the integration of machine learning at the edge. In traditional distributed systems, machine learning models are often centralized, requiring large amounts of data to be sent to the cloud for processing. With the advent of smaller, more efficient machine learning models designed for edge devices, these models can now be deployed directly on the nodes themselves <span class="citation" data-cites="grieco2014iot">(<a href="#ref-grieco2014iot" role="doc-biblioref">Grieco et al. 2014</a>)</span>. For example, low-power devices such as smartphones or IoT sensors can run lightweight models for tasks like anomaly detection or image classification. This allows more sophisticated data analysis at the source, allowing for quicker decision-making and reducing reliance on central cloud services.</p>
<div class="no-row-height column-margin column-container"><div id="ref-grieco2014iot" class="csl-entry" role="listitem">
Grieco, L. A., A. Rizzo, S. Colucci, S. Sicari, G. Piro, D. Di Paola, and G. Boggia. 2014. <span>“IoT-Aided Robotics Applications: Technological Implications, Target Domains and Open Issues.”</span> <em>Computer Communications</em> 54 (December): 32–47. <a href="https://doi.org/10.1016/j.comcom.2014.07.013">https://doi.org/10.1016/j.comcom.2014.07.013</a>.
</div></div><p>In terms of network communication, modern mesh networks and 5G technology have significantly improved the efficiency and speed of data sharing between nodes. Mesh networks allow nodes to communicate with each other directly, forming a self-healing and scalable network. This decentralized approach to communication ensures that even if a node or connection fails, the network can still operate seamlessly. With the advent of 5G, the bandwidth and latency issues traditionally associated with large-scale data transfer in distributed systems are mitigated, enabling faster and more reliable communication between nodes in real-time applications.</p>
</section>
<section id="sec-ai-good-system-implications-5f92" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-system-implications-5f92">System Implications</h4>
<p>The Distributed Knowledge Pattern fundamentally reshapes how machine learning systems handle data collection, model training, and inference across decentralized nodes. These implications extend beyond traditional distributed computing challenges to encompass ML-specific considerations in model architecture, training dynamics, and inference optimization.</p>
<p>Model architecture design requires specific adaptations for distributed deployment. Models must be structured to operate effectively within node-level resource constraints while maintaining sufficient complexity for accurate inference. This often necessitates specialized architectures that support incremental learning and knowledge distillation. For instance, neural network architectures might implement modular components that can be selectively activated based on local computational resources, typically operating within 1-5 MB memory constraints while maintaining 85-90% of centralized model accuracy.</p>
<p>Training dynamics become particularly complex in Distributed Knowledge Pattern systems. Unlike centralized training approaches, these systems must implement collaborative learning mechanisms that function effectively across unreliable networks. Federated averaging protocols must be adapted to handle non-IID (Independent and Identically Distributed) data distributions across nodes while maintaining convergence guarantees. Training procedures must also account for varying data qualities and quantities across nodes, implementing weighted aggregation schemes that reflect data reliability and relevance.</p>
<p>Inference optimization presents unique challenges in distributed environments. Models must adapt their inference strategies based on local resource availability while maintaining consistent output quality across the network. This often requires implementing dynamic batching strategies, adaptive quantization, and selective feature computation. Systems typically target sub-100 ms inference latency at the node level while operating within strict power envelopes (50-150 mW).</p>
<p>Model lifecycle management becomes significantly more complex in Distributed Knowledge Pattern systems. Version control must handle multiple model variants operating across different nodes, managing both forward and backward compatibility. Systems must implement robust update mechanisms that can handle partial network connectivity while preventing model divergence across the network.</p>
</section>
<section id="sec-ai-good-limitations-8def" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-limitations-8def">Limitations</h4>
<p>While the Distributed Knowledge Pattern offers many advantages, particularly in decentralized, resource-constrained environments, it also presents several challenges, especially when applied to machine learning systems. These challenges stem from the complexity of managing distributed nodes, ensuring data consistency, and addressing the constraints of decentralized systems.</p>
<p>One of the primary challenges is model synchronization and consistency. In distributed systems, each node may operate with its own version of a machine learning model, which is trained using local data. As these models are updated over time, ensuring consistency across all nodes becomes a difficult task. Without careful synchronization, nodes may operate using outdated models, leading to inconsistencies in the system’s overall performance. Furthermore, when nodes are intermittently connected or have limited bandwidth, synchronizing model updates across all nodes in real-time can be resource-intensive and prone to delays.</p>
<p>The issue of data fragmentation is another significant challenge. In a distributed system, data is often scattered across different nodes, and each node may have access to only a subset of the entire dataset. This fragmentation can limit the effectiveness of machine learning models, as the models may not be exposed to the full range of data needed for training. Aggregating data from multiple sources and ensuring that the data from different nodes is compatible for analysis is a complex and time-consuming process. Additionally, because some nodes may operate in offline modes or have intermittent connectivity, data may be unavailable for periods, further complicating the process.</p>
<p>Scalability also poses a challenge in distributed systems. As the number of nodes in the network increases, so does the volume of data generated and the complexity of managing the system. The system must be designed to handle this growth without overwhelming the infrastructure or degrading performance. The addition of new nodes often requires rebalancing data, recalibrating models, or introducing new coordination mechanisms, all of which can increase the complexity of the system.</p>
<p>Latency is another issue that arises in distributed systems. While data is processed locally on each node, real-time decision-making often requires the aggregation of insights from multiple nodes. The time it takes to share data and updates between nodes, and the time needed to process that data, can introduce delays in system responsiveness. In applications like autonomous systems or disaster response, these delays can undermine the effectiveness of the system, as immediate action is often necessary.</p>
<p>Finally, security and privacy concerns are magnified in distributed systems. Since data is often transmitted between nodes or stored across multiple devices, ensuring the integrity and confidentiality of the data becomes a significant challenge. The system must employ strong encryption and authentication mechanisms to prevent unauthorized access or tampering of sensitive information. This is especially important in applications involving private or protected data, such as healthcare or financial systems. Additionally, decentralized systems may be more susceptible to certain types of attacks, such as Sybil attacks, where an adversary can introduce fake nodes into the network.</p>
<p>Despite these challenges, there are several strategies that can help mitigate the limitations of the Distributed Knowledge Pattern. For example, federated learning techniques can help address model synchronization issues by enabling nodes to update models locally and only share the updates, rather than raw data. Decentralized data aggregation methods can help address data fragmentation by allowing nodes to perform more localized aggregation before sending data to higher tiers. Similarly, edge computing can reduce latency by processing data closer to the source, reducing the time needed to transmit information to central servers.</p>
</section>
</section>
<section id="sec-ai-good-adaptive-resource-c0d5" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-adaptive-resource-c0d5">Adaptive Resource</h3>
<p>The Adaptive Resource Pattern focuses on enabling systems to dynamically adjust their operations in response to varying resource availability, ensuring efficiency, scalability, and resilience in real-time. This pattern allows systems to allocate resources flexibly depending on factors like computational load, network bandwidth, and storage capacity. The key idea is that systems should be able to scale up or down based on the resources they have access to at any given time.</p>
<p>Rather than being a standalone pattern, Adaptive Resource Pattern management is often integrated within other system design patterns. It enhances systems by allowing them to perform efficiently even under changing conditions, ensuring that they continue to meet their objectives, regardless of resource fluctuations.</p>
<p><a href="#fig-patterns_adaptive" class="quarto-xref">Figure&nbsp;6</a> below illustrates how systems using the Adaptive Resource Pattern adapt to different levels of resource availability. The system adjusts its operations based on the resources available at the time, optimizing its performance accordingly.</p>
<div id="fig-patterns_adaptive" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-patterns_adaptive-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="6e48b8e4e1a8c2886e2508f5afba922e40d47605.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Resource Adaptation: Machine learning systems prioritize core functionality under resource constraints by dynamically adjusting operational capabilities based on available resources—ranging from full performance with high resources to reduced functionality with low resources. This pattern enhances system resilience and allows continuous operation even when computational or energy budgets are limited."><img src="ai_for_good_files/mediabag/6e48b8e4e1a8c2886e2508f5afba922e40d47605.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-patterns_adaptive-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>Resource Adaptation</strong>: Machine learning systems prioritize core functionality under resource constraints by dynamically adjusting operational capabilities based on available resources—ranging from full performance with high resources to reduced functionality with low resources. This pattern enhances system resilience and allows continuous operation even when computational or energy budgets are limited.
</figcaption>
</figure>
</div>
<p>In the diagram, when the system is operating under low resources, it switches to simplified operations, ensuring basic functionality with minimal resource use. As resources become more available, the system adjusts to medium resources, enabling more moderate operations and optimized functionality. When resources are abundant, the system can use high resources, enabling advanced operations and full capabilities, such as processing complex data or running resource-intensive tasks.</p>
<p>The feedback loop is an important part of this pattern, as it ensures continuous adjustment based on the system’s resource conditions. This feedback allows the system to recalibrate and adapt in real-time, scaling resources up or down to maintain optimal performance.</p>
<section id="sec-ai-good-case-studies-3646" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-case-studies-3646">Case Studies</h4>
<p>Looking at the systems we discussed earlier, it is clear that these systems could benefit from Adaptive Resource Pattern allocation in their operations. In the case of Google’s flood forecasting system, the Hierarchical Processing Pattern approach ensures that data is processed at the appropriate level, from edge sensors to cloud-based analysis. However, Adaptive Resource Pattern management would allow this system to adjust its operations dynamically depending on the resources available. In areas with limited infrastructure, the system could rely more heavily on edge processing to reduce the need for constant connectivity, while in regions with better infrastructure, the system could scale up and use more cloud-based processing power.</p>
<p>Similarly, PlantVillage Nuru could integrate Adaptive Resource Pattern allocation into its progressive enhancement approach. The app is designed to work in a variety of settings, from low-resource rural areas to more developed regions. The Adaptive Resource Pattern management in this context would help the system adjust the complexity of its processing based on the available device and network resources, ensuring that it provides useful insights without overwhelming the system or device.</p>
<p>In the case of Wildlife Insights, the Adaptive Resource Pattern management would complement the Distributed Knowledge Pattern. The camera traps in the field process data locally, but when network conditions improve, the system could scale up to transmit more data to central systems for deeper analysis. By using adaptive techniques, the system ensures that the camera traps can continue to function even with limited power and network connectivity, while still providing valuable insights when resources allow for greater computational effort.</p>
<p>These systems could integrate the Adaptive Resource Pattern management to dynamically adjust based on available resources, improving efficiency and ensuring continuous operation under varying conditions. By incorporating the Adaptive Resource Pattern allocation into their design, these systems can remain responsive and scalable, even as resource availability fluctuates. The Adaptive Resource Pattern, in this context, acts as an allowr, supporting the operations of these systems and helping them adapt to the demands of real-time environments.</p>
</section>
<section id="sec-ai-good-structure-1bdc" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-structure-1bdc">Structure</h4>
<p>The Adaptive Resource Pattern revolves around dynamically allocating resources in response to changing environmental conditions, such as network bandwidth, computational power, or storage. This requires the system to monitor available resources continuously and adjust its operations accordingly to ensure optimal performance and efficiency.</p>
<p>It is structured around several key components. First, the system needs a monitoring mechanism to constantly evaluate the availability of resources. This can involve checking network bandwidth, CPU utilization, memory usage, or other relevant metrics. Once these metrics are gathered, the system can then determine the appropriate course of action—whether it needs to scale up, down, or adjust its operations to conserve resources.</p>
<p>Next, the system must include an adaptive decision-making process that interprets these metrics and decides how to allocate resources dynamically. In high-resource environments, the system might increase the complexity of tasks, using more powerful computational models or increasing the number of concurrent processes. Conversely, in low-resource environments, the system may scale back operations, reduce the complexity of models, or shift some tasks to local devices (such as edge processing) to minimize the load on the central infrastructure.</p>
<p>An important part of this structure is the feedback loop, which allows the system to adjust its resource allocation over time. After making an initial decision based on available resources, the system monitors the outcome and adapts accordingly. This process ensures that the system continues to operate effectively even as resource conditions change. The feedback loop helps the system fine-tune its resource usage, leading to more efficient operations as it learns to optimize resource allocation.</p>
<p>The system can also be organized into different tiers or layers based on the complexity and resource requirements of specific tasks. For instance, tasks requiring high computational resources, such as training machine learning models or processing large datasets, could be handled by a cloud layer, while simpler tasks, such as data collection or pre-processing, could be delegated to edge devices or local nodes. The system can then adapt the tiered structure based on available resources, allocating more tasks to the cloud or edge depending on the current conditions.</p>
</section>
<section id="sec-ai-good-modern-adaptations-77d4" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-modern-adaptations-77d4">Modern Adaptations</h4>
<p>The Adaptive Resource Pattern has evolved significantly with advancements in cloud computing, edge computing, and AI-driven resource management. These innovations have enhanced the flexibility and scalability of the pattern, allowing it to adapt more efficiently in increasingly complex environments.</p>
<p>One of the most notable modern adaptations is the integration of cloud computing. Cloud platforms like AWS, Microsoft Azure, and Google Cloud offer the ability to dynamically allocate resources based on demand, making it easier to scale applications in real-time. This integration allows systems to offload intensive processing tasks to the cloud when resources are available and return to more efficient, localized solutions when demand decreases or resources are constrained. The elasticity provided by cloud computing allows systems to perform heavy computational tasks, such as machine learning model training or big data processing, without requiring on-premise infrastructure.</p>
<p>At the other end of the spectrum, edge computing has emerged as a important adaptation for the Adaptive Resource Pattern. In edge computing, data is processed locally on devices or at the edge of the network, reducing the dependency on centralized servers and improving real-time responsiveness. Edge devices, such as IoT sensors or smartphones, often operate in resource-constrained environments, and the ability to process data locally allows for more efficient use of limited resources. By offloading certain tasks to the edge, systems can maintain functionality even in low-resource areas while ensuring that computationally intensive tasks are shifted to the cloud when available.</p>
<p>The rise of AI-driven resource management has also transformed how adaptive systems function. AI can now monitor resource usage patterns in real-time and predict future resource needs, allowing systems to adjust resource allocation proactively. For example, machine learning models can be trained to identify patterns in network traffic, processing power, or storage utilization, enabling the system to predict peak usage times and prepare resources accordingly. This proactive adaptation ensures that the system can handle fluctuations in demand smoothly and without interruption, reducing latency and improving overall system performance.</p>
<p>These modern adaptations allow systems to perform complex tasks while adapting to local conditions. For example, in disaster response systems, resources such as rescue teams, medical supplies, and communication tools can be dynamically allocated based on the evolving needs of the situation. Cloud computing allows large-scale coordination, while edge computing ensures that important decisions can be made at the local level, even when the network is down. By integrating AI-driven resource management, the system can predict resource shortages or surpluses, ensuring that resources are allocated in the most effective way.</p>
<p>These modern adaptations make the Adaptive Resource Pattern more powerful and flexible than ever. By leveraging cloud, edge computing, and AI, systems can dynamically allocate resources across distributed environments, ensuring that they remain scalable, efficient, and resilient in the face of changing conditions.</p>
</section>
<section id="sec-ai-good-system-implications-7ad5" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-system-implications-7ad5">System Implications</h4>
<p>Adaptive Resource Pattern has significant implications for machine learning systems, especially when deployed in environments with fluctuating resources, such as mobile devices, edge computing platforms, and distributed systems. Machine learning workloads can be resource-intensive, requiring substantial computational power, memory, and storage. By integrating the Adaptive Resource Pattern allocation, ML systems can optimize their performance, ensure scalability, and maintain efficiency under varying resource conditions.</p>
<p>In the context of distributed machine learning (e.g., federated learning), the Adaptive Resource Pattern ensures that the system adapts to varying computational capacities across devices. For example, in federated learning, models are trained collaboratively across many edge devices (such as smartphones or IoT devices), where each device has limited resources. The Adaptive Resource Pattern management can allocate the model training tasks based on the resources available on each device. Devices with more computational power can handle heavier workloads, while devices with limited resources can participate in lighter tasks, such as local model updates or simple computations. This ensures that all devices can contribute to the learning process without overloading them.</p>
<p>Another implication of the Adaptive Resource Pattern in ML systems is its ability to optimize real-time inference. In applications like autonomous vehicles, healthcare diagnostics, and environmental monitoring, ML models need to make real-time decisions based on available data. The system must dynamically adjust its computational requirements based on the resources available at the time. For instance, an autonomous vehicle running an image recognition model may process simpler, less detailed frames when computing resources are constrained or when the vehicle is in a resource-limited area (e.g., an area with poor connectivity). When computational resources are more plentiful, such as in a connected city with high-speed internet, the system can process more detailed frames and apply more complex models.</p>
<p>The adaptive scaling of ML models also plays a significant role in cloud-based ML systems. In cloud environments, the Adaptive Resource Pattern allows the system to scale the number of resources used for tasks like model training or batch inference. When large-scale data processing or model training is required, cloud services can dynamically allocate resources to handle the increased load. When demand decreases, resources are scaled back to reduce operational costs. This dynamic scaling ensures that ML systems run efficiently and cost-effectively, without over-provisioning or underutilizing resources.</p>
<p>Additionally, AI-driven resource management is becoming an increasingly important component of adaptive ML systems. AI techniques, such as reinforcement learning or predictive modeling, can be used to optimize resource allocation in real-time. For example, reinforcement learning algorithms can be applied to predict future resource needs based on historical usage patterns, allowing systems to preemptively allocate resources before demand spikes. This proactive approach ensures that ML models are trained and inference tasks are executed with minimal latency, even as resources fluctuate.</p>
<p>Lastly, edge AI systems benefit greatly from the Adaptive Resource Pattern. These systems often operate in environments with highly variable resources, such as remote areas, rural regions, or environments with intermittent connectivity. The pattern allows these systems to adapt their resource allocation based on the available resources in real-time, ensuring that important tasks, such as model inference or local data processing, can continue even in challenging conditions. For example, an environmental monitoring system deployed in a remote area may adapt by running simpler models or processing less detailed data when resources are low, while more complex analysis is offloaded to the cloud when the network is available.</p>
</section>
<section id="sec-ai-good-limitations-d4d0" class="level4">
<h4 class="anchored" data-anchor-id="sec-ai-good-limitations-d4d0">Limitations</h4>
<p>The Adaptive Resource Pattern faces several fundamental constraints in practical implementations, particularly when applied to machine learning systems in resource-variable environments. These limitations arise from the inherent complexities of real-time adaptation and the technical challenges of maintaining system performance across varying resource levels.</p>
<p>Performance predictability presents a primary challenge in adaptive systems. While adaptation allows systems to continue functioning under varying conditions, it can lead to inconsistent performance characteristics. For example, when a system transitions from high to low resource availability (e.g., from 8&nbsp;GB to 500 MB RAM), inference latency might increase from 50 ms to 200&nbsp;ms. Managing these performance variations while maintaining minimum quality-of-service requirements becomes increasingly complex as the range of potential resource states expands.</p>
<p>State synchronization introduces significant technical hurdles in adaptive systems. As resources fluctuate, maintaining consistent system state across components becomes challenging. For instance, when adapting to reduced network bandwidth (from 50 Mbps to 50 Kbps), systems must manage partial updates and ensure that important state information remains synchronized. This challenge is particularly acute in distributed ML systems, where model states and inference results must remain consistent despite varying resource conditions.</p>
<p>Resource transition overhead poses another fundamental limitation. Adapting to changing resource conditions incurs computational and time costs. For example, switching between different model architectures (from a 50 MB full model to a 5 MB quantized version) typically requires 100-200 ms of transition time. During these transitions, system performance may temporarily degrade or become unpredictable. This overhead becomes particularly problematic in environments where resources fluctuate frequently.</p>
<p>Quality degradation management presents ongoing challenges, especially in ML applications. As systems adapt to reduced resources, maintaining acceptable quality metrics becomes increasingly difficult. For instance, model accuracy might drop from 95% to 85% when switching to lightweight architectures, while energy consumption must stay within strict limits (typically 50-150 mW for edge devices). Finding acceptable trade-offs between resource usage and output quality requires sophisticated optimization strategies.</p>
<p>These limitations necessitate careful system design and implementation strategies. Successful deployments often implement robust monitoring systems, graceful degradation mechanisms, and clear quality thresholds for different resource states. While these challenges don’t negate the pattern’s utility, they emphasize the importance of thorough planning and realistic performance expectations in adaptive system deployments.</p>
<div id="quiz-question-sec-ai-good-design-patterns-cf75" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.6</strong></summary><div>
<ol type="1">
<li><p>Which design pattern is most suitable for maintaining system functionality across varying infrastructure qualities in machine learning deployments?</p>
<ol type="a">
<li>Distributed Knowledge Pattern</li>
<li>Progressive Enhancement Pattern</li>
<li>Hierarchical Processing Pattern</li>
<li>Adaptive Resource Pattern</li>
</ol></li>
<li><p>Explain how the Hierarchical Processing Pattern supports the deployment of machine learning systems in environments with unreliable networks.</p></li>
<li><p>What is a key benefit of using the Distributed Knowledge Pattern in machine learning systems?</p>
<ol type="a">
<li>Enhanced local autonomy and collaborative learning</li>
<li>Centralized control of data and models</li>
<li>Simplified system architecture</li>
<li>Uniform resource allocation across nodes</li>
</ol></li>
<li><p>In Google’s Flood Forecasting Initiative, the edge tier likely employs ____ models for anomaly detection to enable low-power operation.</p></li>
<li><p>How might you apply the Progressive Enhancement Pattern in a machine learning system designed for agricultural monitoring?</p></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-design-patterns-cf75" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-ai-good-selection-framework-8d82" class="level2">
<h2 class="anchored" data-anchor-id="sec-ai-good-selection-framework-8d82">Selection Framework</h2>
<p>The selection of an appropriate design pattern for machine learning systems in social impact contexts requires careful consideration of both technical constraints and operational requirements. Rather than treating patterns as rigid templates, system architects should view them as adaptable frameworks that can be tailored to specific deployment scenarios.</p>
<p>To support this adaptive approach, the selection process begins with a systematic analysis of four critical dimensions: resource variability, operational scale, data distribution requirements, and adaptation needs. Resource variability encompasses both the range and predictability of available computational resources, typically spanning from severely constrained environments (50-150 mW power, &lt; 1 MB RAM) to resource-rich deployments (multi-core servers, GB+ RAM). Operational scale considers both geographic distribution and user base size, ranging from localized deployments to systems spanning multiple regions. Data distribution requirements address how information needs to flow through the system, from centralized architectures to fully distributed networks. Adaptation needs examine how dynamically the system must respond to changing conditions, from relatively stable environments to highly variable scenarios.</p>
<section id="sec-ai-good-selection-dimensions-b80c" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-selection-dimensions-b80c">Selection Dimensions</h3>
<p>To make these multidimensional considerations more manageable, these dimensions can be visualized through a quadrant analysis framework that maps patterns based on their resource requirements and adaptability needs. This approach simplifies understanding (at least from a pedagogical perspective) by providing a structured view of how systems align with varying constraints.</p>
<p>As shown in <a href="#fig-quadrant" class="quarto-xref">Figure&nbsp;7</a>, this framework provides a structured approach for pattern selection based on two key axes: resource availability and scalability/adaptability needs. The horizontal axis corresponds to the level of computational, network, and power resources available to the system. Systems designed for resource-constrained environments, such as rural or remote areas, are positioned towards the left, while those leveraging robust infrastructure, such as cloud-supported systems, are placed towards the right. The vertical axis captures the system’s ability to function across diverse settings or respond dynamically to changing conditions.</p>
<div id="fig-quadrant" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-quadrant-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="4b559740f6f67cf518039daa26430fc8e0abc9d0.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: Design Space Mapping: AI system patterns align with resource availability and adaptability needs, guiding selection for diverse deployment contexts—from resource-constrained environments to scalable infrastructures. This quadrant analysis simplifies pattern selection by visually representing trade-offs between system complexity and operational flexibility."><img src="ai_for_good_files/mediabag/4b559740f6f67cf518039daa26430fc8e0abc9d0.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-quadrant-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: <strong>Design Space Mapping</strong>: AI system patterns align with resource availability and adaptability needs, guiding selection for diverse deployment contexts—from resource-constrained environments to scalable infrastructures. This quadrant analysis simplifies pattern selection by visually representing trade-offs between system complexity and operational flexibility.
</figcaption>
</figure>
</div>
<p>In low-resource environments with high adaptability needs, the progressive enhancement pattern dominates. Projects like PlantVillage Nuru (detailed in <a href="#sec-ai-good-agriculture-0b70" class="quarto-xref">Section&nbsp;1.3.1</a>) demonstrate TinyML implementations for offline crop diagnostics. Similarly, Medic Mobile uses these paradigms to support community health workers, enabling offline data collection and basic diagnostics that sync when connectivity permits.</p>
<p>For environments with higher resource availability and significant scalability demands, the Hierarchical Processing Pattern prevails. Google’s Flood Forecasting Initiative exemplifies this approach, combining Edge ML for local sensor processing with Cloud ML for analytics. Global Fishing Watch similarly uses this pattern, processing satellite data through a hierarchy of computational tiers to monitor fishing activities worldwide.</p>
<p>The Distributed Knowledge Pattern excels in low-resource environments requiring decentralized operations. Wildlife Insights demonstrates this through AI-allowd camera traps that employ Edge ML for local image processing while sharing insights across peer networks. <a href="https://wildeyeconservation.org/">WildEyes AI</a> follows a similar approach, using distributed nodes for poaching detection with minimal central coordination.</p>
<p>Systems requiring dynamic resource allocation in fluctuating environments benefit from the Adaptive Resource Pattern. AI for Disaster Response exemplifies this approach, combining Edge ML for immediate local processing with Cloud ML scalability during crises. The AI-powered Famine Action Mechanism similarly adapts its resource allocation dynamically, scaling analysis capabilities based on emerging conditions and available infrastructure.</p>
</section>
<section id="sec-ai-good-implementation-guidance-752c" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-implementation-guidance-752c">Implementation Guidance</h3>
<p>As outlined in <a href="#tbl-patterns" class="quarto-xref">Table&nbsp;5</a>, each pattern presents distinct strengths and challenges that influence implementation decisions. The practical deployment of these patterns requires careful consideration of both the operational context and the specific requirements of machine learning systems.</p>
<div id="tbl-patterns" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: <strong>Design Pattern Trade-Offs</strong>: Common machine learning system design patterns offer distinct advantages and disadvantages regarding scalability, resilience, and implementation complexity, guiding architects toward appropriate choices based on specific application requirements. Careful consideration of these trade-offs ensures robust and efficient system deployments in diverse operational contexts.
</figcaption>
<div aria-describedby="tbl-patterns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 20%">
<col style="width: 19%">
<col style="width: 20%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Design Pattern</th>
<th style="text-align: left;">Core Idea</th>
<th style="text-align: left;">Strengths</th>
<th style="text-align: left;">Challenges</th>
<th style="text-align: left;">Best Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Hierarchical Processing</td>
<td style="text-align: left;">Organizes operations into edge, regional, and cloud tiers.</td>
<td style="text-align: left;">Scalability, resilience, fault tolerance</td>
<td style="text-align: left;">Synchronization issues, model versioning, and latency in updates.</td>
<td style="text-align: left;">Distributed workloads spanning diverse infrastructures (e.g., Google’s Flood Forecasting).</td>
</tr>
<tr class="even">
<td style="text-align: left;">Progressive Enhancement</td>
<td style="text-align: left;">Provides baseline functionality and scales up dynamically.</td>
<td style="text-align: left;">Adaptability to resource variability, inclusivity</td>
<td style="text-align: left;">Ensuring consistent UX and increased complexity in layered design.</td>
<td style="text-align: left;">Applications serving both resource-constrained and resource-rich environments (e.g., PlantVillage Nuru).</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Distributed Knowledge</td>
<td style="text-align: left;">Decentralizes data processing and sharing across nodes.</td>
<td style="text-align: left;">Resilient in low-bandwidth environments, scalability</td>
<td style="text-align: left;">Data fragmentation and challenges with synchronizing decentralized models.</td>
<td style="text-align: left;">Systems requiring collaborative, decentralized insights (e.g., Wildlife Insights for conservation).</td>
</tr>
<tr class="even">
<td style="text-align: left;">Adaptive Resource</td>
<td style="text-align: left;">Dynamically adjusts operations based on resource availability.</td>
<td style="text-align: left;">Resource efficiency and real-time adaptability</td>
<td style="text-align: left;">Predicting resource demand and managing trade-offs between performance and simplicity.</td>
<td style="text-align: left;">Real-time systems operating under fluctuating resource conditions (e.g., disaster response systems).</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The implementation approach for each pattern should align with both its position in the resource-adaptability space and its core characteristics. In low-resource, high-adaptability environments, Progressive Enhancement implementations focus on establishing reliable baseline capabilities that can scale smoothly as resources become available. This often involves careful coordination between local processing and cloud resources, ensuring that systems maintain functionality even when operating at minimal resource levels.</p>
<p>Hierarchical Processing Pattern implementations, suited for environments with more stable infrastructure, require careful attention to the interfaces between tiers. The key challenge lies in managing the flow of data and model updates across the hierarchy while maintaining system responsiveness. This becomes particularly important in social impact applications where real-time response capabilities often determine intervention effectiveness.</p>
<p>Distributed Knowledge Pattern implementations emphasize resilient peer-to-peer operations, particularly important in environments where centralized coordination isn’t feasible. Success depends on establishing efficient knowledge-sharing protocols that maintain system effectiveness while operating within strict resource constraints. This pattern’s implementation often requires careful balance between local autonomy and network-wide consistency.</p>
<p>The Adaptive Resource Pattern implementations focus on dynamic resource management, particularly important in environments with fluctuating resource availability. These systems require sophisticated monitoring and control mechanisms that can adjust operations in real-time while maintaining important functionality. The implementation challenge lies in managing these transitions smoothly without disrupting important operations.</p>
</section>
<section id="sec-ai-good-comparison-analysis-3ce7" class="level3">
<h3 class="anchored" data-anchor-id="sec-ai-good-comparison-analysis-3ce7">Comparison Analysis</h3>
<p>Each design pattern offers unique advantages and trade-offs in ML system implementations. Understanding these distinctions allows system architects to make informed decisions based on deployment requirements and operational constraints.</p>
<p>The Hierarchical Processing Pattern and progressive enhancement pattern represent fundamentally different approaches to resource management. While the Hierarchical Processing Pattern establishes fixed infrastructure tiers with clear boundaries and responsibilities, progressive enhancement implements a continuous spectrum of capabilities that can scale smoothly with available resources. This distinction makes the Hierarchical Processing Pattern more suitable for environments with well-defined infrastructure tiers, while progressive enhancement better serves deployments where resource availability varies unpredictably.</p>
<p>The Distributed Knowledge Pattern and Adaptive Resource Pattern address different aspects of system flexibility. The Distributed Knowledge Pattern focuses on spatial distribution and peer-to-peer collaboration, while the Adaptive Resource Pattern management emphasizes temporal adaptation to changing conditions. These patterns can be complementary. The Distributed Knowledge Pattern handles geographic scale, while the Adaptive Resource Pattern management handles temporal variations in resource availability.</p>
<p>Selection between patterns often depends on the primary constraint facing the deployment. Systems primarily constrained by network reliability typically benefit from the Distributed Knowledge Pattern or Hierarchical Processing Pattern approaches. Those facing computational resource variability align better with progressive enhancement or Adaptive Resource Pattern approaches. The resource adaptability analysis presented earlier provides a structured framework for navigating these decisions based on specific deployment contexts.</p>
<div id="quiz-question-sec-ai-good-selection-framework-8d82" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.7</strong></summary><div>
<ol type="1">
<li><p>Which dimension is NOT considered in the selection framework for ML system design patterns?</p>
<ol type="a">
<li>Resource variability</li>
<li>Operational scale</li>
<li>User interface design</li>
<li>Data distribution requirements</li>
</ol></li>
<li><p>Explain how the Progressive Enhancement Pattern benefits ML systems in resource-constrained environments.</p></li>
<li><p>Order the following design patterns based on their suitability for environments with increasing resource availability: (1) Progressive Enhancement, (2) Distributed Knowledge, (3) Hierarchical Processing.</p></li>
<li><p>In which scenario would the Adaptive Resource Pattern be most beneficial?</p>
<ol type="a">
<li>A system with stable infrastructure and low variability</li>
<li>A system with hierarchical data processing needs</li>
<li>A system focused on peer-to-peer data sharing</li>
<li>A system requiring real-time adaptability to fluctuating conditions</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-selection-framework-8d82" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="fallacies-and-pitfalls" class="level2">
<h2 class="anchored" data-anchor-id="fallacies-and-pitfalls">Fallacies and Pitfalls</h2>
<p>AI for social good operates at the intersection of advanced technology and complex social challenges, where well-intentioned efforts can produce unintended consequences if not carefully designed and implemented. The appeal of using sophisticated AI to address pressing social issues can overshadow critical considerations about community needs, cultural context, and sustainable deployment practices.</p>
<p><strong>Fallacy:</strong> <em>Good intentions automatically ensure positive social impact from AI deployments.</em></p>
<p>This misconception assumes that well-meaning AI applications inherently benefit target communities without considering implementation challenges or unintended consequences. Technology solutions developed without deep community engagement often fail to address actual needs or create new problems that developers did not anticipate. Cultural misunderstandings, inadequate local context, or technical constraints can transform beneficial intentions into harmful outcomes. These challenges align with broader considerations of fairness, bias, and ethical deployment discussed in <strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong>. Effective AI for social good requires sustained community partnership, careful impact assessment, and adaptive implementation approaches that prioritize recipient needs over technological capabilities.</p>
<p><strong>Pitfall:</strong> <em>Applying technology-first solutions without understanding community needs and constraints.</em></p>
<p>Many practitioners approach social good applications by starting with available AI techniques and searching for applications rather than beginning with community-identified problems. This approach often results in technically sophisticated solutions that fail to address real priorities or operate effectively under local constraints. Resource-constrained environments require deep understanding of operational realities including power availability, connectivity patterns, user literacy levels, and maintenance capabilities. Successful deployments emerge from thorough needs assessment and co-design processes that align technical capabilities with actual requirements.</p>
<p><strong>Fallacy:</strong> <em>Resource-constrained deployments require only simplified versions of existing solutions.</em></p>
<p>This belief assumes that social good applications simply need scaled-down versions of mainstream AI systems rather than fundamentally different approaches. Resource constraints in developing regions often require novel system architectures, interaction paradigms, and evaluation frameworks that cannot be achieved through simple scaling. Limited power, intermittent connectivity, and diverse user contexts demand innovative engineering solutions like adaptive computation, distributed inference, and resilient communication protocols. Effective solutions require original engineering rather than reduced functionality.</p>
<p><strong>Pitfall:</strong> <em>Assuming that technical success ensures sustainable long-term impact.</em></p>
<p>Teams often focus on achieving technical milestones like model accuracy or system performance without considering sustainability factors that determine long-term community benefit. Successful deployments require ongoing maintenance, user training, infrastructure support, and adaptation to changing conditions that extend far beyond initial technical implementation. Evaluating these systems requires metrics that extend beyond traditional technical benchmarks covered in <strong><a href="../core/benchmarking/benchmarking.html#sec-benchmarking-ai">Chapter 7: Benchmarking AI</a></strong> to include social impact, community adoption, and long-term sustainability indicators. Projects that achieve impressive technical results but lack sustainable support mechanisms often fail to provide lasting benefit. Sustainable AI for good requires comprehensive planning for maintenance, training, governance, and continuous adaptation rather than treating deployment as a terminal milestone.</p>
<p><strong>Pitfall:</strong> <em>Underestimating the complexity of deploying AI systems in infrastructure-limited environments.</em></p>
<p>Many teams underestimate the substantial infrastructure challenges that arise when deploying AI systems in underserved regions or resource-constrained environments. These deployments often require custom solutions for power management, data synchronization over unreliable networks, offline operation capabilities, and hardware maintenance in remote locations without technical support infrastructure. Simple assumptions about internet connectivity, power availability, or device capabilities can lead to system failures that make valuable AI applications inaccessible to communities that could benefit most. Successful deployments require sophisticated engineering solutions for edge computing, robust offline capabilities, adaptive bandwidth utilization, and resilient hardware designs that can operate effectively in challenging physical environments. These robustness requirements complement the fault tolerance and reliability considerations detailed in <strong><a href="../core/robust_ai/robust_ai.html#sec-robust-ai">Chapter 14: Robust AI</a></strong>. Additionally, these systems must integrate with existing social and institutional infrastructures that may lack technical capacity for ongoing support, requiring careful attention to knowledge transfer, local capacity building, and sustainable maintenance protocols.</p>
</section>
<section id="sec-ai-good-summary-2437" class="level2">
<h2 class="anchored" data-anchor-id="sec-ai-good-summary-2437">Summary</h2>
<p>AI for social good represents one of the most challenging yet rewarding applications of machine learning technology, requiring systems that operate effectively under severe resource constraints while delivering meaningful impact to underserved communities. These environments present unique engineering challenges including limited power, unreliable connectivity, sparse data availability, and diverse user contexts that demand innovative approaches to system design. Success requires moving beyond traditional deployment models to create adaptive, resilient systems specifically engineered for high-impact, low-resource scenarios.</p>
<p>Systematic design patterns provide structured approaches to the complexities inherent in social impact applications. Hierarchical Processing enables graceful degradation under resource constraints. Progressive Enhancement enables systems to adapt functionality based on available resources. Distributed Knowledge facilitates coordination across heterogeneous devices and networks. Adaptive Resource Management optimizes performance under changing operational conditions. These patterns work together to create robust systems that maintain effectiveness across diverse deployment contexts while ensuring sustainability and scalability.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Key Takeaways">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Takeaways
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>AI for social good requires specialized engineering approaches that address severe resource constraints and diverse operational environments</li>
<li>Design patterns provide systematic frameworks for building resilient systems: Hierarchical Processing, Progressive Enhancement, Distributed Knowledge, and Adaptive Resource Management</li>
<li>Implementation success depends on comprehensive analysis of deployment contexts, resource availability, and specific community needs</li>
<li>Systems must balance technical performance with accessibility, sustainability, and real-world impact across the entire computing spectrum</li>
</ul>
</div>
</div>
<p>The evidence from real-world applications spanning agriculture monitoring to healthcare delivery demonstrates both the transformative potential and practical challenges of deploying AI in resource-constrained environments. These implementations reveal the importance of context-aware design, community engagement, and continuous adaptation to local conditions. As technological capabilities advance through edge computing, federated learning, and adaptive architectures, the opportunities for creating meaningful social impact through AI systems continue to expand, requiring sustained focus on engineering excellence and social responsibility.</p>
<!-- This is here to make sure that quizzes are inserted properly before a part begins. -->
<div id="quiz-question-sec-ai-good-summary-2437" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.8</strong></summary><div>
<ol type="1">
<li><p>Which design pattern is specifically aimed at ensuring ML systems can adapt to varying resource availability in constrained environments?</p>
<ol type="a">
<li>Hierarchical Processing</li>
<li>Adaptive Resource</li>
<li>Distributed Knowledge</li>
<li>Progressive Enhancement</li>
</ol></li>
<li><p>Explain how the design pattern of Progressive Enhancement can be applied in a machine learning system intended for deployment in a resource-constrained environment.</p></li>
<li><p>True or False: The Distributed Knowledge pattern is primarily concerned with enhancing system reliability in environments with unreliable network connectivity.</p></li>
<li><p>In the context of ML systems for social impact, the principle of ____ is essential for ensuring systems remain effective across diverse deployment contexts.</p></li>
</ol>
<p><a href="#quiz-answer-sec-ai-good-summary-2437" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="self-check-answers" class="level2">
<h2 class="anchored" data-anchor-id="self-check-answers">Self-Check Answers</h2>
<div id="quiz-answer-sec-ai-good-overview-c977" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.1</strong></summary><div>
<ol type="1">
<li><p><strong>What is the primary focus of AI for Good?</strong></p>
<ol type="a">
<li>Maximizing commercial profits</li>
<li>Improving computational efficiency</li>
<li>Developing advanced neural network architectures</li>
<li>Enhancing human welfare and promoting sustainability</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Enhancing human welfare and promoting sustainability. AI for Good aims to address societal and environmental challenges by leveraging machine learning to create positive, equitable, and lasting impacts.</p>
<p><em>Learning Objective</em>: Understand the primary goals and focus of AI for Good in the context of machine learning systems.</p></li>
<li><p><strong>Why is deploying ML systems in resource-constrained environments challenging, and how does it differ from commercial deployments?</strong></p>
<p><em>Answer</em>: Deploying ML systems in resource-constrained environments is challenging due to limited computing resources, intermittent connectivity, and minimal technical support. Unlike commercial deployments, these systems must be robust, maintainable, and effective despite these limitations. For example, models may need to be simplified to run on less powerful hardware, and deployment strategies must account for unreliable internet access. This is important because it requires rethinking traditional design patterns to ensure the systems can operate effectively in such environments.</p>
<p><em>Learning Objective</em>: Identify the unique challenges and differences in deploying ML systems for social impact compared to commercial applications.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-overview-c977" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-global-challenges-d7d2" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.2</strong></summary><div>
<ol type="1">
<li><p><strong>Timely interventions and coordinated responses could have significantly altered the outcomes of historical global challenges such as the 2014-2016 Ebola outbreak.</strong></p>
<p><em>Answer</em>: True. Timely interventions could have saved lives and reduced economic costs, as demonstrated by the delayed response during the Ebola outbreak.</p>
<p><em>Learning Objective</em>: Understand the impact of timely interventions on global challenges.</p></li>
<li><p><strong>Which of the following is a key characteristic shared by global challenges discussed in the section?</strong></p>
<ol type="a">
<li>They primarily affect developed countries.</li>
<li>They are easily solved with existing technologies.</li>
<li>They disproportionately affect vulnerable populations.</li>
<li>They have no connection to environmental issues.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. They disproportionately affect vulnerable populations. This is correct because global challenges often exacerbate existing inequalities and resource constraints in vulnerable regions.</p>
<p><em>Learning Objective</em>: Identify the common characteristics of global challenges.</p></li>
<li><p><strong>How can machine learning systems help address the systemic barriers faced by smallholder farmers?</strong></p>
<p><em>Answer</em>: Machine learning systems can provide smallholder farmers with predictive insights into weather patterns, pest outbreaks, and soil conditions, helping them make informed decisions. For example, ML models can forecast weather changes, allowing farmers to plan their planting and harvesting schedules more effectively. This is important because it can increase crop yields and enhance food security in vulnerable regions.</p>
<p><em>Learning Objective</em>: Explain the role of ML systems in overcoming barriers in agriculture.</p></li>
<li><p><strong>Order the following global challenges by their historical occurrence: (1) 2010 Haiti earthquake, (2) 2011 Somalia famine, (3) 2014-2016 Ebola outbreak.</strong></p>
<p><em>Answer</em>: The correct order is: (1) 2010 Haiti earthquake, (2) 2011 Somalia famine, (3) 2014-2016 Ebola outbreak. This sequence is based on the chronological order in which these events occurred, highlighting the recurring nature of global challenges.</p>
<p><em>Learning Objective</em>: Understand the timeline of significant global challenges.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-global-challenges-d7d2" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-key-ai-applications-f9fd" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.3</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following AI technologies is used in agriculture to provide real-time feedback on plant diseases?</strong></p>
<ol type="a">
<li>Mobile ML</li>
<li>Cloud ML</li>
<li>Edge ML</li>
<li>Tiny ML</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Mobile ML. This is correct because mobile ML allows for real-time disease detection on smartphones, as demonstrated with cassava disease detection. Cloud ML and Edge ML are not used in this specific context.</p>
<p><em>Learning Objective</em>: Understand the application of Mobile ML in agriculture for disease detection.</p></li>
<li><p><strong>True or False: Tiny ML is primarily used in agriculture to optimize water usage through precision irrigation.</strong></p>
<p><em>Answer</em>: True. This is true because Tiny ML sensors are used to monitor microclimates and optimize water usage, as seen in the example of rice farmers in Indonesia.</p>
<p><em>Learning Objective</em>: Recognize the role of Tiny ML in optimizing agricultural practices.</p></li>
<li><p><strong>In what ways do AI technologies like Tiny ML and Cloud ML contribute to healthcare in underserved areas?</strong></p>
<p><em>Answer</em>: AI technologies like Tiny ML enable diagnostics at the patient’s side, making healthcare accessible in remote areas. For example, a Tiny ML-powered wearable can detect pneumonia by analyzing cough patterns. Cloud ML, on the other hand, supports large-scale data analysis for research, such as identifying disease markers in genomics. These technologies democratize healthcare access by providing cost-effective, scalable solutions.</p>
<p><em>Learning Objective</em>: Explain how different AI technologies enhance healthcare access and outcomes.</p></li>
<li><p><strong>Order the following AI applications by their primary focus area: (1) Mobile ML for disease detection, (2) Tiny ML for precision irrigation, (3) Cloud ML for genomics research.</strong></p>
<p><em>Answer</em>: The correct order is: (1) Mobile ML for disease detection, (2) Tiny ML for precision irrigation, (3) Cloud ML for genomics research. Mobile ML focuses on real-time disease detection in agriculture, Tiny ML optimizes water usage for precision irrigation, and Cloud ML analyzes large datasets for healthcare research.</p>
<p><em>Learning Objective</em>: Sequence AI applications based on their primary focus areas.</p></li>
<li><p><strong>What is a key benefit of using Edge ML in environmental conservation?</strong></p>
<ol type="a">
<li>Requires constant internet connectivity</li>
<li>High power consumption</li>
<li>Limited to small-scale applications</li>
<li>Processes data locally, reducing power needs</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Processes data locally, reducing power needs. This is correct because Edge ML processes data on the device itself, minimizing power consumption and the need for frequent battery changes, as seen in tracking animal behavior.</p>
<p><em>Learning Objective</em>: Identify the benefits of Edge ML in environmental conservation.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-key-ai-applications-f9fd" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-global-development-perspective-8f64" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.4</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following Sustainable Development Goals (SDGs) can be directly impacted by machine learning systems that optimize resource distribution and reduce waste in food supply chains?</strong></p>
<ol type="a">
<li>Goal 1: No Poverty</li>
<li>Goal 13: Climate Action</li>
<li>Goal 5: Gender Equality</li>
<li>Goal 2: Zero Hunger</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Goal 2: Zero Hunger. This is correct because optimizing resource distribution and reducing waste directly address food availability and security, which are central to Goal 2. Other options focus on different aspects such as poverty, gender equality, and climate action.</p>
<p><em>Learning Objective</em>: Understand how ML systems can contribute to specific SDGs.</p></li>
<li><p><strong>True or False: The majority of AI research is focused on addressing basic human needs such as water, food, and health.</strong></p>
<p><em>Answer</em>: False. This is false because 97% of AI research focuses on SDG 9 (Industry/Innovation), while only 1% addresses basic needs like water, food, and health.</p>
<p><em>Learning Objective</em>: Challenge the misconception about the focus of current AI research relative to global needs.</p></li>
<li><p><strong>How might the lack of reliable electricity and internet infrastructure in certain regions affect the deployment of machine learning systems aimed at advancing the SDGs?</strong></p>
<p><em>Answer</em>: The lack of reliable electricity and internet infrastructure can significantly hinder the deployment of ML systems in these regions. For example, ML systems require consistent power and connectivity to function effectively, which may not be available in underserved areas. This is important because it necessitates the design of systems that can operate under these constraints, ensuring they are accessible and useful in advancing the SDGs.</p>
<p><em>Learning Objective</em>: Analyze the infrastructural challenges in deploying ML systems for global development.</p></li>
<li><p><strong>Order the following Sustainable Development Goals by their focus on environmental challenges: (1) Goal 7: Affordable and Clean Energy, (2) Goal 13: Climate Action, (3) Goal 15: Life on Land.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Goal 13: Climate Action, (1) Goal 7: Affordable and Clean Energy, (3) Goal 15: Life on Land. Goal 13 focuses directly on combating climate change, Goal 7 addresses energy sustainability, and Goal 15 emphasizes the conservation of terrestrial ecosystems.</p>
<p><em>Learning Objective</em>: Understand the prioritization of SDGs related to environmental challenges.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-global-development-perspective-8f64" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-engineering-challenges-d6a8" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.5</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the primary challenge of deploying ML systems in rural environments compared to urban environments?</strong></p>
<ol type="a">
<li>Higher computational resources in rural areas</li>
<li>Stable power infrastructure in rural areas</li>
<li>Abundant standardized data in rural areas</li>
<li>Limited network bandwidth and data availability in rural areas</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Limited network bandwidth and data availability in rural areas. Rural environments often face constraints in network bandwidth and sparse data availability, unlike urban areas with stable infrastructure and abundant data.</p>
<p><em>Learning Objective</em>: Understand the primary challenges in deploying ML systems in rural versus urban environments.</p></li>
<li><p><strong>Explain how the ‘Social Good Resource Paradox’ influences the design of ML systems for rural deployments.</strong></p>
<p><em>Answer</em>: The ‘Social Good Resource Paradox’ highlights the need for ML systems in resource-constrained environments, which lack infrastructure. This necessitates significant model compression and optimization to fit within limited computational and power resources. For example, models must be compressed from 50MB to 500KB while maintaining effectiveness. This is important because it challenges engineers to innovate under constraints, benefiting broader applications.</p>
<p><em>Learning Objective</em>: Analyze how resource constraints shape ML system design in rural contexts.</p></li>
<li><p><strong>Order the following deployment challenges from most to least affected by network bandwidth limitations: (1) Rural Deployment, (2) Urban Deployment, (3) Scaling Challenges.</strong></p>
<p><em>Answer</em>: The correct order is: (1) Rural Deployment, (3) Scaling Challenges, (2) Urban Deployment. Rural deployments face the most significant bandwidth limitations, followed by scaling challenges that require protocol adjustments. Urban deployments generally have high-bandwidth options available.</p>
<p><em>Learning Objective</em>: Evaluate how network bandwidth limitations impact different deployment scenarios.</p></li>
<li><p><strong>In a production system, which optimization technique is most critical when scaling ML deployments to thousands of devices?</strong></p>
<ol type="a">
<li>Increasing model complexity</li>
<li>Aggressive model quantization</li>
<li>Enhancing data collection frequency</li>
<li>Utilizing high-power computing resources</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Aggressive model quantization. Scaling to thousands of devices requires reducing model size to fit within limited resources, making quantization essential for maintaining performance under constraints.</p>
<p><em>Learning Objective</em>: Understand the importance of model optimization techniques in scaling ML deployments.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-engineering-challenges-d6a8" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-design-patterns-cf75" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.6</strong></summary><div>
<ol type="1">
<li><p><strong>Which design pattern is most suitable for maintaining system functionality across varying infrastructure qualities in machine learning deployments?</strong></p>
<ol type="a">
<li>Distributed Knowledge Pattern</li>
<li>Progressive Enhancement Pattern</li>
<li>Hierarchical Processing Pattern</li>
<li>Adaptive Resource Pattern</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Hierarchical Processing Pattern. This pattern organizes systems into tiers to optimize resource usage and maintain functionality under varying conditions. Other options focus on different aspects like enhancement, knowledge sharing, or resource adaptation.</p>
<p><em>Learning Objective</em>: Understand the suitability of different design patterns for maintaining system functionality in ML deployments.</p></li>
<li><p><strong>Explain how the Hierarchical Processing Pattern supports the deployment of machine learning systems in environments with unreliable networks.</strong></p>
<p><em>Answer</em>: The Hierarchical Processing Pattern supports deployment by organizing operations into tiers: edge devices handle local processing, regional nodes manage aggregation, and cloud infrastructure performs advanced analytics. This structure allows systems to operate independently at each tier, maintaining functionality during network disruptions. For example, edge devices can perform basic anomaly detection locally, ensuring continuity even without cloud connectivity.</p>
<p><em>Learning Objective</em>: Analyze how hierarchical processing enables ML system resilience in unreliable network environments.</p></li>
<li><p><strong>What is a key benefit of using the Distributed Knowledge Pattern in machine learning systems?</strong></p>
<ol type="a">
<li>Enhanced local autonomy and collaborative learning</li>
<li>Centralized control of data and models</li>
<li>Simplified system architecture</li>
<li>Uniform resource allocation across nodes</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Enhanced local autonomy and collaborative learning. The Distributed Knowledge Pattern emphasizes peer-to-peer knowledge sharing and collaborative model improvement, allowing systems to function effectively even with limited connectivity. Other options do not capture the decentralized nature of this pattern.</p>
<p><em>Learning Objective</em>: Understand the benefits of distributed knowledge sharing in decentralized ML systems.</p></li>
<li><p><strong>In Google’s Flood Forecasting Initiative, the edge tier likely employs ____ models for anomaly detection to enable low-power operation.</strong></p>
<p><em>Answer</em>: quantized. Quantized models reduce computational requirements, allowing edge devices to perform anomaly detection efficiently with limited power.</p>
<p><em>Learning Objective</em>: Recall the type of models used in edge computing for efficient processing.</p></li>
<li><p><strong>How might you apply the Progressive Enhancement Pattern in a machine learning system designed for agricultural monitoring?</strong></p>
<p><em>Answer</em>: In agricultural monitoring, the Progressive Enhancement Pattern can be applied by deploying a baseline model on low-resource devices for basic crop disease detection. As resources increase, more sophisticated models can be activated to provide detailed analysis and recommendations. This ensures the system maintains core functionality with minimal resources and scales capabilities as resources become available.</p>
<p><em>Learning Objective</em>: Apply the progressive enhancement pattern to real-world ML system scenarios, focusing on scalability and resource adaptability.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-design-patterns-cf75" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-selection-framework-8d82" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.7</strong></summary><div>
<ol type="1">
<li><p><strong>Which dimension is NOT considered in the selection framework for ML system design patterns?</strong></p>
<ol type="a">
<li>Resource variability</li>
<li>Operational scale</li>
<li>User interface design</li>
<li>Data distribution requirements</li>
</ol>
<p><em>Answer</em>: The correct answer is C. User interface design. This is correct because the section focuses on resource variability, operational scale, data distribution requirements, and adaptation needs as the key dimensions. User interface design is not mentioned as a selection dimension.</p>
<p><em>Learning Objective</em>: Understand the key dimensions influencing design pattern selection in ML systems.</p></li>
<li><p><strong>Explain how the Progressive Enhancement Pattern benefits ML systems in resource-constrained environments.</strong></p>
<p><em>Answer</em>: The Progressive Enhancement Pattern benefits ML systems in resource-constrained environments by providing baseline functionality that can scale as resources become available. For example, PlantVillage Nuru uses this pattern to offer offline crop diagnostics on basic smartphones, ensuring functionality even with limited connectivity. This is important because it allows systems to operate effectively in environments with unpredictable resource availability.</p>
<p><em>Learning Objective</em>: Analyze the advantages of using the Progressive Enhancement Pattern in specific deployment contexts.</p></li>
<li><p><strong>Order the following design patterns based on their suitability for environments with increasing resource availability: (1) Progressive Enhancement, (2) Distributed Knowledge, (3) Hierarchical Processing.</strong></p>
<p><em>Answer</em>: The correct order is: (1) Progressive Enhancement, (2) Distributed Knowledge, (3) Hierarchical Processing. Progressive Enhancement is suitable for low-resource environments, Distributed Knowledge for decentralized operations, and Hierarchical Processing for environments with stable infrastructure and higher resource availability.</p>
<p><em>Learning Objective</em>: Understand the relationship between design patterns and resource availability in ML systems.</p></li>
<li><p><strong>In which scenario would the Adaptive Resource Pattern be most beneficial?</strong></p>
<ol type="a">
<li>A system with stable infrastructure and low variability</li>
<li>A system with hierarchical data processing needs</li>
<li>A system focused on peer-to-peer data sharing</li>
<li>A system requiring real-time adaptability to fluctuating conditions</li>
</ol>
<p><em>Answer</em>: The correct answer is D. A system requiring real-time adaptability to fluctuating conditions. This is correct because the Adaptive Resource Pattern is designed to dynamically adjust operations based on resource availability, making it ideal for environments with fluctuating conditions.</p>
<p><em>Learning Objective</em>: Identify scenarios where the Adaptive Resource Pattern provides the most benefit.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-selection-framework-8d82" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-ai-good-summary-2437" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.8</strong></summary><div>
<ol type="1">
<li><p><strong>Which design pattern is specifically aimed at ensuring ML systems can adapt to varying resource availability in constrained environments?</strong></p>
<ol type="a">
<li>Hierarchical Processing</li>
<li>Adaptive Resource</li>
<li>Distributed Knowledge</li>
<li>Progressive Enhancement</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Adaptive Resource. This pattern focuses on adapting system functionality based on available resources, making it ideal for constrained environments. Other patterns address different aspects of system design.</p>
<p><em>Learning Objective</em>: Understand the purpose of the Adaptive Resource pattern in ML system design.</p></li>
<li><p><strong>Explain how the design pattern of Progressive Enhancement can be applied in a machine learning system intended for deployment in a resource-constrained environment.</strong></p>
<p><em>Answer</em>: Progressive Enhancement involves building a basic system that functions under minimal resources, with additional features activated as resources allow. For example, an ML system could start with local processing and enable cloud-based enhancements when connectivity improves. This ensures basic functionality while allowing for scalability.</p>
<p><em>Learning Objective</em>: Apply the Progressive Enhancement pattern in designing ML systems for constrained environments.</p></li>
<li><p><strong>True or False: The Distributed Knowledge pattern is primarily concerned with enhancing system reliability in environments with unreliable network connectivity.</strong></p>
<p><em>Answer</em>: True. This is true because the Distributed Knowledge pattern focuses on decentralizing data processing to enhance reliability and reduce dependency on continuous network connectivity, which is crucial in environments with unreliable networks.</p>
<p><em>Learning Objective</em>: Understand the role of the Distributed Knowledge pattern in enhancing system reliability.</p></li>
<li><p><strong>In the context of ML systems for social impact, the principle of ____ is essential for ensuring systems remain effective across diverse deployment contexts.</strong></p>
<p><em>Answer</em>: scalability. Scalability is essential for ensuring that ML systems can handle varying loads and expand their capabilities across different deployment contexts, which is crucial for sustainable social impact.</p>
<p><em>Learning Objective</em>: Recall key principles essential for effective ML system deployment.</p></li>
</ol>
<p><a href="#quiz-question-sec-ai-good-summary-2437" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>



</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="pagination-link" aria-label="Sustainable AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Sustainable AI</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/frontiers/frontiers.html" class="pagination-link" aria-label="AGI Systems">
        <span class="nav-page-text">AGI Systems</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>