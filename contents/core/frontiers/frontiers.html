<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/conclusion/conclusion.html" rel="next">
<link href="../../../contents/core/ai_for_good/ai_for_good.html" rel="prev">
<link href="../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ae75ed80ef5b3e74590777de1ac3d8c3.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-0769fbf68cc3e722256a1e1e51d908bf.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<script src="../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script>
<style>
.callout-example {
  --color1: #F0F8F6;
  --color2: #148F77;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
.callout-definition {
  --color1: #F0F4F8;
  --color2: #1B4F72;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
</style>
<style>
details.callout-example > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-example.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-resource-videos > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
details.callout-quiz-answer > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
details.callout-definition > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-definition.png");
}
details.callout-code > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-code.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
details.callout-quiz-question > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-md " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/images/icons/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-file-pdf" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/epub" target="_blank"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text">EPUB</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/frontiers/frontiers.html">Frontiers of ML Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/frontiers/frontiers.html">AGI Systems</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden"><i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p style="margin: 0 0 12px 0; padding: 8px 12px; background: rgba(255,193,7,0.2); border: 1px solid #ffc107; border-radius: 4px; font-weight: 600;"><i class="bi bi-exclamation-triangle-fill" style="margin-right: 6px; color: #856404;"></i><strong>🚧 DEVELOPMENT PREVIEW</strong> - Built from dev@<code style="background: rgba(0,0,0,0.1); padding: 2px 4px; border-radius: 3px; font-size: 0.9em;">e2acb2a4</code> • 2025-10-02 19:58 UTC • <a href="https://mlsysbook.ai" style="color: #856404; text-decoration: underline;"><em>Stable version →</em></a></p>
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div><i class="bi bi-x-lg quarto-announcement-action" style="display: none;"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frontiers/frontiers.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">AGI Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">Glossary</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/glossary/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Glossary</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">References</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Bibliography</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-agi-systems" id="toc-sec-agi-systems" class="nav-link active" data-scroll-target="#sec-agi-systems">AGI Systems</a>
  <ul>
  <li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose</a></li>
  <li><a href="#sec-agi-systems-current-revolution-2025-snapshot-894e" id="toc-sec-agi-systems-current-revolution-2025-snapshot-894e" class="nav-link" data-scroll-target="#sec-agi-systems-current-revolution-2025-snapshot-894e">Overview</a></li>
  <li><a href="#sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" id="toc-sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="nav-link" data-scroll-target="#sec-agi-systems-agi-vision-intelligence-systems-problem-2b44">The AGI Vision: Intelligence as a Systems Problem</a></li>
  <li><a href="#sec-agi-systems-compound-ai-framework" id="toc-sec-agi-systems-compound-ai-framework" class="nav-link" data-scroll-target="#sec-agi-systems-compound-ai-framework">The Compound AI Systems Framework</a></li>
  <li><a href="#sec-agi-systems-building-blocks-compound-intelligence" id="toc-sec-agi-systems-building-blocks-compound-intelligence" class="nav-link" data-scroll-target="#sec-agi-systems-building-blocks-compound-intelligence">Building Blocks for Compound Intelligence</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-data-engineering-scale" id="toc-sec-agi-systems-data-engineering-scale" class="nav-link" data-scroll-target="#sec-agi-systems-data-engineering-scale">Data Engineering at Scale</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-self-supervised-components" id="toc-sec-agi-systems-self-supervised-components" class="nav-link" data-scroll-target="#sec-agi-systems-self-supervised-components">Self-Supervised Learning Components</a></li>
  <li><a href="#sec-agi-systems-synthetic-data-generation" id="toc-sec-agi-systems-synthetic-data-generation" class="nav-link" data-scroll-target="#sec-agi-systems-synthetic-data-generation">Synthetic Data Generation</a></li>
  <li><a href="#sec-agi-systems-selfplay-components" id="toc-sec-agi-systems-selfplay-components" class="nav-link" data-scroll-target="#sec-agi-systems-selfplay-components">Self-Play Components</a></li>
  <li><a href="#sec-agi-systems-webscale-data-processing" id="toc-sec-agi-systems-webscale-data-processing" class="nav-link" data-scroll-target="#sec-agi-systems-webscale-data-processing">Web-Scale Data Processing</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-dynamic-architectures-compound" id="toc-sec-agi-systems-dynamic-architectures-compound" class="nav-link" data-scroll-target="#sec-agi-systems-dynamic-architectures-compound">Dynamic Architectures for Compound Systems</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-specialization-selective-computation" id="toc-sec-agi-systems-specialization-selective-computation" class="nav-link" data-scroll-target="#sec-agi-systems-specialization-selective-computation">Specialization Through Selective Computation</a></li>
  <li><a href="#sec-agi-systems-expert-routing-compound" id="toc-sec-agi-systems-expert-routing-compound" class="nav-link" data-scroll-target="#sec-agi-systems-expert-routing-compound">Expert Routing in Compound Systems</a></li>
  <li><a href="#sec-agi-systems-external-memory-compound" id="toc-sec-agi-systems-external-memory-compound" class="nav-link" data-scroll-target="#sec-agi-systems-external-memory-compound">External Memory for Compound Systems</a></li>
  <li><a href="#sec-agi-systems-modular-reasoning-architectures" id="toc-sec-agi-systems-modular-reasoning-architectures" class="nav-link" data-scroll-target="#sec-agi-systems-modular-reasoning-architectures">Modular Reasoning Architectures</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-training-compound-intelligence" id="toc-sec-agi-systems-training-compound-intelligence" class="nav-link" data-scroll-target="#sec-agi-systems-training-compound-intelligence">Training Compound Intelligence</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-alignment-across-components" id="toc-sec-agi-systems-alignment-across-components" class="nav-link" data-scroll-target="#sec-agi-systems-alignment-across-components">Alignment Across Components</a></li>
  <li><a href="#sec-agi-systems-human-feedback-component-training" id="toc-sec-agi-systems-human-feedback-component-training" class="nav-link" data-scroll-target="#sec-agi-systems-human-feedback-component-training">Human Feedback for Component Training</a></li>
  <li><a href="#sec-agi-systems-constitutional-ai-principled-selfimprovement-0f15" id="toc-sec-agi-systems-constitutional-ai-principled-selfimprovement-0f15" class="nav-link" data-scroll-target="#sec-agi-systems-constitutional-ai-principled-selfimprovement-0f15">Constitutional AI: Principled Self-Improvement</a></li>
  <li><a href="#sec-agi-systems-continual-learning-adapting-without-forgetting-f74b" id="toc-sec-agi-systems-continual-learning-adapting-without-forgetting-f74b" class="nav-link" data-scroll-target="#sec-agi-systems-continual-learning-adapting-without-forgetting-f74b">Continual Learning: Adapting Without Forgetting</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-optimization-compression-capability-ae5a" id="toc-sec-agi-systems-optimization-compression-capability-ae5a" class="nav-link" data-scroll-target="#sec-agi-systems-optimization-compression-capability-ae5a">Optimization: From Compression to Capability</a></li>
  <li><a href="#sec-agi-systems-hardware-acceleration-specialization-de7e" id="toc-sec-agi-systems-hardware-acceleration-specialization-de7e" class="nav-link" data-scroll-target="#sec-agi-systems-hardware-acceleration-specialization-de7e">Hardware: From Acceleration to Specialization</a></li>
  <li><a href="#sec-agi-systems-operations-deployment-evolution-4755" id="toc-sec-agi-systems-operations-deployment-evolution-4755" class="nav-link" data-scroll-target="#sec-agi-systems-operations-deployment-evolution-4755">Operations: From Deployment to Evolution</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-implementing-compound-intelligence-scale" id="toc-sec-agi-systems-implementing-compound-intelligence-scale" class="nav-link" data-scroll-target="#sec-agi-systems-implementing-compound-intelligence-scale">Implementing Compound Intelligence at Scale</a></li>
  <li><a href="#sec-agi-systems-beyond-transformers-alternative-architectures-6243" id="toc-sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="nav-link" data-scroll-target="#sec-agi-systems-beyond-transformers-alternative-architectures-6243">Beyond Transformers: Alternative Architectures</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-energy-based-models-alternative" id="toc-sec-agi-systems-energy-based-models-alternative" class="nav-link" data-scroll-target="#sec-agi-systems-energy-based-models-alternative">Energy-Based Models: An Alternative to Autoregressive Approaches</a></li>
  <li><a href="#sec-agi-systems-world-models-predictive-learning" id="toc-sec-agi-systems-world-models-predictive-learning" class="nav-link" data-scroll-target="#sec-agi-systems-world-models-predictive-learning">World Models and Predictive Learning</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-remaining-technical-barriers" id="toc-sec-agi-systems-remaining-technical-barriers" class="nav-link" data-scroll-target="#sec-agi-systems-remaining-technical-barriers">Remaining Technical Barriers</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-context-memory-bottleneck-intelligence-0db6" id="toc-sec-agi-systems-context-memory-bottleneck-intelligence-0db6" class="nav-link" data-scroll-target="#sec-agi-systems-context-memory-bottleneck-intelligence-0db6">Context and Memory: The Bottleneck of Intelligence</a></li>
  <li><a href="#sec-agi-systems-energy-sustainability-trilliondollar-question-f4e3" id="toc-sec-agi-systems-energy-sustainability-trilliondollar-question-f4e3" class="nav-link" data-scroll-target="#sec-agi-systems-energy-sustainability-trilliondollar-question-f4e3">Energy and Sustainability: The Trillion-Dollar Question</a></li>
  <li><a href="#sec-agi-systems-reasoning-planning-beyond-pattern-matching-4108" id="toc-sec-agi-systems-reasoning-planning-beyond-pattern-matching-4108" class="nav-link" data-scroll-target="#sec-agi-systems-reasoning-planning-beyond-pattern-matching-4108">Reasoning and Planning: Beyond Pattern Matching</a></li>
  <li><a href="#sec-agi-systems-embodiment-grounding-symbol-grounding-problem-a0ef" id="toc-sec-agi-systems-embodiment-grounding-symbol-grounding-problem-a0ef" class="nav-link" data-scroll-target="#sec-agi-systems-embodiment-grounding-symbol-grounding-problem-a0ef">Embodiment and Grounding: The Symbol Grounding Problem</a></li>
  <li><a href="#sec-agi-systems-alignment-control-value-loading-problem-f409" id="toc-sec-agi-systems-alignment-control-value-loading-problem-f409" class="nav-link" data-scroll-target="#sec-agi-systems-alignment-control-value-loading-problem-f409">Alignment and Control: The Value Loading Problem</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" id="toc-sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" class="nav-link" data-scroll-target="#sec-agi-systems-multiagent-futures-collective-intelligence-3ee4">Multi-Agent Futures: Collective Intelligence</a></li>
  <li><a href="#sec-agi-systems-challenges-opportunities-opens-51a8" id="toc-sec-agi-systems-challenges-opportunities-opens-51a8" class="nav-link" data-scroll-target="#sec-agi-systems-challenges-opportunities-opens-51a8">Challenges and Opportunities: What This Opens Up</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-infrastructure-opportunity-2386" id="toc-sec-agi-systems-infrastructure-opportunity-2386" class="nav-link" data-scroll-target="#sec-agi-systems-infrastructure-opportunity-2386">The Infrastructure Opportunity</a></li>
  <li><a href="#sec-agi-systems-personalization-revolution-2016" id="toc-sec-agi-systems-personalization-revolution-2016" class="nav-link" data-scroll-target="#sec-agi-systems-personalization-revolution-2016">The Personalization Revolution</a></li>
  <li><a href="#sec-agi-systems-automation-acceleration-1a04" id="toc-sec-agi-systems-automation-acceleration-1a04" class="nav-link" data-scroll-target="#sec-agi-systems-automation-acceleration-1a04">The Automation Acceleration</a></li>
  <li><a href="#sec-agi-systems-realtime-intelligence-challenge-7e48" id="toc-sec-agi-systems-realtime-intelligence-challenge-7e48" class="nav-link" data-scroll-target="#sec-agi-systems-realtime-intelligence-challenge-7e48">The Real-Time Intelligence Challenge</a></li>
  <li><a href="#sec-agi-systems-explainability-imperative-78c4" id="toc-sec-agi-systems-explainability-imperative-78c4" class="nav-link" data-scroll-target="#sec-agi-systems-explainability-imperative-78c4">The Explainability Imperative</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-implications-ml-systems-engineers-781e" id="toc-sec-agi-systems-implications-ml-systems-engineers-781e" class="nav-link" data-scroll-target="#sec-agi-systems-implications-ml-systems-engineers-781e">Implications for ML Systems Engineers</a></li>
  <li><a href="#sec-agi-systems-next-decade-systems-perspective" id="toc-sec-agi-systems-next-decade-systems-perspective" class="nav-link" data-scroll-target="#sec-agi-systems-next-decade-systems-perspective">The Next Decade: A Systems Engineering Perspective</a></li>
  <li><a href="#sec-agi-systems-engineering-foundations-uncertain-future" id="toc-sec-agi-systems-engineering-foundations-uncertain-future" class="nav-link" data-scroll-target="#sec-agi-systems-engineering-foundations-uncertain-future">Engineering Foundations for an Uncertain Future</a></li>
  <li><a href="#sec-agi-systems-common-fallacies-pitfalls" id="toc-sec-agi-systems-common-fallacies-pitfalls" class="nav-link" data-scroll-target="#sec-agi-systems-common-fallacies-pitfalls">Common Fallacies and Engineering Pitfalls</a>
  <ul class="collapse">
  <li><a href="#sec-agi-systems-biological-intelligence-design-template" id="toc-sec-agi-systems-biological-intelligence-design-template" class="nav-link" data-scroll-target="#sec-agi-systems-biological-intelligence-design-template">Biological Intelligence as a Design Template</a></li>
  </ul></li>
  <li><a href="#sec-agi-systems-implications-ml-engineers-6c31" id="toc-sec-agi-systems-implications-ml-engineers-6c31" class="nav-link" data-scroll-target="#sec-agi-systems-implications-ml-engineers-6c31">Implications for ML Engineers</a></li>
  <li><a href="#sec-agi-systems-summary-297d" id="toc-sec-agi-systems-summary-297d" class="nav-link" data-scroll-target="#sec-agi-systems-summary-297d">Summary</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers">Self-Check Answers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/frontiers/frontiers.html">Frontiers of ML Systems</a></li><li class="breadcrumb-item"><a href="../../../contents/core/frontiers/frontiers.html">AGI Systems</a></li></ol></nav></header>




<section id="sec-agi-systems" class="level1 page-columns page-full">
<h1>AGI Systems</h1>
<div class="{layout-narrow} page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="">
<p><em>DALL·E 3 Prompt: A futuristic visualization showing the evolution from current ML systems to AGI. The image depicts a technical visualization with three distinct zones: in the foreground, familiar ML components like neural networks, GPUs, and data pipelines; in the middle ground, emerging systems like large language models and multi-agent architectures forming interconnected constellations; and in the background, a luminous horizon suggesting AGI. The scene uses a gradient from concrete technical blues and greens in the foreground to abstract golden and white light at the horizon. Circuit patterns and data flows connect all elements, showing how today’s building blocks evolve into tomorrow’s intelligence. The style is technical yet aspirational, suitable for an advanced textbook.</em></p>
</div></div><p> <img src="images/png/cover_frontiers.png" class="img-fluid"></p>
</div>
<section id="purpose" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="purpose">Purpose</h2>
<p><em>Why must machine learning systems practitioners understand emerging trends and anticipate technological evolution rather than simply mastering current implementations?</em></p>
<p>Machine learning systems operate in a rapidly evolving technological landscape where yesterday’s cutting-edge approaches become tomorrow’s legacy systems, demanding practitioners who can anticipate and adapt to fundamental shifts. Unlike mature engineering disciplines, ML systems face continuous disruption from algorithmic breakthroughs, hardware advances, and changing computational paradigms that reshape system architecture requirements. Understanding emerging trends enables engineers to make forward-looking design decisions that extend system lifespans, avoid technological dead ends, and position infrastructure for future capabilities. This anticipatory mindset becomes critical as organizations invest heavily in ML systems expected to operate for years while the underlying technology continues evolving at unprecedented rates. By studying frontier developments, practitioners develop the strategic thinking necessary to build adaptive systems, evaluate emerging technologies against current implementations, and make informed decisions about when and how to incorporate innovations into production environments.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Map current state-of-the-art systems (LLMs, multimodal models) to core concepts from previous chapters</p></li>
<li><p>Understand how AGI represents a systems integration challenge beyond algorithmic innovation</p></li>
<li><p>Identify technical barriers between current ML systems and AGI through an engineering lens</p></li>
<li><p>Analyze compound AI systems as practical pathways combining specialized components</p></li>
<li><p>Evaluate emerging paradigms (state space models, neuromorphic computing) for future architectures</p></li>
<li><p>Apply systems thinking to understand the evolution from narrow AI to general intelligence</p></li>
</ul>
</div>
</div>
</section>
<section id="sec-agi-systems-current-revolution-2025-snapshot-894e" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-current-revolution-2025-snapshot-894e">Overview</h2>
<p>The year 2025 marks an inflection point in artificial intelligence capabilities. Large Language Models<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> including GPT-4, Claude, and Gemini demonstrate competencies previously considered unattainable: code generation, visual analysis, multi-step reasoning, and natural language interaction. These capabilities result from the transformer architectures detailed in <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong>, scaled through the distributed training methodologies of <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>. These systems emerge from systematic integration of established machine learning components rather than algorithmic breakthroughs.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<strong>Large Language Models (LLMs)</strong>: Neural networks trained on internet-scale text corpora, typically containing &gt;10 billion parameters. GPT-3 (175B parameters) required approximately 3.14 × 10²³ floating-point operations for training. GPT-4’s exact size remains undisclosed but estimates suggest over 1 trillion parameters distributed across multiple expert models.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;<strong>ChatGPT User Adoption</strong>: Reached 100 million monthly active users in January 2023, 2 months after launch, the fastest consumer application adoption in history. For comparison: TikTok required 9 months, Instagram 2.5 years. This growth necessitated rapid scaling of inference infrastructure from hundreds to tens of thousands of GPUs.</p></div></div><p>The rapid practical deployment validates this systems integration approach. ChatGPT’s acquisition of 100 million users within two months<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> represents successful systems integration rather than algorithmic innovation. The transformer architecture scales to hundreds of billions of parameters through architectural principles established in <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong>. Distributed training methodologies from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong> support model optimization across thousands of accelerators. Model compression techniques from <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong> reduce inference costs to economically viable levels. Operational infrastructure from <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong> maintains system reliability for millions of concurrent users.</p>
<p>This engineering achievement validates Sutton’s “bitter lesson”<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a><span class="citation" data-cites="sutton2019bitter">(<a href="#ref-sutton2019bitter" role="doc-biblioref">Sutton 2019</a>)</span>: computational scale coupled with general methods consistently outperforms specialized algorithms. These capabilities emerge through engineering at scale, transforming quantitative improvements into qualitative capability shifts through phase transitions<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<strong>Sutton’s Bitter Lesson</strong>: Articulated by Rich Sutton (University of Alberta) in 2019, stating that methods leveraging computation (search, learning) consistently outperform human knowledge-based approaches over 70 years of AI history. Examples: Deep Blue’s brute-force search defeated chess expertise (1997), AlphaGo’s Monte Carlo tree search exceeded Go intuition (2016), transformer scaling surpassed linguistic rules (2020). Each breakthrough involved more computation, not more human insight.</p></div><div id="ref-sutton2019bitter" class="csl-entry" role="listitem">
Sutton, Richard S. 2019. <span>“The Bitter Lesson.”</span> <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a>.
</div><div id="fn4"><p><sup>4</sup>&nbsp;<strong>Phase Transition</strong>: In physics, abrupt changes in system properties at critical thresholds (like water becoming ice at 0°C). In neural networks, refers to sudden appearance of capabilities at specific model scales—abilities appear rapidly rather than gradually. Examples: GPT models gain arithmetic ability around 10B parameters, reasoning around 100B parameters. These discontinuous jumps suggest major changes in network dynamics.</p></div><div id="ref-wei2022emergent" class="csl-entry" role="listitem">
Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. <span>“Emergent Abilities of Large Language Models.”</span> <em>Transactions on Machine Learning Research</em>, June. <a href="http://arxiv.org/abs/2206.07682v2">http://arxiv.org/abs/2206.07682v2</a>.
</div></div><p>Contemporary systems demonstrate capabilities that seemed impossible just years ago, achieved through engineering at scale rather than algorithmic breakthroughs. These phase transitions manifest as emergent abilities that appear suddenly at specific parameter thresholds: chain-of-thought reasoning <span class="citation" data-cites="wei2022emergent">(<a href="#ref-wei2022emergent" role="doc-biblioref">Wei et al. 2022</a>)</span> materializes for certain reasoning tasks around 60-100B parameters like a phase transition in physics. Below this threshold, models show near-zero reasoning performance; above it, they achieve 50-80% accuracy on complex logical problems without explicit training on reasoning tasks. GPT-3 exhibits 150+ such emergent abilities absent in GPT-2, including arithmetic, translation, and code generation, appearing discontinuously rather than gradually. These scaling phenomena validate the distributed training approaches covered in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>, where coordinating computation across thousands of accelerators enables reaching parameter thresholds.</p>
<p>This scaling enables few-shot learning that transforms machine learning paradigms. Traditional systems required thousands of examples to learn new tasks; modern LLMs adapt to novel problems with just 1-10 demonstrations in their context window. The implications for systems design are significant: rather than training task-specific models, engineers build general systems that adapt dynamically to user needs.</p>
<p>Multimodal processing has unified previously separate research domains. Contemporary systems process text, images, audio, and video through shared architectures, eliminating the complex pipeline engineering that once connected separate vision and language models. This unification simplifies system architecture while supporting richer applications.</p>
<p>The integration extends to tool use, where models learn to invoke external APIs, execute code, and interact with environments. Rather than functioning as isolated language processors, these systems orchestrate digital ecosystems by calling search engines for information, running calculations through code interpreters, and coordinating with other software tools.</p>
<p>Constitutional AI<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> enables these capabilities through iterative self-refinement using principle-based feedback mechanisms. Models critique their own outputs, identify improvements, and generate better responses through automated feedback loops. This transforms quality assurance from a human bottleneck into a scalable system component.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<strong>Constitutional AI</strong>: A training method developed by Anthropic where models learn to improve their own outputs by critiquing responses against a set of principles. This technique reduces harmful content while maintaining helpfulness, detailed in the training section of this chapter.</p></div></div><p>These capabilities represent discontinuous improvements rather than incremental refinements through phase transitions enabled by engineering at scale.</p>
<div id="quiz-question-sec-agi-systems-current-revolution-2025-snapshot-894e" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.1</strong></summary><div>
<ol type="1">
<li><p>What is a key factor that distinguishes the capabilities of large language models like GPT-4 from previous AI models?</p>
<ol type="a">
<li>Fundamental algorithmic breakthroughs</li>
<li>Systematic integration of established components</li>
<li>Reduced computational requirements</li>
<li>Specialized algorithms for specific tasks</li>
</ol></li>
<li><p>Explain how the concept of ‘emergent capabilities’ is demonstrated in large language models.</p></li>
<li><p>True or False: The rapid adoption of ChatGPT was primarily due to novel algorithmic innovations.</p></li>
<li><p>How do modern AI systems achieve few-shot learning capabilities?</p>
<ol type="a">
<li>Through emergent capabilities at scale</li>
<li>By training on large datasets with many examples</li>
<li>By using specialized models for each task</li>
<li>Through manual tuning of model parameters</li>
</ol></li>
<li><p>In a production system, what are the implications of integrating multimodal processing capabilities?</p></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-current-revolution-2025-snapshot-894e" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-agi-vision-intelligence-systems-problem-2b44">The AGI Vision: Intelligence as a Systems Problem</h2>
<div id="callout-definition*-1.1" class="callout callout-definition" title="Definition of Artificial General Intelligence (AGI)">
<p></p><details class="callout-definition fbx-default closebutton" open=""><summary><strong>Definition: </strong>Definition of Artificial General Intelligence (AGI)</summary><div><strong>Artificial General Intelligence (AGI)</strong> refers to computational systems that match or exceed human cognitive capabilities across <em>all domains of knowledge and reasoning</em>. Unlike narrow AI systems that excel at specific tasks, AGI systems can <em>generalize across diverse problem domains</em> without task-specific training, <em>transfer knowledge</em> from one domain to apply insights in completely different areas, and <em>learn continuously</em> from limited examples and experience. AGI systems demonstrate <em>abstract reasoning</em> about novel situations never encountered during training and <em>adapt flexibly</em> to changing goals and environments. The key distinction from current AI lies in <em>general applicability</em>: an AGI system should be capable of learning and excelling at any cognitive task a human can perform, from scientific research to creative problem-solving to strategic planning.<p></p>
</div></details>
</div>
<p>Building on this comprehensive definition, foundational AGI research by <span class="citation" data-cites="goertzel2007artificial">Goertzel and Pennachin (<a href="#ref-goertzel2007artificial" role="doc-biblioref">2007</a>)</span> characterized AGI as “the ability to achieve complex goals in complex environments using limited computational resources.” Intelligence transcends performance metrics. True intelligence requires understanding the difference between memorization and reasoning, between correlation and causation, between pattern completion and genuine creativity<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. Current systems excel at statistical pattern matching but struggle with tasks requiring genuine understanding of physical causality, intentionality, or symbolic abstraction.</p>
<div class="no-row-height column-margin column-container"><div id="ref-goertzel2007artificial" class="csl-entry" role="listitem">
Goertzel, Ben, and Cassio Pennachin. 2007. <em>Artificial General Intelligence</em>. Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-540-68677-4">https://doi.org/10.1007/978-3-540-68677-4</a>.
</div><div id="fn6"><p><sup>6</sup>&nbsp;<strong>Intelligence vs.&nbsp;Performance</strong>: Intelligence involves understanding underlying principles rather than memorizing patterns. Humans generalize from few examples through causal reasoning, while current AI requires massive datasets for statistical correlation. The symbol grounding problem asks how abstract symbols connect to embodied experience, a challenge absent in pure language models.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;<strong>Energy-Based Models (EBMs)</strong>: Unlike discriminative models that output single predictions, EBMs learn energy functions where probable outcomes have low energy. This enables modeling multiple solutions, handling uncertainty, and optimization-based inference. Applications include molecular design, theorem proving, and multi-step reasoning where multiple valid solutions exist.</p></div></div><p>Energy-based models provide a unifying theoretical framework for intelligence that goes beyond current probabilistic approaches<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. Unlike traditional models that directly output predictions, energy-based models learn to assign lower energy (higher preference) to more probable or desirable outcomes. This framework naturally handles uncertainty, supports multiple plausible solutions, and enables reasoning through optimization rather than just feedforward computation. The approach shows promise for handling the multi-modal, multi-solution reasoning required for AGI, though current implementations remain computationally intensive.</p>
<p>Artificial General Intelligence presents a major systems engineering challenge. While narrow AI systems demonstrate superhuman performance in constrained domains (defeating world champions at chess and Go, diagnosing medical conditions with greater accuracy than specialists, generating human-quality text), AGI requires integration of perception, reasoning, planning, learning, and action within unified architectures capable of unrestricted adaptation.</p>
<p>Human intelligence encompasses multiple integrated cognitive systems: - <strong>Multimodal perception</strong>: Integrating sight, sound, touch, and other senses into coherent world models - <strong>Working memory</strong>: Maintaining and manipulating information dynamically with ~7 item capacity - <strong>Long-term knowledge</strong>: Storing and retrieving vast amounts of information with associative access patterns - <strong>Reasoning</strong>: Both logical deduction and intuitive pattern recognition through fast/slow thinking systems - <strong>Planning</strong>: Strategizing across multiple time horizons from milliseconds to decades - <strong>Learning</strong>: Continuously improving from limited examples through few-shot adaptation - <strong>Social intelligence</strong>: Understanding and modeling other agents’ beliefs, desires, and intentions - <strong>Creativity</strong>: Generating novel solutions through conceptual combination and analogical reasoning - <strong>Metacognition</strong>: Self-awareness and understanding of one’s own thinking processes - <strong>Symbol grounding</strong>: Connecting abstract symbols to embodied experience and causal understanding</p>
<p>Integrating these cognitive capabilities, human intelligence operates through world models that capture causal relationships, support counterfactual reasoning, and enable planning in novel environments. These capabilities emerge from learning systems that extract structure from minimal data through strong inductive biases and self-supervised prediction.</p>
<p>No singular algorithm or architecture encompasses these capabilities. AGI emergence requires integration of specialized subsystems, an engineering challenge addressed throughout this textbook, from the foundational architectures in <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong> to the system integration principles in <strong><a href="../core/ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong>.</p>
<p>Contemporary AGI approaches reflect tension between different beliefs about how intelligence emerges. The scaling hypothesis argues that current transformer architectures will achieve AGI through larger parameters, more data, and greater compute <span class="citation" data-cites="kaplan2020scaling">(<a href="#ref-kaplan2020scaling" role="doc-biblioref">Kaplan et al. 2020</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kaplan2020scaling" class="csl-entry" role="listitem">
Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. <span>“Scaling Laws for Neural Language Models.”</span> <em>arXiv Preprint arXiv:2001.08361</em>, January. <a href="http://arxiv.org/abs/2001.08361v1">http://arxiv.org/abs/2001.08361v1</a>.
</div><div id="fn8"><p><sup>8</sup>&nbsp;<strong>AGI Compute Requirements</strong>: Two approaches estimate the computational scale for AGI training. First, biological baseline: the human brain processes ~10¹⁵ operations/second over 20 years of learning, totaling 6.3 × 10²³ operations. Second, scaling laws: extrapolating Chinchilla’s C ∝ N^1.3 relationship for a hypothetical 100-trillion parameter AGI model suggests 4.98 × 10²⁶ FLOPs, reduced to 2.5 × 10²⁶ FLOPs with 10× efficiency improvements. These estimates carry significant uncertainty (±1 order of magnitude) depending on architectural breakthroughs.</p></div><div id="fn9"><p><sup>9</sup>&nbsp;<strong>AGI Infrastructure Scale Engineering Analysis</strong>: <strong>GPU calculation</strong>: 2.5 × 10²⁶ FLOPs ÷ (1,000 × 10¹² FLOPS per H100) = 2.5 × 10¹¹ GPU-seconds total. <strong>Time conversion</strong>: 2.5 × 10¹¹ ÷ (365 × 24 × 3600 seconds/year) ≈ 7,900 GPU-years. <strong>For 1-year training</strong>: 175,000 H100s running continuously. <strong>Power calculation</strong>: 175,000 GPUs × 700W + 30% cooling overhead = 159 MW total consumption. <strong>Cost breakdown</strong>: 175,000 × $30,000/GPU = $5.25B hardware + $15B infrastructure + $10B power (3 years) + $20B operational = $52B total. <strong>Network bandwidth</strong>: 175,000 GPUs × 900 GB/s NVLink = 158 PB/s bisection bandwidth requiring 100,000+ optical links. <strong>Memory requirements</strong>: 175,000 × 80GB HBM = 14 petabytes active parameter storage. Post-Moore’s Law efficiency gains (neuromorphic 100×, quantum-hybrid 10× for optimization) could reduce total requirements to $5-10B.</p></div></div><p>From an engineering perspective, AGI training may require 2.5 × 10²⁶ FLOPs<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, representing a 250× increase over GPT-4’s estimated compute. At current H100 efficiency, this demands 175,000 GPUs running continuously for one year, consuming 122 MW power and requiring $52 billion in hardware costs<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<p>This scale leverages every system covered in this textbook: distributed training from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>, hardware acceleration from <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>, data pipelines from <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>, and operational infrastructure from <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>. The magnitude drives exploration of post-Moore’s Law architectures: 3D chip stacking, optical interconnects, processing-in-memory, neuromorphic computing, and quantum-classical hybrid systems.</p>
<p>Pure scaling may hit fundamental limits. This realization drives hybrid architectures that combine neural networks’ pattern recognition with symbolic systems’ logical reasoning <span class="citation" data-cites="alphageometry2024">(<a href="#ref-alphageometry2024" role="doc-biblioref">Trinh et al. 2024</a>)</span>. Rather than expecting transformers to learn everything from scratch, these systems integrate external memory, specialized reasoning modules, and structured knowledge representations<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. The engineering challenge requires framework infrastructure from <strong><a href="../core/frameworks/frameworks.html#sec-ai-frameworks">Chapter 5: AI Frameworks</a></strong> and workflow orchestration from <strong><a href="../core/workflow/workflow.html#sec-ai-workflow">Chapter 19: AI Workflow</a></strong> to coordinate these heterogeneous components seamlessly.</p>
<div class="no-row-height column-margin column-container"><div id="ref-alphageometry2024" class="csl-entry" role="listitem">
Trinh, Trieu H., Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. 2024. <span>“Solving Olympiad Geometry Without Human Demonstrations.”</span> <em>Nature</em> 625 (7995): 476–82. <a href="https://doi.org/10.1038/s41586-023-06747-5">https://doi.org/10.1038/s41586-023-06747-5</a>.
</div><div id="fn10"><p><sup>10</sup>&nbsp;<strong>Neurosymbolic AI</strong>: Combines neural networks’ pattern recognition with symbolic reasoning’s logical manipulation. Gary Marcus coined the term in 2020. Examples include Google’s Neural Module Networks (2016), MIT’s Neural Logic Machines (2017), and IBM’s AlphaGeometry (2024) which solved 25 of 30 International Mathematical Olympiad geometry problems by combining neural theorem guidance with symbolic proof search.</p></div><div id="ref-brooks1986robust" class="csl-entry" role="listitem">
Brooks, R. 1986. <span>“A Robust Layered Control System for a Mobile Robot.”</span> <em>IEEE Journal on Robotics and Automation</em> 2 (1): 14–23. <a href="https://doi.org/10.1109/jra.1986.1087032">https://doi.org/10.1109/jra.1986.1087032</a>.
</div><div id="ref-pfeifer2007body" class="csl-entry" role="listitem">
Pfeifer, Rolf, and Josh Bongard. 2006. <em>How the Body Shapes the Way We Think: A New View of Intelligence</em>. The MIT Press. <a href="https://doi.org/10.7551/mitpress/3585.001.0001">https://doi.org/10.7551/mitpress/3585.001.0001</a>.
</div><div id="ref-rt2023robotics" class="csl-entry" role="listitem">
Brohan, Anthony, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, et al. 2023. <span>“RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control,”</span> July. <a href="http://arxiv.org/abs/2307.15818v1">http://arxiv.org/abs/2307.15818v1</a>.
</div></div><p>A third school argues that intelligence requires embodied interaction with the world <span class="citation" data-cites="brooks1986robust pfeifer2007body">(<a href="#ref-brooks1986robust" role="doc-biblioref">Brooks 1986</a>; <a href="#ref-pfeifer2007body" role="doc-biblioref">Pfeifer and Bongard 2006</a>)</span>. Drawing from decades of robotics research, this approach suggests that abstract reasoning emerges from grounding in physical or simulated environments. These systems emphasize on-device learning from <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong> and edge deployment architectures that enable real-time interaction. The recent success of <span class="citation" data-cites="rt2023robotics">Brohan et al. (<a href="#ref-rt2023robotics" role="doc-biblioref">2023</a>)</span> in transferring web knowledge to robotic control demonstrates early progress, though the systems engineering challenges of reliable embodied AI remain substantial.</p>
<p>Multi-agent systems propose that intelligence emerges from interactions between specialized agents rather than monolithic models<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. Like distributed software systems, these approaches require robust operational infrastructure from <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong> and distributed systems expertise. OpenAI’s hide-and-seek agents <span class="citation" data-cites="baker2019emergent">(<a href="#ref-baker2019emergent" role="doc-biblioref">Baker et al. 2019</a>)</span> developed unexpected strategies through competition, while projects like AutoGPT <span class="citation" data-cites="autogpt2023">(<a href="#ref-autogpt2023" role="doc-biblioref">Richards et al. 2023</a>)</span> demonstrate early autonomous capabilities, though they remain limited by context windows and error accumulation.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;<strong>Multi-Agent Intelligence</strong>: <span class="citation" data-cites="baker2019emergent">Baker et al. (<a href="#ref-baker2019emergent" role="doc-biblioref">2019</a>)</span> hide-and-seek agents developed unexpected strategies through competition. <span class="citation" data-cites="autogpt2023">Richards et al. (<a href="#ref-autogpt2023" role="doc-biblioref">2023</a>)</span> and <span class="citation" data-cites="babbage2023">Nakajima (<a href="#ref-babbage2023" role="doc-biblioref">2022</a>)</span> demonstrate early autonomous agent capabilities, though remain limited by context windows and error accumulation.</p><div id="ref-baker2019emergent" class="csl-entry" role="listitem">
Baker, Bowen, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew, and Igor Mordatch. 2019. <span>“Emergent Tool Use from Multi-Agent Autocurricula.”</span> <em>International Conference on Learning Representations</em>, September. <a href="http://arxiv.org/abs/1909.07528v2">http://arxiv.org/abs/1909.07528v2</a>.
</div><div id="ref-autogpt2023" class="csl-entry" role="listitem">
Richards, Toran Bruce et al. 2023. <span>“AutoGPT: An Autonomous GPT-4 Experiment.”</span> <a href="https://github.com/Significant-Gravitas/AutoGPT">https://github.com/Significant-Gravitas/AutoGPT</a>.
</div><div id="ref-babbage2023" class="csl-entry" role="listitem">
Nakajima, Makoto. 2022. <span>“Foreword.”</span> <em>Chemical and Pharmaceutical Bulletin</em> 70 (9): 594–94. <a href="https://doi.org/10.1248/cpb.c22-ctf7009">https://doi.org/10.1248/cpb.c22-ctf7009</a>.
</div></div></div><div id="quiz-question-sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.2</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes Artificial General Intelligence (AGI)?</p>
<ol type="a">
<li>A system that excels at a specific task using task-specific training.</li>
<li>A system that requires extensive data to perform well in a narrow domain.</li>
<li>A system capable of generalizing across diverse problem domains without task-specific training.</li>
<li>A system that uses symbolic reasoning exclusively to solve problems.</li>
</ol></li>
<li><p>Explain why AGI is considered a formidable systems engineering challenge.</p></li>
<li><p>Order the following cognitive capabilities that need to be integrated for AGI: (1) Reasoning, (2) Multimodal perception, (3) Planning, (4) Learning.</p></li>
<li><p>Which approach suggests that intelligence requires embodied interaction with the world?</p>
<ol type="a">
<li>Scaling hypothesis</li>
<li>Neurosymbolic AI</li>
<li>Multi-agent systems</li>
<li>Embodied cognition</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-agi-systems-compound-ai-framework" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-compound-ai-framework">The Compound AI Systems Framework</h2>
<p>The trajectory toward AGI favors “Compound AI Systems”: multiple specialized components operating in concert rather than monolithic models. This architectural paradigm represents the organizing principle for understanding how today’s building blocks assemble into tomorrow’s intelligent systems.</p>
<p>Modern AI assistants exemplify this compound approach through integration of specialized subsystems. Each component leverages distinct engineering principles covered throughout this textbook: language models employ architectures from model design chapters, code interpreters require secure execution environments following security principles, web search demands efficient data pipelines, memory systems necessitate storage and retrieval engineering, and safety filters implement responsible AI principles. The central orchestrator applies workflow orchestration techniques to coordinate these heterogeneous components seamlessly.</p>
<p>This compound approach provides five advantages over monolithic alternatives: modularity enables independent component updates without retraining entire systems, specialization allows task-specific optimization for each module achieving better performance than general-purpose alternatives, interpretability emerges through decomposable decision paths where you can trace exactly which components contributed to each output, scalability supports capability addition without complete retraining as new tools integrate into existing frameworks, and safety benefits from multi-layer validation where multiple specialized components verify and constrain each other’s outputs. These advantages establish the foundation for the building blocks we explore next.</p>
</section>
<section id="sec-agi-systems-building-blocks-compound-intelligence" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-building-blocks-compound-intelligence">Building Blocks for Compound Intelligence</h2>
<p>The evolution from monolithic models to compound AI systems requires fundamental advances in how we engineer data, integrate components, and scale infrastructure. These building blocks represent the critical enablers that will determine whether compound intelligence can achieve the flexibility and capability needed for artificial general intelligence. Each component addresses specific limitations of current approaches while creating new engineering challenges that span data availability, system integration, and computational scaling.</p>
<section id="sec-agi-systems-data-engineering-scale" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-data-engineering-scale">Data Engineering at Scale</h3>
<p>Data engineering represents the first and most fundamental building block. Compound AI systems require sophisticated data engineering to feed their specialized components, yet machine learning faces a data availability crisis. The scale of this challenge becomes apparent when examining actual model requirements: GPT-3 consumed 300 billion tokens (as reported by OpenAI), GPT-4 likely used over 10 trillion tokens (based on scaling law extrapolations<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>), while research estimates suggest only 4.6-17 trillion high-quality tokens exist on the entire internet<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. This represents a fundamental bottleneck: at current consumption rates, traditional web-scraped text data may be exhausted by 2026, forcing exploration of synthetic data generation and alternative scaling paths. This limitation directly challenges the scaling hypothesis that model capabilities improve predictably with more data and compute.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;<strong>Chinchilla Scaling Laws</strong>: Discovered by DeepMind in 2022, optimal model performance requires balanced scaling of parameters N and training tokens D following N ∝ D^0.74. Previous models were under-trained: GPT-3 (175B parameters, 300B tokens) should have used 4.6 trillion tokens for optimal performance. Chinchilla (70B parameters, 1.4T tokens) outperformed GPT-3 despite being 2.5× smaller, proving data quality matters more than model size.</p></div><div id="fn13"><p><sup>13</sup>&nbsp;<strong>Data Availability Analysis</strong>: GPT-3’s 300B token consumption comes from OpenAI’s technical report. GPT-4 estimates derive from Chinchilla scaling laws requiring ~13T tokens for optimal training of a ~1T parameter model. Internet data estimates come from multiple studies: Villalobos et al.&nbsp;(2022) estimate 4.6T high-quality tokens, while broader estimates reach 17T including lower-quality text. Timeline projections assume continued exponential scaling at current rates.</p></div></div><p>Three data engineering approaches address this challenge through compound system design:</p>
<section id="sec-agi-systems-self-supervised-components" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-agi-systems-self-supervised-components">Self-Supervised Learning Components</h4>
<p>Self-supervised learning forms the backbone of compound AI systems by enabling specialized components to learn from unlabeled data, and represents the most promising path toward AGI. Unlike supervised learning that requires explicit labels, self-supervised learning extracts knowledge from data structure itself. Biological brains process approximately 10¹¹ bits per second but receive fewer than 10⁴ bits per second of labeled supervision, with the remaining 99.99% coming from self-supervised pattern extraction.</p>
<p>Building on this biological insight, Yann LeCun argues that self-supervised learning constitutes the “dark matter” of intelligence—the vast majority of learning that occurs without explicit supervision <span class="citation" data-cites="lecun2022path">(<a href="#ref-lecun2022path" role="doc-biblioref">LeCun 2022</a>)</span>. Current autoregressive language models represent only a primitive form of self-supervised learning, predicting the next token in a sequence. True AGI will emerge from more sophisticated self-supervised methods that learn world models: internal representations of how the world works that enable prediction, planning, and reasoning.</p>
<div class="no-row-height column-margin column-container"><div id="ref-lecun2022path" class="csl-entry" role="listitem">
LeCun, Yann. 2022. <span>“A Path Towards Autonomous Machine Intelligence.”</span> <em>OpenReview</em>. <a href="https://openreview.net/pdf?id=BZ5a1r-kVsf">https://openreview.net/pdf?id=BZ5a1r-kVsf</a>.
</div><div id="fn14"><p><sup>14</sup>&nbsp;<strong>Joint Embedding Predictive Architecture (JEPA)</strong>: Proposed by Yann LeCun at Meta AI in 2022, JEPA learns to predict in abstract representation space rather than raw pixels. Unlike autoregressive models predicting next tokens, JEPA predicts representations of future states. V-JEPA (Video JEPA, 2024) learns object permanence and physics from video without labels, achieving 3× better sample efficiency than pixel prediction methods.</p></div></div><p>Addressing this need, the Joint Embedding Predictive Architecture (JEPA)<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> framework enables this approach by learning abstract representations rather than predicting raw sensory data. When shown a video of a ball rolling, rather than predicting every pixel in the next frame, the system learns representations encoding object persistence, motion dynamics, and causal relationships. This abstraction enables more efficient learning and better generalization, making it ideal for specialized components in compound systems.</p>
<p>Current language models excel at next-token prediction but struggle with planning and causal reasoning because they lack genuine world models. Self-supervised learning offers a path beyond autoregressive generation toward predictive intelligence that understands causality. Instead of generating text tokens sequentially, future AGI systems will learn to predict the consequences of actions in abstract representation spaces, enabling true planning and reasoning capabilities.</p>
<p>This paradigm shift requires new architectures that can learn hierarchical world models from sensory data, systems that can efficiently train on continuous streams of unlabeled multimodal data, and frameworks that enable compositional reasoning in learned representation spaces. The engineering challenges involve building systems that can process petabytes of multimodal data to extract compressed world models capturing the essential structure of reality.</p>
</section>
<section id="sec-agi-systems-synthetic-data-generation" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-synthetic-data-generation">Synthetic Data Generation</h4>
<p>Compound systems generate their own training data through guided synthesis rather than relying solely on human-generated content. This approach seems paradoxical: how can models learn from themselves without degrading? The answer lies in guided generation and verification between specialized components.</p>
<p>Microsoft’s Phi-2 (2.7B parameters) matches GPT-3.5 (175B) performance using primarily synthetic data, while Anthropic generates millions of constitutional AI examples through iterative refinement. Constitutional AI demonstrates this approach: one component generates responses, another critiques them against principles, and a third produces improved versions. Each iteration creates training examples that exceed original quality.</p>
<p>This compound approach fundamentally shifts data engineering from cleaning existing data to synthesizing optimal training examples. Microsoft’s Phi models use GPT-4 to generate textbook-quality explanations, creating cleaner training data than web scraping. For compound systems, this enables specialized data generation components that create domain-specific training examples for other system components.</p>
</section>
<section id="sec-agi-systems-selfplay-components" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-selfplay-components">Self-Play Components</h4>
<p>AlphaGo Zero demonstrated a key principle for compound systems: components can bootstrap expertise through self-competition without human data. Starting from random play, it achieved superhuman Go performance in 72 hours purely through self-play reinforcement learning.</p>
<p>This principle extends beyond games to create specialized system components. OpenAI’s debate models argue both sides to find truth, Anthropic’s models critique their own outputs, and DeepMind’s AlphaCode generates millions of programs and tests them. Each interaction generates new training data while exploring solution spaces.</p>
<p>Implementing this approach in compound systems requires data pipelines that handle dynamic generation: managing continuous streams of self-generated examples, filtering for quality, and preventing mode collapse. The engineering challenge involves orchestrating multiple self-playing components while maintaining diversity and preventing system-wide convergence to suboptimal patterns.</p>
</section>
<section id="sec-agi-systems-webscale-data-processing" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-webscale-data-processing">Web-Scale Data Processing</h4>
<p>High-quality curated text may be limited, but self-supervised learning, synthetic generation, and self-play create new data sources. The internet’s long tail contains untapped resources for compound systems: GitHub repositories, academic papers, technical documentation, and specialized forums. Common Crawl contains 250 billion pages, GitHub hosts 200M+ repositories, arXiv contains 2M+ papers, and Reddit has 3B+ comments, combining to over 100 trillion tokens of varied quality. The challenge lies in extraction and quality assessment rather than availability.</p>
<p>Modern compound systems employ sophisticated filtering pipelines (<a href="#fig-frontier-data-pipeline" class="quarto-xref">Figure&nbsp;1</a>) where specialized components handle different aspects: deduplication removes 30-60% redundancy in web crawls, quality classifiers trained on curated data identify high-value content, and domain-specific extractors process code, mathematics, and scientific text. GPT-4’s training likely processed over 100 trillion raw tokens to extract 10-13 trillion training tokens, with deduplication reducing data by 30% and quality filtering removing 80-90%.</p>
<p>This represents a shift from batch processing to continuous, adaptive data curation where multiple specialized components work together to transform raw internet data into training-ready content.</p>
<div id="fig-frontier-data-pipeline" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-frontier-data-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="282c72d737903d7dea9cccae8e2f6403f5fea0c8.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Data Engineering Pipeline for Frontier Models: The multi-stage pipeline transforms 100+ trillion raw tokens into 10-13 trillion high-quality training tokens. Each stage applies increasingly sophisticated filtering, with synthetic generation augmenting the final dataset. This pipeline represents the evolution from simple web scraping to intelligent data curation systems."><img src="frontiers_files/mediabag/282c72d737903d7dea9cccae8e2f6403f5fea0c8.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-frontier-data-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>Data Engineering Pipeline for Frontier Models</strong>: The multi-stage pipeline transforms 100+ trillion raw tokens into 10-13 trillion high-quality training tokens. Each stage applies increasingly sophisticated filtering, with synthetic generation augmenting the final dataset. This pipeline represents the evolution from simple web scraping to intelligent data curation systems.
</figcaption>
</figure>
</div>
<p>The pipeline in <a href="#fig-frontier-data-pipeline" class="quarto-xref">Figure&nbsp;1</a> reveals an important insight: the bottleneck isn’t data availability but processing capacity. Starting with 111.5 trillion raw tokens, aggressive filtering reduces this to just 10-13 trillion training tokens, with over 90% of data discarded. For ML engineers, this means that improving filter quality could be more impactful than gathering more raw data. A 10% improvement in the quality filter’s precision could yield an extra trillion high-quality tokens, equivalent to doubling the amount of books available.</p>
<p>These data engineering approaches (synthetic generation, self-play, and advanced harvesting) represent the first building block of compound AI systems. They transform data limitations from barriers into opportunities for innovation, with specialized components generating, filtering, and processing data streams continuously.</p>
<p>However, generating high-quality training data only addresses part of the compound systems challenge. The next building block involves architectural innovations that enable efficient computation across specialized components while maintaining system coherence.</p>
</section>
</section>
<section id="sec-agi-systems-dynamic-architectures-compound" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-dynamic-architectures-compound">Dynamic Architectures for Compound Systems</h3>
<p>Compound systems require dynamic approaches that can adapt computation based on task requirements and input characteristics. This section explores architectural innovations that enable efficient specialization through selective computation and sophisticated routing mechanisms. Mixture of experts and similar approaches allow systems to activate only relevant components for each task, improving computational efficiency while maintaining system capability.</p>
<section id="sec-agi-systems-specialization-selective-computation" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-specialization-selective-computation">Specialization Through Selective Computation</h4>
<p>Compound systems face an efficiency challenge: not all components need to activate for every task. A mathematics question requires different processing than language translation or code generation. Dense monolithic models waste computation by activating all parameters for every input, creating inefficiency that compounds at scale.</p>
<p>GPT-3 (175B parameters) activates all parameters for every token, requiring 350GB memory and 350 GFLOPs per token. Only 10-20% of parameters contribute meaningfully to any given prediction, suggesting 80-90% computational waste. This inefficiency motivates architectural designs that enable selective activation of system components.</p>
</section>
<section id="sec-agi-systems-expert-routing-compound" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-expert-routing-compound">Expert Routing in Compound Systems</h4>
<p>The Mixture of Experts (MoE) architecture demonstrates the compound systems principle at the model level: specialized components activated through intelligent routing. Rather than processing every input through all parameters, MoE models consist of multiple expert networks, each specializing in different problem types. A routing mechanism (learned gating function) determines which experts process each input, as illustrated in <a href="#fig-moe-routing" class="quarto-xref">Figure&nbsp;2</a>.</p>
<p>The router computes probabilities for each expert using learned linear transformations followed by softmax, typically selecting the top-2 experts per token. Load balancing losses ensure uniform expert utilization to prevent collapse to few specialists. This pattern extends naturally to compound systems where different models, tools, or processing pipelines are routed based on input characteristics.</p>
<p>As shown in <a href="#fig-moe-routing" class="quarto-xref">Figure&nbsp;2</a>, when a token enters the system, the router evaluates which experts are most relevant. For “2+2=”, the router assigns high weights (0.7) to arithmetic specialists while giving zero weight to vision or language experts. For “Bonjour means”, it activates translation experts instead. GPT-4 reportedly uses eight expert models of 220B parameters each, activating only two per token, reducing active computation to 280B parameters while maintaining 1.8T total capacity with 5-7x inference speedup.</p>
<p>This introduces systems challenges: load balancing across experts, preventing collapse where all routing converges to few experts, and managing irregular memory access patterns. For compound systems, these same challenges apply to routing between different models, databases, and processing pipelines, requiring sophisticated orchestration infrastructure.</p>
<div id="fig-moe-routing" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-moe-routing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="29e8575850a9c287d0c1f55fe5b358a4828df743.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Mixture of Experts (MoE) Routing: Conditional computation through learned routing enables efficient scaling to trillions of parameters. The router (gating function) determines which experts process each token, activating only relevant specialists. This sparse activation pattern reduces computational cost while maintaining model capacity, though it introduces load balancing and memory access challenges."><img src="frontiers_files/mediabag/29e8575850a9c287d0c1f55fe5b358a4828df743.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-moe-routing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <strong>Mixture of Experts (MoE) Routing</strong>: Conditional computation through learned routing enables efficient scaling to trillions of parameters. The router (gating function) determines which experts process each token, activating only relevant specialists. This sparse activation pattern reduces computational cost while maintaining model capacity, though it introduces load balancing and memory access challenges.
</figcaption>
</figure>
</div>
</section>
<section id="sec-agi-systems-external-memory-compound" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-agi-systems-external-memory-compound">External Memory for Compound Systems</h4>
<p>Beyond routing efficiency, compound systems require memory architectures that scale beyond individual model constraints. As detailed in <a href="#sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="quarto-xref">Section&nbsp;1.6</a>, transformers face quadratic memory scaling with sequence length, limiting knowledge access during inference and preventing long-context reasoning across system components.</p>
<p>Retrieval-Augmented Generation (RAG)<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> addresses this by creating external memory stores accessible to multiple system components. Instead of encoding all knowledge in parameters, specialized retrieval components query databases containing billions of documents, incorporating relevant information into generation processes. This transforms the architecture from purely parametric to hybrid parametric-nonparametric systems.</p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;<strong>Retrieval-Augmented Generation (RAG)</strong>: Introduced by Meta AI researchers in 2020, RAG combines parametric knowledge (stored in model weights) with non-parametric knowledge (retrieved from external databases). Facebook’s RAG system retrieves from 21M Wikipedia passages, enabling models to access current information without retraining. Modern RAG systems like ChatGPT plugins and Bing Chat handle billions of documents with sub-second retrieval latency.</p></div></div><p>For compound systems, this enables shared knowledge bases accessible to different specialized components, efficient similarity search across diverse content types, and coordinated retrieval that supports complex multi-step reasoning processes.</p>
</section>
<section id="sec-agi-systems-modular-reasoning-architectures" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-modular-reasoning-architectures">Modular Reasoning Architectures</h4>
<p>Multi-step reasoning exemplifies the compound systems advantage: breaking complex problems into verifiable components. While monolithic models can answer simple questions directly, multi-step problems produce compounding errors (90% accuracy per step yields only 59% overall accuracy for 5-step problems). GPT-3 exhibits 40-60% error rates on complex reasoning, primarily from intermediate step failures.</p>
<p>Chain-of-thought prompting and modular reasoning architectures address this through decomposition where different components handle different reasoning stages. Rather than generating answers directly, specialized components produce intermediate reasoning steps that verification components can check and correct. Chain-of-thought prompting improves GSM8K accuracy from 17.9% to 58.1%, with step verification reaching 78.2%.</p>
<p>This architectural approach, decomposing complex tasks across specialized components with verification, represents the core compound systems pattern: multiple specialists collaborating through structured interfaces rather than monolithic processing.</p>
<p>These innovations demonstrate the transition from static architectures toward dynamic compound systems that route computation, access external memory, and decompose reasoning across specialized components. This architectural foundation enables the sophisticated orchestration required for AGI-scale intelligence.</p>
<p>Dynamic architectures alone cannot achieve compound intelligence without aligned training processes. The third building block involves training methodologies that enable components to learn from interaction, align with human values, and improve continuously through deployment.</p>
</section>
</section>
<section id="sec-agi-systems-training-compound-intelligence" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-training-compound-intelligence">Training Compound Intelligence</h3>
<p>The development of compound systems requires sophisticated training methodologies that go beyond traditional machine learning approaches. This section examines how to train systems with multiple specialized components while ensuring alignment with human values and intentions. We explore how reinforcement learning from human feedback can be applied to compound architectures and how continuous learning enables these systems to improve through deployment and interaction.</p>
<section id="sec-agi-systems-alignment-across-components" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-alignment-across-components">Alignment Across Components</h4>
<p>Compound systems face an alignment challenge: each specialized component must align with human values while the orchestrator must coordinate these components appropriately. Traditional supervised learning creates a mismatch where models trained on internet text learn to predict what humans write, not what humans want. GPT-3 trained on web data completes “The Holocaust was” with historically accurate information 65% of the time, but also with denial or conspiracy theories 12% of the time, accurately reflecting web content distribution rather than truth.</p>
<p>For compound systems, misalignment in any component can compromise the entire system: a search component that retrieves biased information, a reasoning component that perpetuates harmful stereotypes, or a safety filter that fails to catch problematic content.</p>
</section>
<section id="sec-agi-systems-human-feedback-component-training" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-agi-systems-human-feedback-component-training">Human Feedback for Component Training</h4>
<p>Addressing these alignment challenges, Reinforcement Learning from Human Feedback (RLHF) addresses alignment through multi-stage training that compounds naturally to system-level alignment. Rather than training on text prediction alone, RLHF creates specialized components within the training pipeline itself.</p>
<p>The process exemplifies compound systems design: a generation component produces multiple responses to prompts, human evaluators rank these responses by quality (helpfulness, accuracy, safety), a reward modeling component learns to predict human preferences, and a reinforcement learning component fine-tunes the policy to maximize reward scores (<a href="#fig-rlhf-pipeline" class="quarto-xref">Figure&nbsp;3</a>). Each stage represents a specialized component with distinct engineering requirements.</p>
<div id="fig-rlhf-pipeline" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rlhf-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="a06ed192c580268bea1afc4a3559c82df70f9671.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: RLHF Training Pipeline: The three-stage process transforms base language models into aligned assistants. Stage 1 uses human demonstrations for initial fine-tuning. Stage 2 collects human preferences to train a reward model. Stage 3 applies reinforcement learning (PPO) to optimize for human preferences while preventing mode collapse through KL divergence penalties."><img src="frontiers_files/mediabag/a06ed192c580268bea1afc4a3559c82df70f9671.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rlhf-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>RLHF Training Pipeline</strong>: The three-stage process transforms base language models into aligned assistants. Stage 1 uses human demonstrations for initial fine-tuning. Stage 2 collects human preferences to train a reward model. Stage 3 applies reinforcement learning (PPO) to optimize for human preferences while preventing mode collapse through KL divergence penalties.
</figcaption>
</figure>
</div>
<p>The engineering complexity of <a href="#fig-rlhf-pipeline" class="quarto-xref">Figure&nbsp;3</a> is substantial. Each stage requires distinct infrastructure: Stage 1 needs demonstration collection systems, Stage 2 demands ranking interfaces that present multiple outputs side-by-side, and Stage 3 requires careful hyperparameter tuning to prevent the policy from diverging too far from the original model (the KL penalty shown). The feedback loop at the bottom represents continuous iteration, with models often going through multiple rounds of RLHF, each round requiring fresh human data to prevent overfitting to the reward model.</p>
<p>This approach yields dramatic improvements: InstructGPT with 1.3B parameters outperforms GPT-3 with 175B parameters in human evaluations<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>, demonstrating that alignment matters more than scale for user satisfaction. For ML engineers, this means that investing in alignment infrastructure can be more valuable than scaling compute: a 100x smaller aligned model outperforms a larger unaligned one.</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;<strong>RLHF Effectiveness</strong>: InstructGPT preferred over GPT-3 in 85% of comparisons despite being 100x smaller. Harmful output reduction: 90%. Hallucination reduction: 40%. User satisfaction increase: 72%.</p></div></div></section>
<section id="sec-agi-systems-constitutional-ai-principled-selfimprovement-0f15" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-agi-systems-constitutional-ai-principled-selfimprovement-0f15">Constitutional AI: Principled Self-Improvement</h4>
<p>Human feedback remains expensive and inconsistent: different annotators provide conflicting preferences, and scaling human oversight to billions of interactions proves challenging<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>. Constitutional AI <span class="citation" data-cites="bai2022constitutional">(<a href="#ref-bai2022constitutional" role="doc-biblioref">Bai et al. 2022</a>)</span> addresses these limitations through automated preference learning.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;<strong>Human Feedback Bottlenecks</strong>: ChatGPT required 40 annotators working full-time for 3 months to generate 200K labels. Scaling to GPT-4’s capabilities would require 10,000+ annotators. Inter-annotator agreement typically reaches only 70-80%.</p></div><div id="fn18"><p><sup>18</sup>&nbsp;<strong>Constitutional AI Method</strong>: <span class="citation" data-cites="bai2022constitutional">Bai et al. (<a href="#ref-bai2022constitutional" role="doc-biblioref">2022</a>)</span> implementation uses 16 principles like “avoid harmful content” and “be helpful.” The model performs 5 rounds of self-critique and revision. Harmful outputs reduced by 95% while maintaining 90% of original helpfulness.</p><div id="ref-bai2022constitutional" class="csl-entry" role="listitem">
Bai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, et al. 2022. <span>“Constitutional AI: Harmlessness from AI Feedback.”</span> <em>arXiv Preprint arXiv:2212.08073</em>, December. <a href="http://arxiv.org/abs/2212.08073v1">http://arxiv.org/abs/2212.08073v1</a>.
</div></div></div><p>Instead of human rankings, Constitutional AI uses a set of principles (a “constitution”) to guide model behavior<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>. The model generates responses, critiques its own outputs against these principles, and revises responses iteratively. This self-improvement loop removes the human bottleneck while maintaining alignment objectives.</p>
<div id="fig-constitutional-ai" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-constitutional-ai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="e0ff650f77002e458e20bbce059ecfaf70a735c9.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Constitutional AI Self-Improvement Loop: The iterative refinement process eliminates human feedback bottlenecks. Each cycle evaluates outputs against constitutional principles, generates critiques, and produces improved versions. After 5 iterations, harmful content reduces by 95% while maintaining helpfulness. The final outputs become training data for the next model generation."><img src="frontiers_files/mediabag/e0ff650f77002e458e20bbce059ecfaf70a735c9.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-constitutional-ai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>Constitutional AI Self-Improvement Loop</strong>: The iterative refinement process eliminates human feedback bottlenecks. Each cycle evaluates outputs against constitutional principles, generates critiques, and produces improved versions. After 5 iterations, harmful content reduces by 95% while maintaining helpfulness. The final outputs become training data for the next model generation.
</figcaption>
</figure>
</div>
<p>The approach leverages optimization techniques from <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong> by having the model distill its own knowledge through principled self-refinement (<a href="#fig-constitutional-ai" class="quarto-xref">Figure&nbsp;4</a>), similar to knowledge distillation but guided by constitutional objectives rather than teacher models.</p>
</section>
<section id="sec-agi-systems-continual-learning-adapting-without-forgetting-f74b" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-agi-systems-continual-learning-adapting-without-forgetting-f74b">Continual Learning: Adapting Without Forgetting</h4>
<p>Deployed models face a limitation: they cannot learn from user interactions without retraining. Each conversation provides valuable feedback (corrections, clarifications, new information) but models remain frozen after training<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>. This creates an ever-widening gap between training data and current reality.</p>
<div class="no-row-height column-margin column-container"><div id="fn19"><p><sup>19</sup>&nbsp;<strong>Static Model Problem</strong>: GPT-3 trained on data before 2021 permanently believes it’s 2021. Models cannot learn user preferences, correct mistakes, or incorporate new knowledge without full retraining costing millions of dollars.</p></div><div id="fn20"><p><sup>20</sup>&nbsp;<strong>Catastrophic Forgetting Severity</strong>: Standard neural networks lose 20-80% accuracy on task A when trained on task B. In language models, fine-tuning on medical text degrades general conversation ability by 30-50%. This occurs because gradient descent modifies parameters globally without considering which changes might destroy previous knowledge. EWC addresses this by adding a regularization term that increases loss when important parameters change significantly, effectively creating “protected” regions of parameter space.</p></div></div><p>Continual learning aims to update models from ongoing interactions while preventing catastrophic forgetting: the phenomenon where learning new information erases previous knowledge<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a>. Standard gradient descent overwrites parameters without discrimination, destroying prior learning.</p>
<p>Solutions require memory management inspired by <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong> that protect important knowledge while enabling new learning. Elastic Weight Consolidation (EWC) <span class="citation" data-cites="kirkpatrick2017overcoming">(<a href="#ref-kirkpatrick2017overcoming" role="doc-biblioref">Kirkpatrick et al. 2017</a>)</span> addresses this by identifying which neural network parameters were critical for previous tasks, then penalizing changes to those specific weights when learning new tasks. The technique computes the Fisher Information Matrix to measure parameter importance—parameters with high Fisher information contributed significantly to previous performance and should be preserved. Progressive Neural Networks take a different approach by adding entirely new pathways for new knowledge while freezing original pathways, ensuring previous capabilities remain intact. Memory replay techniques periodically rehearse examples from previous tasks during new training, maintaining performance through continued practice rather than architectural constraints.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kirkpatrick2017overcoming" class="csl-entry" role="listitem">
Kirkpatrick, James, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, et al. 2017. <span>“Overcoming Catastrophic Forgetting in Neural Networks.”</span> <em>Proceedings of the National Academy of Sciences</em> 114 (13): 3521–26. <a href="https://doi.org/10.1073/pnas.1611835114">https://doi.org/10.1073/pnas.1611835114</a>.
</div></div><p>These training innovations (alignment through human feedback, principled self-improvement, and continual adaptation) transform the training paradigms from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong> into dynamic learning systems that improve through deployment rather than remaining static after training.</p>
</section>
</section>
<section id="sec-agi-systems-optimization-compression-capability-ae5a" class="level3">
<h3 class="anchored" data-anchor-id="sec-agi-systems-optimization-compression-capability-ae5a">Optimization: From Compression to Capability</h3>
<p>The optimization techniques from <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong> take on new significance as we move toward AGI, evolving from static compression to dynamic intelligence allocation.</p>
<p>Consider the inefficiency in current models: when GPT-4 answers “2+2=4”, it activates the same trillion parameters used for reasoning about quantum mechanics. This represents computational waste, like using a supercomputer to calculate basic arithmetic. Sparse models address this inefficiency by learning which parameters matter for which inputs. Instead of activating every parameter, these models route different types of problems through different subsets of their capacity, enabling trillion-parameter models that run as efficiently as much smaller dense networks.</p>
<p>Static sparsity captures only part of the opportunity. Some questions require deep thinking while others need quick responses. This enables adaptive computation where models dynamically adjust computational time based on problem difficulty. These systems learn to spend computational resources proportionally to problem complexity, allocating seconds to simple questions but extensive computation to complex problems. This requires systems engineering for dynamic resource allocation, real-time difficulty assessment, and graceful scaling across different computational budgets.</p>
<p>The approach combines both methods by creating distillation cascades (families of models where larger, more capable systems teach progressively smaller, more specialized ones) rather than building one monolithic model. Frontier models handle the hardest problems while distilled variants handle routine queries. This mirrors human organizations where senior experts train junior staff who handle most day-to-day work, escalating only when necessary. The result is efficient model families that maintain capabilities while reducing computational requirements. The systems engineering challenge involves orchestrating model hierarchies and routing problems to appropriate computational levels.</p>
</section>
<section id="sec-agi-systems-hardware-acceleration-specialization-de7e" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-hardware-acceleration-specialization-de7e">Hardware: From Acceleration to Specialization</h3>
<p>The hardware landscape from <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong> is undergoing a major transformation driven by AGI-scale requirements and the end of Moore’s Law. Training GPT-4 class models demands massive parallelism coordinating thousands of GPUs using sophisticated combinations of tensor, pipeline, and data parallelism, pushing distributed systems engineering to its limits. However, traditional silicon scaling has slowed dramatically: transistor densities now improve by only 10-20% annually compared to the historical 50% yearly gains of Moore’s Law<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>. This forces exploration of radically new computing paradigms.</p>
<div class="no-row-height column-margin column-container"><div id="fn21"><p><sup>21</sup>&nbsp;<strong>End of Moore’s Law</strong>: Transistor density improvements slowed from 50% annually (1970-2010) to 10-20% (2010-2025). Physical limits include quantum tunneling at 3-5nm nodes, manufacturing costs exceeding $20B per fab, and power density approaching nuclear reactor levels.</p></div></div><p>Post-Moore’s Law computing architectures become essential for AGI-scale requirements:</p>
<p>3D chip stacking enables 10x density improvements by building upward instead of shrinking horizontally. Companies like Samsung and TSMC demonstrate 100+ layer 3D NAND memories, and similar approaches apply to processing units. Heat dissipation becomes critical, as stacked chips generate thermal hot-spots requiring advanced cooling solutions including liquid cooling and thermal interface materials<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn22"><p><sup>22</sup>&nbsp;<strong>3D Chip Stacking</strong>: Samsung’s 176-layer 3D NAND achieves 100x higher density than planar designs. Thermal management becomes critical: stacked processors generate 1000W/cm² heat flux requiring advanced cooling. Applications include high-bandwidth memory (HBM) and processing-in-memory architectures.</p></div><div id="fn23"><p><sup>23</sup>&nbsp;<strong>Chiplet Architecture</strong>: AMD’s EPYC uses 8-12 chiplets connected via Infinity Fabric, achieving better yields and performance than monolithic designs. For AGI, enables mixing specialized processors: matrix units, memory controllers, and networking components in optimal ratios.</p></div></div><p>Chiplet architectures provide modular scaling where multiple specialized chips communicate through high-bandwidth interconnects. AMD’s EPYC processors demonstrate 8-12 chiplets per package, achieving higher performance than monolithic designs while reducing manufacturing costs. For AGI training, this enables mixing different specialized processors (matrix units, memory controllers, networking chips) in optimal combinations<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a>.</p>
<p>Optical interconnects deliver 100x bandwidth improvements over electrical connections, crucial for coordinating massive model training across thousands of processors. Silicon photonics integrates optical transmitters and receivers directly on chips, enabling communication at light speeds with dramatically lower energy consumption than copper interconnects<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn24"><p><sup>24</sup>&nbsp;<strong>Optical Interconnects</strong>: Silicon photonics achieves 100 Tbps bandwidth with 10x lower energy than electrical interconnects. Critical for AGI training where communication between 100,000+ processors becomes the bottleneck. Intel, NVIDIA, and startups developing optical chip-to-chip links.</p></div><div id="fn25"><p><sup>25</sup>&nbsp;<strong>Processing-in-Memory (PIM)</strong>: Performs computation directly in DRAM or flash memory, eliminating data movement. Samsung’s HBM-PIM and Upmem’s PIM-DIMM demonstrate 100x energy reduction for memory-bound workloads. Essential for AGI where parameter access dominates energy consumption.</p></div></div><p>Processing-in-memory (PIM) reduces data movement energy by 100x by performing computations directly where data resides. Rather than shuttling massive weight matrices between memory and processors, PIM architectures compute matrix multiplications within DRAM or flash memory arrays. This approach could address the memory wall that limits current AI accelerator efficiency<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a>.</p>
<p>Neuromorphic computing promises brain-inspired hardware achieving 1000x energy efficiency improvements over digital computation. Intel’s Loihi and IBM’s TrueNorth demonstrate event-driven processing with spiking neural networks that activate only when receiving input, mimicking biological efficiency. While current prototypes remain limited to simple tasks, the approach could enable continuous learning systems that adapt in real-time<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn26"><p><sup>26</sup>&nbsp;<strong>Neuromorphic Computing</strong>: Intel’s Loihi chip achieves 1000x energy efficiency over digital processors for sparse, event-driven workloads. IBM’s TrueNorth demonstrates 1 million neurons with 70mW power consumption. Promise for continuous learning AGI systems but programming remains challenging.</p></div><div id="fn27"><p><sup>27</sup>&nbsp;<strong>Quantum-Classical Hybrid</strong>: IBM’s quantum processors demonstrate quantum advantage for optimization problems. D-Wave’s annealing systems solve scheduling and resource allocation. For AGI, quantum processors could accelerate search through exponentially large solution spaces while classical systems handle standard neural computation.</p></div></div><p>Quantum-classical hybrid systems deliver exponential speedups for combinatorial optimization problems that bottleneck AGI training, including neural architecture search and hyperparameter optimization. IBM’s 1000+ qubit processors and Google’s Sycamore demonstrate quantum advantage for specific optimization tasks, though current systems remain too noisy for general computation. Hybrid approaches partition workloads strategically: quantum processors solve discrete optimization problems while classical systems handle matrix operations and gradient computations. However, orchestration becomes complex: quantum and classical systems operate on fundamentally different timescales and error models, requiring sophisticated middleware to decompose AGI workflows across heterogeneous quantum-classical resources<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a>.</p>
</section>
<section id="sec-agi-systems-operations-deployment-evolution-4755" class="level3">
<h3 class="anchored" data-anchor-id="sec-agi-systems-operations-deployment-evolution-4755">Operations: From Deployment to Evolution</h3>
<p>The MLOps principles from <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong> become more critical as AI systems evolve from static models to dynamic, learning entities. Continuous learning systems represent the next frontier: models that update from user interactions in real-time while maintaining safety and reliability. This requires rethinking everything from version control to rollback strategies, as models now change continuously rather than through discrete deployments.</p>
<p>Traditional A/B testing scales to compare model versions across millions of users while ensuring consistent experiences. Frontier AI systems introduce complications where personalized models make comparison difficult, and emergent behaviors can appear suddenly as capabilities scale. The operations challenge involves detecting subtle performance regressions across diverse use cases while maintaining user trust.</p>
<p>Safety monitoring must detect and prevent harmful outputs, prompt injections, and adversarial attacks in real-time across billions of interactions. Unlike traditional software monitoring that tracks system metrics, AI safety monitoring requires understanding content, intent, and potential harm, demanding new tooling and methodologies.</p>
</section>
</section>
<section id="sec-agi-systems-implementing-compound-intelligence-scale" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-implementing-compound-intelligence-scale">Implementing Compound Intelligence at Scale</h2>
<p>The compound AI systems framework established earlier in this chapter provides the conceptual foundation, but implementing these systems at scale requires sophisticated orchestration infrastructure. Production systems like GPT-4’s tool integration, Gemini’s search augmentation, and Claude’s constitutional AI implementation demonstrate how specialized components coordinate to achieve capabilities beyond individual model limits.</p>
<p><a href="#fig-compound-ai-system" class="quarto-xref">Figure&nbsp;5</a> illustrates the engineering complexity with specific performance metrics: the central orchestrator routes user queries to appropriate specialized modules within 10-50ms decision latency, manages bidirectional communication between components through 1-10 GB/s data flows depending on modality (text: 1 MB/s, code: 10 MB/s, multimodal: 1 GB/s), coordinates iterative refinement processes with 100-500ms round-trip times per component, and maintains conversation state across the entire interaction using 1-100 GB memory per session. Each component represents distinct engineering challenges requiring different optimization strategies (LLM: GPU-optimized inference, Search: distributed indexing, Code: secure sandboxing), hardware configurations (orchestrator: CPU+memory, retrieval: SSD+bandwidth, compute: GPU clusters), and operational practices (sub-second latency SLAs, 99.9% availability, failure isolation). <strong>Failure modes</strong> include component timeouts (10-30 second fallbacks), dependency failures (graceful degradation), and coordination deadlocks (circuit breaker patterns).</p>
<div id="fig-compound-ai-system" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-compound-ai-system-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="c595b02339d0921a6635426f4b6c27c89af1fbba.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Compound AI System Architecture: Modern AI assistants integrate specialized components through a central orchestrator, enabling capabilities beyond monolithic models. Each module handles specific tasks while the LLM coordinates information flow, decisions, and responses. This architecture enables independent scaling, specialized optimization, and multi-layer safety validation."><img src="frontiers_files/mediabag/c595b02339d0921a6635426f4b6c27c89af1fbba.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-compound-ai-system-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>Compound AI System Architecture</strong>: Modern AI assistants integrate specialized components through a central orchestrator, enabling capabilities beyond monolithic models. Each module handles specific tasks while the LLM coordinates information flow, decisions, and responses. This architecture enables independent scaling, specialized optimization, and multi-layer safety validation.
</figcaption>
</figure>
</div>
</section>
<section id="sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-beyond-transformers-alternative-architectures-6243">Beyond Transformers: Alternative Architectures</h2>
<p>While transformers achieve notable capabilities, they suffer from a limitation: processing longer sequences becomes prohibitively expensive. The attention mechanism that enables transformers to focus on relevant parts of input requires comparing every token with every other token, creating quadratic scaling; a 100,000 token context requires 10 billion comparisons.</p>
<p>This limitation drives research into alternative architectures that could maintain transformer-like capabilities while scaling to much longer contexts. The promising approaches rethink how models maintain and access information across long sequences.</p>
<p>Among these alternatives, state space models represent one promising direction: architectures that process sequences more efficiently by maintaining compressed memory of past information. Rather than attending to all previous tokens simultaneously (as transformers do), these architectures maintain a compressed representation of past information that updates incrementally as new tokens arrive. Think of it like maintaining a running summary instead of re-reading the entire conversation history for each new sentence. Models like Mamba<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> <span class="citation" data-cites="gu2023mamba">(<a href="#ref-gu2023mamba" role="doc-biblioref">Gu and Dao 2023</a>)</span> demonstrate that this approach can match transformer performance on many tasks while scaling linearly rather than quadratically with sequence length.</p>
<div class="no-row-height column-margin column-container"><div id="fn28"><p><sup>28</sup>&nbsp;<strong>Mamba State Space Model</strong>: Developed by Carnegie Mellon and Princeton researchers in 2023, Mamba achieves linear O(n) scaling vs.&nbsp;transformer’s quadratic O(n²) attention complexity. Uses selective state spaces with input-dependent parameters, enabling 5× better throughput on long sequences. Mamba-7B matches transformer-7B performance on text while using 5× less memory for 100K token sequences.</p></div><div id="ref-gu2023mamba" class="csl-entry" role="listitem">
Gu, Albert, and Tri Dao. 2023. <span>“Mamba: Linear-Time Sequence Modeling with Selective State Spaces.”</span> <em>arXiv Preprint arXiv:2312.00752</em>, December. <a href="http://arxiv.org/abs/2312.00752v2">http://arxiv.org/abs/2312.00752v2</a>.
</div></div><p>The systems engineering implications are substantial. Linear scaling enables processing of book-length contexts, multi-hour conversations, or entire codebases within single model calls. This requires rethinking data loading strategies, memory management, and distributed inference patterns optimized for sequential processing rather than parallel attention.</p>
<p>However, these alternatives remain experimental. The transformer architecture benefits from years of optimization across the entire ML systems stack, from specialized hardware kernels to distributed training frameworks. Alternative architectures must not only match transformer capabilities but also justify the engineering effort required to rebuild this ecosystem. For compound systems, the path forward likely involves hybrid approaches that combine transformer strengths with alternative architectures’ scaling benefits across different specialized components.</p>
<section id="sec-agi-systems-energy-based-models-alternative" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-agi-systems-energy-based-models-alternative">Energy-Based Models: An Alternative to Autoregressive Approaches</h4>
<p>Addressing the transformer limitations discussed above, researchers explore fundamentally different modeling approaches that could overcome these architectural constraints. Energy-based models (EBMs) offer a different approach to modeling intelligence: they learn to assign energy scores to different configurations rather than predicting next tokens. This paradigm offers a compelling alternative to autoregressive generation that may prove essential for achieving AGI-level reasoning capabilities.</p>
<p>Current language models generate text by predicting one token at a time, conditioning each prediction on all previous tokens. This autoregressive approach has fundamental limitations for complex reasoning: it cannot easily revise earlier decisions based on later constraints, struggles with problems requiring global optimization, and tends to produce locally coherent but globally inconsistent outputs. For tasks requiring planning, constraint satisfaction, or multi-step reasoning, autoregressive generation often fails because the model commits to early decisions without considering their downstream implications.</p>
<p>Energy-based models learn an energy function <span class="math inline">\(E(x)\)</span> that assigns low energy to probable or desirable configurations <span class="math inline">\(x\)</span> and high energy to improbable ones. Rather than directly generating outputs, EBMs perform inference through optimization: finding configurations that minimize energy. This enables several capabilities unavailable to autoregressive models:</p>
<ul>
<li><strong>Global optimization</strong>: EBMs can consider multiple interacting constraints simultaneously rather than making sequential local decisions</li>
<li><strong>Multiple solutions</strong>: The energy landscape naturally represents multiple valid solutions with different energy levels</li>
<li><strong>Uncertainty quantification</strong>: Energy levels provide principled measures of solution quality and confidence</li>
<li><strong>Bidirectional reasoning</strong>: EBMs can reason backward from desired outcomes to necessary preconditions</li>
</ul>
<p>EBMs present significant systems engineering challenges. Inference requires solving optimization problems that can be computationally expensive, particularly for high-dimensional spaces. Training EBMs often involves contrastive learning methods that require generating negative examples through MCMC sampling<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a> or other computationally intensive procedures. The optimization landscapes can be complex with many local minima, requiring sophisticated inference algorithms.</p>
<div class="no-row-height column-margin column-container"><div id="fn29"><p><sup>29</sup>&nbsp;<strong>Markov Chain Monte Carlo (MCMC)</strong>: Statistical sampling method using Markov chains to generate samples from complex probability distributions. Developed by Metropolis (1953) and Hastings (1970). In ML, MCMC generates negative examples for contrastive learning by sampling from energy-based models. Gibbs sampling and Hamiltonian Monte Carlo are common variants. Computational cost grows exponentially with dimension, requiring 1000-10000 samples per iteration.</p></div></div><p>These challenges also create opportunities for systems innovation. Specialized hardware for optimization (like quantum annealers or optical computers) could provide computational advantages for EBM inference. Hierarchical energy models could decompose complex problems into tractable subproblems. Hybrid architectures could combine fast autoregressive generation with EBM refinement for improved solution quality.</p>
<p>In compound AI systems, EBMs could serve as specialized reasoning components that handle constraint satisfaction, planning, and verification tasks. While autoregressive models excel at fluent text generation, EBMs could provide the logical reasoning and global consistency checking needed for complex problem-solving. This division of labor leverages each approach’s strengths while mitigating their respective weaknesses.</p>
</section>
<section id="sec-agi-systems-world-models-predictive-learning" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-world-models-predictive-learning">World Models and Predictive Learning</h4>
<p>The development of internal world models represents perhaps the most crucial advancement needed for AGI. Unlike current language models that excel at pattern completion, AGI systems must develop rich internal representations of how the world works—models that support prediction, planning, and causal reasoning across diverse domains.</p>
<p>These world models are learned internal representations that capture the causal structure of environments, enabling systems to predict the consequences of actions, reason about counterfactuals, and plan sequences of actions to achieve goals. While current AI systems can predict surface patterns in data, they lack the deeper causal understanding that characterizes human intelligence. A true world model would capture not just correlations but causal relationships: understanding that rain causes wetness, that pushing objects causes movement, and that actions have consequences that persist over time.</p>
<p>Current self-supervised learning focuses primarily on next-token prediction, which captures statistical regularities but not causal structure. More sophisticated approaches focus on learning compressed representations that capture the essential dynamics of environments. The JEPA framework exemplifies this: instead of predicting raw pixels in the next video frame, the system learns abstract representations that encode object persistence, physics, and causal relationships. This enables more efficient learning and better generalization to novel situations.</p>
<p>Effective world models must operate at multiple temporal and spatial scales simultaneously. At the lowest level, they must capture immediate sensory-motor relationships (how actions affect immediate percepts). At intermediate levels, they must understand object persistence and basic physics (how objects move and interact). At the highest levels, they must capture abstract causal relationships and long-term consequences of actions. This hierarchical organization mirrors the structure of biological intelligence and enables efficient planning and reasoning across different timescales.</p>
<p>Building systems that can learn world models from experience presents significant engineering challenges. These systems must process continuous streams of multimodal sensory data (vision, audio, proprioception), learn compressed representations that capture essential causal structure while discarding irrelevant details, update world models continuously as new experience arrives, and support efficient planning and reasoning using the learned models.</p>
<p>The computational requirements are substantial: learning world models requires processing vast amounts of temporal data, training on sequences that capture long-term dependencies, and supporting both offline learning from historical data and online adaptation from new experiences. This demands new architectures optimized for temporal learning, memory systems that can efficiently store and retrieve temporal patterns, and inference systems that can perform planning and reasoning using learned world models.</p>
<p>In compound AI architectures, world models could serve as specialized components that provide causal understanding and planning capabilities to other system components. A world model component might learn the dynamics of a particular domain (physical, social, or abstract), while other components handle perception, action selection, or communication. This specialization enables developing robust world models for specific domains while maintaining the flexibility to combine them for complex, multi-domain reasoning tasks.</p>
<p>Significant technical barriers remain that require systems-level innovations beyond current capabilities. Understanding these barriers helps identify where compound systems can address limitations through specialization and where fundamental breakthroughs are still needed.</p>
<div id="quiz-question-sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.3</strong></summary><div>
<ol type="1">
<li><p>What is a key limitation of transformers when processing long sequences?</p>
<ol type="a">
<li>They require linear scaling with sequence length.</li>
<li>They require quadratic scaling with sequence length.</li>
<li>They cannot handle sequences longer than 10,000 tokens.</li>
<li>They are unable to maintain context over long sequences.</li>
</ol></li>
<li><p>Explain how state space models address the limitations of transformers in processing long sequences.</p></li>
<li><p>True or False: State space models require the same level of engineering optimization as transformers to be effective.</p></li>
<li><p>State space models maintain a ____ of past information to efficiently process long sequences.</p></li>
<li><p>In a production system, what are the potential benefits and challenges of adopting state space models over transformers?</p></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-agi-systems-remaining-technical-barriers" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-remaining-technical-barriers">Remaining Technical Barriers</h2>
<p>Five critical barriers separate current ML systems from artificial general intelligence. Each represents not just an algorithmic challenge but a systems engineering problem requiring innovation across the entire stack, though compound systems approaches may address some through intelligent component orchestration.</p>
<p>Consider these concrete failures that reveal the gap between current systems and AGI: GPT-4 can write code but fails to track variable state across a long debugging session. It can explain quantum mechanics but cannot learn from your corrections within a conversation. It can translate between languages but lacks the cultural context to know when literal translation misleads. These aren’t minor bugs but architectural limitations.</p>
<section id="sec-agi-systems-context-memory-bottleneck-intelligence-0db6" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-context-memory-bottleneck-intelligence-0db6">Context and Memory: The Bottleneck of Intelligence</h3>
<p>Human working memory holds approximately seven items, yet long-term memory stores lifetime experiences <span class="citation" data-cites="landauer1986much">(<a href="#ref-landauer1986much" role="doc-biblioref">Landauer 1986</a>)</span>. Current AI systems invert this: transformer context windows reach 128K tokens (approximately 100K words) but cannot maintain information across sessions. This creates systems that can process books but cannot remember yesterday’s conversation.</p>
<div class="no-row-height column-margin column-container"><div id="ref-landauer1986much" class="csl-entry" role="listitem">
Landauer, Thomas K. 1986. <span>“How Much Do People Remember? Some Estimates of the Quantity of Learned Information in Long-Term Memory.”</span> <em>Cognitive Science</em> 10 (4): 477–93. <a href="https://doi.org/10.1207/s15516709cog1004\_4">https://doi.org/10.1207/s15516709cog1004\_4</a>.
</div><div id="fn30"><p><sup>30</sup>&nbsp;<strong>Associative Memory</strong>: Biological neural networks recall information through spreading activation: one memory trigger activates related memories through learned associations. Hopfield networks (1982) demonstrate this computationally but scale poorly (O(n²) storage). Modern approaches include differentiable neural dictionaries and memory-augmented networks. Human associative recall operates in 100-500ms across 100 billion memories.</p></div></div><p>The challenge extends beyond storage to organization and retrieval. Human memory operates hierarchically (events within days within years) and associatively (smell triggering childhood memories). Current systems lack these structures, treating all information equally. Vector databases store billions of embeddings but lack temporal or semantic organization, while humans retrieve relevant memories from decades of experience in milliseconds through associative activation spreading<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a>.</p>
<p>Addressing these memory limitations, building AGI memory systems requires innovations from <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>: hierarchical indexing supporting multi-scale retrieval, attention mechanisms that selectively forget irrelevant information, and experience consolidation that transfers short-term interactions into long-term knowledge. Compound systems may address this through specialized memory components with different temporal scales and retrieval mechanisms.</p>
</section>
<section id="sec-agi-systems-energy-sustainability-trilliondollar-question-f4e3" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-energy-sustainability-trilliondollar-question-f4e3">Energy and Sustainability: The Trillion-Dollar Question</h3>
<p>Energy consumption presents equally daunting challenges. GPT-4 training is estimated to have consumed 50-100 GWh of electricity (unofficial estimates), enough to power 50,000 homes for a year<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a>. Extrapolating to AGI suggests energy requirements exceeding small nations’ output, creating both economic and environmental challenges.</p>
<div class="no-row-height column-margin column-container"><div id="fn31"><p><sup>31</sup>&nbsp;<strong>GPT-4 Energy Consumption</strong>: Estimated 50-100 GWh for training (equivalent to 50,000 US homes’ annual usage). At $0.10/kWh plus hardware amortization, training cost exceeds $100 million. AGI might require 1000x more.</p></div><div id="fn32"><p><sup>32</sup>&nbsp;<strong>Biological vs Digital Efficiency</strong>: Brain: ~10¹⁵ ops/sec ÷ 20W = 5 × 10¹³ ops/watt. H100 GPU: 1,000 × 10¹² ops/sec ÷ 700W = 1.4 × 10¹² ops/watt. Efficiency ratio: ~360x advantage for biological computation. However, this comparison requires careful interpretation: biological neurons use analog, chemical signaling with massive parallelism, while digital systems use precise, electronic switching with sequential processing. The mechanisms are fundamentally different, making direct efficiency comparisons approximate at best.</p></div></div><p>The human brain operates on 20 watts (less than a light bulb) while performing computations that would require megawatts on current hardware<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a>. This six-order-of-magnitude efficiency gap emerges from fundamental architectural differences: biological neurons operate at ~1 Hz effective compute rates using chemical signaling, while digital processors run at GHz frequencies using electronic switching. Despite the frequency disadvantage, the brain’s massive parallelism (10¹¹ neurons with 10¹⁴ connections) and analog processing enable efficient pattern recognition that digital systems achieve only through brute force computation. This efficiency gap, detailed earlier with specific computational metrics in <a href="#sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="quarto-xref">Section&nbsp;1.2</a>, cannot be closed through incremental improvements. Solutions require reimagining of computation, building on <strong><a href="../core/sustainable_ai/sustainable_ai.html#sec-sustainable-ai">Chapter 17: Sustainable AI</a></strong>: neuromorphic architectures that compute with spikes rather than matrix multiplications, reversible computing that recycles energy through computation, and algorithmic improvements that reduce training iterations by orders of magnitude.</p>
</section>
<section id="sec-agi-systems-reasoning-planning-beyond-pattern-matching-4108" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-reasoning-planning-beyond-pattern-matching-4108">Reasoning and Planning: Beyond Pattern Matching</h3>
<p>Fundamental algorithmic limitations remain even with efficient hardware. Current models excel at pattern completion but struggle with novel reasoning. Ask GPT-4 to plan a trip, and it produces plausible itineraries. Ask it to solve a problem requiring new reasoning (proving a novel theorem or designing an experiment) and performance degrades rapidly<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn33"><p><sup>33</sup>&nbsp;<strong>Reasoning Performance Cliff</strong>: LLMs achieve 90%+ on familiar problem types but drop to 10-30% on problems requiring genuine novelty. ARC challenge (abstraction and reasoning) reveals models memorize patterns rather than learning abstract rules.</p></div><div id="fn34"><p><sup>34</sup>&nbsp;<strong>Reasoning vs Pattern Matching</strong>: <strong>World models</strong>: Internal simulators predicting consequences (“if I move this chess piece, opponent’s likely responses are…”). Current LLMs lack persistent state—each token generation starts fresh. <strong>Search</strong>: Systematic exploration of possibilities with backtracking. Chess programs search millions of positions; LLMs generate tokens sequentially without reconsideration. <strong>Causal understanding</strong>: Distinguishing causation from correlation. Humans understand that medicine causes healing (even if correlation isn’t perfect), while LLMs may learn “medicine” and “healing” co-occur without causal direction. Classical planning requires explicit state representation, action models, goal specification, and search algorithms. Neural networks provide none explicitly. Neurosymbolic approaches attempt integration but remain limited to narrow domains.</p></div></div><p>True reasoning requires capabilities absent from current architectures. Consider three fundamental requirements: <strong>World models</strong> represent internal simulations of how systems behave over time—for example, understanding that dropping a ball causes it to fall, not just that “dropped” and “fell” co-occur in text. <strong>Search mechanisms</strong> explore solution spaces systematically rather than relying on pattern matching—finding mathematical proofs requires testing hypotheses and backtracking, not just recognizing solution patterns. <strong>Causal understanding</strong> distinguishes correlation from causation—recognizing that umbrellas correlate with rain but don’t cause it, while clouds do<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a>. These capabilities demand architectural innovations beyond those in <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong>, potentially hybrid systems combining neural networks with symbolic reasoners, or new architectures inspired by cognitive science.</p>
</section>
<section id="sec-agi-systems-embodiment-grounding-symbol-grounding-problem-a0ef" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-embodiment-grounding-symbol-grounding-problem-a0ef">Embodiment and Grounding: The Symbol Grounding Problem</h3>
<p>Language models learn “cat” co-occurs with “meow” and “fur” but have never experienced a cat’s warmth or heard its purr. This symbol grounding problem <span class="citation" data-cites="harnad1990symbol searle1980minds">(<a href="#ref-harnad1990symbol" role="doc-biblioref">Harnad 1990</a>; <a href="#ref-searle1980minds" role="doc-biblioref">Searle 1980</a>)</span> (connecting symbols to experiences) may fundamentally limit intelligence without embodiment.</p>
<div class="no-row-height column-margin column-container"><div id="ref-harnad1990symbol" class="csl-entry" role="listitem">
Harnad, Stevan. 1990. <span>“The Symbol Grounding Problem.”</span> <em>Physica D: Nonlinear Phenomena</em> 42 (1-3): 335–46. <a href="https://doi.org/10.1016/0167-2789(90)90087-6">https://doi.org/10.1016/0167-2789(90)90087-6</a>.
</div><div id="ref-searle1980minds" class="csl-entry" role="listitem">
Searle, John R. 1980. <span>“Minds, Brains, and Programs.”</span> <em>Behavioral and Brain Sciences</em> 3 (3): 417–24. <a href="https://doi.org/10.1017/s0140525x00005756">https://doi.org/10.1017/s0140525x00005756</a>.
</div><div id="fn35"><p><sup>35</sup>&nbsp;<strong>Robotic System Requirements</strong>: Boston Dynamics’ Atlas runs 1KHz control loops with 28 actuators. Tesla’s FSD processes 36 camera streams at 36 FPS. Both require &lt;10ms inference latency—impossible with cloud processing.</p></div></div><p>Robotic embodiment introduces systems constraints from <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong>: real-time inference requirements (sub-100ms control loops), continuous learning from noisy sensor data, and safe exploration in environments where mistakes cause physical damage<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a>. These constraints mirror the efficiency challenges covered in <strong><a href="../core/efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 10: Efficient AI</a></strong> but with even stricter latency and reliability requirements. Yet embodiment might be essential for understanding concepts like “heavy,” “smooth,” or “careful” that are grounded in physical experience.</p>
</section>
<section id="sec-agi-systems-alignment-control-value-loading-problem-f409" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-alignment-control-value-loading-problem-f409">Alignment and Control: The Value Loading Problem</h3>
<p>The most critical barrier involves ensuring AGI systems pursue human values rather than optimizing simplified objectives that lead to harmful outcomes<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a>. Current reward functions are proxies (maximize engagement, minimize error) that can produce unintended behaviors when optimized strongly.</p>
<div class="no-row-height column-margin column-container"><div id="fn36"><p><sup>36</sup>&nbsp;<strong>Alignment Failure Modes</strong>: YouTube’s algorithm optimizing watch time promoted increasingly extreme content. Trading algorithms optimizing profit caused flash crashes. AGI optimizing misspecified objectives could cause existential risks.</p></div><div id="fn37"><p><sup>37</sup>&nbsp;<strong>Alignment Technical Challenges</strong>: Value specification: Arrow’s impossibility theorem shows no perfect aggregation of preferences. Robust optimization: Goodhart’s law states optimized metrics cease being good metrics. Corrigibility: Self-modifying systems might remove safety constraints. Scalable oversight: Humans cannot verify solutions to problems they cannot solve.</p></div></div><p>Alignment requires solving multiple interconnected problems: value specification (what do humans actually want?), robust optimization (pursuing goals without exploiting loopholes), corrigibility (remaining modifiable as capabilities grow), and scalable oversight (maintaining control over systems smarter than overseers)<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a>. These challenges span technical and philosophical domains, requiring advances in interpretability from <strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong>, formal verification methods, and new frameworks for specifying and verifying objectives.</p>
<div id="fig-technical-barriers" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="htb" data-fig-env="figure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-technical-barriers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="6c1f85138f1eb26a8e9e4df3ae67bb1aa84c58ff.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Technical Barriers to AGI: Five fundamental challenges must be solved simultaneously for artificial general intelligence. Each represents orders-of-magnitude gaps: memory systems need persistence across sessions, energy efficiency requires 1000x improvements, reasoning needs genuine planning beyond pattern matching, embodiment demands symbol grounding, and alignment requires value specification. Red arrows show critical blocking paths; dashed gray lines indicate key interdependencies."><img src="frontiers_files/mediabag/6c1f85138f1eb26a8e9e4df3ae67bb1aa84c58ff.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-technical-barriers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>Technical Barriers to AGI</strong>: Five fundamental challenges must be solved simultaneously for artificial general intelligence. Each represents orders-of-magnitude gaps: memory systems need persistence across sessions, energy efficiency requires 1000x improvements, reasoning needs genuine planning beyond pattern matching, embodiment demands symbol grounding, and alignment requires value specification. Red arrows show critical blocking paths; dashed gray lines indicate key interdependencies.
</figcaption>
</figure>
</div>
<p>These five barriers form an interconnected web of challenges. Progress on any single barrier remains insufficient, as AGI requires coordinated breakthroughs across all dimensions, as illustrated in <a href="#fig-technical-barriers" class="quarto-xref">Figure&nbsp;6</a>. The engineering principles developed throughout this textbook, from data engineering (<strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>) through distributed training (<strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>) to robust deployment (<strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>), provide foundations for addressing each barrier, though the complete solutions remain unknown.</p>
</section>
</section>
<section id="sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-multiagent-futures-collective-intelligence-3ee4">Multi-Agent Futures: Collective Intelligence</h2>
<p>An alternative path to AGI may emerge through collective intelligence. Rather than a single AGI system, we may see intelligence emerge from interactions between specialized agents, a vision that draws on distributed systems principles and MLOps practices covered throughout this textbook. However, AGI-scale multi-agent systems face distributed coordination challenges that dwarf current systems.</p>
<p>AGI systems might require coordination between millions of specialized agents distributed across continents while today’s distributed systems coordinate thousands of servers<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a>. Each agent could be a frontier-model-scale system consuming gigawatts of power, making coordination latency and bandwidth major bottlenecks. Communication between agents in Tokyo and New York introduces 150ms round-trip delays, unacceptable for real-time reasoning requiring millisecond coordination.</p>
<div class="no-row-height column-margin column-container"><div id="fn38"><p><sup>38</sup>&nbsp;<strong>AGI Agent Scale</strong>: Estimates suggest AGI systems might require 10⁶-10⁷ specialized agents for human-level capabilities across all domains. Each agent could be GPT-4 scale or larger. Coordination complexity grows as O(n²) without hierarchical organization, making flat architectures impossible at this scale.</p></div></div><p>Addressing these coordination challenges requires first establishing agent specialization across different domains. Scientific reasoning agents would process exabytes of literature, creative agents would generate multimedia content, strategic planning agents would optimize across decades-long timescales, and embodied agents would control robotic systems. Each agent excels in its specialty while sharing common interfaces that enable coordination. This mirrors how modern software systems decompose complex functionality into microservices, but at unprecedented scale and complexity.</p>
<p>The effectiveness of such specialization critically depends on communication protocols between agents. Unlike traditional distributed systems that exchange simple state updates, AGI agents must communicate rich semantic information including partial world models, reasoning chains, uncertainty estimates, and intent representations<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a>. The protocols must compress complex cognitive states into network packets while preserving semantic fidelity across heterogeneous agent architectures. Current internet protocols lack semantic understanding; future AGI networks might require content-aware routing that understands reasoning context.</p>
<div class="no-row-height column-margin column-container"><div id="fn39"><p><sup>39</sup>&nbsp;<strong>AGI Communication Complexity</strong>: Agent communication must convey semantic content equivalent to full reasoning states, potentially terabytes per message. Current internet protocols (TCP/IP) lack semantic understanding. Future AGI networks might use content-addressable routing, semantic compression, and reasoning-aware network stacks.</p></div><div id="fn40"><p><sup>40</sup>&nbsp;<strong>AGI Network Topology</strong>: Hierarchical networks reduce communication complexity from O(n²) to O(n log n). Biological neural networks use similar hierarchies: local processing clusters, regional integration areas, and global coordination structures. AGI systems likely require analogous network architectures.</p></div></div><p>Beyond protocols, network topology design becomes critical for achieving efficient communication at scale. Rather than flat network architectures, AGI systems might require hierarchical topologies mimicking biological neural organization: local agent clusters for rapid coordination, regional hubs for cross-domain integration, and global coordination layers for system-wide coherence<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a>. Load balancing algorithms must consider not just computational load but semantic affinity—routing related reasoning tasks to agents with shared context.</p>
<p>These architectural considerations lead naturally to questions of consensus mechanisms, which for AGI agents face complexity beyond traditional distributed systems. While blockchain consensus involves simple state transitions, AGI consensus must handle conflicting world models, competing reasoning chains, and subjective value judgments<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a>. When scientific reasoning agents disagree about experimental interpretations, creative agents propose conflicting artistic directions, and strategic agents recommend opposing policies, the system needs mechanisms for productive disagreement rather than forced consensus. This might involve reputation systems that weight agent contributions by past accuracy, voting mechanisms that consider argument quality not just agent count, and meta-reasoning systems that identify when disagreement indicates genuine uncertainty versus agent malfunction.</p>
<div class="no-row-height column-margin column-container"><div id="fn41"><p><sup>41</sup>&nbsp;<strong>AGI Consensus Complexity</strong>: Unlike traditional consensus on simple state transitions, AGI consensus involves competing world models, subjective values, and reasoning chains. This requires new consensus mechanisms that handle semantic disagreement, argument quality assessment, and uncertainty quantification.</p></div><div id="fn42"><p><sup>42</sup>&nbsp;<strong>AGI Byzantine Threats</strong>: Beyond random failures, AGI agents face systematic threats: biased training data causing consistent errors, misaligned objectives leading to subtle manipulation, and adversarial attacks spreading sophisticated misinformation. Defense requires advances beyond traditional 3f+1 Byzantine fault tolerance.</p></div></div><p>Consensus challenges intensify when considering Byzantine fault tolerance, which becomes more challenging when agents are not just providing incorrect information but potentially pursuing different objectives. Unlike server failures that are random, agent failures might be systematic: an agent trained on biased data consistently providing skewed recommendations, an agent with misaligned objectives subtly manipulating other agents, or an agent compromised by adversarial attacks spreading misinformation<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a>. Traditional Byzantine algorithms require 3f+1 honest nodes to tolerate f Byzantine nodes, but AGI systems might face sophisticated, coordinated attacks requiring novel defense mechanisms.</p>
<p>Finally, resource coordination across millions of agents demands new distributed algorithms that move beyond current orchestration frameworks. When multiple reasoning chains compete for compute resources, memory bandwidth, and network capacity, the system needs real-time resource allocation that considers not just current load but predicted reasoning complexity. This requires advances beyond current Kubernetes orchestration: predictive load balancing based on reasoning difficulty estimation, priority systems that understand reasoning urgency, and graceful degradation that maintains system coherence when resources become constrained<a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn43"><p><sup>43</sup>&nbsp;<strong>AGI Resource Coordination</strong>: Managing compute resources across millions of reasoning agents requires predictive load balancing based on reasoning complexity estimation, priority systems understanding reasoning urgency, and graceful degradation maintaining system coherence under resource constraints.</p></div></div><p>The goal is emergent intelligence: capabilities arising from agent interaction that no single agent possesses. Like how behaviors emerge from simple rules in swarm systems, reasoning might emerge from relatively simple agents working together. The whole becomes greater than the sum of its parts, but only through careful systems engineering of the coordination mechanisms.</p>
<p>This multi-agent approach requires orchestration (<strong><a href="../core/workflow/workflow.html#sec-ai-workflow">Chapter 19: AI Workflow</a></strong>), robust communication infrastructure, and attention to failure modes where agent interactions could lead to unexpected behaviors.</p>
<div id="quiz-question-sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.4</strong></summary><div>
<ol type="1">
<li><p>What is the primary benefit of agent specialization in a multi-agent system?</p>
<ol type="a">
<li>Increased redundancy</li>
<li>Simplified communication protocols</li>
<li>Improved efficiency in specific tasks</li>
<li>Reduced need for consensus mechanisms</li>
</ol></li>
<li><p>Explain how communication protocols in multi-agent systems are similar to those in distributed systems.</p></li>
<li><p>True or False: Consensus mechanisms in multi-agent systems are unnecessary if agents are specialized.</p></li>
<li><p>The goal of multi-agent systems is to achieve ____ intelligence, where capabilities arise from agent interactions.</p></li>
<li><p>In a production system, what challenges might arise from implementing consensus mechanisms in multi-agent systems?</p></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-agi-systems-challenges-opportunities-opens-51a8" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-agi-systems-challenges-opportunities-opens-51a8">Challenges and Opportunities: What This Opens Up</h2>
<p>The convergence of technologies and principles covered in this textbook creates opportunities for innovation and introduces new classes of challenges that demand systems engineering solutions. Understanding these emerging areas is important for ML systems engineers positioning themselves at the frontier, building upon the foundational skills developed throughout this textbook.</p>
<section id="sec-agi-systems-infrastructure-opportunity-2386" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-infrastructure-opportunity-2386">The Infrastructure Opportunity</h3>
<p>Current AI development faces infrastructure bottlenecks. Training frontier models requires coordinating tens of thousands of GPUs across multiple datacenters, yet most AI infrastructure remains ad-hoc and inefficient<a href="#fn44" class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a>. This creates substantial opportunities for systems engineers who understand the full stack.</p>
<div class="no-row-height column-margin column-container"><div id="fn44"><p><sup>44</sup>&nbsp;<strong>Infrastructure Efficiency Gap</strong>: Current GPU clusters achieve 20-40% utilization during training due to communication overhead, load imbalancing, and fault recovery. Improving utilization to 70-80% would reduce training costs by 40-60%, worth billions annually. AGI-scale systems require 99.99% utilization across million-GPU clusters.</p></div></div><section id="sec-agi-systems-technical-barrier-classification-framework-c20c" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-technical-barrier-classification-framework-c20c">Technical Barrier Classification Framework</h5>
<p>AGI development faces barriers that fall into distinct categories, each requiring different engineering approaches and investment strategies:</p>
<p><strong>Category 1: Engineering Solvable Barriers</strong> - These challenges have clear technical solutions requiring implementation at scale: - <strong>Memory bandwidth limitations</strong>: Current systems move 10-100TB/s between processors and memory, but AGI training requires 1-10PB/s. As analyzed in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong> memory hierarchy chapter, the memory wall emerges when data movement dominates computation time. AGI compounds this challenge by requiring access to trillions of parameters per inference step. Solutions exist through HBM stacking (extending the memory bandwidth analysis from <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>), processing-in-memory (implementing the near-data computing principles covered in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>), and optical interconnects - <strong>Energy efficiency gaps</strong>: Training consumes 50-100 GWh while human learning uses equivalent of 20W-years. The energy analysis from <strong><a href="../core/sustainable_ai/sustainable_ai.html#sec-sustainable-ai">Chapter 17: Sustainable AI</a></strong> provides frameworks for measuring computational energy efficiency, which becomes critical at AGI scale. Post-Moore’s Law architectures (neuromorphic computing principles from <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>, quantum-hybrid systems) provide clear paths to 100-1000x efficiency improvements - <strong>Communication latency</strong>: Distributed training faces 1-10ms interconnect delays limiting coordination. The distributed training principles from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong> become critical at AGI scale where 100,000+ accelerators must coordinate gradient updates. The all-reduce communication patterns analyzed in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong> face bandwidth limitations when scaling beyond 10,000 nodes. Solutions include optical networks, hierarchical topologies (extending the network topology optimization from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>), and intelligent caching - <strong>Fault tolerance at scale</strong>: Million-GPU clusters need 99.99% reliability requiring advanced checkpointing, predictive failure detection, and graceful degradation mechanisms</p>
<p><strong>Category 2: Research Required Barriers</strong> - These demand algorithmic breakthroughs, not just scaling: - <strong>Planning and reasoning</strong>: Current models lack systematic search through solution spaces, causal understanding, and multi-step verification. Solutions require hybrid architectures combining neural networks with symbolic reasoners - <strong>Transfer learning across domains</strong>: Models struggle to apply knowledge from one domain to radically different areas. This requires architectural innovations in representation learning and meta-learning - <strong>Continual learning without forgetting</strong>: Systems cannot update from new information without degrading previous capabilities. Solutions need advances in memory consolidation and parameter protection - <strong>Robustness to distribution shift</strong>: Models fail when deployed data differs from training data. This requires fundamental advances in uncertainty quantification and out-of-distribution detection</p>
<p><strong>Category 3: Fundamental Unknowns</strong> - These may require conceptual breakthroughs: - <strong>Consciousness and self-awareness</strong>: Whether AGI requires phenomenal consciousness remains unknown, with implications for both technical implementation and ethical considerations - <strong>Value alignment at scale</strong>: Specifying human values precisely enough for optimization remains unsolved, potentially requiring advances in moral philosophy alongside technical implementation - <strong>Control and corrigibility</strong>: Maintaining control over systems more capable than their overseers presents logical paradoxes that may require novel approaches to verification and governance</p>
</section>
<section id="sec-agi-systems-emerging-infrastructure-opportunities-10d4" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-emerging-infrastructure-opportunities-10d4">Emerging Infrastructure Opportunities</h5>
<p>Next-generation training platforms must efficiently handle the architectures emerging at the frontier. Current systems struggle with mixture-of-experts models that route different inputs through different parameters (requiring dynamic load balancing across 1000+ expert modules), dynamic computation graphs that change during training (demanding just-in-time compilation and memory management), and continuous learning pipelines that update models from streaming data (needing real-time parameter updates without service interruption). Companies that build platforms handling these challenges will define the AGI development environment, as traditional frameworks reach their limits.</p>
<p>The infrastructure opportunity extends to <strong>multi-modal processing platforms</strong> capable of unified handling across text, images, audio, video, and sensor data. Current systems optimize separately for each modality, requiring complex engineering to combine them. Unified platforms represent untapped markets worth hundreds of billions annually: systems where adding a new modality requires configuration changes rather than architectural redesign. The technical challenge involves shared representation learning, cross-modal attention mechanisms, and unified tokenization strategies.</p>
<p><strong>Edge-cloud hybrid intelligence systems</strong> blur the boundary between local and remote computation through intelligent workload distribution. These systems begin processing on edge devices for sub-100ms latency, dynamically offload complex reasoning to cloud resources based on computational requirements, and return results transparently to applications. Market opportunities exceed $50B annually across autonomous vehicles, robotics, and IoT applications. This requires innovations spanning adaptive model partitioning, predictive resource allocation, and context-aware caching strategies.</p>
</section>
<section id="sec-agi-systems-critical-challenges-ae15" class="level5 page-columns page-full">
<h5 class="anchored" data-anchor-id="sec-agi-systems-critical-challenges-ae15">Critical Challenges</h5>
<p>These opportunities come with challenges. When training runs cost millions of dollars and involve thousands of components, even 99.9% reliability means frequent failures that can destroy weeks of progress. This demands approaches to checkpointing that can restart from recent states, recovery mechanisms that salvage partial progress, and graceful degradation that maintains training quality when components fail.</p>
<p>The complexity multiplies as systems must coordinate heterogeneous hardware. Future infrastructure must orchestrate CPUs for preprocessing, GPUs for matrix operations, TPUs<a href="#fn45" class="footnote-ref" id="fnref45" role="doc-noteref"><sup>45</sup></a> for inference, quantum processors for optimization, and neuromorphic chips for energy-efficient computation. This heterogeneity demands abstractions that hide complexity from developers and scheduling algorithms that optimize across different computational paradigms.</p>
<div class="no-row-height column-margin column-container"><div id="fn45"><p><sup>45</sup>&nbsp;<strong>Tensor Processing Unit (TPU)</strong>: Google’s custom application-specific integrated circuit (ASIC) designed specifically for neural network machine learning. First generation (2015) achieved 15-30x higher performance and 30-80x better performance-per-watt than contemporary CPUs/GPUs for inference. TPU v4 (2021) delivers 275 teraFLOPs for training with specialized matrix multiplication units.</p></div></div></section>
</section>
<section id="sec-agi-systems-personalization-revolution-2016" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-personalization-revolution-2016">The Personalization Revolution</h3>
<p>Current AI systems provide the same responses to all users, though technical foundations now exist for personalized AI that adapts to individual preferences, knowledge, and context<a href="#fn46" class="footnote-ref" id="fnref46" role="doc-noteref"><sup>46</sup></a>. This creates opportunities for new categories of applications.</p>
<div class="no-row-height column-margin column-container"><div id="fn46"><p><sup>46</sup>&nbsp;<strong>Personalization Technical Foundations</strong>: Parameter-efficient fine-tuning reduces personalization costs by 1000x. Retrieval systems enable personal knowledge bases. Constitutional AI allows custom value alignment per user.</p></div></div><section id="sec-agi-systems-emerging-opportunities-ef50" class="level5 page-columns page-full">
<h5 class="anchored" data-anchor-id="sec-agi-systems-emerging-opportunities-ef50">Emerging Opportunities</h5>
<p>The opportunity involves personal AI systems that learn individual workflows, preferences, and expertise over months or years. Unlike current one-size-fits-all models, these systems would understand that you prefer technical explanations over simplified ones, remember your ongoing projects, and adapt their communication style to match your expertise level. Building these systems requires solving continual learning challenges covered in this textbook: how models update without forgetting, memory management for long-term interactions, and privacy preservation techniques from <strong><a href="../core/privacy_security/privacy_security.html#sec-security-privacy">Chapter 15: Security & Privacy</a></strong> that keep personal data secure.</p>
<p>This personalization extends to adaptive interfaces that modify their complexity based on user expertise. Consider a medical AI that provides pharmacological mechanisms and molecular pathways to doctors, but offers simplified explanations and visual aids to patients, all through the same underlying system. The interface intelligence lies not just in the knowledge base but in understanding how to present information appropriately for each user’s background and current needs.</p>
<p>The foundation enables federated intelligence systems where personal models learn locally but benefit from global knowledge through privacy-preserving aggregation. Your personal assistant learns from your specific workflows while incorporating insights from millions of other users, without any personal data leaving your device. This approach combines techniques from <strong><a href="../core/privacy_security/privacy_security.html#sec-security-privacy">Chapter 15: Security & Privacy</a></strong> with distributed training methodologies from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong><a href="#fn47" class="footnote-ref" id="fnref47" role="doc-noteref"><sup>47</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn47"><p><sup>47</sup>&nbsp;<strong>Federated Learning</strong>: Introduced by Google in 2016, enables model training across decentralized devices without sharing raw data. Google’s Gboard uses federated learning across 2 billion devices for next-word prediction. Technical challenges include non-IID data distribution, communication efficiency (1000× compression needed), and differential privacy guarantees. Apple implements federated learning for Siri wake word detection across 1.5 billion devices.</p></div></div></section>
<section id="sec-agi-systems-critical-challenges-2882" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-critical-challenges-2882">Critical Challenges</h5>
<p>Personalization introduces tensions between capability and privacy. Personalization requires user data (conversation histories, work patterns, personal preferences) yet privacy regulations and user expectations increasingly demand local processing. The challenge lies in developing federated learning and differential privacy techniques that enable personalization while maintaining privacy guarantees. Current approaches often sacrifice significant performance for privacy protection.</p>
<p>Personalized systems risk creating filter bubbles and reinforcing biases. When AI systems learn to give users what they want to hear rather than what they need to know, they can limit exposure to diverse perspectives and challenging ideas. Building responsible personalization requires careful attention to the principles from <strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong>: ensuring systems occasionally introduce diverse viewpoints and challenge user assumptions rather than simply confirming existing beliefs.</p>
</section>
</section>
<section id="sec-agi-systems-automation-acceleration-1a04" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-automation-acceleration-1a04">The Automation Acceleration</h3>
<p>Current AI systems excel at individual tasks, though the next frontier involves end-to-end automation of workflows. This requires orchestrating multiple AI systems with human oversight, a classic systems engineering challenge<a href="#fn48" class="footnote-ref" id="fnref48" role="doc-noteref"><sup>48</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn48"><p><sup>48</sup>&nbsp;<strong>Workflow Automation Scale</strong>: McKinsey estimates 60-70% of current jobs contain 30%+ automatable activities. But current automation covers &lt;5% of possible workflows due to integration complexity, not capability limitations.</p></div></div><section id="sec-agi-systems-emerging-opportunities-10c4" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-emerging-opportunities-10c4">Emerging Opportunities</h5>
<p>The opportunity lies in scientific discovery acceleration through AI systems that can hypothesize, design experiments, analyze results, and iterate autonomously. Imagine systems that read scientific literature, identify research gaps, formulate testable hypotheses, design experimental protocols, coordinate robotic laboratories for execution, analyze results, and iterate based on findings, accelerating research by orders of magnitude. This requires integrating reasoning systems for hypothesis generation, robotic laboratories for physical experimentation, and knowledge bases spanning multiple scientific domains.</p>
<p>Creative production pipelines that automate content creation from initial concept through final production offer promise. These systems would understand a creative brief, generate initial concepts, iterate based on feedback, produce final assets across multiple formats (text, images, video, interactive media) and optimize for different distribution channels. Current manual creative processes involve dozens of specialists and weeks of iteration; automated pipelines could compress this to hours while maintaining quality. Market opportunities exceed $100B annually across advertising, entertainment, and publishing industries.</p>
<p>Software development represents another frontier where AI systems understand natural language requirements, design system architectures, implement code across multiple languages and frameworks, write tests, and deploy to production environments. Early versions like GitHub Copilot already demonstrate 30-50% productivity improvements for individual coding tasks. Complete workflow automation could enable non-programmers to build software systems through conversation, democratizing software development.</p>
</section>
<section id="sec-agi-systems-critical-challenges-1136" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-critical-challenges-1136">Critical Challenges</h5>
<p>Automation introduces tension between autonomy and reliability. Higher automation requires higher reliability, yet current AI systems still make errors that compound through long workflow chains. A small mistake in early stages can invalidate hours or days of subsequent work. This demands verification and validation techniques designed for AI-driven workflows, including automated testing that understands AI behavior patterns, checkpoint systems that enable rollback from failure points, and confidence monitoring that triggers human review when uncertainty increases.</p>
<p>More challenging is designing effective human-AI collaboration patterns. Complete automation often fails, but determining optimal handoff points between AI systems and human oversight requires understanding both technical capabilities and human factors. The challenge involves creating interfaces that provide context for human decision-making, developing trust calibration so humans know when to intervene, and maintaining human expertise in domains where automation becomes dominant.</p>
</section>
</section>
<section id="sec-agi-systems-realtime-intelligence-challenge-7e48" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-realtime-intelligence-challenge-7e48">The Real-Time Intelligence Challenge</h3>
<p>Most current AI applications can tolerate seconds or minutes of latency, but emerging applications demand real-time response: autonomous vehicles, robotic surgery, high-frequency trading, and live conversation systems<a href="#fn49" class="footnote-ref" id="fnref49" role="doc-noteref"><sup>49</sup></a>. This creates new optimization challenges.</p>
<div class="no-row-height column-margin column-container"><div id="fn49"><p><sup>49</sup>&nbsp;<strong>Real-Time Latency Requirements</strong>: Autonomous vehicles need &lt;10ms perception-to-action loops. Conversational AI requires &lt;200ms response for natural interaction. Robotic surgery demands &lt;1ms control loops. Current cloud systems achieve 50-200ms best case.</p></div></div><section id="sec-agi-systems-emerging-opportunities-96fa" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-emerging-opportunities-96fa">Emerging Opportunities</h5>
<p>The opportunity involves edge AI platforms that run powerful models locally with millisecond latency. Rather than sending data to distant cloud servers, these systems perform inference directly on user devices, autonomous vehicles, or industrial equipment. This approach eliminates network latency while providing the computational power needed for complex reasoning. Building these platforms requires innovations spanning model compression techniques from <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong>, specialized hardware optimized for specific neural network patterns, and distributed deployment strategies that coordinate multiple edge devices.</p>
<p>Beyond static inference, streaming intelligence systems process continuous data streams (video feeds, audio conversations, sensor measurements) in real-time rather than batch processing. These systems must maintain temporal context across long sequences, update their understanding as new data arrives, and make decisions without waiting for complete information. The architectural challenge involves designing neural networks optimized for temporal modeling and incremental computation rather than the batch processing assumptions underlying most current systems.</p>
<p>Interactive AI systems that respond instantly to user input, enabling new forms of human-AI collaboration. Conversational agents that understand and respond within natural conversation timing, creative tools that provide real-time feedback as artists work, and collaborative systems where AI contributes to human workflows. The difference between 200ms and 2000ms response time fundamentally changes interaction patterns, with the former feeling like conversation and the latter like operating a slow computer.</p>
</section>
<section id="sec-agi-systems-critical-challenges-9844" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-critical-challenges-9844">Critical Challenges</h5>
<p>Real-time requirements introduce trade-offs between quality and speed. Real-time systems often cannot use the most advanced models due to latency constraints, a dilemma that becomes more severe as model capabilities increase. The challenge lies in developing architectures that maintain reasoning quality under strict timing requirements. This might involve hierarchical processing where simple models handle routine cases while advanced models activate only when needed, or adaptive algorithms that adjust computational depth based on available time.</p>
<p>When real-time deadlines cannot be met, systems must degrade gracefully rather than failing completely. This requires engineering fallback mechanisms that provide approximate results when exact computation isn’t possible, quality adaptation systems that adjust output fidelity based on computational constraints, and user interface design that communicates system limitations without breaking the interaction flow. The engineering challenge involves predicting deadline misses and preparing alternatives.</p>
</section>
</section>
<section id="sec-agi-systems-explainability-imperative-78c4" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-agi-systems-explainability-imperative-78c4">The Explainability Imperative</h3>
<p>As AI systems make important decisions (medical diagnoses, legal judgments, financial investments) the demand for explainable AI grows rapidly<a href="#fn50" class="footnote-ref" id="fnref50" role="doc-noteref"><sup>50</sup></a>. This creates opportunities for systems that can provide interpretable reasoning while maintaining performance.</p>
<div class="no-row-height column-margin column-container"><div id="fn50"><p><sup>50</sup>&nbsp;<strong>Explainability Market Growth</strong>: Explainable AI market projected to grow from $5.2B (2023) to $21.4B (2030). Regulatory requirements in EU AI Act and medical device approval drive 60%+ of demand.</p></div></div><section id="sec-agi-systems-emerging-opportunities-c1c4" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-emerging-opportunities-c1c4">Emerging Opportunities</h5>
<p>This requires developing interpretable model architectures designed for explainability from the ground up rather than relying on post-hoc explanation techniques. Current approaches often involve training black-box models and then building separate systems to explain their decisions, an approach that may miss crucial reasoning steps. Instead, future architectures integrate interpretability as a first-class constraint, potentially requiring rethinking the neural network designs from <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong>. These models might sacrifice some capability for transparency, but enable applications where understanding the reasoning process is more important than marginal performance gains.</p>
<p>Reasoning trace systems represent another direction: AI systems that can show their step-by-step reasoning process with formal verification capabilities. Unlike current chain-of-thought prompting that provides natural language explanations of uncertain reliability, these systems would maintain precise reasoning traces that can be independently verified. Users could inspect every logical step, understand exactly how conclusions were reached, and identify potential errors or biases in the reasoning process.</p>
<p>Interactive explanation interfaces offer opportunity: tools that let users probe AI decisions at multiple levels of detail based on their expertise and needs. Rather than providing fixed explanations, these systems adapt explanations dynamically, offering high-level summaries for quick understanding, detailed technical analysis for experts, and intermediate explanations for users seeking more depth. The interface challenge involves understanding user expertise levels and presenting appropriate amounts of detail without overwhelming or under-informing users.</p>
</section>
<section id="sec-agi-systems-critical-challenges-3b55" class="level5">
<h5 class="anchored" data-anchor-id="sec-agi-systems-critical-challenges-3b55">Critical Challenges</h5>
<p>Explainability introduces tensions between explanation quality and model performance. More interpretable models often sacrifice accuracy because the constraints required for human understanding may conflict with computational patterns. The challenge lies in developing techniques that provide both high performance and meaningful explanations, possibly through hybrid architectures using interpretable models for explanation while maintaining high-performance models for prediction.</p>
<p>Different users need different types of explanations. Medical professionals want detailed causal reasoning showing how symptoms relate to diagnoses, while patients want simple, reassuring summaries that help them understand their treatment options. Regulatory auditors need compliance-focused explanations demonstrating fairness, while researchers need technical details enabling reproducibility. Building systems that adapt explanations appropriately requires combining technical expertise with user experience design: understanding not just what explanations are possible, but which explanations are useful for specific audiences and contexts.</p>
<div id="quiz-question-sec-agi-systems-challenges-opportunities-opens-51a8" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.5</strong></summary><div>
<ol type="1">
<li><p>What is a primary reason for the inefficiency in current AI infrastructure?</p>
<ol type="a">
<li>High GPU utilization rates</li>
<li>Lack of advanced AI algorithms</li>
<li>Excessive redundancy in model parameters</li>
<li>Communication overhead and load imbalancing</li>
</ol></li>
<li><p>Explain the trade-offs involved in designing real-time AI systems that need to balance quality and speed.</p></li>
<li><p>Which of the following represents an opportunity for innovation in AI infrastructure?</p>
<ol type="a">
<li>Developing separate systems for each data modality</li>
<li>Increasing reliance on cloud-only computation</li>
<li>Creating unified platforms for multi-modal processing</li>
<li>Focusing solely on text-based AI models</li>
</ol></li>
<li><p>In a production system, how might edge-cloud hybrid systems improve AI application performance?</p></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-challenges-opportunities-opens-51a8" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-agi-systems-implications-ml-systems-engineers-781e" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-implications-ml-systems-engineers-781e">Implications for ML Systems Engineers</h2>
<p>ML systems engineers with understanding of this textbook’s content are uniquely positioned for AGI development. The competencies developed, from data engineering through distributed training and model optimization through robust deployment, constitute essential AGI infrastructure requirements.</p>
<p>Three key career paths emerge: <strong>Infrastructure Specialists</strong> build platforms enabling next-generation AI development through distributed systems and hardware acceleration expertise. <strong>Applied AI Engineers</strong> create personalized, real-time, and automated systems by combining model optimization with domain expertise. <strong>AI Safety Engineers</strong> ensure beneficial system behavior through robust design and responsible AI principles.</p>
<p>AGI development demands full-stack engineering capabilities: infrastructure construction for unprecedented scale (GPT-4 required 25,000 A100 GPUs consuming 50-100 GWh electricity, while AGI may require 500,000-5,000,000 accelerators and $100B-$1T infrastructure investments), efficient experimentation tools, safety and alignment system design, and reproducible complex system interactions. Post-Moore’s Law efficiency improvements could reduce these requirements by 10-100x.</p>
<div id="quiz-question-sec-agi-systems-implications-ml-systems-engineers-781e" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.6</strong></summary><div>
<ol type="1">
<li><p>Which role is primarily responsible for building platforms that enable next-generation AI development?</p>
<ol type="a">
<li>Data Scientists</li>
<li>Applied AI Engineers</li>
<li>AI Safety Engineers</li>
<li>Infrastructure Specialists</li>
</ol></li>
<li><p>Explain how the role of AI Safety Engineers is crucial in the development of AGI systems.</p></li>
<li><p>What is a key challenge that Infrastructure Specialists face when developing AGI systems?</p>
<ol type="a">
<li>Creating personalized AI systems</li>
<li>Ensuring system safety and alignment</li>
<li>Scaling infrastructure to support massive computational needs</li>
<li>Optimizing models for specific domains</li>
</ol></li>
<li><p>How might an Applied AI Engineer leverage their skills to optimize AI systems for production environments?</p></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-implications-ml-systems-engineers-781e" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-agi-systems-next-decade-systems-perspective" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-next-decade-systems-perspective">The Next Decade: A Systems Engineering Perspective</h2>
<p>Based on current trajectories and compound systems principles, the next decade will likely unfold in three phases:</p>
<p><strong>2025-2027: Efficiency and Standardization</strong> Self-supervised learning becomes dominant, reducing data requirements while compound AI systems standardize through orchestration frameworks. Post-Moore’s Law architectures (3D stacking, chiplets, optical interconnects) provide efficiency gains, enabling trillion-parameter edge deployment through aggressive optimization.</p>
<p><strong>2027-2030: Integration and Scale</strong> Multi-agent systems coordinate millions of specialized components using hierarchical consensus mechanisms. Distributed AGI infrastructure spans continents while energy-based models enable robust reasoning through optimization-based inference. Hardware advances (neuromorphic, quantum-hybrid) reduce training energy by orders of magnitude.</p>
<p><strong>2030-2035: Emergence and Coordination</strong> Systems approach 10<sup>26-10</sup>28 FLOP training scales through global infrastructure coordination. Breakthrough solutions enable genuine reasoning, planning, and transfer learning while AGI coordination protocols manage planetary-scale intelligence with Byzantine fault tolerance.</p>
<p>This trajectory depends on the systems engineering principles developed throughout this textbook: distributed infrastructure, efficient optimization, robust deployment, and safe operation at unprecedented scale.</p>
</section>
<section id="sec-agi-systems-engineering-foundations-uncertain-future" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-engineering-foundations-uncertain-future">Engineering Foundations for an Uncertain Future</h2>
<p>AGI trajectory remains uncertain. Breakthroughs may emerge from unexpected directions: transformers displaced RNNs in 2017 despite decades of LSTM dominance, state space models achieve transformer performance with linear complexity, and quantum neural networks could provide exponential speedups for specific problems.</p>
<p>This uncertainty amplifies systems engineering value. Regardless of architectural breakthroughs, successful approaches require efficient data processing pipelines handling exabyte-scale datasets, scalable training infrastructure supporting million-GPU clusters, optimized model deployment across heterogeneous hardware, robust operational practices ensuring 99.99% availability, and integrated safety and ethics frameworks.</p>
<p>The systematic approaches to distributed systems, efficient deployment, and robust operation covered throughout this textbook remain essential whether AGI emerges from scaled transformers, compound systems, or entirely new architectures. Engineering principles transcend specific technologies, providing foundations for intelligent system construction across any technological trajectory.</p>
</section>
<section id="sec-agi-systems-common-fallacies-pitfalls" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-common-fallacies-pitfalls">Common Fallacies and Engineering Pitfalls</h2>
<p>Four critical misconceptions can derail AGI development:</p>
<p><strong>Scaling Fallacy</strong>: Assuming parameters and data alone achieve general intelligence ignores architectural innovation, efficiency improvements, and training paradigm advances. The human brain achieves intelligence through 86 billion neurons via architecture and learning mechanisms, not scale alone.</p>
<p><strong>Compound Systems Neglect</strong>: Focusing on larger models while ignoring compound AI systems wastes current capabilities. Combinations of specialized models, tools, and databases solve problems today while establishing patterns essential for AGI.</p>
<section id="sec-agi-systems-biological-intelligence-design-template" class="level4">
<h4 class="anchored" data-anchor-id="sec-agi-systems-biological-intelligence-design-template">Biological Intelligence as a Design Template</h4>
<p>The striking efficiency gap between biological and artificial intelligence suggests that biological principles could fundamentally reshape how we approach AGI system design. Understanding these principles provides crucial insights for building more efficient, robust, and capable artificial systems.</p>
<p><strong>Energy Efficiency and Neural Computation</strong>: The human brain’s remarkable energy efficiency—processing 10¹⁵ synaptic operations per second on just 20 watts—reveals fundamental computational principles absent in current digital systems. Biological neurons communicate through discrete spikes rather than continuous activations, enabling event-driven computation that activates only when information needs processing. This sparse, asynchronous processing contrasts sharply with the dense matrix operations of current neural networks that activate every parameter for every input.</p>
<p>Neuromorphic computing attempts to replicate these principles through spike-based processing, achieving 1000x energy improvements over conventional processors for certain tasks. Intel’s Loihi chip demonstrates how biological timing and sparsity can be engineered into silicon, though current implementations remain limited compared to biological neural networks. Future AGI systems might adopt hybrid architectures that combine digital precision for symbolic reasoning with neuromorphic efficiency for pattern recognition and sensory processing.</p>
<p><strong>Hierarchical Learning and Development</strong>: Biological intelligence develops through structured stages, from basic sensory-motor coordination to abstract reasoning capabilities. This developmental process suggests that AGI might emerge more efficiently through staged learning rather than attempting to train all capabilities simultaneously. The human brain employs critical periods where specific capabilities develop optimally, followed by phases where these skills integrate with higher-level reasoning.</p>
<p>This developmental approach could inform AGI training pipelines: first learning basic perceptual and motor skills, then building world models of physical causality, followed by social understanding and finally abstract reasoning. Each stage builds on previous capabilities while introducing new ones, potentially enabling more sample-efficient learning than current end-to-end training approaches.</p>
<p><strong>Multimodal Integration and Embodiment</strong>: Biological intelligence emerges from continuous interaction between multiple sensory modalities and motor actions. The brain integrates vision, hearing, touch, proprioception, and motor control into unified representations that enable coherent action in complex environments. This multimodal integration provides the grounding that connects abstract concepts to physical experience—a capability notably absent in current language models.</p>
<p>AGI systems might require similar embodied learning, either through physical robotics or rich simulated environments that provide multimodal experience. The engineering challenge involves creating systems that can process multiple synchronized data streams (vision, audio, tactile feedback, proprioception) while learning unified representations that support both perception and action. This demands new architectures optimized for temporal synchronization and multimodal fusion rather than the unimodal processing that dominates current systems.</p>
<p><strong>Continuous Learning and Adaptation</strong>: Most significantly, biological intelligence demonstrates continuous learning throughout life, adapting to new environments and challenges without catastrophic forgetting of previous knowledge. The brain maintains plasticity while preserving essential knowledge, enabling lifelong learning that current artificial systems struggle to achieve.</p>
<p>This continuous adaptation capability is essential for AGI deployment in the real world, where systems must learn from ongoing experience rather than relying solely on pre-training. The systems engineering challenges include designing architectures that support continual learning, developing memory systems that balance plasticity with stability, and creating training procedures that enable learning from streaming data without degrading existing capabilities.</p>
<p><strong>Systems Implications of Biological Principles</strong>: Incorporating biological principles into AGI systems has profound implications for architecture design, requiring event-driven processing systems optimized for sparse, asynchronous computation, multimodal data processing pipelines that can handle synchronized streams of diverse sensory data, hierarchical learning systems that build capabilities progressively through developmental stages, and memory architectures that support both rapid learning and long-term retention.</p>
<p>These biological insights suggest that the path to AGI might require fundamental rethinking of current neural network architectures, moving beyond the transformer-centric approaches toward more biologically-inspired designs that capture the efficiency, robustness, and adaptability of natural intelligence.</p>
<p><strong>Engineering Replacement Myth</strong>: Believing AGI requires entirely new engineering principles leads teams to ignore current best practices. Distributed training, efficient inference, robust deployment, and monitoring remain essential as architectures evolve.</p>
<p><strong>Safety Postponement</strong>: Delaying safety concerns until systems become more capable is dangerous. Current alignment challenges including reward hacking, distributional shift, and adversarial examples become more severe as capabilities grow. Building safety foundations early is easier than retrofitting them later.</p>
</section>
</section>
<section id="sec-agi-systems-implications-ml-engineers-6c31" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-implications-ml-engineers-6c31">Implications for ML Engineers</h2>
<p>The frontiers discussed in this chapter shape the daily work of ML engineers today. Understanding these trajectories helps you make better architectural decisions, even for routine projects.</p>
<p><strong>System Design Decisions</strong>: When building ML applications, the choice between monolithic models and compound systems matters. A compound system with specialized components often outperforms a single large model while being easier to debug, update, and scale. The compound architecture in <a href="#fig-compound-ai-system" class="quarto-xref">Figure&nbsp;5</a> is a pattern you can apply today when building production systems.</p>
<p><strong>Data Strategy</strong>: The data pipeline shown in <a href="#fig-frontier-data-pipeline" class="quarto-xref">Figure&nbsp;1</a> applies to any ML project. Whether you’re training a small domain-specific model or contributing to foundation model development, the principles remain: invest in data quality over quantity, build filtering pipelines, and consider synthetic data generation to address gaps. The 90% filtering rate for frontier models suggests that your data cleaning efforts are likely under-invested.</p>
<p><strong>Alignment and Safety</strong>: The RLHF pipeline (<a href="#fig-rlhf-pipeline" class="quarto-xref">Figure&nbsp;3</a>) demonstrates that alignment is essential for user satisfaction. Even simple classification models benefit from preference learning. The techniques scale down: you can apply RLHF principles to customer service bots, content moderation systems, or recommendation engines.</p>
<p><strong>Scalability Planning</strong>: The MoE architecture (<a href="#fig-moe-routing" class="quarto-xref">Figure&nbsp;2</a>) shows how conditional computation enables scaling. This pattern applies beyond transformers: any system where different inputs require different processing can benefit from routing mechanisms. Database query optimizers, API gateways, and microservice architectures use similar principles.</p>
<p><strong>Career Preparation</strong>: The skills needed for AGI development are extensions of current ML engineering: distributed systems expertise from <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong> becomes critical as models grow, hardware-software co-design knowledge from <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong> becomes essential for efficiency, and understanding of human-AI interaction from <strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong> becomes central to alignment. The fundamentals covered in this textbook provide the foundation; the frontiers simply push these principles to their limits.</p>
<div id="quiz-question-sec-agi-systems-implications-ml-engineers-6c31" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.7</strong></summary><div>
<ol type="1">
<li><p>What is a key advantage of using a compound system over a monolithic model in ML applications?</p>
<ol type="a">
<li>Lower initial development cost</li>
<li>Requires less data</li>
<li>Faster training times</li>
<li>Easier to debug and update</li>
</ol></li>
<li><p>Explain how investing in data quality over quantity can impact the performance of an ML system.</p></li>
<li><p>True or False: The MoE architecture is only applicable to transformer models.</p></li>
<li><p>In ML engineering, understanding ____ becomes critical as models grow and require efficient resource management.</p></li>
<li><p>How might you apply the principles of RLHF to improve user satisfaction in a recommendation engine?</p></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-implications-ml-engineers-6c31" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-agi-systems-summary-297d" class="level2">
<h2 class="anchored" data-anchor-id="sec-agi-systems-summary-297d">Summary</h2>
<p>Artificial intelligence stands at an inflection point where the building blocks mastered throughout this textbook assemble into systems of extraordinary capability. Large language models demonstrate that engineered scale unlocks emergent intelligence through the discontinuous capability improvements detailed in <a href="#sec-agi-systems-current-revolution-2025-snapshot-894e" class="quarto-xref">Section&nbsp;1.1</a>.</p>
<p>The narrow AI to AGI transition constitutes a systems engineering challenge extending beyond algorithmic innovation to encompass integration of data, compute, models, and infrastructure at unprecedented scale. Estimates suggest AGI training will require 10²⁶-10²⁹ FLOPs, 100+ trillion tokens, and $1-100 billion in compute resources with infrastructure supporting 100,000+ accelerators at 99.99% reliability.</p>
<p>Compound AI systems provide the architectural foundation for this transition, revealing how specialized components solve complex problems through intelligent orchestration rather than monolithic scaling.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Key Takeaways">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Takeaways
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Current AI breakthroughs (LLMs, multimodal models) directly build upon ML systems engineering principles established throughout preceding chapters</li>
<li>AGI represents systems integration challenges requiring sophisticated orchestration across multiple components and technologies</li>
<li>Compound AI systems provide practical pathways combining specialized models and tools for complex capability achievement</li>
<li>Engineering competencies developed, from distributed training through efficient deployment, constitute essential AGI development requirements</li>
<li>Future advances emerge from systems engineering improvements equally with algorithmic innovations</li>
</ul>
</div>
</div>
<p>This textbook prepares readers for contribution to this challenge. Understanding encompasses data flow through systems (<strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>), model optimization and deployment (<strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong>), hardware acceleration of computation (<strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>), and reliable ML system operation at scale (<strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>). These capabilities constitute requirements for next-generation intelligent system construction.</p>
<p>AGI arrival timing remains uncertain, whether from scaled transformers or novel architectures. Systems engineering principles remain essential regardless of timeline or technical approach. Artificial intelligence futures build upon tools and techniques covered throughout these chapters, from neural network principles in <strong><a href="../core/dl_primer/dl_primer.html#sec-dl-primer">Chapter 3: Deep Learning Primer</a></strong> to advanced system orchestration in <strong><a href="../core/workflow/workflow.html#sec-ai-workflow">Chapter 19: AI Workflow</a></strong>.</p>
<p>The foundation stands complete, built through systematic mastery of ML systems engineering from data pipelines through distributed training to robust deployment.</p>


<div id="quiz-question-sec-agi-systems-summary-297d" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.8</strong></summary><div>
<ol type="1">
<li><p>What is a key characteristic of emergent capabilities in AI systems like GPT-3?</p>
<ol type="a">
<li>They appear discontinuously at specific parameter thresholds.</li>
<li>They gradually improve with each parameter increase.</li>
<li>They are solely dependent on algorithmic innovations.</li>
<li>They require minimal computational resources.</li>
</ol></li>
<li><p>Explain why the transition from narrow AI to AGI is primarily a systems engineering challenge.</p></li>
<li><p>True or False: The development of AGI will primarily rely on algorithmic innovations rather than systems integration.</p></li>
<li><p>Which of the following best describes the role of systems engineering in AI development?</p>
<ol type="a">
<li>It focuses solely on optimizing algorithms.</li>
<li>It involves the integration and orchestration of various components and technologies.</li>
<li>It is primarily concerned with data collection.</li>
<li>It is only relevant for hardware design.</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-agi-systems-summary-297d" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="self-check-answers" class="level2">
<h2 class="anchored" data-anchor-id="self-check-answers">Self-Check Answers</h2>
<div id="quiz-answer-sec-agi-systems-current-revolution-2025-snapshot-894e" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.1</strong></summary><div>
<ol type="1">
<li><p><strong>What is a key factor that distinguishes the capabilities of large language models like GPT-4 from previous AI models?</strong></p>
<ol type="a">
<li>Fundamental algorithmic breakthroughs</li>
<li>Systematic integration of established components</li>
<li>Reduced computational requirements</li>
<li>Specialized algorithms for specific tasks</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Systematic integration of established components. This is correct because the section emphasizes that the advancements in AI capabilities come from integrating existing components rather than new algorithms. Options A, C, and D are incorrect as they do not align with the section’s focus on integration and scaling.</p>
<p><em>Learning Objective</em>: Understand the role of integration in the advancement of AI capabilities.</p></li>
<li><p><strong>Explain how the concept of ‘emergent capabilities’ is demonstrated in large language models.</strong></p>
<p><em>Answer</em>: Emergent capabilities in large language models appear as sudden improvements in performance at certain parameter thresholds, similar to phase transitions in physics. For example, chain-of-thought reasoning emerges around 60-100 billion parameters, significantly enhancing the model’s reasoning abilities. This is important because it highlights how scaling can lead to qualitative changes in AI performance.</p>
<p><em>Learning Objective</em>: Analyze the concept of emergent capabilities in the context of large language models.</p></li>
<li><p><strong>True or False: The rapid adoption of ChatGPT was primarily due to novel algorithmic innovations.</strong></p>
<p><em>Answer</em>: False. This is false because the section states that ChatGPT’s rapid adoption was due to successful systems integration and scaling, not novel algorithms.</p>
<p><em>Learning Objective</em>: Challenge misconceptions about the factors driving AI adoption and success.</p></li>
<li><p><strong>How do modern AI systems achieve few-shot learning capabilities?</strong></p>
<ol type="a">
<li>Through emergent capabilities at scale</li>
<li>By training on large datasets with many examples</li>
<li>By using specialized models for each task</li>
<li>Through manual tuning of model parameters</li>
</ol>
<p><em>Answer</em>: The correct answer is A. Through emergent capabilities at scale. This is correct because few-shot learning is enabled by the scaling of models that leads to emergent capabilities, allowing them to adapt to new tasks with minimal examples. Options A, C, and D are incorrect as they do not reflect the section’s emphasis on scaling and emergent properties.</p>
<p><em>Learning Objective</em>: Understand the role of scaling in enabling few-shot learning in AI systems.</p></li>
<li><p><strong>In a production system, what are the implications of integrating multimodal processing capabilities?</strong></p>
<p><em>Answer</em>: Integrating multimodal processing capabilities allows a system to handle text, images, audio, and video through a unified architecture. This simplifies system design by eliminating the need for separate pipelines and enables richer applications, such as more interactive and context-aware AI systems. This is important because it enhances the system’s versatility and user engagement.</p>
<p><em>Learning Objective</em>: Evaluate the implications of multimodal processing in AI system design.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-current-revolution-2025-snapshot-894e" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.2</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes Artificial General Intelligence (AGI)?</strong></p>
<ol type="a">
<li>A system that excels at a specific task using task-specific training.</li>
<li>A system that requires extensive data to perform well in a narrow domain.</li>
<li>A system capable of generalizing across diverse problem domains without task-specific training.</li>
<li>A system that uses symbolic reasoning exclusively to solve problems.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. A system capable of generalizing across diverse problem domains without task-specific training. This is correct because AGI is defined by its ability to transfer knowledge and adapt flexibly across various domains, unlike narrow AI.</p>
<p><em>Learning Objective</em>: Understand the core definition and characteristics of AGI.</p></li>
<li><p><strong>Explain why AGI is considered a formidable systems engineering challenge.</strong></p>
<p><em>Answer</em>: AGI is a formidable systems engineering challenge because it requires the integration of multiple cognitive systems such as perception, reasoning, planning, and learning into a unified architecture. This integration must occur within the constraints of limited computational resources, making it a complex task. For example, achieving seamless coordination between these subsystems while ensuring adaptability and generalization across tasks is a significant engineering hurdle. This is important because it highlights the complexity and interdisciplinary nature of developing AGI systems.</p>
<p><em>Learning Objective</em>: Analyze the systems engineering challenges involved in developing AGI.</p></li>
<li><p><strong>Order the following cognitive capabilities that need to be integrated for AGI: (1) Reasoning, (2) Multimodal perception, (3) Planning, (4) Learning.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Multimodal perception, (1) Reasoning, (3) Planning, (4) Learning. Multimodal perception provides the sensory inputs, reasoning processes these inputs, planning strategizes actions based on reasoning, and learning improves all these processes over time. This order reflects the typical flow of information processing in an intelligent system.</p>
<p><em>Learning Objective</em>: Understand the integration sequence of cognitive capabilities necessary for AGI.</p></li>
<li><p><strong>Which approach suggests that intelligence requires embodied interaction with the world?</strong></p>
<ol type="a">
<li>Scaling hypothesis</li>
<li>Neurosymbolic AI</li>
<li>Multi-agent systems</li>
<li>Embodied cognition</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Embodied cognition. This approach is based on the idea that abstract reasoning emerges from grounding in physical or simulated environments, emphasizing real-time interaction and on-device learning.</p>
<p><em>Learning Objective</em>: Identify different approaches to achieving AGI and their underlying principles.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-agi-vision-intelligence-systems-problem-2b44" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.3</strong></summary><div>
<ol type="1">
<li><p><strong>What is a key limitation of transformers when processing long sequences?</strong></p>
<ol type="a">
<li>They require linear scaling with sequence length.</li>
<li>They require quadratic scaling with sequence length.</li>
<li>They cannot handle sequences longer than 10,000 tokens.</li>
<li>They are unable to maintain context over long sequences.</li>
</ol>
<p><em>Answer</em>: The correct answer is B. They require quadratic scaling with sequence length. This is correct because the attention mechanism compares every token with every other token, leading to quadratic computational complexity. Options A and B are incorrect because transformers do not scale linearly and can handle long sequences, albeit inefficiently. Option D is incorrect as transformers can maintain context, but at a computational cost.</p>
<p><em>Learning Objective</em>: Understand the computational limitations of transformers for long sequence processing.</p></li>
<li><p><strong>Explain how state space models address the limitations of transformers in processing long sequences.</strong></p>
<p><em>Answer</em>: State space models address the limitations by maintaining a compressed memory of past information, allowing them to update incrementally with new tokens. This approach enables linear scaling with sequence length, unlike transformers’ quadratic scaling. For example, models like Mamba demonstrate that state space models can match transformer performance while being more efficient. This is important because it allows processing of much longer sequences without prohibitive computational costs.</p>
<p><em>Learning Objective</em>: Analyze how alternative architectures like state space models improve sequence processing efficiency.</p></li>
<li><p><strong>True or False: State space models require the same level of engineering optimization as transformers to be effective.</strong></p>
<p><em>Answer</em>: False. State space models are still experimental and do not yet benefit from the extensive optimization that transformers have across the ML systems stack. This includes specialized hardware and distributed training frameworks.</p>
<p><em>Learning Objective</em>: Evaluate the current state of optimization for alternative architectures compared to transformers.</p></li>
<li><p><strong>State space models maintain a ____ of past information to efficiently process long sequences.</strong></p>
<p><em>Answer</em>: compressed memory. This allows them to update incrementally with new tokens, enabling linear scaling with sequence length.</p>
<p><em>Learning Objective</em>: Recall the key mechanism by which state space models handle long sequences.</p></li>
<li><p><strong>In a production system, what are the potential benefits and challenges of adopting state space models over transformers?</strong></p>
<p><em>Answer</em>: The potential benefits include the ability to process much longer sequences efficiently, such as book-length contexts or entire codebases, due to linear scaling. Challenges include the need for new engineering optimizations and the lack of a mature ecosystem compared to transformers. For example, data loading strategies and memory management must be rethought for state space models. This is important because it impacts the feasibility and cost of deploying these models in real-world applications.</p>
<p><em>Learning Objective</em>: Assess the trade-offs and practical considerations of implementing state space models in production systems.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-beyond-transformers-alternative-architectures-6243" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.4</strong></summary><div>
<ol type="1">
<li><p><strong>What is the primary benefit of agent specialization in a multi-agent system?</strong></p>
<ol type="a">
<li>Increased redundancy</li>
<li>Simplified communication protocols</li>
<li>Improved efficiency in specific tasks</li>
<li>Reduced need for consensus mechanisms</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Improved efficiency in specific tasks. This is correct because agent specialization allows each agent to excel in its domain, similar to microservices optimizing specific functionalities. Other options do not directly relate to the benefits of specialization.</p>
<p><em>Learning Objective</em>: Understand the role and benefit of agent specialization in multi-agent systems.</p></li>
<li><p><strong>Explain how communication protocols in multi-agent systems are similar to those in distributed systems.</strong></p>
<p><em>Answer</em>: Communication protocols in multi-agent systems are similar to those in distributed systems because they both require the design of message formats, error handling, and load balancing to enable effective coordination and information sharing. For example, both systems need to handle complex interactions and ensure scalability. This is important because it ensures seamless interaction among agents, enabling emergent intelligence.</p>
<p><em>Learning Objective</em>: Analyze the similarities between communication protocols in multi-agent and distributed systems.</p></li>
<li><p><strong>True or False: Consensus mechanisms in multi-agent systems are unnecessary if agents are specialized.</strong></p>
<p><em>Answer</em>: False. Consensus mechanisms are necessary even in specialized multi-agent systems because agents may have conflicting information or goals, requiring a method to reach agreement and coordinate actions effectively.</p>
<p><em>Learning Objective</em>: Challenge the misconception that specialization negates the need for consensus mechanisms.</p></li>
<li><p><strong>The goal of multi-agent systems is to achieve ____ intelligence, where capabilities arise from agent interactions.</strong></p>
<p><em>Answer</em>: emergent. Emergent intelligence refers to capabilities that arise from the interactions of agents, which are greater than the sum of individual agent capabilities.</p>
<p><em>Learning Objective</em>: Recall the concept of emergent intelligence in multi-agent systems.</p></li>
<li><p><strong>In a production system, what challenges might arise from implementing consensus mechanisms in multi-agent systems?</strong></p>
<p><em>Answer</em>: In a production system, challenges in implementing consensus mechanisms include preventing deadlocks, handling Byzantine failures where some agents provide misleading information, and ensuring consensus converges efficiently. For example, misaligned goals or faulty communication can lead to inefficiencies. This is important because robust consensus mechanisms are crucial for maintaining system reliability and achieving collective decision-making.</p>
<p><em>Learning Objective</em>: Evaluate the challenges of implementing consensus mechanisms in multi-agent systems.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-multiagent-futures-collective-intelligence-3ee4" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-challenges-opportunities-opens-51a8" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.5</strong></summary><div>
<ol type="1">
<li><p><strong>What is a primary reason for the inefficiency in current AI infrastructure?</strong></p>
<ol type="a">
<li>High GPU utilization rates</li>
<li>Lack of advanced AI algorithms</li>
<li>Excessive redundancy in model parameters</li>
<li>Communication overhead and load imbalancing</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Communication overhead and load imbalancing. These factors contribute to the low utilization rates of GPU clusters, leading to inefficiencies in AI infrastructure.</p>
<p><em>Learning Objective</em>: Understand the factors contributing to inefficiencies in current AI infrastructure.</p></li>
<li><p><strong>Explain the trade-offs involved in designing real-time AI systems that need to balance quality and speed.</strong></p>
<p><em>Answer</em>: Real-time AI systems often face trade-offs between maintaining high reasoning quality and meeting strict latency requirements. For example, using simpler models for routine tasks can ensure speed, while reserving complex models for critical decisions. This balance is crucial because it affects user interaction quality and system reliability. In practice, hierarchical processing or adaptive algorithms can help manage these trade-offs.</p>
<p><em>Learning Objective</em>: Analyze the trade-offs between quality and speed in real-time AI systems.</p></li>
<li><p><strong>Which of the following represents an opportunity for innovation in AI infrastructure?</strong></p>
<ol type="a">
<li>Developing separate systems for each data modality</li>
<li>Increasing reliance on cloud-only computation</li>
<li>Creating unified platforms for multi-modal processing</li>
<li>Focusing solely on text-based AI models</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Creating unified platforms for multi-modal processing. This approach allows for efficient handling of diverse data types, unlocking new market opportunities.</p>
<p><em>Learning Objective</em>: Identify opportunities for innovation in AI infrastructure, particularly in multi-modal processing.</p></li>
<li><p><strong>In a production system, how might edge-cloud hybrid systems improve AI application performance?</strong></p>
<p><em>Answer</em>: Edge-cloud hybrid systems improve AI application performance by reducing latency through local edge processing and leveraging cloud resources for complex computations. For example, initial data processing can occur on edge devices to provide immediate responses, while more intensive tasks are offloaded to the cloud. This architecture enhances user experience by balancing speed and computational power.</p>
<p><em>Learning Objective</em>: Evaluate the impact of edge-cloud hybrid systems on AI application performance.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-challenges-opportunities-opens-51a8" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-implications-ml-systems-engineers-781e" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.6</strong></summary><div>
<ol type="1">
<li><p><strong>Which role is primarily responsible for building platforms that enable next-generation AI development?</strong></p>
<ol type="a">
<li>Data Scientists</li>
<li>Applied AI Engineers</li>
<li>AI Safety Engineers</li>
<li>Infrastructure Specialists</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Infrastructure Specialists. This role focuses on building platforms for AI development, involving distributed systems and hardware acceleration. Applied AI Engineers and AI Safety Engineers have different focuses, such as domain-specific systems and ensuring system safety, respectively.</p>
<p><em>Learning Objective</em>: Understand the distinct roles and responsibilities within ML systems engineering.</p></li>
<li><p><strong>Explain how the role of AI Safety Engineers is crucial in the development of AGI systems.</strong></p>
<p><em>Answer</em>: AI Safety Engineers ensure that powerful AI systems remain beneficial and controllable. They integrate technical ML engineering with responsible AI principles to address safety, robustness, and alignment challenges. This is crucial as AGI capabilities grow, requiring systems to operate safely at scale.</p>
<p><em>Learning Objective</em>: Analyze the importance of AI Safety Engineers in maintaining the safety and alignment of AGI systems.</p></li>
<li><p><strong>What is a key challenge that Infrastructure Specialists face when developing AGI systems?</strong></p>
<ol type="a">
<li>Creating personalized AI systems</li>
<li>Ensuring system safety and alignment</li>
<li>Scaling infrastructure to support massive computational needs</li>
<li>Optimizing models for specific domains</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Scaling infrastructure to support massive computational needs. Infrastructure Specialists must design systems capable of handling the immense resources required for AGI, such as new datacenter designs and cooling systems, unlike the other roles which focus on different challenges.</p>
<p><em>Learning Objective</em>: Identify the scaling challenges faced by Infrastructure Specialists in AGI development.</p></li>
<li><p><strong>How might an Applied AI Engineer leverage their skills to optimize AI systems for production environments?</strong></p>
<p><em>Answer</em>: An Applied AI Engineer combines model optimization and deployment techniques with domain expertise to build systems that perform efficiently in production environments. This involves ensuring real-time performance, reliability, and scalability of AI applications tailored to specific use cases.</p>
<p><em>Learning Objective</em>: Apply the skills of an Applied AI Engineer to optimize AI systems for real-world applications.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-implications-ml-systems-engineers-781e" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-implications-ml-engineers-6c31" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.7</strong></summary><div>
<ol type="1">
<li><p><strong>What is a key advantage of using a compound system over a monolithic model in ML applications?</strong></p>
<ol type="a">
<li>Lower initial development cost</li>
<li>Requires less data</li>
<li>Faster training times</li>
<li>Easier to debug and update</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Easier to debug and update. Compound systems allow for specialized components, making them easier to debug, update, and scale compared to monolithic models.</p>
<p><em>Learning Objective</em>: Understand the benefits of compound systems in ML applications.</p></li>
<li><p><strong>Explain how investing in data quality over quantity can impact the performance of an ML system.</strong></p>
<p><em>Answer</em>: Investing in data quality ensures that the training data is relevant and accurate, which can lead to better model performance. For example, high-quality data reduces noise and improves the model’s ability to generalize. This is important because it enhances the system’s reliability and effectiveness.</p>
<p><em>Learning Objective</em>: Analyze the impact of data quality on ML system performance.</p></li>
<li><p><strong>True or False: The MoE architecture is only applicable to transformer models.</strong></p>
<p><em>Answer</em>: False. The MoE architecture is applicable beyond transformers and can be used in any system where different inputs require different processing, such as database query optimizers and API gateways.</p>
<p><em>Learning Objective</em>: Recognize the applicability of MoE architecture beyond transformer models.</p></li>
<li><p><strong>In ML engineering, understanding ____ becomes critical as models grow and require efficient resource management.</strong></p>
<p><em>Answer</em>: distributed systems expertise. As models grow, efficient resource management becomes crucial, making distributed systems expertise essential.</p>
<p><em>Learning Objective</em>: Identify the critical skills needed for managing large-scale ML models.</p></li>
<li><p><strong>How might you apply the principles of RLHF to improve user satisfaction in a recommendation engine?</strong></p>
<p><em>Answer</em>: By incorporating user preferences and feedback into the learning process, RLHF can tailor recommendations to better align with user interests. For example, adjusting the model based on user interactions can enhance personalization. This is important because it increases user engagement and satisfaction.</p>
<p><em>Learning Objective</em>: Apply RLHF principles to enhance user satisfaction in ML applications.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-implications-ml-engineers-6c31" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-agi-systems-summary-297d" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.8</strong></summary><div>
<ol type="1">
<li><p><strong>What is a key characteristic of emergent capabilities in AI systems like GPT-3?</strong></p>
<ol type="a">
<li>They appear discontinuously at specific parameter thresholds.</li>
<li>They gradually improve with each parameter increase.</li>
<li>They are solely dependent on algorithmic innovations.</li>
<li>They require minimal computational resources.</li>
</ol>
<p><em>Answer</em>: The correct answer is A. They appear discontinuously at specific parameter thresholds. This is correct because emergent capabilities such as arithmetic and translation in GPT-3 do not improve gradually but rather emerge at certain scales. Options A, C, and D are incorrect as they do not capture the nature of emergent capabilities.</p>
<p><em>Learning Objective</em>: Understand the nature of emergent capabilities in large AI models.</p></li>
<li><p><strong>Explain why the transition from narrow AI to AGI is primarily a systems engineering challenge.</strong></p>
<p><em>Answer</em>: The transition from narrow AI to AGI is a systems engineering challenge because it requires the integration of data, compute, models, and infrastructure at scale. For example, AGI development involves orchestrating 100,000+ accelerators with high reliability. This is important because achieving AGI depends not just on algorithms but on the ability to manage complex systems effectively.</p>
<p><em>Learning Objective</em>: Analyze the systems engineering challenges involved in transitioning to AGI.</p></li>
<li><p><strong>True or False: The development of AGI will primarily rely on algorithmic innovations rather than systems integration.</strong></p>
<p><em>Answer</em>: False. This is false because while algorithmic innovations are important, the development of AGI will primarily rely on systems integration, requiring sophisticated orchestration across multiple components and technologies.</p>
<p><em>Learning Objective</em>: Challenge the misconception that AGI development is solely about algorithmic innovation.</p></li>
<li><p><strong>Which of the following best describes the role of systems engineering in AI development?</strong></p>
<ol type="a">
<li>It focuses solely on optimizing algorithms.</li>
<li>It involves the integration and orchestration of various components and technologies.</li>
<li>It is primarily concerned with data collection.</li>
<li>It is only relevant for hardware design.</li>
</ol>
<p><em>Answer</em>: The correct answer is B. It involves the integration and orchestration of various components and technologies. This is correct because systems engineering in AI development requires managing data, compute, models, and infrastructure to build complex systems. Options A, C, and D are incorrect as they do not encompass the full scope of systems engineering.</p>
<p><em>Learning Objective</em>: Understand the comprehensive role of systems engineering in AI development.</p></li>
</ol>
<p><a href="#quiz-question-sec-agi-systems-summary-297d" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>

</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="pagination-link" aria-label="AI for Good">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">AI for Good</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/conclusion/conclusion.html" class="pagination-link" aria-label="Conclusion">
        <span class="nav-page-text">Conclusion</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>