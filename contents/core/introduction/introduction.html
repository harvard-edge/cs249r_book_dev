<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ML Systems Textbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/ml_systems/ml_systems.html" rel="next">
<link href="../../../contents/frontmatter/socratiq/socratiq.html" rel="prev">
<link href="../../../assets/images/icons/favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ae75ed80ef5b3e74590777de1ac3d8c3.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-0769fbf68cc3e722256a1e1e51d908bf.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../tools/scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<script src="../../../assets/scripts/sidebar-auto-collapse.js" defer=""></script>
<style>
.callout-example {
  --color1: #F0F8F6;
  --color2: #148F77;
}
.callout-resource-slides {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-quiz-question {
  --color1: #F0F0F8;
  --color2: #5B4B8A;
}
.callout-chapter-connection {
  --color1: #FDF2F7;
  --color2: #A51C30;
}
.callout-code {
  --color1: #F2F4F8;
  --color2: #D1D7E0;
}
.callout-definition {
  --color1: #F0F4F8;
  --color2: #1B4F72;
}
.callout-resource-exercises {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-resource-videos {
  --color1: #E0F2F1;
  --color2: #20B2AA;
}
.callout-quiz-answer {
  --color1: #E8F2EA;
  --color2: #4a7c59;
}
</style>
<style>
details.callout-example > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-example.png");
}
details.callout-resource-slides > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-slides.png");
}
details.callout-quiz-question > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-question.png");
}
details.callout-chapter-connection > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-chapter-connection.png");
}
details.callout-code > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-code.png");
}
details.callout-definition > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-definition.png");
}
details.callout-resource-exercises > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-exercises.png");
}
details.callout-resource-videos > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-resource-videos.png");
}
details.callout-quiz-answer > summary::before {
  background-image: url("../../../assets/images/icons/callouts/icon_callout-quiz-answer.png");
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-md " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/images/icons/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../contents/labs/labs.html" aria-current="page"> <i class="bi bi-code" role="img">
</i> 
<span class="menu-text">Labs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/labs/kits.html"> <i class="bi bi-box" role="img">
</i> 
<span class="menu-text">Kits</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/pdf" target="_blank"> <i class="bi bi-file-pdf" role="img">
</i> 
<span class="menu-text">PDF</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://mlsysbook.ai/epub" target="_blank"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text">EPUB</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book" target="_blank"> <i class="bi bi-star" role="img">
</i> 
<span class="menu-text">Star</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://opencollective.com/mlsysbook" target="_blank"> <i class="bi bi-heart" role="img">
</i> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-pencil" role="img">
</i> 
 <span class="dropdown-text">Edit this page</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/issues/new" target="_blank"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">Report an issue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book/discussions" target="_blank"><i class="bi bi-chat" role="img">
</i> 
 <span class="dropdown-text">Discussions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/harvard-edge/cs249r_book" target="_blank"><i class="bi bi-code" role="img">
</i> 
 <span class="dropdown-text">View source</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Systems Foundations</a></li><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Introduction</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="80cf830e7ea2136b91547bb117b654b4" class="alert alert-primary hidden"><i class="bi bi-megaphone quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p style="margin: 0 0 12px 0; padding: 8px 12px; background: rgba(255,193,7,0.2); border: 1px solid #ffc107; border-radius: 4px; font-weight: 600;"><i class="bi bi-exclamation-triangle-fill" style="margin-right: 6px; color: #856404;"></i><strong>🚧 DEVELOPMENT PREVIEW</strong> - Built from dev@<code style="background: rgba(0,0,0,0.1); padding: 2px 4px; border-radius: 3px; font-size: 0.9em;">38b88181</code> • 2025-09-29 23:20 UTC • <a href="https://mlsysbook.ai" style="color: #856404; text-decoration: underline;"><em>Stable version →</em></a></p>
<p>🎉 <strong>Just Announced:</strong> <em>Machine Learning Systems</em> will be published by <strong>MIT Press</strong>. <a href="https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_tinyml-tikz-ai-activity-7338324711145136128-6WU-?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA-V7E4BcYtyZgLSeGhXC2t9jRSlmazfp-I">See the news →</a><br></p>
<p>🚀 <strong>Sneak Peek:</strong> <a href="https://mlsysbook.github.io/TinyTorch/intro.html">Tiny🔥Torch</a>. Build your own machine learning framework from scratch!<br></p>
<p>🧠 <strong>Self-checks:</strong> Added lightweight <a href="../../../contents/core/introduction/introduction.html#quiz-question-sec-introduction-ai-ml-basics-041a">quizzes</a> to each chapter for self-assessment.<br></p>
<p>📦 <strong>New Hardware:</strong> <a href="../../../contents/labs/kits.html">Seeed TinyML Kit</a>. Latest hands-on learning platform.</p>
</div><i class="bi bi-x-lg quarto-announcement-action" style="display: none;"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homepage</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Systems Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DL Primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DNN Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Design Principles</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Workflow</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Performance Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficient AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model Optimizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI Acceleration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmarking AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Robust Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On-Device Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Robust AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security &amp; Privacy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Trustworthy Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Responsible AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sustainable AI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI for Good</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Frontiers of ML Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frontiers/frontiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AGI Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hands-on Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/kits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hardware Kits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/ide_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDE Setup</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Arduino</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Seeed XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Grove Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Shared</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">Glossary</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/glossary/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Glossary</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">References</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complete Bibliography</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-introduction" id="toc-sec-introduction" class="nav-link active" data-scroll-target="#sec-introduction">Introduction</a>
  <ul>
  <li><a href="#purpose" id="toc-purpose" class="nav-link" data-scroll-target="#purpose">Purpose</a></li>
  <li><a href="#sec-introduction-ai-pervasiveness-8891" id="toc-sec-introduction-ai-pervasiveness-8891" class="nav-link" data-scroll-target="#sec-introduction-ai-pervasiveness-8891">AI Pervasiveness</a></li>
  <li><a href="#sec-introduction-ai-ml-basics-fa82" id="toc-sec-introduction-ai-ml-basics-fa82" class="nav-link" data-scroll-target="#sec-introduction-ai-ml-basics-fa82">AI and ML Basics</a></li>
  <li><a href="#sec-introduction-ai-evolution-8ff4" id="toc-sec-introduction-ai-evolution-8ff4" class="nav-link" data-scroll-target="#sec-introduction-ai-evolution-8ff4">AI Evolution</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-symbolic-ai-era-0e23" id="toc-sec-introduction-symbolic-ai-era-0e23" class="nav-link" data-scroll-target="#sec-introduction-symbolic-ai-era-0e23">Symbolic AI Era</a></li>
  <li><a href="#sec-introduction-expert-systems-era-8ba7" id="toc-sec-introduction-expert-systems-era-8ba7" class="nav-link" data-scroll-target="#sec-introduction-expert-systems-era-8ba7">Expert Systems Era</a></li>
  <li><a href="#sec-introduction-statistical-learning-era-c064" id="toc-sec-introduction-statistical-learning-era-c064" class="nav-link" data-scroll-target="#sec-introduction-statistical-learning-era-c064">Statistical Learning Era</a></li>
  <li><a href="#sec-introduction-shallow-learning-era-3448" id="toc-sec-introduction-shallow-learning-era-3448" class="nav-link" data-scroll-target="#sec-introduction-shallow-learning-era-3448">Shallow Learning Era</a></li>
  <li><a href="#sec-introduction-deep-learning-era-155a" id="toc-sec-introduction-deep-learning-era-155a" class="nav-link" data-scroll-target="#sec-introduction-deep-learning-era-155a">Deep Learning Era</a></li>
  </ul></li>
  <li><a href="#sec-introduction-bitter-lesson-systems-matter-a8f2" id="toc-sec-introduction-bitter-lesson-systems-matter-a8f2" class="nav-link" data-scroll-target="#sec-introduction-bitter-lesson-systems-matter-a8f2">The Bitter Lesson: Why ML Systems Engineering Matters</a></li>
  <li><a href="#sec-introduction-defining-ml-systems-bf7d" id="toc-sec-introduction-defining-ml-systems-bf7d" class="nav-link" data-scroll-target="#sec-introduction-defining-ml-systems-bf7d">Defining ML Systems</a></li>
  <li><a href="#sec-introduction-lifecycle-ml-systems-6194" id="toc-sec-introduction-lifecycle-ml-systems-6194" class="nav-link" data-scroll-target="#sec-introduction-lifecycle-ml-systems-6194">Lifecycle of ML Systems</a></li>
  <li><a href="#sec-introduction-ml-systems-wild-8f2f" id="toc-sec-introduction-ml-systems-wild-8f2f" class="nav-link" data-scroll-target="#sec-introduction-ml-systems-wild-8f2f">ML Systems in the Wild</a></li>
  <li><a href="#sec-introduction-ml-systems-impact-lifecycle-fb60" id="toc-sec-introduction-ml-systems-impact-lifecycle-fb60" class="nav-link" data-scroll-target="#sec-introduction-ml-systems-impact-lifecycle-fb60">ML Systems Impact on Lifecycle</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-emerging-trends-e527" id="toc-sec-introduction-emerging-trends-e527" class="nav-link" data-scroll-target="#sec-introduction-emerging-trends-e527">Emerging Trends</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-applicationlevel-innovation-e97b" id="toc-sec-introduction-applicationlevel-innovation-e97b" class="nav-link" data-scroll-target="#sec-introduction-applicationlevel-innovation-e97b">Application-Level Innovation</a></li>
  <li><a href="#sec-introduction-system-architecture-evolution-c8cc" id="toc-sec-introduction-system-architecture-evolution-c8cc" class="nav-link" data-scroll-target="#sec-introduction-system-architecture-evolution-c8cc">System Architecture Evolution</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-introduction-practical-applications-0728" id="toc-sec-introduction-practical-applications-0728" class="nav-link" data-scroll-target="#sec-introduction-practical-applications-0728">Practical Applications</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-farmbeats-ml-agriculture-1ec9" id="toc-sec-introduction-farmbeats-ml-agriculture-1ec9" class="nav-link" data-scroll-target="#sec-introduction-farmbeats-ml-agriculture-1ec9">FarmBeats: ML in Agriculture</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-data-considerations-0dfa" id="toc-sec-introduction-data-considerations-0dfa" class="nav-link" data-scroll-target="#sec-introduction-data-considerations-0dfa">Data Considerations</a></li>
  <li><a href="#sec-introduction-algorithmic-considerations-d292" id="toc-sec-introduction-algorithmic-considerations-d292" class="nav-link" data-scroll-target="#sec-introduction-algorithmic-considerations-d292">Algorithmic Considerations</a></li>
  <li><a href="#sec-introduction-infrastructure-considerations-346b" id="toc-sec-introduction-infrastructure-considerations-346b" class="nav-link" data-scroll-target="#sec-introduction-infrastructure-considerations-346b">Infrastructure Considerations</a></li>
  <li><a href="#sec-introduction-future-implications-8871" id="toc-sec-introduction-future-implications-8871" class="nav-link" data-scroll-target="#sec-introduction-future-implications-8871">Future Implications</a></li>
  </ul></li>
  <li><a href="#sec-introduction-alphafold-scientific-ml-d3fd" id="toc-sec-introduction-alphafold-scientific-ml-d3fd" class="nav-link" data-scroll-target="#sec-introduction-alphafold-scientific-ml-d3fd">AlphaFold: Scientific ML</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-data-considerations-e519" id="toc-sec-introduction-data-considerations-e519" class="nav-link" data-scroll-target="#sec-introduction-data-considerations-e519">Data Considerations</a></li>
  <li><a href="#sec-introduction-algorithmic-considerations-c152" id="toc-sec-introduction-algorithmic-considerations-c152" class="nav-link" data-scroll-target="#sec-introduction-algorithmic-considerations-c152">Algorithmic Considerations</a></li>
  <li><a href="#sec-introduction-infrastructure-considerations-fcd1" id="toc-sec-introduction-infrastructure-considerations-fcd1" class="nav-link" data-scroll-target="#sec-introduction-infrastructure-considerations-fcd1">Infrastructure Considerations</a></li>
  <li><a href="#sec-introduction-future-implications-b549" id="toc-sec-introduction-future-implications-b549" class="nav-link" data-scroll-target="#sec-introduction-future-implications-b549">Future Implications</a></li>
  </ul></li>
  <li><a href="#sec-introduction-autonomous-vehicles-2910" id="toc-sec-introduction-autonomous-vehicles-2910" class="nav-link" data-scroll-target="#sec-introduction-autonomous-vehicles-2910">Autonomous Vehicles</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-data-considerations-8b4d" id="toc-sec-introduction-data-considerations-8b4d" class="nav-link" data-scroll-target="#sec-introduction-data-considerations-8b4d">Data Considerations</a></li>
  <li><a href="#sec-introduction-algorithmic-considerations-a0ae" id="toc-sec-introduction-algorithmic-considerations-a0ae" class="nav-link" data-scroll-target="#sec-introduction-algorithmic-considerations-a0ae">Algorithmic Considerations</a></li>
  <li><a href="#sec-introduction-infrastructure-considerations-3779" id="toc-sec-introduction-infrastructure-considerations-3779" class="nav-link" data-scroll-target="#sec-introduction-infrastructure-considerations-3779">Infrastructure Considerations</a></li>
  <li><a href="#sec-introduction-future-implications-2934" id="toc-sec-introduction-future-implications-2934" class="nav-link" data-scroll-target="#sec-introduction-future-implications-2934">Future Implications</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-introduction-challenges-ml-systems-7167" id="toc-sec-introduction-challenges-ml-systems-7167" class="nav-link" data-scroll-target="#sec-introduction-challenges-ml-systems-7167">Challenges in ML Systems</a>
  <ul class="collapse">
  <li><a href="#sec-introduction-datarelated-challenges-9e99" id="toc-sec-introduction-datarelated-challenges-9e99" class="nav-link" data-scroll-target="#sec-introduction-datarelated-challenges-9e99">Data-Related Challenges</a></li>
  <li><a href="#sec-introduction-modelrelated-challenges-6c1a" id="toc-sec-introduction-modelrelated-challenges-6c1a" class="nav-link" data-scroll-target="#sec-introduction-modelrelated-challenges-6c1a">Model-Related Challenges</a></li>
  <li><a href="#sec-introduction-systemrelated-challenges-fb4f" id="toc-sec-introduction-systemrelated-challenges-fb4f" class="nav-link" data-scroll-target="#sec-introduction-systemrelated-challenges-fb4f">System-Related Challenges</a></li>
  <li><a href="#sec-introduction-ethical-considerations-c579" id="toc-sec-introduction-ethical-considerations-c579" class="nav-link" data-scroll-target="#sec-introduction-ethical-considerations-c579">Ethical Considerations</a>
  <ul class="collapse">
  <li><a href="#silent-failures-the-hidden-danger" id="toc-silent-failures-the-hidden-danger" class="nav-link" data-scroll-target="#silent-failures-the-hidden-danger">Silent Failures: The Hidden Danger</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-introduction-looking-ahead-34a3" id="toc-sec-introduction-looking-ahead-34a3" class="nav-link" data-scroll-target="#sec-introduction-looking-ahead-34a3">Looking Ahead</a></li>
  <li><a href="#sec-introduction-book-structure-learning-path-f3ea" id="toc-sec-introduction-book-structure-learning-path-f3ea" class="nav-link" data-scroll-target="#sec-introduction-book-structure-learning-path-f3ea">Book Structure and Learning Path</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers">Self-Check Answers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Systems Foundations</a></li><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.html">Introduction</a></li></ol></nav></header>




<section id="sec-introduction" class="level1 page-columns page-full">
<h1>Introduction</h1>
<div class="{layout-narrow} page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="">
<p><em>DALL·E 3 Prompt: A detailed, rectangular, flat 2D illustration depicting a roadmap of a book’s chapters on machine learning systems, set on a crisp, clean white background. The image features a winding road traveling through various symbolic landmarks. Each landmark represents a chapter topic: Introduction, ML Systems, Deep Learning, AI Workflow, Data Engineering, AI Frameworks, AI Training, Efficient AI, Model Optimizations, AI Acceleration, Benchmarking AI, On-Device Learning, Embedded AIOps, Security &amp; Privacy, Responsible AI, Sustainable AI, AI for Good, Robust AI, Generative AI. The style is clean, modern, and flat, suitable for a technical book, with each landmark clearly labeled with its chapter title.</em></p>
</div></div><p> <img src="images/png/cover_introduction.png" class="img-fluid"></p>
</div>
<section id="purpose" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="purpose">Purpose</h2>
<p><em>How do we build computing systems that can learn, adapt, and operate reliably at the scale of billions of users?</em></p>
<p>We stand at the emergence of a new engineering discipline. Just as Computer Engineering emerged in the 1970s to systematically bridge Electrical Engineering and Computer Science, Machine Learning Systems Engineering is emerging today as the systematic discipline needed to build reliable AI systems across all computational environments, from embedded sensors to cloud infrastructure. This discipline extends beyond applying traditional software engineering to machine learning. ML systems, where behavior emerges from data rather than explicit programming, require new engineering principles, methodologies, and practices. These systems present unique challenges because they learn, adapt, and degrade in ways that traditional software does not, establishing ML Systems Engineering as a foundational discipline for the age of artificial intelligence.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Define machine learning systems engineering and distinguish it from traditional model development</p></li>
<li><p>Analyze the pervasive role of AI across different sectors and scales of human activity</p></li>
<li><p>Explain the historical evolution of AI from symbolic systems to modern deep learning approaches</p></li>
<li><p>Compare key differences between AI research and ML systems implementation practices</p></li>
<li><p>Identify key challenges in transitioning from research prototypes to production ML systems</p></li>
<li><p>Evaluate real-world ML applications through data, algorithmic, and infrastructure considerations</p></li>
<li><p>Apply the five-pillar framework to categorize ML system components and their interdependencies</p></li>
</ul>
</div>
</div>
</section>
<section id="sec-introduction-ai-pervasiveness-8891" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ai-pervasiveness-8891">AI Pervasiveness</h2>
<p>Artificial Intelligence (AI) has emerged as one of the most transformative forces in human history. From the moment we wake up to when we go to sleep, AI systems invisibly shape our world. They manage traffic flows in our cities, optimize power distribution across electrical grids, and enable billions of wireless devices to communicate seamlessly through IoT<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> networks. In hospitals, AI analyzes medical images and helps doctors diagnose diseases. In research laboratories, it accelerates scientific discovery by simulating molecular interactions and processing vast datasets from particle accelerators<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. In space exploration, it helps rovers traverse distant planets and telescopes detect new celestial phenomena.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<strong>Internet of Things (IoT)</strong>: A network of interconnected devices embedded with sensors, software, and connectivity that enables them to collect and exchange data. Industry forecasts predict 27-42 billion IoT devices by 2025, with over 18.8 billion already connected by 2024. The data generated by IoT connections is projected to reach 79.4 zettabytes by 2025, representing an exponential growth in data generation compared to pre-2020 levels.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;<strong>Particle Accelerators</strong>: Massive scientific instruments that propel particles to near light-speed for physics experiments, generating enormous datasets. CERN’s Large Hadron Collider processes approximately 1 billion particle collisions per second, generating about 25-200 petabytes of data annually that must be filtered in real-time. The computational challenge requires a global computing grid with over 170 centers across 42 countries—infrastructure that pioneered distributed computing techniques now essential for machine learning.</p></div><div id="ref-brynjolfsson2014second" class="csl-entry" role="listitem">
Brynjolfsson, Erik, and Andrew McAfee. 2014. <em>The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, 1st Edition.</em> W. W. Norton Company.
</div><div id="ref-domingos2015master" class="csl-entry" role="listitem">
Domingos, Pedro. 2016. <span>“The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World.”</span> <em>Choice Reviews Online</em> 53 (07): 53–3100. <a href="https://doi.org/10.5860/choice.194685">https://doi.org/10.5860/choice.194685</a>.
</div></div><p>This pervasive integration into our daily lives reflects a deeper historical pattern. Throughout history, certain technologies have transformed human civilization, defining their eras. The 18th and 19th centuries were shaped by the Industrial Revolution, where steam power and mechanization transformed how humans could use physical energy. The 20th century was defined by the Digital Revolution, where the computer and internet transformed how we process and share information. Now, the 21st century appears to be the era of Artificial Intelligence, a shift noted by leading thinkers in technological evolution <span class="citation" data-cites="brynjolfsson2014second domingos2015master">(<a href="#ref-brynjolfsson2014second" role="doc-biblioref">Brynjolfsson and McAfee 2014</a>; <a href="#ref-domingos2015master" role="doc-biblioref">Domingos 2016</a>)</span>.</p>
<p>Beyond these historical parallels, the vision driving AI development encompasses broader goals than current practical applications. The goal is creating systems that work alongside humanity, enhancing problem-solving capabilities and accelerating scientific progress. AI systems may help understand consciousness, decode biological system complexities, or address global challenges like climate change, disease, and sustainable energy production. This extends beyond automation or efficiency to expanding the boundaries of human knowledge and capability.</p>
<p>These ambitious goals translate into impact that operates at multiple scales, each with profound implications. At the individual level, AI personalizes our experiences and augments our daily decision-making capabilities. At the organizational level, it transforms how businesses operate and how research institutions make discoveries. At the societal level, it reshapes everything from transportation systems to healthcare delivery. At the global level, it offers new approaches to addressing humanity’s greatest challenges, from climate change to drug discovery.</p>
<p>What makes this revolution particularly remarkable is how rapidly this transformation proceeds. While the Industrial Revolution unfolded over centuries and the Digital Revolution over decades, AI capabilities advance at an accelerated rate. Technologies that seemed impossible years ago (systems understanding human speech, generating content, or making complex decisions) are now commonplace. This acceleration indicates we are beginning to understand AI’s profound impact on society. Given this unprecedented pace of change, we stand at a historic inflection point. The Industrial Revolution required mastering mechanical engineering to control steam and machinery. The Digital Revolution demanded electrical and computer engineering expertise to build the internet age. The AI Revolution presents a new engineering challenge. Building systems that learn, reason, and potentially achieve superhuman capabilities<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> in specific domains requires new expertise.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;<strong>Superhuman AI Capabilities</strong>: AI systems already exceed human performance in specific domains. AlphaGo defeated the world champion in Go (a game with more possible positions than atoms in the observable universe), protein folding prediction models like AlphaFold achieved accuracy that would take human scientists decades to match, and modern language models can process and synthesize information from millions of documents in seconds.</p></div></div><div id="quiz-question-sec-introduction-ai-pervasiveness-8891" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.1</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the role of AI in modern society?</p>
<ol type="a">
<li>AI is primarily used for entertainment purposes.</li>
<li>AI is primarily focused on replacing human jobs.</li>
<li>AI is an emerging technology with limited current applications.</li>
<li>AI is a transformative force impacting multiple domains, including healthcare, transportation, and scientific research.</li>
</ol></li>
<li><p>True or False: The AI Revolution is progressing at the same pace as the Industrial Revolution.</p></li>
<li><p>How does the AI Revolution compare to the Digital Revolution in terms of societal impact?</p></li>
<li><p>In what way is AI expected to expand the boundaries of human knowledge?</p>
<ol type="a">
<li>By automating all manual tasks.</li>
<li>By enhancing problem-solving capabilities and accelerating scientific progress.</li>
<li>By replacing the need for human decision-making.</li>
<li>By focusing solely on entertainment and media.</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ai-pervasiveness-8891" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ai-ml-basics-fa82" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ai-ml-basics-fa82">AI and ML Basics</h2>
<p>The transformative impact of AI across society raises a critical question: How do we actually create these intelligent capabilities? Understanding the relationship between Artificial Intelligence and Machine Learning provides the key to answering this question and forms the foundation for everything that follows in this book.</p>
<p><strong>Artificial Intelligence (AI)</strong> represents the broad goal of creating systems that can perform tasks requiring human-like intelligence: recognizing images, understanding language, making decisions, and solving problems. AI is the <strong>what</strong>, the vision of intelligent machines that can learn, reason, and adapt.</p>
<p><strong>Machine Learning (ML)</strong> represents the methodological approach and practical discipline for creating systems that demonstrate intelligent behavior. Rather than implementing intelligence through predetermined rules, machine learning provides the computational techniques to automatically discover patterns in data through mathematical processes. This methodology transforms AI’s theoretical insights into functioning systems.</p>
<p>Object recognition in machine learning systems parallels human visual learning, requiring exposure to numerous examples to develop robust recognition capabilities. Similarly, natural language processing systems acquire linguistic capabilities through extensive analysis of textual data, demonstrating how ML operationalizes AI’s understanding of intelligence. These learning approaches build on mathematical foundations that we establish systematically.</p>
<div id="callout-example*-1.1" class="callout callout-example" title="AI vs ML in Practice">
<p></p><details class="callout-example fbx-default closebutton" open=""><summary><strong>Example: </strong>AI vs ML in Practice</summary><div><strong>AI Goal</strong>: Build a system that can recognize cats in photos <strong>ML Approach</strong>: Show the system millions of photos labeled “cat” or “not cat” and let it learn to identify the patterns that distinguish cats from other objects<p></p>
<p><strong>Traditional Programming</strong>: Write explicit rules (“if it has pointy ears AND whiskers AND four legs…”) <strong>Machine Learning</strong>: Learn the rules automatically from examples</p>
</div></details>
</div>
<p>This distinction matters because modern ML’s data-driven approach requires sophisticated systems to collect, process, and learn from data at unprecedented scale. Machine learning emerged as a practical approach to artificial intelligence through extensive research and major paradigm shifts<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;<strong>Paradigm Shift</strong>: A term coined by philosopher Thomas Kuhn in 1962 <span class="citation" data-cites="kuhn1962structure">(<a href="#ref-kuhn1962structure" role="doc-biblioref">Kvasz 2014</a>)</span> to describe major changes in scientific approach. In AI, the key paradigm shift was moving from symbolic reasoning (encoding human knowledge as rules) to statistical learning (discovering patterns from data). This shift required abandoning decades of established methods and embracing radically different approaches to creating intelligence.</p></div></div><p>The progression of artificial intelligence encompasses both theoretical advances in understanding intelligence and practical developments in implementation methodologies, explaining why systems engineering has become crucial for achieving AI goals. The modern deep learning approaches that emerged from this evolution form the algorithmic foundation of today’s AI systems.</p>
<div id="callout-definition*-1.2" class="callout callout-definition" title="Key Definitions">
<details class="callout-definition fbx-default closebutton" open=""><summary><strong>Definition: </strong>Key Definitions</summary><div>
<ul>
<li><p><strong>Artificial Intelligence (AI)</strong>: The goal of creating systems that can perform tasks requiring human-like intelligence, including learning, reasoning, and adapting to new situations.</p></li>
<li><p><strong>Machine Learning (ML)</strong>: The practical approach to achieving AI by building systems that automatically discover patterns in data through computational techniques, rather than following predetermined rules.</p></li>
</ul>
</div></details>
</div>
<p>These concepts help us understand that the evolution from rule-based AI to data-driven ML represents one of the most significant paradigm shifts<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> in computing history. This shift explains why ML systems engineering has emerged as a critical discipline. The path to intelligent systems now runs through the engineering challenge of building systems that can effectively learn from data at massive scale.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<strong>Paradigm Shift</strong>: A term coined by philosopher Thomas Kuhn in 1962 <span class="citation" data-cites="kuhn1962structure">(<a href="#ref-kuhn1962structure" role="doc-biblioref">Kvasz 2014</a>)</span> to describe major changes in scientific approach. In AI, the key paradigm shift was moving from symbolic reasoning (encoding human knowledge as rules) to statistical learning (discovering patterns from data). This shift required abandoning decades of established methods and embracing radically different approaches to creating intelligence.</p><div id="ref-kuhn1962structure" class="csl-entry" role="listitem">
Kvasz, Ladislav. 2014. <span>“Kuhn’s Structure of Scientific Revolutions Between Sociology and Epistemology.”</span> <em>Studies in History and Philosophy of Science Part A</em> 46 (June): 78–84. <a href="https://doi.org/10.1016/j.shpsa.2014.02.006">https://doi.org/10.1016/j.shpsa.2014.02.006</a>.
</div></div></div><div id="quiz-question-sec-introduction-ai-ml-basics-fa82" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.2</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the relationship between AI and ML?</p>
<ol type="a">
<li>AI is a subset of ML focused on pattern recognition.</li>
<li>ML focuses on hardware implementation of AI theories.</li>
<li>AI and ML are unrelated fields.</li>
<li>ML is a subset of AI focused on learning from data.</li>
</ol></li>
<li><p>True or False: Machine Learning systems implement intelligence through predetermined rules.</p></li>
<li><p>How does the development of machine learning reflect fundamental biological learning processes?</p></li>
<li><p>Order the following developments in AI and ML: (1) Paradigm shift from symbolic reasoning to statistical learning, (2) Emergence of machine learning as a scientific discipline, (3) Shift from shallow to deep learning.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ai-ml-basics-fa82" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ai-evolution-8ff4" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ai-evolution-8ff4">AI Evolution</h2>
<p>To understand why ML systems engineering has emerged as a critical discipline, we first trace the historical trajectory that led to our current computational paradigm. This evolution reveals not just technological progress, but a key shift in how we approach intelligent systems. This shift directly explains today’s emphasis on scalable infrastructure and data-driven methods.</p>
<p>The evolution of AI, depicted in the timeline shown in <a href="#fig-ai-timeline" class="quarto-xref">Figure&nbsp;1</a>, highlights key milestones such as the development of the perceptron<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> in 1957 by Frank Rosenblatt <span class="citation" data-cites="rosenblatt1957perceptron">(<a href="#ref-rosenblatt1957perceptron" role="doc-biblioref">Wolfe et al. 2024</a>)</span>, an early computational learning algorithm. Computer labs in 1965 contained room-sized mainframes<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> running programs that could prove basic mathematical theorems or play simple games like tic-tac-toe. These early artificial intelligence systems, though groundbreaking for their time, differed substantially from today’s machine learning systems that detect cancer in medical images or understand human speech. The timeline shows the progression from early innovations like the ELIZA<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> chatbot in 1966, to significant breakthroughs such as IBM’s Deep Blue defeating chess champion Garry Kasparov in 1997 <span class="citation" data-cites="campbell2002deep">(<a href="#ref-campbell2002deep" role="doc-biblioref">Campbell, Hoane, and Hsu 2002</a>)</span>. More recent advancements include the introduction of OpenAI’s GPT-3 in 2020 and GPT-4 in 2023 <span class="citation" data-cites="openai2023gpt4">(<a href="#ref-openai2023gpt4" role="doc-biblioref">OpenAI et al. 2023</a>)</span>, demonstrating the dramatic evolution and increasing complexity of AI systems over the decades.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<strong>Perceptron</strong>: One of the first computational learning algorithms. This system could learn to classify patterns by making yes/no decisions based on inputs.</p></div><div id="ref-rosenblatt1957perceptron" class="csl-entry" role="listitem">
Wolfe, Jeremy M., Dennis M. Levi, Lori L. Holt, Linda M. Bartoshuk, Rachel S. Herz, Roberta L. Klatzky, and Daniel M. Merfeld. 2024. <span>“Perceiving and Recognizing Objects.”</span> Technical Report. In <em>Sensation &amp;Amp; Perception</em>. 85-460-1. Cornell Aeronautical Laboratory; Oxford University Press. <a href="https://doi.org/10.1093/hesc/9780197663813.003.0005">https://doi.org/10.1093/hesc/9780197663813.003.0005</a>.
</div><div id="fn7"><p><sup>7</sup>&nbsp;<strong>Mainframes</strong>: Room-sized computers that dominated the 1960s-70s, typically costing millions of dollars and requiring dedicated cooling systems. IBM’s System/360 mainframe from 1964 weighed 20,000 pounds and had just 64KB of memory, about 1/millionth the memory of a modern smartphone, yet represented the cutting edge of computing power that enabled early AI research.</p></div><div id="fn8"><p><sup>8</sup>&nbsp;<strong>ELIZA</strong>: Created by MIT’s Joseph Weizenbaum in 1966 <span class="citation" data-cites="weizenbaum1966eliza">(<a href="#ref-weizenbaum1966eliza" role="doc-biblioref">Weizenbaum 1966</a>)</span>, ELIZA was one of the first chatbots that could simulate human conversation by pattern matching and substitution. Ironically, Weizenbaum was horrified when people began forming emotional attachments to his simple program, leading him to become a critic of AI.</p><div id="ref-weizenbaum1966eliza" class="csl-entry" role="listitem">
Weizenbaum, Joseph. 1966. <span>“ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.”</span> <em>Communications of the ACM</em> 9 (1): 36–45. <a href="https://doi.org/10.1145/365153.365168">https://doi.org/10.1145/365153.365168</a>.
</div></div><div id="ref-openai2023gpt4" class="csl-entry" role="listitem">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, et al. 2023. <span>“GPT-4 Technical Report,”</span> March. <a href="http://arxiv.org/abs/2303.08774v6">http://arxiv.org/abs/2303.08774v6</a>.
</div></div><div id="fig-ai-timeline" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="t!">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="25cf57367aa5f23646232b9ae71c6b1104010d47.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: AI Development Timeline: Early AI research focused on symbolic reasoning and rule-based systems, while modern AI leverages data-driven approaches like neural networks to achieve increasingly complex tasks. This progression exposes a shift from hand-coded intelligence to learned intelligence, marked by milestones such as the perceptron, deep blue, and large language models like GPT-3."><img src="introduction_files/mediabag/25cf57367aa5f23646232b9ae71c6b1104010d47.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>AI Development Timeline</strong>: Early AI research focused on symbolic reasoning and rule-based systems, while modern AI leverages data-driven approaches like neural networks to achieve increasingly complex tasks. This progression exposes a shift from hand-coded intelligence to learned intelligence, marked by milestones such as the perceptron, deep blue, and large language models like GPT-3.
</figcaption>
</figure>
</div>
<p>Examining this timeline more closely, we can identify several distinct eras of development that demonstrate how each approach built upon the lessons of its predecessors.</p>
<section id="sec-introduction-symbolic-ai-era-0e23" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-symbolic-ai-era-0e23">Symbolic AI Era</h3>
<p>The story of machine learning begins at the historic Dartmouth Conference<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> in 1956, where pioneers like John McCarthy, Marvin Minsky, and Claude Shannon first coined the term “artificial intelligence” <span class="citation" data-cites="mccarthy1956dartmouth">(<a href="#ref-mccarthy1956dartmouth" role="doc-biblioref">McCarthy et al. 1955</a>)</span>. Their approach assumed that intelligence could be reduced to symbol manipulation. Daniel Bobrow’s STUDENT system from 1964 <span class="citation" data-cites="bobrow1964student">(<a href="#ref-bobrow1964student" role="doc-biblioref">Bobrow 1964</a>)</span> exemplifies this era by solving algebra word problems through natural language understanding.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;<strong>Dartmouth Conference (1956)</strong>: The legendary 8-week workshop at Dartmouth College where AI was officially born. Organized by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, it was the first time researchers gathered specifically to discuss “artificial intelligence,” a term McCarthy coined for the proposal. The ambitious goal was to make machines “simulate every aspect of learning or any other feature of intelligence.” Though overly optimistic, this gathering launched AI as a formal research field.</p></div><div id="ref-mccarthy1956dartmouth" class="csl-entry" role="listitem">
McCarthy, John, Marvin L. Minsky, Nathaniel Rochester, and Claude E. Shannon. 1955. <span>“A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence.”</span> In. <a href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html">http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html</a>.
</div><div id="ref-bobrow1964student" class="csl-entry" role="listitem">
Bobrow, Daniel G. 1964. <span>“Natural Language Input for a Computer Problem Solving System.”</span> <em>PhD Thesis, MIT</em>. <a href="https://dspace.mit.edu/handle/1721.1/12962">https://dspace.mit.edu/handle/1721.1/12962</a>.
</div></div><div id="callout-example*-1.3" class="callout callout-example" title="STUDENT (1964)">
<details class="callout-example fbx-default closebutton" open=""><summary><strong>Example: </strong>STUDENT (1964)</summary><div>
<pre><code>Problem: "If the number of customers Tom gets is twice the
square of 20% of the number of advertisements he runs, and
the number of advertisements is 45, what is the number of
customers Tom gets?"

STUDENT would:

1. Parse the English text
2. Convert it to algebraic equations
3. Solve the equation: n = 2(0.2 × 45)²
4. Provide the answer: 162 customers</code></pre>
</div></details>
</div>
<p>Early AI like STUDENT suffered from a significant limitation: they could only handle inputs that exactly matched their pre-programmed patterns and rules. A language translator that only works with perfect grammatical structure demonstrates this limitation. Even slight variations like changed word order, synonyms, or natural speech patterns would cause the system to fail. This “brittleness”<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> meant that while these solutions could appear intelligent when handling very specific cases they were designed for, they would break down completely when faced with even minor variations or real-world complexity. This limitation revealed a deeper problem with rule-based AI approaches: they couldn’t genuinely understand or generalize from their programming, only match and manipulate text patterns exactly as specified.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;<strong>Brittleness in AI Systems</strong>: The tendency of rule-based systems to fail completely when encountering inputs that fall outside their programmed scenarios, no matter how similar those inputs might be to what they were designed to handle. This contrasts with human intelligence, which can adapt and make reasonable guesses even in unfamiliar situations. The brittleness problem drove researchers toward machine learning approaches that could generalize from examples rather than relying on exhaustive rule sets.</p></div></div></section>
<section id="sec-introduction-expert-systems-era-8ba7" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-expert-systems-era-8ba7">Expert Systems Era</h3>
<p>Recognizing these limitations of symbolic AI, by the mid-1970s researchers recognized general AI as overly ambitious and focused on capturing human expert knowledge in specific domains. MYCIN <span class="citation" data-cites="shortliffe1976mycin">(<a href="#ref-shortliffe1976mycin" role="doc-biblioref">Shortliffe 1976</a>)</span>, developed at Stanford, was one of the first large-scale expert systems designed to diagnose blood infections.</p>
<div class="no-row-height column-margin column-container"><div id="ref-shortliffe1976mycin" class="csl-entry" role="listitem">
Shortliffe, Edward H. 1976. <span>“Computer-Based Consultations in Clinical Therapeutics: Explanation and Rule Acquisition Capabilities of the MYCIN System.”</span> <em>Computers and Biomedical Research</em> 9 (3): 303–20. <a href="https://doi.org/10.1016/0010-4809(76)90063-5">https://doi.org/10.1016/0010-4809(76)90063-5</a>.
</div></div><div class="callout callout-example" title="MYCIN (1976)">
<details class="callout-example fbx-default closebutton" open=""><summary><strong>Example: </strong>MYCIN (1976)</summary><div>
<pre><code>Rule Example from MYCIN:
IF
  The infection is primary-bacteremia
  The site of the culture is one of the sterile sites
  The suspected portal of entry is the gastrointestinal tract
THEN
  Found suggestive evidence (0.7) that infection is bacteroid</code></pre>
</div></details>
</div>
<p>MYCIN represented a major advance in medical AI with 600 expert rules for diagnosing blood infections, yet it revealed key challenges persisting in contemporary ML. Getting domain knowledge from human experts and converting it into precise rules proved incredibly time-consuming and difficult, as doctors often couldn’t explain exactly how they made decisions. MYCIN struggled with uncertain or incomplete information, unlike human doctors who could make educated guesses. Perhaps most importantly, maintaining and updating the rule base became exponentially more complex as MYCIN grew, as adding new rules frequently conflicted with existing ones, while medical knowledge itself continued to evolve. Knowledge capture, uncertainty handling, and maintenance remain central concerns in modern machine learning, addressed through different technical approaches.</p>
</section>
<section id="sec-introduction-statistical-learning-era-c064" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-statistical-learning-era-c064">Statistical Learning Era</h3>
<p>These persistent challenges with knowledge capture and system maintenance drove researchers toward a different approach. The 1990s marked a radical transformation in artificial intelligence as the field shifted from hand-coded rules toward statistical learning approaches. Three converging factors made statistical methods both possible and powerful. The digital revolution meant massive amounts of data were suddenly available to train the algorithms. Moore’s Law<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> delivered the computational power needed to process this data effectively. And researchers developed new algorithms like Support Vector Machines and improved neural networks that could actually learn patterns from this data rather than following pre-programmed rules. This combination transformed AI development: rather than encoding human knowledge directly, machines could discover patterns automatically from examples, creating more robust and adaptable systems.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;<strong>Moore’s Law</strong>: The observation made by Intel co-founder Gordon Moore in 1965 that the number of transistors on a microchip doubles approximately every two years, while the cost halves. This exponential growth in computing power has been a key driver of advances in machine learning, though the pace has begun to slow in recent years.</p></div></div><p>Email spam filtering evolution illustrates this transformation. Early rule-based systems used explicit patterns but proved brittle and easily circumvented. Statistical systems took a different approach: if the word ‘viagra’ appears in 90% of spam emails but only 1% of normal emails, we can use this pattern to identify spam. Rather than writing explicit rules, statistical systems learn these patterns automatically from thousands of example emails, making them adaptable to new spam techniques. The mathematical foundation relies on Bayes’ theorem to calculate the probability that an email is spam given specific words: <span class="math inline">\(P(\text{spam}|\text{word}) = P(\text{word}|\text{spam}) \times P(\text{spam}) / P(\text{word})\)</span>. For emails with multiple words, we combine these probabilities across the entire message assuming conditional independence of words given the class (spam or not spam), which allows efficient computation despite the simplifying assumption that words don’t depend on each other.</p>
<div id="callout-example*-1.4" class="callout callout-example" title="Early Spam Detection Systems">
<details class="callout-example fbx-default closebutton" open=""><summary><strong>Example: </strong>Early Spam Detection Systems</summary><div>
<pre><code>Rule-based (1980s):
IF contains("viagra") OR contains("winner") THEN spam

Statistical (1990s):
P(spam|word) = (frequency in spam emails) / (total frequency)

Combined using Naive Bayes:
P(spam|email) ∝ P(spam) × ∏ P(word|spam)</code></pre>
</div></details>
</div>
<p>Statistical approaches introduced three core concepts that remain central to AI development. First, the quality and quantity of training data became as important as the algorithms themselves. AI could only learn patterns that were present in its training examples. Second, rigorous evaluation methods became essential to measure AI performance, leading to metrics that could measure success and compare different approaches. Third, an inherent tension exists between precision (being right when making a prediction) and recall (catching all the cases we should find), forcing designers to make explicit trade-offs based on their application’s needs. The systematic approaches to these challenges are covered in <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong> and <strong><a href="../core/benchmarking/benchmarking.html#sec-benchmarking-ai">Chapter 7: Benchmarking AI</a></strong>. Spam filters might tolerate some spam to avoid blocking important emails, while medical diagnosis systems prioritize catching every potential case despite increased false alarms.</p>
<p><a href="#tbl-ai-evolution-strengths" class="quarto-xref">Table&nbsp;1</a> summarizes the evolutionary journey of AI approaches, highlighting key strengths and capabilities emerging with each paradigm. Moving from left to right reveals important trends. Before examining shallow and deep learning, understanding trade-offs between existing approaches provides important context.</p>
<div id="tbl-ai-evolution-strengths" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ai-evolution-strengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: <strong>AI Paradigm Evolution</strong>: Shifting from symbolic AI to statistical approaches transformed machine learning by prioritizing data quantity and quality, enabling rigorous performance evaluation, and necessitating explicit trade-offs between precision and recall to optimize system behavior for specific applications. The table outlines how each paradigm addressed these challenges, revealing a progression towards data-driven systems capable of handling complex, real-world problems.
</figcaption>
<div aria-describedby="tbl-ai-evolution-strengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspect</th>
<th style="text-align: left;">Symbolic AI</th>
<th style="text-align: left;">Expert Systems</th>
<th style="text-align: left;">Statistical Learning</th>
<th style="text-align: left;">Shallow / Deep Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Key Strength</td>
<td style="text-align: left;">Logical reasoning</td>
<td style="text-align: left;">Domain expertise</td>
<td style="text-align: left;">Versatility</td>
<td style="text-align: left;">Pattern recognition</td>
</tr>
<tr class="even">
<td style="text-align: left;">Best Use Case</td>
<td style="text-align: left;">Well-defined, rule-based problems</td>
<td style="text-align: left;">Specific domain problems</td>
<td style="text-align: left;">Various structured data problems</td>
<td style="text-align: left;">Complex, unstructured data problems</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Data Handling</td>
<td style="text-align: left;">Minimal data needed</td>
<td style="text-align: left;">Domain knowledge-based</td>
<td style="text-align: left;">Moderate data required</td>
<td style="text-align: left;">Large-scale data processing</td>
</tr>
<tr class="even">
<td style="text-align: left;">Adaptability</td>
<td style="text-align: left;">Fixed rules</td>
<td style="text-align: left;">Domain-specific adaptability</td>
<td style="text-align: left;">Adaptable to various domains</td>
<td style="text-align: left;">Highly adaptable to diverse tasks</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Problem Complexity</td>
<td style="text-align: left;">Simple, logic-based</td>
<td style="text-align: left;">Complicated, domain- specific</td>
<td style="text-align: left;">Complex, structured</td>
<td style="text-align: left;">Highly complex, unstructured</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>This analysis bridges early approaches with recent developments in shallow and deep learning. It explains why certain approaches gained prominence in different eras and how each paradigm built upon predecessors while addressing their limitations. Earlier approaches continue to influence and enhance modern AI techniques, particularly in foundation model development.</p>
<p>These core concepts that emerged from statistical learning (data quality, evaluation metrics, and precision-recall trade-offs) became the foundation for all subsequent developments in machine learning.</p>
</section>
<section id="sec-introduction-shallow-learning-era-3448" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-shallow-learning-era-3448">Shallow Learning Era</h3>
<p>Building on these statistical foundations, the 2000s marked a significant period in machine learning history known as the “shallow learning” era. The term “shallow” refers to architectural depth: shallow learning typically employed one or two processing levels, contrasting with deep learning’s multiple hierarchical layers that emerged later.</p>
<p>During this time, several powerful algorithms dominated the machine learning landscape. Each brought unique strengths to different problems: Decision trees<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> provided interpretable results by making choices much like a flowchart. K-nearest neighbors made predictions by finding similar examples in past data, like asking your most experienced neighbors for advice. Linear and logistic regression offered straightforward, interpretable models that worked well for many real-world problems. Support Vector Machines<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> (SVMs) excelled at finding complex boundaries between categories using the “kernel trick”<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. This technique transforms complex patterns by projecting data into higher dimensions where linear separation becomes possible. These algorithms formed the foundation of practical machine learning.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;<strong>Decision Trees</strong>: A machine learning algorithm that makes predictions by following a series of yes/no questions, much like a flowchart. Popularized in the 1980s, decision trees are highly interpretable—you can trace exactly why the algorithm made each decision. They’re still widely used today in scenarios where explainability is crucial, such as medical diagnosis or loan approval, where regulations require understanding the reasoning behind automated decisions.</p></div><div id="fn13"><p><sup>13</sup>&nbsp;<strong>Support Vector Machines (SVMs)</strong>: A powerful machine learning algorithm developed by Vladimir Vapnik in the 1990s that finds the optimal boundary between different categories of data. SVMs were the dominant technique for many classification problems before deep learning emerged, winning numerous machine learning competitions. They remain highly effective for smaller datasets and are still used today in text classification, bioinformatics, and other specialized applications.</p></div><div id="fn14"><p><sup>14</sup>&nbsp;<strong>Kernel Trick</strong>: A mathematical technique that allows algorithms like SVMs to find complex, non-linear patterns by transforming data into higher-dimensional spaces where linear separation becomes possible. For example, data points that form a circle in 2D space can be projected into 3D space where they become linearly separable. This breakthrough, formalized in the 1960s but popularized in the 1990s, allowed relatively simple algorithms to solve complex problems without explicitly computing in high-dimensional spaces.</p></div></div><p>A typical computer vision solution from 2005 exemplifies this approach:</p>
<div id="callout-example*-1.5" class="callout callout-example" title="Traditional Computer Vision Pipeline">
<details class="callout-example fbx-default closebutton" open=""><summary><strong>Example: </strong>Traditional Computer Vision Pipeline</summary><div>
<pre><code>1. Manual Feature Extraction
  - SIFT (Scale-Invariant Feature Transform)
  - HOG (Histogram of Oriented Gradients)
  - Gabor filters
2. Feature Selection/Engineering
3. "Shallow" Learning Model (e.g., SVM)
4. Post-processing</code></pre>
</div></details>
</div>
<p>This era’s hybrid approach combined human-engineered features with statistical learning. They had strong mathematical foundations (researchers could prove why they worked). They performed well even with limited data. They were computationally efficient. They produced reliable, reproducible results.</p>
<p>The Viola-Jones algorithm <span class="citation" data-cites="viola2001rapidobject">(<a href="#ref-viola2001rapidobject" role="doc-biblioref">Viola and Jones, n.d.</a>)</span><a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> (2001) exemplifies this era, achieving real-time face detection using simple rectangular features and cascaded classifiers<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>. This algorithm powered digital camera face detection for nearly a decade.</p>
<div class="no-row-height column-margin column-container"><div id="ref-viola2001rapidobject" class="csl-entry" role="listitem">
Viola, P., and M. Jones. n.d. <span>“Rapid Object Detection Using a Boosted Cascade of Simple Features.”</span> In <em>Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001</em>, 1:I-511-I-518. IEEE Comput. Soc. <a href="https://doi.org/10.1109/cvpr.2001.990517">https://doi.org/10.1109/cvpr.2001.990517</a>.
</div><div id="fn15"><p><sup>15</sup>&nbsp;<strong>Viola-Jones Algorithm</strong>: A groundbreaking computer vision algorithm that could detect faces in real-time by using simple rectangular patterns (like comparing the brightness of eye regions versus cheek regions) and making decisions in stages, filtering out non-faces quickly and spending more computation only on promising candidates.</p></div><div id="fn16"><p><sup>16</sup>&nbsp;<strong>Cascade of Classifiers</strong>: A multi-stage decision system where each stage acts as a filter, quickly rejecting obvious non-matches and passing promising candidates to the next, more sophisticated stage. This approach is similar to how security screening works at airports with multiple checkpoints of increasing thoroughness.</p></div></div></section>
<section id="sec-introduction-deep-learning-era-155a" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-deep-learning-era-155a">Deep Learning Era</h3>
<p>While Support Vector Machines excelled at finding complex category boundaries through mathematical transformations, deep learning adopted a radically different approach inspired by brain architecture. Deep learning employs layers of simple computational units inspired by brain neurons<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>, with each layer transforming input data into increasingly abstract representations. The detailed architecture and functioning of these neural networks are explored in <strong><a href="../core/dl_primer/dl_primer.html#sec-dl-primer">Chapter 3: Deep Learning Primer</a></strong> and <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong>.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;<strong>Artificial Neurons</strong>: Basic computational units in neural networks that mimic biological neurons, taking multiple inputs, applying weights and biases, and producing an output signal through an activation function.</p></div></div><p>In image processing, this layered approach works systematically. The first layer detects simple edges and contrasts, subsequent layers combine these into basic shapes and textures, higher layers recognize specific features like whiskers and ears, and final layers assemble these into concepts like “cat.”</p>
<p>Unlike shallow learning methods requiring carefully engineered features, deep learning networks automatically discover useful features from raw data. This layered approach to learning, building from simple patterns to complex concepts, defines “deep” learning and proves remarkably effective for complex, real-world data like images, speech, and text.</p>
<p>AlexNet, shown in <a href="#fig-alexnet" class="quarto-xref">Figure&nbsp;2</a>, achieved a breakthrough in the 2012 ImageNet<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> competition that transformed machine learning through a perfect alignment of algorithmic innovation and hardware capability. The network required two NVIDIA GTX 580 GPUs with 3GB memory each, delivering 2.3 GFLOPS peak performance per GPU, but the real breakthrough was memory bandwidth utilization. Each GTX 580 provided 192 GB/s memory bandwidth, and AlexNet’s convolutional operations required approximately 288 GB/s total memory bandwidth to feed the computation engines—making this the first neural network specifically designed around memory bandwidth constraints rather than just compute requirements. The 60 million parameters demanded 240MB storage, while training on 1.2 million images required sophisticated memory management to split the network across GPU boundaries and coordinate gradient updates. Training consumed approximately 1,287 GPU-hours over 6 days, achieving 15.3% top-5 error rate compared to 26.2% for second place, a 42% relative improvement that demonstrated the power of hardware-software co-design. This represented a 10-100x speedup over CPU implementations, reducing training time from months to days and proving that specialized hardware could unlock previously intractable algorithms <span class="citation" data-cites="krizhevsky2012imagenet">(<a href="#ref-krizhevsky2012imagenet" role="doc-biblioref">Krizhevsky, Sutskever, and Hinton 2017</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;<strong>ImageNet</strong>: A massive visual database containing over 14 million labeled images across 20,000+ categories, created by Stanford’s Fei-Fei Li starting in 2009 <span class="citation" data-cites="deng2009imagenet">(<a href="#ref-deng2009imagenet" role="doc-biblioref">Deng et al. 2009</a>)</span>. The annual ImageNet challenge became the Olympics of computer vision, driving breakthrough after breakthrough in image recognition until neural networks became so good they essentially solved the competition.</p><div id="ref-deng2009imagenet" class="csl-entry" role="listitem">
Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. <span>“ImageNet: A Large-Scale Hierarchical Image Database.”</span> In <em>2009 IEEE Conference on Computer Vision and Pattern Recognition</em>, 248–55. IEEE. <a href="https://doi.org/10.1109/cvpr.2009.5206848">https://doi.org/10.1109/cvpr.2009.5206848</a>.
</div></div><div id="ref-krizhevsky2012imagenet" class="csl-entry" role="listitem">
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. 2017. <span>“ImageNet Classification with Deep Convolutional Neural Networks.”</span> <em>Communications of the ACM</em> 60 (6): 84–90. <a href="https://doi.org/10.1145/3065386">https://doi.org/10.1145/3065386</a>.
</div></div><p>The success of AlexNet wasn’t just a technical achievement; it was a watershed moment that demonstrated the practical viability of deep learning. Critically, this breakthrough required both algorithmic innovation and systems engineering advances. The achievement wasn’t just algorithmic, it was enabled by framework infrastructure like Theano that could efficiently orchestrate GPU parallelism, handle automatic differentiation at scale, and manage the complex computational workflows that deep learning demands. Without these framework foundations, the algorithmic insights would have remained computationally intractable.</p>
<p>This pattern of requiring both algorithmic and systems breakthroughs has defined every major AI advance since. Modern frameworks represent critical infrastructure that transforms algorithmic possibilities into practical realities. Automatic differentiation (autograd) systems represent perhaps the most critical innovation that makes modern deep learning possible, handling gradient computation automatically and enabling the complex architectures we use today. Understanding this framework-centric perspective (that major AI capabilities emerge from the intersection of algorithms and systems engineering) is essential for building robust, scalable machine learning systems. This single result triggered an explosion of research and applications in deep learning that continues to this day. The infrastructure requirements that enabled this breakthrough represent the convergence of algorithmic innovation with systems engineering that this book explores.</p>
<div id="fig-alexnet" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="719f646bcb413a020dff4682273395e92c893105.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Convolutional Neural Network Architecture: AlexNet demonstrated that deep neural networks could automatically learn effective features from images, dramatically outperforming traditional computer vision methods. This breakthrough showed that with sufficient data and computing power, neural networks could achieve remarkable accuracy in image recognition tasks."><img src="introduction_files/mediabag/719f646bcb413a020dff4682273395e92c893105.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <strong>Convolutional Neural Network Architecture</strong>: AlexNet demonstrated that deep neural networks could automatically learn effective features from images, dramatically outperforming traditional computer vision methods. This breakthrough showed that with sufficient data and computing power, neural networks could achieve remarkable accuracy in image recognition tasks.
</figcaption>
</figure>
</div>
<p>Deep learning subsequently entered an era of extraordinary scale. By the late 2010s, companies like Google, Facebook, and OpenAI trained neural networks thousands of times larger than AlexNet. These massive models, often called “foundation models”<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>, expanded deep learning capabilities to new domains.</p>
<div class="no-row-height column-margin column-container"><div id="fn19"><p><sup>19</sup>&nbsp;<strong>Foundation Models</strong>: Large-scale AI models trained on broad datasets that serve as the “foundation” for many different applications through fine-tuning, like GPT for language tasks or CLIP for vision tasks. The term was coined by Stanford’s AI researchers in 2021 to capture how these models became the basis for building more specific AI systems.</p></div><div id="ref-brown2020language" class="csl-entry" role="listitem">
Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. <span>“Language Models Are Few-Shot Learners.”</span> <em>Advances in Neural Information Processing Systems</em> 33: 1877–1901.
</div><div id="fn20"><p><sup>20</sup>&nbsp;<strong>BERT-Large</strong>: A transformer-based language model developed by Google in 2018 with 340 million parameters, representing the previous generation of large language models before the GPT era. BERT (Bidirectional Encoder Representations from Transformers) was revolutionary for understanding context in both directions of a sentence, but GPT-3’s 175 billion parameters dwarfed it by over 500x, marking the transition to truly large-scale language models.</p></div><div id="fn21"><p><sup>21</sup>&nbsp;<strong>Parameters</strong>: The adjustable values within a neural network that are modified during training, similar to how the brain’s neural connections grow stronger as you learn a new skill. Having more parameters generally means that the model can learn more complex patterns.</p></div><div id="fn22"><p><sup>22</sup>&nbsp;<strong>ZettaFLOPs</strong>: A measure of computational performance equal to one sextillion (10^21) floating-point operations per second. Training GPT-3 required approximately 3.114 × 10^23 FLOPS (roughly 314 zettaFLOPs), which would theoretically take 355 years on a single V100 GPU. This massive computational requirement illustrates why modern AI training requires distributed systems with thousands of GPUs working in parallel.</p></div><div id="fn23"><p><sup>23</sup>&nbsp;<strong>V100 GPUs</strong>: NVIDIA’s data center graphics processing units designed specifically for AI training, featuring 32GB of high-bandwidth memory and 125 teraFLOPs of deep learning performance. Each V100 costs approximately $8,000-$10,000, making the 1,024 GPUs used for GPT-3 training worth roughly $8-10 million in hardware alone, highlighting the enormous infrastructure investment required for cutting-edge AI research.</p></div></div><p>GPT-3, released in 2020 <span class="citation" data-cites="brown2020language">(<a href="#ref-brown2020language" role="doc-biblioref">Brown et al. 2020</a>)</span>, contained 175 billion parameters requiring approximately 800GB of memory to store, representing a 1,000x scale increase from earlier neural networks like BERT-Large<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> (340 million parameters)<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>. Training GPT-3 consumed approximately 314 zettaFLOPs<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a> of computation across 1,024 V100 GPUs<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a> over several weeks, with training costs estimated at $4.6 million. The model processes text at approximately 1.7GB/s memory bandwidth and requires specialized infrastructure to serve millions of users with sub-second latency. These models demonstrated remarkable emergent abilities that appeared only at scale: writing human-like text, engaging in sophisticated conversation, generating images from descriptions, and writing functional computer code. These capabilities emerged from the scale of computation and data rather than explicit programming.</p>
<p>A key insight emerged: larger neural networks trained on more data became capable of solving increasingly complex tasks. This scale introduced significant systems challenges<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a>. Efficiently training large models requires thousands of parallel GPUs, storing and serving models hundreds of gigabytes in size, and handling massive training datasets.</p>
<div class="no-row-height column-margin column-container"><div id="fn24"><p><sup>24</sup>&nbsp;<strong>Large-Scale Training Challenges</strong>: Training GPT-3 required approximately 3,640 petaflop-days. At $2-3 per GPU-hour on cloud platforms (2020 pricing), this translates to approximately $4.6M in compute costs alone (Lambda Labs estimate), excluding data preprocessing, experimentation, and failed training runs <span class="citation" data-cites="li2020estimating">(<a href="#ref-li2020estimating" role="doc-biblioref">Li 2020</a>)</span>. Rule of thumb: total project cost is typically 3-5x raw compute cost due to experimentation overhead, making the full GPT-3 development cost approximately $15-20M. Modern foundation models can consume 100+ terabytes of training data and require specialized distributed training techniques to coordinate thousands of accelerators across multiple data centers.</p><div id="ref-li2020estimating" class="csl-entry" role="listitem">
Li, Chengwei. 2020. <span>“Estimating the Training Cost of GPT-3.”</span> <a href="https://lambdalabs.com/blog/demystifying-gpt-3">https://lambdalabs.com/blog/demystifying-gpt-3</a>.
</div></div><div id="ref-minsky1969perceptrons" class="csl-entry" role="listitem">
Minsky, Marvin, and Seymour A. Papert. 2017. <em>Perceptrons: An Introduction to Computational Geometry</em>. Cambridge, MA: The MIT Press. <a href="https://doi.org/10.7551/mitpress/11301.001.0001">https://doi.org/10.7551/mitpress/11301.001.0001</a>.
</div><div id="ref-rumelhart1986learning" class="csl-entry" role="listitem">
Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1986. <span>“Learning Representations by Back-Propagating Errors.”</span> <em>Nature</em> 323 (6088): 533–36. <a href="https://doi.org/10.1038/323533a0">https://doi.org/10.1038/323533a0</a>.
</div><div id="fn25"><p><sup>25</sup>&nbsp;<strong>Backpropagation (Historical Context)</strong>: A mathematical technique that allows neural networks to learn by calculating how much each component contributed to errors and adjusting accordingly—like a coach analyzing a team’s mistakes and giving each player specific feedback to improve their performance.</p></div><div id="ref-lecun1989backpropagation" class="csl-entry" role="listitem">
LeCun, Y., B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. 1989. <span>“Backpropagation Applied to Handwritten Zip Code Recognition.”</span> <em>Neural Computation</em> 1 (4): 541–51. <a href="https://doi.org/10.1162/neco.1989.1.4.541">https://doi.org/10.1162/neco.1989.1.4.541</a>.
</div><div id="fn26"><p><sup>26</sup>&nbsp;<strong>Convolutional Neural Network (CNN)</strong>: A type of neural network specially designed for processing images, inspired by how the human visual system works. The “convolutional” part refers to how it scans images in small chunks, similar to how our eyes focus on different parts of a scene.</p></div></div><p>The 2012 deep learning revolution built upon neural network research dating to the 1950s. The story begins with Frank Rosenblatt’s Perceptron in 1957, which captured the imagination of researchers by showing how a simple artificial neuron could learn to classify patterns. Though limited to linearly separable problems, as Minsky and Papert’s 1969 book “Perceptrons” <span class="citation" data-cites="minsky1969perceptrons">(<a href="#ref-minsky1969perceptrons" role="doc-biblioref">Minsky and Papert 2017</a>)</span> demonstrated, it introduced the core concept of trainable neural networks. The 1980s brought more important breakthroughs: Rumelhart, Hinton, and Williams introduced backpropagation <span class="citation" data-cites="rumelhart1986learning">(<a href="#ref-rumelhart1986learning" role="doc-biblioref">Rumelhart, Hinton, and Williams 1986</a>)</span><a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a> in 1986, providing a systematic way to train multi-layer networks, while Yann LeCun demonstrated its practical application in recognizing handwritten digits using specialized neural networks designed for image processing <span class="citation" data-cites="lecun1989backpropagation">(<a href="#ref-lecun1989backpropagation" role="doc-biblioref">LeCun et al. 1989</a>)</span><a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a>.</p>
<p>These networks largely stagnated through the 1990s and 2000s not because the ideas were incorrect, but because they preceded necessary technological developments. The field lacked three important ingredients: sufficient data to train complex networks, enough computational power to process this data, and the technical innovations needed to train very deep networks effectively.</p>
<p>Deep learning’s potential required the convergence of big data, advanced computing hardware, and algorithmic breakthroughs. This extended development period explains why the 2012 ImageNet breakthrough represented accumulated research culminating rather than sudden revolution. This evolution produced two significant developments. First, it established machine learning systems engineering as a discipline bridging theoretical advancements with practical implementation. Second, it necessitated comprehensive machine learning system definitions encompassing algorithms, data, and computing infrastructure. Today’s challenges of scale echo many of the same core questions about computation, data, and learning methods that researchers have grappled with since the field’s inception, but now within a more complex and interconnected framework.</p>


<div class="no-row-height column-margin column-container"><div class="">
  <div class="margin-video">
    <iframe src="https://www.youtube.com/embed/FwFduRA_L6Q?start=" style="width:100%; aspect-ratio: ; border:0;" allowfullscreen="">
    </iframe>
  </div>
  <p><em>Convolutional Network Demo from 1989 - Yann LeCun</em></p>
</div></div><p>This evolution reveals a crucial insight: as AI progressed from symbolic reasoning to statistical learning and deep learning, applications became increasingly ambitious and complex. However, this growth introduced challenges extending beyond algorithms, necessitating engineering entire systems capable of deploying and sustaining AI at scale. This transition from algorithmic innovation to systems integration challenges explains the emergence of Machine Learning Systems Engineering as a distinct discipline.</p>
<div id="quiz-question-sec-introduction-ai-evolution-8ff4" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.3</strong></summary><div>
<ol type="1">
<li><p>Which of the following milestones marked the beginning of the symbolic AI era?</p>
<ol type="a">
<li>The Dartmouth Conference in 1956</li>
<li>The invention of the perceptron by Frank Rosenblatt</li>
<li>The introduction of IBM’s Deep Blue</li>
<li>The release of OpenAI’s GPT-3</li>
</ol></li>
<li><p>Explain the impact of the shift from symbolic AI to statistical learning on the development of AI systems.</p></li>
<li><p>Order the following AI milestones chronologically: (1) ELIZA chatbot, (2) IBM’s Deep Blue, (3) OpenAI’s GPT-3, (4) Perceptron by Frank Rosenblatt.</p></li>
<li><p>True or False: The development of deep learning marked a return to rule-based systems similar to those used in symbolic AI.</p></li>
<li><p>What was a key factor that enabled the transition from shallow to deep learning in AI?</p>
<ol type="a">
<li>Focus on symbolic reasoning</li>
<li>Development of rule-based systems</li>
<li>Introduction of the ELIZA chatbot</li>
<li>Increased availability of large datasets</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ai-evolution-8ff4" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
<section id="sec-introduction-bitter-lesson-systems-matter-a8f2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-bitter-lesson-systems-matter-a8f2">The Bitter Lesson: Why ML Systems Engineering Matters</h2>
<p>The historical progression we’ve traced (from symbolic AI through statistical learning to deep learning) reveals a consistent underlying pattern that helps explain why an entirely new engineering discipline has emerged. This pattern, which reinforcement learning pioneer Richard Sutton would later articulate as “The Bitter Lesson,” demonstrates that each major breakthrough succeeded not by better encoding human knowledge, but by finding ways to leverage greater computational resources more effectively. Systems engineering thus becomes the crucial determinant of AI success, shifting focus from algorithmic sophistication to computational scalability.</p>
<p>This pattern emerges clearly when we examine what actually drove these transitions. Expert systems failed not because logical reasoning was inherently flawed, but because hand-coding knowledge couldn’t scale to real-world complexity. Statistical machine learning succeeded because it could automatically extract patterns from data, but it required substantial computational infrastructure to process large datasets. Deep learning’s dominance came from its ability to learn complex representations automatically, but only when sufficient computational power became available to train very large networks on massive amounts of data.</p>
<p>Reinforcement learning pioneer Richard Sutton captured this insight precisely in his influential 2019 essay “The Bitter Lesson” <span class="citation" data-cites="sutton2019bitter">(<a href="#ref-sutton2019bitter" role="doc-biblioref">Sutton 2019</a>)</span>. Sutton<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a> observed that the greatest breakthroughs in AI have consistently come not from incorporating human knowledge and expertise, but from scaling general-purpose methods that leverage massive computational resources.</p>
<div class="no-row-height column-margin column-container"><div id="ref-sutton2019bitter" class="csl-entry" role="listitem">
Sutton, Richard S. 2019. <span>“The Bitter Lesson.”</span> <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a>.
</div><div id="fn27"><p><sup>27</sup>&nbsp;<strong>Richard Sutton</strong>: A foundational figure in reinforcement learning and AI, Sutton co-authored the seminal textbook “Reinforcement Learning: An Introduction” and developed key algorithms like temporal difference learning. He received the 2024 Turing Award, computing’s highest honor, for his pioneering contributions to reinforcement learning that have significantly shaped how AI systems learn and adapt. His perspective on AI’s development carries particular weight given his decades of contributions to both the theoretical foundations and practical advancement of machine learning.</p></div><div id="ref-campbell2002deep" class="csl-entry" role="listitem">
Campbell, Murray, Jr. Hoane A.Joseph, and Feng-hsiung Hsu. 2002. <span>“Deep Blue.”</span> <em>Artificial Intelligence</em> 134 (1-2): 57–83. <a href="https://doi.org/10.1016/s0004-3702(01)00129-1">https://doi.org/10.1016/s0004-3702(01)00129-1</a>.
</div><div id="ref-silver2016mastering" class="csl-entry" role="listitem">
Silver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, et al. 2016. <span>“Mastering the Game of Go with Deep Neural Networks and Tree Search.”</span> <em>Nature</em> 529 (7587): 484–89. <a href="https://doi.org/10.1038/nature16961">https://doi.org/10.1038/nature16961</a>.
</div></div><p>Sutton’s observation finds validation across numerous AI breakthroughs. In chess, IBM’s Deep Blue defeated world champion Garry Kasparov in 1997 <span class="citation" data-cites="campbell2002deep">(<a href="#ref-campbell2002deep" role="doc-biblioref">Campbell, Hoane, and Hsu 2002</a>)</span> not by encoding sophisticated chess strategies, but through brute-force search evaluating millions of positions per second. In Go, DeepMind’s AlphaGo <span class="citation" data-cites="silver2016mastering">(<a href="#ref-silver2016mastering" role="doc-biblioref">Silver et al. 2016</a>)</span> achieved superhuman performance by learning from self-play rather than studying centuries of human Go wisdom. In computer vision, convolutional neural networks that learn features directly from data have surpassed decades of carefully hand-crafted feature engineering. In speech recognition, end-to-end deep learning systems have outperformed approaches built on detailed models of human phonetics and linguistics.</p>
<p>The “bitter” aspect of this lesson is that approaches emphasizing human expertise and domain knowledge, while providing short-term improvements, are often surpassed by general methods that can leverage greater computational resources. Sutton writes: “The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin.”</p>
<p>This principle extends directly to today’s most advanced systems. Consider modern language models like GPT-4 or image generation systems like DALL-E. Their capabilities emerge not from sophisticated linguistic or artistic theories encoded by humans, but from training general-purpose neural networks on vast amounts of data using enormous computational resources. Training GPT-3 consumed approximately 1,287 MWh of energy, equivalent to 120 U.S. homes for a year, while serving the model to millions of users requires data centers consuming megawatts of continuous power. The engineering challenge is building systems that can manage this scale: collecting and processing petabytes<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> of training data, coordinating training across thousands of GPUs each consuming 300-500 watts, serving models to millions of users with millisecond latency while managing thermal and power constraints, and continuously updating systems based on real-world performance.</p>
<div class="no-row-height column-margin column-container"><div id="fn28"><p><sup>28</sup>&nbsp;<strong>Petabytes</strong>: One million gigabytes, or enough storage for 500 billion pages of text. To put this in perspective, the entire printed collection of the U.S. Library of Congress is about 20 terabytes, so a petabyte could store 50 copies. Modern AI training datasets like Common Crawl contain multiple petabytes of web text, representing essentially the entire public internet’s text content.</p></div><div id="fn29"><p><sup>29</sup>&nbsp;<strong>Amdahl’s Law</strong>: Formulated by computer architect Gene Amdahl in 1967, this law quantifies the theoretical speedup of a program when only part of it can be parallelized. The speedup is limited by the sequential portion: if P is the fraction that can be parallelized, maximum speedup = 1/(1-P). For example, if 90% of a program can be parallelized, maximum speedup is 10x regardless of processor count. In ML systems, this explains why memory bandwidth and data movement often become the primary bottlenecks rather than compute capacity.</p></div></div><p>These scale requirements reveal an important technical reality: the primary constraint in modern ML systems is not compute capacity but memory bandwidth, the rate at which data can move between storage and processing units. This memory wall represents the primary bottleneck that determines system performance. Modern ML systems are severely memory bound, with matrix multiply operations achieving only 1-10% of theoretical peak FLOPS because processors spend most of their time waiting for data rather than computing. Moving 1GB from DRAM costs approximately 1000x more energy than a 32-bit multiply operation, making data movement the dominant factor in both performance and energy consumption. Amdahl’s Law<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a> quantifies this limitation: if data movement takes 80% of execution time, even infinite compute capacity provides only 5x speedup. This memory wall drives all modern architectural innovations, from in-memory computing and near-data processing to specialized accelerators that co-locate compute and storage elements. These system-scale challenges represent core engineering problems that this book explores systematically.</p>
<p>Sutton’s bitter lesson helps explain the core motivation for this book. If AI progress depends on our ability to scale computation effectively, then understanding how to build, deploy, and maintain these computational systems becomes the most important skill for AI practitioners. The theoretical algorithms are important, but the systems that bring them to life at scale determine what’s actually possible in practice. ML systems engineering has become critical because our success depends on building systems that can effectively harness computational resources: training models on massive datasets, deploying them at global scale, and continuously improving them through feedback loops.</p>
<p>The practical implications of Sutton’s bitter lesson are profound. Creating a modern language model requires coordinating thousands of GPUs across multiple data centers, processing petabytes of text data, and serving the resulting system to millions of users with millisecond latency requirements. This challenge extends far beyond algorithmic innovation. It demands expertise in distributed systems, data engineering, hardware optimization, and operational practices that represent an entirely new engineering discipline.</p>
<p>The emergence of this systems-focused approach mirrors a similar transition that occurred in the late 1960s and early 1970s. As computing systems grew more complex, Computer Engineering<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a> emerged as a new discipline to bridge the gap between Electrical Engineering’s hardware expertise and Computer Science’s focus on algorithms and software. Computer Engineering arose because the challenges of designing and building complex computing systems required an integrated approach that neither discipline could fully address on its own.</p>
<div class="no-row-height column-margin column-container"><div id="fn30"><p><sup>30</sup>&nbsp;<strong>Computer Engineering</strong>: This discipline emerged in the late 1960s when IBM System/360 and other complex computing systems required expertise that spanned both hardware and software. Before Computer Engineering, electrical engineers focused on circuits while computer scientists worked on algorithms, but no one specialized in the integration challenges. Today’s Computer Engineering programs, established at schools like Case Western Reserve and Stanford in the 1970s, combine hardware design, software systems, and computer architecture—laying the groundwork for what ML Systems Engineering is becoming today.</p></div></div><p>Today, we witness a remarkably similar transition occurring in AI. While Computer Science advances ML algorithms and Electrical Engineering develops specialized AI hardware, neither discipline fully addresses the engineering principles needed to deploy, optimize, and sustain ML systems at scale. This gap necessitates a new discipline: Machine Learning Systems Engineering.</p>
<p>While this field lacks universal definition, drawing from our analysis of computational scalability and systems integration challenges, it can be broadly characterized as:</p>
<div id="callout-definition*-1.6" class="callout callout-definition" title="Machine Learning Systems Engineering">
<p></p><details class="callout-definition fbx-default closebutton" open=""><summary><strong>Definition: </strong>Machine Learning Systems Engineering</summary><div><strong>Machine Learning Systems Engineering (MLSysEng)</strong> is the engineering discipline focused on building <em>reliable</em>, <em>efficient</em>, and <em>scalable</em> AI systems across computational platforms, ranging from <em>embedded devices</em> to <em>data centers</em>. It spans the entire AI lifecycle, including <em>data acquisition</em>, <em>model development</em>, <em>system integration</em>, <em>deployment</em>, and <em>operations</em>, with an emphasis on <em>resource-awareness</em> and <em>system-level optimization</em>.<p></p>
</div></details>
</div>
<p>Space exploration provides an apt analogy. Astronauts venture into new frontiers, but their discoveries depend on complex engineering systems including rockets providing lift, life support systems sustaining them, and communication networks maintaining Earth connectivity. Similarly, AI researchers advance learning algorithms, but breakthroughs become practical reality through careful systems engineering. Modern AI systems require robust infrastructure for data collection and management, powerful computing systems for model training, and reliable deployment platforms serving millions of users.</p>
<p>This space exploration analogy illuminates why machine learning systems engineering has emerged as such an important discipline. Converting AI algorithms into real-world systems requires bridging theoretical possibilities with practical implementation. A brilliant algorithm requires efficient data collection and processing, distributed computation across hundreds of machines, reliable service to millions of users, and production performance monitoring. Modern ML systems must treat energy efficiency as a first-class design constraint alongside traditional metrics like accuracy and latency, not as an afterthought. The physics constraints of memory bandwidth limitations, Dennard scaling breakdown, and the energy costs of data movement shape every architectural decision from chip design to data center deployment.</p>
<p>Understanding the interplay between algorithms and engineering is essential for modern AI practitioners. Researchers advance algorithmic possibilities while engineers address the complex challenge of reliable, efficient real-world implementation. This raises a central question: what constitutes a machine learning system, and how does it differ from traditional software systems?</p>
</section>
<section id="sec-introduction-defining-ml-systems-bf7d" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-defining-ml-systems-bf7d">Defining ML Systems</h2>
<p>No universally accepted definition of machine learning systems exists, reflecting the field’s rapid evolution and multidisciplinary nature. This ambiguity stems from practitioners, researchers, and industries referring to machine learning systems in varying contexts with different scopes—some focus solely on algorithmic aspects while others encompass the entire pipeline from data collection to model deployment.</p>
<p>However, the systems engineering perspective we’ve established through our examination of AI’s evolution toward computational scalability demands a more comprehensive view. Building on our understanding of why systems thinking has become central to AI progress, this textbook adopts a holistic approach that encompasses the entire ecosystem in which algorithms operate. We define a machine learning system as:</p>
<div id="callout-definition*-1.7" class="callout callout-definition" title="Machine Learning System">
<p></p><details class="callout-definition fbx-default closebutton" open=""><summary><strong>Definition: </strong>Machine Learning System</summary><div>A machine learning system is an integrated computing system comprising three core components: (1) data that guides algorithmic behavior, (2) learning algorithms that extract patterns from this data, and (3) computing infrastructure that enables both the learning process (i.e., training) and the application of learned knowledge (i.e., inference/serving). Together, these components create a computing system capable of making predictions, generating content, or taking actions based on learned patterns.<p></p>
</div></details>
</div>
<p>As illustrated in <a href="#fig-ai-triangle" class="quarto-xref">Figure&nbsp;3</a>, the core of any machine learning system consists of three interrelated components that form a triangular dependency: Models/Algorithms, Data, and Computing Infrastructure. Each element significantly shapes the possibilities of the others. The model architecture dictates both the computational demands for training and inference, as well as the volume and structure of data required for effective learning. The data’s scale and complexity influence what infrastructure is needed for storage and processing, while simultaneously determining which model architectures are feasible. The infrastructure capabilities establish practical limits on both model scale and data processing capacity, creating a framework within which the other components must operate.</p>
<div id="fig-ai-triangle" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-triangle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="e73fbb4194a2cf9fe1a8daf5e52828624a7facc5.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Component Interdependencies: Machine learning system performance relies on the coordinated interaction of models, data, and computing infrastructure; limitations in any one component constrain the capabilities of the others. Effective system design requires balancing these interdependencies to optimize overall performance and feasibility."><img src="introduction_files/mediabag/e73fbb4194a2cf9fe1a8daf5e52828624a7facc5.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-triangle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>Component Interdependencies</strong>: Machine learning system performance relies on the coordinated interaction of models, data, and computing infrastructure; limitations in any one component constrain the capabilities of the others. Effective system design requires balancing these interdependencies to optimize overall performance and feasibility.
</figcaption>
</figure>
</div>
<p>Each of these components serves a distinct but interconnected purpose:</p>
<ul>
<li><p><strong>Algorithms</strong>: Mathematical models and methods that learn patterns from data to make predictions or decisions</p></li>
<li><p><strong>Data</strong>: Processes and infrastructure for collecting, storing, processing, managing, and serving data for both training and inference.</p></li>
<li><p><strong>Computing</strong>: Hardware and software infrastructure that enables efficient training, serving, and operation of models at scale.</p></li>
</ul>
<p>This interdependency means no single element can function in isolation. Sophisticated algorithms require data and computing resources, large datasets require algorithms and infrastructure to be useful, and powerful infrastructure requires algorithms and data to serve any purpose.</p>
<p>Space exploration provides an apt analogy for these relationships. Algorithm developers resemble astronauts exploring new frontiers and making discoveries. Data science teams function like mission control specialists ensuring constant flow of critical information and resources for mission operations. Computing infrastructure engineers resemble rocket engineers designing and building systems that enable missions. Just as space missions require seamless integration of astronauts, mission control, and rocket systems, machine learning systems demand careful orchestration of algorithms, data, and computing infrastructure.</p>
<p>The 2012 AlexNet breakthrough illustrates the principle of hardware-software co-design that defines modern ML systems engineering. This deep learning revolution succeeded because the algorithmic innovation (convolutional neural networks) perfectly matched the hardware capability (parallel GPU architectures). Convolutional operations are inherently parallel (each filter can process different parts of an image simultaneously), making them naturally suited to GPU’s thousands of parallel cores. This wasn’t just about using available hardware more efficiently; it demonstrated that the most successful AI systems emerge when algorithms and hardware are designed together from the ground up. NVIDIA’s CUDA-enabled GPUs<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a> provided not just computational efficiency but also the programming model that made massive parallelism accessible to machine learning researchers. This co-design approach continues to shape ML system development: transformer attention mechanisms stress memory bandwidth differently than CNNs, leading to new accelerator architectures; edge deployment constraints drive algorithmic innovations like quantization and pruning; and specialized chips like Google’s TPUs co-evolve with TensorFlow to optimize specific operations like matrix multiplication.</p>
<div class="no-row-height column-margin column-container"><div id="fn31"><p><sup>31</sup>&nbsp;<strong>CUDA (Compute Unified Device Architecture)</strong>: NVIDIA’s parallel computing platform introduced in 2007 that transformed gaming graphics cards into general-purpose computing powerhouses. CUDA enabled developers to harness GPU’s thousands of cores for AI computations, providing 10-100x speedups over traditional CPUs for machine learning tasks. This breakthrough made deep learning practically feasible, as training a neural network that would take months on a CPU could be completed in days on CUDA-enabled hardware.</p></div></div><div id="quiz-question-sec-introduction-defining-ml-systems-bf7d" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.4</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes a machine learning system according to the textbook’s definition?</p>
<ol type="a">
<li>An integrated system comprising data, algorithms, and computing infrastructure.</li>
<li>A system focused solely on data collection and processing.</li>
<li>A system that only involves learning algorithms and their optimization.</li>
<li>A computing infrastructure that supports model deployment.</li>
</ol></li>
<li><p>True or False: The effectiveness of a machine learning system is independent of the interdependencies between its components.</p></li>
<li><p>Explain how the interdependencies between data, algorithms, and computing infrastructure influence the design of a machine learning system.</p></li>
<li><p>The three core components of a machine learning system are algorithms, data, and ____.</p></li>
<li><p>In a production ML system, which trade-off must be considered when balancing the three core components?</p>
<ol type="a">
<li>Choosing the simplest algorithm to reduce computational costs.</li>
<li>Maximizing data collection without regard to storage limitations.</li>
<li>Focusing solely on model accuracy without considering inference speed.</li>
<li>Balancing model complexity with available computational resources and data quality.</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-defining-ml-systems-bf7d" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-lifecycle-ml-systems-6194" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-lifecycle-ml-systems-6194">Lifecycle of ML Systems</h2>
<p>With this three-component framework established, we can now examine how ML systems fundamentally differ from traditional software in their development and operational lifecycle. This distinction shows why ML systems engineering requires new approaches and methodologies.</p>
<p>Traditional software systems follow predictable lifecycles where developers write explicit computer instructions. These systems build on decades of established software engineering practices. Version control systems maintain precise histories of code changes. Continuous integration and deployment pipelines automate testing and release processes. Static analysis tools measure code quality and identify potential issues. This infrastructure enables reliable software system development, testing, and deployment following well-defined software engineering principles.</p>
<p>Machine learning systems depart significantly from this traditional paradigm. Traditional systems execute explicit programming logic while machine learning systems derive behavior from data patterns. This shift from code to data as the primary behavior driver introduces new complexities. The specialized development workflows needed to manage these data-driven systems are explored in <strong><a href="../core/workflow/workflow.html#sec-ai-workflow">Chapter 19: AI Workflow</a></strong>.</p>
<p><a href="#fig-ml_lifecycle_overview" class="quarto-xref">Figure&nbsp;4</a> illustrates the ML lifecycle’s interconnected stages from data collection through model monitoring, with feedback loops for continuous improvement when performance degrades or models require enhancement.</p>
<div id="fig-ml_lifecycle_overview" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml_lifecycle_overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="7fe5c375ca4b6b91e493a3bcd4ce3a3debb9bfc1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: ML System Lifecycle: Continuous iteration defines successful machine learning systems, requiring feedback loops to refine models and address performance degradation across data collection, model training, evaluation, and deployment. This cyclical process contrasts with traditional software development and emphasizes the importance of ongoing monitoring and adaptation to maintain system reliability and accuracy in dynamic environments."><img src="introduction_files/mediabag/7fe5c375ca4b6b91e493a3bcd4ce3a3debb9bfc1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml_lifecycle_overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>ML System Lifecycle</strong>: Continuous iteration defines successful machine learning systems, requiring feedback loops to refine models and address performance degradation across data collection, model training, evaluation, and deployment. This cyclical process contrasts with traditional software development and emphasizes the importance of ongoing monitoring and adaptation to maintain system reliability and accuracy in dynamic environments.
</figcaption>
</figure>
</div>
<p>Unlike source code changing only through developer modifications, data reflects real-world dynamics. Data distribution changes can silently alter system behavior. Traditional software engineering tools designed for deterministic code-based systems prove insufficient for managing data-dependent systems. Version control systems excelling at tracking discrete code changes struggle with large, evolving datasets. Testing frameworks designed for deterministic outputs require adaptation for probabilistic predictions. The specialized data engineering practices needed to address these challenges are covered in <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>, while operational approaches for monitoring data-dependent systems are explored in <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>. This data-dependent nature creates dynamic lifecycles requiring continuous monitoring and adaptation to maintain system relevance as real-world data patterns evolve.</p>
<p>Understanding the machine learning system lifecycle requires examining distinct stages. Each stage presents unique requirements from learning and infrastructure perspectives. This dual consideration of learning needs and systems support is critical for building effective machine learning systems.</p>
<p>ML lifecycle stages in production are deeply interconnected rather than isolated. This interconnectedness creates virtuous or vicious cycles. In virtuous cycles, high-quality data enables effective learning, robust infrastructure supports efficient processing, and well-engineered systems facilitate better data collection. In vicious cycles, poor data quality undermines learning, inadequate infrastructure hampers processing, and system limitations prevent data collection improvements, with each problem compounding others.</p>
<div id="quiz-question-sec-introduction-lifecycle-ml-systems-6194" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.5</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes a key difference between traditional software systems and machine learning systems?</p>
<ol type="a">
<li>Traditional systems are more data-dependent than ML systems.</li>
<li>Traditional systems do not require version control, while ML systems do.</li>
<li>ML systems have a static lifecycle, unlike traditional systems.</li>
<li>Traditional systems rely on explicit programming logic, while ML systems derive behavior from data patterns.</li>
</ol></li>
<li><p>True or False: The lifecycle of machine learning systems is more dynamic and requires continuous monitoring compared to traditional software systems.</p></li>
<li><p>How does the shift from code-driven to data-driven behavior in ML systems impact the lifecycle management of these systems?</p></li>
<li><p>In a production ML system, what is a potential consequence of failing to monitor data distribution changes?</p>
<ol type="a">
<li>Improved model accuracy</li>
<li>Decreased system performance</li>
<li>Increased system reliability</li>
<li>Reduced need for model retraining</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-lifecycle-ml-systems-6194" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ml-systems-wild-8f2f" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ml-systems-wild-8f2f">ML Systems in the Wild</h2>
<p>The interconnected nature of ML lifecycle stages becomes even more apparent when considering the broad spectrum of real-world deployments. Managing machine learning systems’ complexity varies dramatically across different environments. ML systems exist at vastly different scales and in diverse environments, each presenting unique challenges and constraints.</p>
<p>At one spectrum end, cloud-based ML systems run in massive data centers<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a>. These systems, including large language models and recommendation engines, process petabytes of data while serving millions of users simultaneously. They leverage virtually unlimited computing resources but manage enormous operational complexity and costs. The architectural approaches for building such large-scale systems are covered in <strong><a href="../core/ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong> and <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>.</p>
<div class="no-row-height column-margin column-container"><div id="fn32"><p><sup>32</sup>&nbsp;<strong>Data Centers</strong>: Massive facilities housing thousands of servers, often consuming 100-300 megawatts of power, equivalent to a small city. Google operates over 20 data centers globally, each one costing $1-2 billion to build. These facilities maintain temperatures of exactly 80°F (27°C) with backup power systems that can run for days, enabling the reliable operation of AI services used by billions of people worldwide.</p></div><div id="fn33"><p><sup>33</sup>&nbsp;<strong>Microcontrollers</strong>: Tiny computers-on-a-chip costing under $1 each, with just kilobytes of memory, about 1/millionth the memory of a smartphone. Popular chips like the Arduino Uno have only 32KB of storage and 2KB of RAM, yet can run simple AI models that classify sensor data, recognize voice commands, or detect movement patterns while consuming less power than a digital watch.</p></div></div><p>At the other end, TinyML systems run on microcontrollers<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a> and embedded devices, performing ML tasks with severe memory, computing power, and energy consumption constraints. Smart home devices like Alexa or Google Assistant must recognize voice commands using less power than LED bulbs, while sensors must detect anomalies on battery power for months or years. The specialized techniques for deploying ML on such constrained devices are explored in <strong><a href="../core/efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 10: Efficient AI</a></strong> and <strong><a href="../core/optimizations/optimizations.html#sec-model-optimizations">Chapter 11: Model Optimizations</a></strong>, while the unique challenges of embedded ML systems are covered in <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong>.</p>
<p>Between these extremes lies a rich variety of ML systems adapted for different contexts. Edge ML systems bring computation closer to data sources, reducing latency<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a> and bandwidth requirements while managing local computing resources. Mobile ML systems must balance sophisticated capabilities with severe constraints: modern smartphones typically have 4-12GB RAM, ARM processors operating at 1.5-3 GHz, and power budgets of 2-5 watts that must be shared across all system functions. For example, running a state-of-the-art image classification model on a smartphone might consume 100-500mW and complete inference in 10-100ms, compared to cloud servers that can use 200+ watts but deliver results in under 1ms. Enterprise ML systems often operate within specific business constraints, focusing on particular tasks while integrating with existing infrastructure. Some organizations employ hybrid approaches, distributing ML capabilities across multiple tiers to balance various requirements.</p>
<div class="no-row-height column-margin column-container"><div id="fn34"><p><sup>34</sup>&nbsp;<strong>Latency</strong>: The time delay between when a request is made and when a response is received. In ML systems, this is critical: autonomous vehicles need &lt;10ms latency for safety decisions, while voice assistants target &lt;100ms for natural conversation. For comparison, sending data to a distant cloud server typically adds 50-100ms, which is why edge computing became essential for real-time AI applications.</p></div></div><div id="quiz-question-sec-introduction-ml-systems-wild-8f2f" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.6</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes a TinyML system?</p>
<ol type="a">
<li>A system that processes petabytes of data in cloud data centers.</li>
<li>A system that balances computing resources across multiple tiers.</li>
<li>A system that runs on microcontrollers with limited computing power.</li>
<li>A system that operates within specific business constraints.</li>
</ol></li>
<li><p>Explain the trade-offs involved in deploying ML systems on the edge compared to cloud-based systems.</p></li>
<li><p>True or False: Mobile ML systems prioritize sophisticated capabilities over battery life.</p></li>
<li><p>In a production system, ____, such as Alexa or Google Assistant, must recognize voice commands using less power than LED bulbs.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ml-systems-wild-8f2f" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-ml-systems-impact-lifecycle-fb60" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-ml-systems-impact-lifecycle-fb60">ML Systems Impact on Lifecycle</h2>
<p>Having surveyed this diverse landscape of ML deployments, we can now examine how this spectrum of systems represents a complex interplay of requirements, constraints, and trade-offs. These decisions significantly impact every stage of the ML lifecycle we discussed earlier, from data collection to continuous operation.</p>
<p>Performance requirements often drive initial architectural decisions. Latency-sensitive applications, like autonomous vehicles or real-time fraud detection, might require edge or embedded architectures despite their resource constraints. Conversely, applications requiring massive computational power for training, such as large language models, naturally gravitate toward centralized cloud architectures. However, raw performance is just one consideration in a complex decision space.</p>
<p>Resource management varies dramatically across architectures. Cloud systems must optimize for cost efficiency at scale, balancing expensive GPU clusters, storage systems, and network bandwidth. Edge systems face fixed resource limits and must carefully manage local compute and storage. Mobile and embedded systems operate under the strictest constraints, where every byte of memory and milliwatt of power matters. These resource considerations directly influence both model design and system architecture.</p>
<p>Operational complexity increases with system distribution. While centralized cloud architectures benefit from mature deployment tools and managed services, edge and hybrid systems must handle the complexity of distributed system management<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a>. This complexity manifests throughout the ML lifecycle, from data collection and version control to model deployment and monitoring. This operational complexity can compound over time if not carefully managed. The systematic approaches to operational excellence, including incident response and debugging methodologies for production ML systems, are thoroughly addressed in <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>.</p>
<div class="no-row-height column-margin column-container"><div id="fn35"><p><sup>35</sup>&nbsp;<strong>Distributed Systems</strong>: Computing systems where components located on networked computers communicate and coordinate their actions. In ML, this might mean training a single model across 1,000+ GPUs in different server racks, or deploying models across thousands of edge devices globally. The complexity comes from handling network failures, coordinating updates, ensuring data consistency, and managing the “Two Generals’ Problem”: confirming that all parts of the system agree on the current state.</p></div></div><p>Data considerations often introduce competing pressures. Privacy requirements or data sovereignty regulations might push toward edge or embedded architectures, while the need for large-scale training data might favor cloud approaches. The velocity and volume of data also influence architectural choices: real-time sensor data might require edge processing to manage bandwidth, while batch analytics might be better suited to cloud processing.</p>
<p>Evolution and maintenance requirements must be considered from the start. Cloud architectures offer flexibility for system evolution but can incur significant ongoing costs. Edge and embedded systems might be harder to update but could offer lower operational overhead. The continuous cycle of ML systems we discussed earlier becomes particularly challenging in distributed architectures, where updating models and maintaining system health requires careful orchestration across multiple tiers.</p>
<p>These trade-offs are rarely simple binary choices. Modern ML systems often adopt hybrid approaches, carefully balancing these considerations based on specific use cases and constraints. The key is understanding how these decisions will impact the system throughout its lifecycle, from initial development through continuous operation and evolution.</p>
<section id="sec-introduction-emerging-trends-e527" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-emerging-trends-e527">Emerging Trends</h3>
<p>While the three-component framework and deployment spectrum provide stable conceptual foundations for ML systems engineering, the field continues to evolve rapidly. Understanding current trends becomes important not just for staying current, but for anticipating how the core challenges and trade-offs we’ve discussed will manifest in future systems. These emerging developments represent new approaches to the persistent challenges of managing data, algorithms, and infrastructure at scale.</p>
<p>The landscape of machine learning systems is evolving rapidly, with innovations happening from user-facing applications down to core infrastructure. These changes are reshaping how we design and deploy ML systems.</p>
<section id="sec-introduction-applicationlevel-innovation-e97b" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-applicationlevel-innovation-e97b">Application-Level Innovation</h4>
<p>The rise of agentic systems marks a profound shift from traditional reactive ML systems that simply made predictions based on input data. Modern applications can now take actions, learn from outcomes, and adapt their behavior accordingly through multi-agent systems<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a> and advanced planning algorithms. These autonomous agents can plan, reason, and execute complex tasks, introducing new requirements for decision-making frameworks and safety constraints.</p>
<div class="no-row-height column-margin column-container"><div id="fn36"><p><sup>36</sup>&nbsp;<strong>Multi-Agent System</strong>: A computational system where multiple intelligent agents interact within an environment, each pursuing their own objectives while potentially cooperating or competing with other agents.</p></div></div><p>This increased sophistication extends to operational intelligence. Applications will likely incorporate sophisticated self-monitoring, automated resource management, and adaptive deployment strategies. They can automatically handle data distribution shifts, model updates, and system optimization, marking a significant advance in autonomous operation.</p>
</section>
<section id="sec-introduction-system-architecture-evolution-c8cc" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-system-architecture-evolution-c8cc">System Architecture Evolution</h4>
<p>Supporting these advanced applications requires significant changes in the underlying system architecture. Integration frameworks are evolving to handle increasingly complex interactions between ML systems and broader technology ecosystems. Modern ML systems must seamlessly connect with existing software, process diverse data sources, and operate across organizational boundaries, driving new approaches to system design.</p>
<p>Resource efficiency has become a central architectural concern as ML systems scale. Innovation in model compression and efficient training techniques is being driven by both environmental and economic factors. Future architectures must carefully balance the pursuit of more powerful models against growing sustainability concerns.</p>
<p>At the infrastructure level, new hardware is reshaping deployment possibilities. Specialized AI accelerators are emerging across the spectrum, from powerful data center chips to efficient edge processors<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a> to tiny neural processing units in mobile devices. This heterogeneous computing landscape enables dynamic model distribution across tiers based on computing capabilities and conditions, blurring traditional boundaries between cloud, edge, and embedded systems.</p>
<div class="no-row-height column-margin column-container"><div id="fn37"><p><sup>37</sup>&nbsp;<strong>Edge Processor</strong>: A specialized computing device designed to perform AI computations close to where data is generated, optimized for low latency and energy efficiency rather than raw computing power.</p></div></div><p>These trends are creating ML systems that are more capable and efficient while managing increasing complexity. Success in this evolving landscape requires understanding how application requirements flow down to infrastructure decisions, ensuring systems can grow sustainably while delivering increasingly sophisticated capabilities.</p>
<div id="quiz-question-sec-introduction-ml-systems-impact-lifecycle-fb60" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.7</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes a key trade-off when choosing between edge and cloud architectures for ML systems?</p>
<ol type="a">
<li>Edge architectures offer unlimited computational power compared to cloud.</li>
<li>Cloud architectures inherently provide better latency than edge systems.</li>
<li>Cloud architectures are always more cost-effective than edge systems.</li>
<li>Edge architectures prioritize low latency and data privacy, while cloud architectures focus on computational power and scalability.</li>
</ol></li>
<li><p>Explain how operational complexity increases in distributed ML systems compared to centralized cloud architectures.</p></li>
<li><p>In ML systems, the need for real-time sensor data processing often requires ____ architectures to manage bandwidth efficiently.</p></li>
<li><p>What is a primary consideration when designing ML systems for mobile and embedded environments?</p>
<ol type="a">
<li>Maximizing computational power at any cost.</li>
<li>Ensuring the system can handle large-scale data processing.</li>
<li>Minimizing power consumption and optimizing resource usage.</li>
<li>Prioritizing complex model architectures over simplicity.</li>
</ol></li>
<li><p>In a production system, how might you balance the trade-offs between computational power and operational costs when choosing an architecture?</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-ml-systems-impact-lifecycle-fb60" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-introduction-practical-applications-0728" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-practical-applications-0728">Practical Applications</h2>
<p>Having established the three-component framework for understanding ML systems (data, algorithms, and infrastructure), we can now examine how these components interact in practice. The theoretical model becomes most meaningful when we see how real-world applications navigate the complex interdependencies between these elements and the trade-offs that emerge at different scales of deployment.</p>
<p>To illustrate these dynamics, we’ll examine three carefully selected case studies that span the deployment spectrum we discussed earlier. These examples were chosen because they represent significantly different approaches to managing the data-algorithm-infrastructure triangle, each optimized for distinct operating environments and constraints. <strong>FarmBeats</strong> demonstrates edge-focused ML systems where connectivity limitations and power constraints drive infrastructure decisions, which in turn shape both algorithmic choices and data collection strategies. <strong>AlphaFold</strong> exemplifies large-scale scientific computing where algorithmic sophistication demands massive computational resources and carefully curated datasets. <strong>Waymo</strong> represents hybrid edge-cloud systems where safety requirements drive the complex coordination between real-time edge processing and cloud-based learning.</p>
<p>As you examine each case study, notice how the three components evolve together rather than independently. Infrastructure constraints don’t just limit algorithmic complexity, they significantly reshape what kinds of algorithms become viable. Data availability doesn’t just feed existing algorithms, it influences the entire system architecture, from edge processing decisions to cloud storage strategies. Algorithmic requirements don’t exist in isolation, they determine infrastructure needs and data collection approaches.</p>
<p>This interdependence helps explain why ML systems engineering has emerged as a distinct discipline. Each case study reveals different aspects of this systems thinking: how practical constraints drive architectural decisions, how scale changes the nature of engineering challenges, and how the three components must be optimized together rather than separately.</p>
<section id="sec-introduction-farmbeats-ml-agriculture-1ec9" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-farmbeats-ml-agriculture-1ec9">FarmBeats: ML in Agriculture</h3>
<p><a href="https://www.microsoft.com/en-us/research/project/farmbeats-iot-agriculture/">FarmBeats</a>, a project developed by Microsoft Research shown in <a href="#fig-farmbeats-overview" class="quarto-xref">Figure&nbsp;5</a>, is a significant advancement in the application of machine learning to agriculture. This system aims to increase farm productivity and reduce costs by leveraging AI and IoT technologies. FarmBeats exemplifies how edge and embedded ML systems can be deployed in challenging, real-world environments to solve practical problems. By bringing ML capabilities directly to the farm, FarmBeats demonstrates the potential of distributed AI systems in transforming traditional industries.</p>
<div id="fig-farmbeats-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-farmbeats-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./images/png/farmbeats.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Edge-Based Agricultural System: FarmBeats leverages IoT devices and edge computing to collect and process real-time data on soil conditions, microclimate, and plant health, enabling data-driven decision-making for optimized resource allocation and increased crop yields. This distributed architecture minimizes reliance on cloud connectivity, reducing latency and improving responsiveness in remote or bandwidth-constrained agricultural environments."><img src="./images/png/farmbeats.png" class="img-fluid figure-img" style="width:95.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-farmbeats-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>Edge-Based Agricultural System</strong>: FarmBeats leverages IoT devices and edge computing to collect and process real-time data on soil conditions, microclimate, and plant health, enabling data-driven decision-making for optimized resource allocation and increased crop yields. This distributed architecture minimizes reliance on cloud connectivity, reducing latency and improving responsiveness in remote or bandwidth-constrained agricultural environments.
</figcaption>
</figure>
</div>
<section id="sec-introduction-data-considerations-0dfa" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-data-considerations-0dfa">Data Considerations</h4>
<p>The data ecosystem in FarmBeats is diverse and distributed. Sensors deployed across fields collect real-time data on soil moisture, temperature, and nutrient levels. Drones equipped with multispectral cameras capture high-resolution imagery of crops, providing insights into plant health and growth patterns. Weather stations contribute local climate data, while historical farming records offer context for long-term trends. The challenge lies not just in collecting this heterogeneous data, but in managing its flow from dispersed, often remote locations with limited connectivity. FarmBeats employs innovative data transmission techniques, such as using TV white spaces (unused broadcasting frequencies) to extend internet connectivity to far-flung sensors. This approach to data collection and transmission embodies the principles of edge computing we discussed earlier, where data processing begins at the source to reduce bandwidth requirements and enable real-time decision making. The systematic approaches to managing such distributed data pipelines are covered in <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>.</p>
</section>
<section id="sec-introduction-algorithmic-considerations-d292" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-algorithmic-considerations-d292">Algorithmic Considerations</h4>
<p>FarmBeats uses a variety of ML algorithms tailored to agricultural applications. For soil moisture prediction, it uses temporal neural networks that can capture the complex dynamics of water movement in soil. Image analysis algorithms process drone imagery to detect crop stress, pest infestations, and yield estimates. These models must be robust to noisy data and capable of operating with limited computational resources. Machine learning methods such as transfer learning<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a> allow models to learn on data-rich farms to be adapted for use in areas with limited historical data. The training techniques that enable such adaptation, including transfer learning and domain adaptation, are explored in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>.</p>
<div class="no-row-height column-margin column-container"><div id="fn38"><p><sup>38</sup>&nbsp;<strong>Transfer Learning</strong>: A machine learning technique where a model developed for one task is reused as the starting point for a model on a related task, significantly reducing the amount of training data and computation required. This approach is particularly valuable in domains like agriculture where labeled data may be scarce.</p></div></div></section>
<section id="sec-introduction-infrastructure-considerations-346b" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-infrastructure-considerations-346b">Infrastructure Considerations</h4>
<p>FarmBeats exemplifies the edge computing paradigm we explored in our discussion of the ML system spectrum. At the lowest level, embedded ML models run directly on IoT devices and sensors, performing basic data filtering and anomaly detection. Edge devices, such as ruggedized field gateways, aggregate data from multiple sensors and run more complex models for local decision-making. These edge devices operate in challenging conditions, requiring robust hardware designs and efficient power management to function reliably in remote agricultural settings. The system employs a hierarchical architecture, with more computationally intensive tasks offloaded to on-premises servers or the cloud. This tiered approach allows FarmBeats to balance the need for real-time processing with the benefits of centralized data analysis and model training. The infrastructure also includes mechanisms for over-the-air model updates, ensuring that edge devices can receive improved models as more data becomes available and algorithms are refined. The operational practices for managing such distributed model updates are covered in <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong> and <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong>.</p>
</section>
<section id="sec-introduction-future-implications-8871" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-future-implications-8871">Future Implications</h4>
<p>FarmBeats shows how ML systems can be deployed in resource-constrained, real-world environments to drive significant improvements in traditional industries. By providing farmers with AI-driven insights, the system has shown potential to increase crop yields, reduce water usage, and optimize resource allocation. Looking forward, the FarmBeats approach could be extended to address global challenges in food security and sustainable agriculture. The success of this system also highlights the growing importance of edge and embedded ML in IoT applications, where bringing intelligence closer to the data source can lead to more responsive, efficient, and scalable solutions. As edge computing capabilities advance, similar distributed ML architectures will likely expand to other domains, from smart cities to environmental monitoring.</p>
<p>However, deployment challenges reveal how system components must be carefully balanced. Rural connectivity issues require algorithmic compromises (local buffering, simpler models), while harsh conditions affecting sensor reliability demand robust data validation, demonstrating the infrastructure-algorithm-data interdependencies discussed earlier.</p>
<p>While FarmBeats demonstrates how resource constraints at the edge drive ML system design, our next case study explores the opposite extreme of the deployment spectrum. Where FarmBeats must operate with limited connectivity and power constraints that favor simpler algorithms and local processing, scientific applications like protein folding can leverage virtually unlimited computational resources to tackle problems that would be impossible with constrained architectures. This contrast illuminates how the three-component framework manifests differently across the deployment spectrum. The same principles apply, but the trade-offs and optimization priorities shift dramatically.</p>
</section>
</section>
<section id="sec-introduction-alphafold-scientific-ml-d3fd" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-alphafold-scientific-ml-d3fd">AlphaFold: Scientific ML</h3>
<p><a href="https://deepmind.google/technologies/alphafold/">AlphaFold</a> <span class="citation" data-cites="jumper2021highly">(<a href="#ref-jumper2021highly" role="doc-biblioref">Jumper et al. 2021</a>)</span>, developed by DeepMind, is a landmark achievement in the application of machine learning to complex scientific problems. This AI system is designed to predict the three-dimensional structure of proteins, as shown in <a href="#fig-alphafold-overview" class="quarto-xref">Figure&nbsp;6</a>, from their amino acid sequences, a challenge known as the “protein folding problem” that has puzzled scientists for decades. AlphaFold’s success demonstrates how large-scale ML systems can accelerate scientific discovery and potentially revolutionize fields like structural biology and drug design. This case study exemplifies the use of advanced ML techniques and massive computational resources to tackle problems at the frontiers of science.</p>
<div class="no-row-height column-margin column-container"><div id="ref-jumper2021highly" class="csl-entry" role="listitem">
Jumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. <span>“Highly Accurate Protein Structure Prediction with AlphaFold.”</span> <em>Nature</em> 596 (7873): 583–89. <a href="https://doi.org/10.1038/s41586-021-03819-2">https://doi.org/10.1038/s41586-021-03819-2</a>.
</div></div><div id="fig-alphafold-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alphafold-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/gif/alphafold.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: AlphaFold: Protein targets that AlphaFold can predict solely from amino acid sequences, showcasing its prowess in tackling the protein folding problem."><img src="images/gif/alphafold.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alphafold-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>AlphaFold</strong>: Protein targets that AlphaFold can predict solely from amino acid sequences, showcasing its prowess in tackling the protein folding problem.
</figcaption>
</figure>
</div>
<section id="sec-introduction-data-considerations-e519" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-data-considerations-e519">Data Considerations</h4>
<p>The data underpinning AlphaFold’s success is vast and multifaceted. The primary dataset is the Protein Data Bank (PDB), which contains the experimentally determined structures of over 180,000 proteins. This is complemented by databases of protein sequences, which number in the hundreds of millions. AlphaFold also utilizes evolutionary data in the form of multiple sequence alignments (MSAs), which provide insights into the conservation patterns of amino acids across related proteins. The challenge lies not just in the volume of data, but in its quality and representation. Experimental protein structures can contain errors or be incomplete, requiring sophisticated data cleaning and validation processes. The representation of protein structures and sequences in a form amenable to machine learning is a significant challenge in itself. AlphaFold’s data pipeline involves complex preprocessing steps to convert raw sequence and structural data into meaningful features that capture the physical and chemical properties relevant to protein folding.</p>
</section>
<section id="sec-introduction-algorithmic-considerations-c152" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-algorithmic-considerations-c152">Algorithmic Considerations</h4>
<p>AlphaFold’s algorithmic approach represents a tour de force in the application of deep learning to scientific problems. At its core, AlphaFold uses a novel neural network architecture that combines with techniques from computational biology. The model learns to predict how protein components relate to each other in 3D space, using advanced neural network techniques specifically designed for scientific data. The learning process involves multiple stages, including initial “pretraining” on a large corpus of protein sequences, followed by fine-tuning on known structures. AlphaFold also incorporates domain knowledge in the form of physics-based constraints and scoring functions, creating a hybrid system that leverages both data-driven learning and scientific prior knowledge. The model’s ability to generate accurate confidence estimates for its predictions is crucial, allowing researchers to assess the reliability of the predicted structures.</p>
</section>
<section id="sec-introduction-infrastructure-considerations-fcd1" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-infrastructure-considerations-fcd1">Infrastructure Considerations</h4>
<p>The computational demands of AlphaFold epitomize the challenges of large-scale scientific ML systems. Training the model requires massive parallel computing resources, leveraging clusters of GPUs or specialized AI chips (TPUs)<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a> in a distributed computing environment. DeepMind utilized Google’s cloud infrastructure, with the final version of AlphaFold trained on 128 TPUv3 cores for several weeks. Such large-scale training requires sophisticated distributed systems and specialized hardware that represent the cutting edge of AI engineering.</p>
<div class="no-row-height column-margin column-container"><div id="fn39"><p><sup>39</sup>&nbsp;<strong>Tensor Processing Unit (TPU)</strong>: A specialized AI accelerator chip designed by Google specifically for neural network machine learning, particularly efficient at matrix operations common in deep learning workloads.</p></div></div></section>
<section id="sec-introduction-future-implications-b549" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-future-implications-b549">Future Implications</h4>
<p>AlphaFold’s impact on structural biology has been profound, with the potential to accelerate research in areas ranging from fundamental biology to drug discovery. By providing accurate structural predictions for proteins that have resisted experimental methods, AlphaFold opens new avenues for understanding disease mechanisms and designing targeted therapies. The success of AlphaFold also serves as a powerful demonstration of how ML can be applied to other complex scientific problems, potentially leading to breakthroughs in fields like materials science or climate modeling. However, it also raises important questions about the role of AI in scientific discovery and the changing nature of scientific inquiry in the age of large-scale ML systems. The AlphaFold approach suggests a new paradigm for scientific ML, where massive computational resources combine with domain-specific knowledge to push the boundaries of human understanding.</p>
<p>Yet this paradigm shift also illustrates the infrastructure-algorithm trade-offs central to ML systems engineering. The massive computational requirements (over $100,000 in training costs) demonstrate how algorithmic sophistication demands proportional infrastructure investment. The system’s data dependencies reveal another core ML systems principle: model performance degrades when deployment data differs from training data, as seen with understudied protein families. This exemplifies why successful ML systems require coordinated optimization across all three components, not just algorithmic advancement.</p>
<p>Our final case study bridges the resource extremes we’ve seen in FarmBeats and AlphaFold, demonstrating the most complex variant of ML systems architecture: hybrid edge-cloud systems that must satisfy both computational and latency constraints simultaneously. While AlphaFold can afford extended training times and inference delays measured in hours, and FarmBeats can accept simplified algorithms due to non-critical timing requirements, autonomous vehicles face the challenge of requiring both sophisticated algorithms and real-time decision-making. This creates a unique architectural challenge where some computation must happen locally for safety and latency reasons, while other aspects benefit from cloud-scale resources for continuous learning and improvement.</p>
</section>
</section>
<section id="sec-introduction-autonomous-vehicles-2910" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-autonomous-vehicles-2910">Autonomous Vehicles</h3>
<p><a href="https://waymo.com/">Waymo</a>, a subsidiary of Alphabet Inc., stands at the forefront of autonomous vehicle technology, representing one of the most ambitious applications of machine learning systems to date. Evolving from the Google Self-Driving Car Project initiated in 2009, Waymo’s approach to autonomous driving exemplifies how ML systems can span the entire spectrum from embedded systems to cloud infrastructure. This case study demonstrates the practical implementation of complex ML systems in a safety-critical, real-world environment, integrating real-time decision-making with long-term learning and adaptation.</p>
<section id="sec-introduction-data-considerations-8b4d" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-data-considerations-8b4d">Data Considerations</h4>
<p>The data ecosystem underpinning Waymo’s technology is vast and dynamic. Each vehicle serves as a roving data center, its sensor suite, which comprises LiDAR, radar, and high-resolution cameras, generating approximately one terabyte of data per hour of driving. This real-world data is complemented by an even more extensive simulated dataset, with Waymo’s vehicles having traversed over 20 billion miles in simulation and more than 20 million miles on public roads. The challenge lies not just in the volume of data, but in its heterogeneity and the need for real-time processing. Waymo must handle both structured (e.g., GPS coordinates) and unstructured data (e.g., camera images) simultaneously. The data pipeline spans from edge processing on the vehicle itself to massive cloud-based storage and processing systems. Sophisticated data cleaning and validation processes are necessary, given the safety-critical nature of the application. The representation of the vehicle’s environment in a form amenable to machine learning presents significant challenges, requiring complex preprocessing to convert raw sensor data into meaningful features that capture the dynamics of traffic scenarios.</p>
</section>
<section id="sec-introduction-algorithmic-considerations-a0ae" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="sec-introduction-algorithmic-considerations-a0ae">Algorithmic Considerations</h4>
<p>Waymo’s ML stack represents a sophisticated ensemble of algorithms tailored to the multifaceted challenge of autonomous driving. The perception system employs specialized neural networks to process visual data for object detection and tracking. Prediction models, needed for anticipating the behavior of other road users, use neural networks that can understand patterns over time<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a> in road user behavior. The architectural patterns for building such complex multi-model systems are explored in <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong> and <strong><a href="../core/frameworks/frameworks.html#sec-ai-frameworks">Chapter 5: AI Frameworks</a></strong>. Waymo has developed custom ML models like VectorNet for predicting vehicle trajectories. The planning and decision-making systems may incorporate learning-from-experience techniques to handle complex traffic scenarios.</p>
<div class="no-row-height column-margin column-container"><div id="fn40"><p><sup>40</sup>&nbsp;<strong>Sequential Neural Networks</strong>: Neural network architectures designed to process data that occurs in sequences over time, such as predicting where a pedestrian will move next based on their previous movements. These networks maintain a form of “memory” of previous inputs to inform current decisions.</p></div></div></section>
<section id="sec-introduction-infrastructure-considerations-3779" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-infrastructure-considerations-3779">Infrastructure Considerations</h4>
<p>The computing infrastructure supporting Waymo’s autonomous vehicles epitomizes the challenges of deploying ML systems across the full spectrum from edge to cloud. Each vehicle is equipped with a custom-designed compute platform capable of processing sensor data and making decisions in real-time, often leveraging specialized hardware like GPUs or tensor processing units (TPUs). This edge computing is complemented by extensive use of cloud infrastructure, leveraging the power of Google’s data centers for training models, running large-scale simulations, and performing fleet-wide learning. The specialized hardware architectures and edge-cloud coordination strategies that enable such systems are covered in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong> and <strong><a href="../core/ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong>. The connectivity between these tiers is critical, with vehicles requiring reliable, high-bandwidth communication for real-time updates and data uploading. Waymo’s infrastructure must be designed for robustness and fault tolerance, ensuring safe operation even in the face of hardware failures or network disruptions. The scale of Waymo’s operation presents significant challenges in data management, model deployment, and system monitoring across a geographically distributed fleet of vehicles.</p>
</section>
<section id="sec-introduction-future-implications-2934" class="level4">
<h4 class="anchored" data-anchor-id="sec-introduction-future-implications-2934">Future Implications</h4>
<p>Waymo’s impact extends beyond technological advancement, potentially revolutionizing transportation, urban planning, and numerous aspects of daily life. The launch of Waymo One, a commercial ride-hailing service using autonomous vehicles in Phoenix, Arizona, represents a significant milestone in the practical deployment of AI systems in safety-critical applications. Waymo’s progress has broader implications for the development of robust, real-world AI systems, driving innovations in sensor technology, edge computing, and AI safety that have applications far beyond the automotive industry. However, it also raises important questions about liability, ethics, and the interaction between AI systems and human society. As Waymo continues to expand its operations and explore applications in trucking and last-mile delivery, it serves as an important test bed for advanced ML systems, driving progress in areas such as continual learning, robust perception, and human-AI interaction. The Waymo case study underscores both the tremendous potential of ML systems to transform industries and the complex challenges involved in deploying AI in the real world.</p>
<div id="quiz-question-sec-introduction-practical-applications-0728" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.8</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the primary goal of the FarmBeats project?</p>
<ol type="a">
<li>To develop a cloud-based system for urban farming</li>
<li>To increase farm productivity and reduce costs using AI and IoT</li>
<li>To replace traditional farming methods with fully automated systems</li>
<li>To create a global database of agricultural data for research</li>
</ol></li>
<li><p>True or False: FarmBeats relies entirely on cloud connectivity for data processing and decision-making.</p></li>
<li><p>Explain how FarmBeats utilizes edge computing to address the challenges of data collection and processing in remote agricultural environments.</p></li>
<li><p>What is a key advantage of using TV white spaces in FarmBeats for data transmission?</p>
<ol type="a">
<li>It extends internet connectivity to remote sensors</li>
<li>It provides high-speed internet access similar to fiber optics</li>
<li>It eliminates the need for any physical sensors</li>
<li>It allows for real-time data processing in the cloud</li>
</ol></li>
<li><p>In what ways might the FarmBeats approach be applied to address global challenges in food security and sustainable agriculture?</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-practical-applications-0728" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-introduction-challenges-ml-systems-7167" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-introduction-challenges-ml-systems-7167">Challenges in ML Systems</h2>
<p>The pattern evident across our case studies (from FarmBeats’ rural connectivity issues to AlphaFold’s computational requirements to Waymo’s safety validation complexity) reflects deeper challenges inherent to building and deploying machine learning systems. Each case study illuminates different aspects of how the three-component framework creates interdependent challenges that distinguish ML engineering from traditional software development.</p>
<p>These challenges emerge precisely because data, algorithms, and infrastructure cannot be optimized independently. FarmBeats demonstrates how infrastructure constraints (limited connectivity, power restrictions) force data collection compromises (sensor reliability, transmission delays) that in turn require algorithmic adaptations (simpler models, local processing). AlphaFold shows how algorithmic sophistication (complex neural architectures) demands both infrastructure investment (massive compute clusters) and data quality assurance (curated protein databases). Waymo reveals how safety requirements create cascading constraints across all three components: real-time algorithmic decisions require edge infrastructure capabilities that must be supported by continuous data collection and cloud-based model updates.</p>
<p>The specific challenges revealed by FarmBeats, AlphaFold, and Waymo illustrate why creating effective ML systems requires simultaneous optimization of data, algorithms, and infrastructure.</p>
<section id="sec-introduction-datarelated-challenges-9e99" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-datarelated-challenges-9e99">Data-Related Challenges</h3>
<p>The foundation of any ML system is its data, and managing this data introduces several core challenges that manifest differently across our case studies. Data quality emerges as the primary concern: real-world data is often messy and inconsistent. FarmBeats illustrates this challenge vividly: environmental sensors in harsh agricultural conditions frequently produce unreliable readings due to weather damage, power fluctuations, or connectivity issues. AlphaFold faced similar quality challenges with experimental protein structures, where incomplete or error-containing data from crystallographic experiments required sophisticated validation and cleaning processes before use in training.</p>
<p>Scale represents another critical dimension of data challenges. AlphaFold demonstrates the extreme end of this spectrum, requiring training on hundreds of millions of protein sequences and structural data. Waymo generates approximately one terabyte of sensor data per hour per vehicle, creating enormous challenges in data storage, transmission, and processing across a distributed fleet. Even FarmBeats, seemingly simpler in scale, must handle diverse data streams from thousands of sensors across multiple farms, each with different connectivity patterns and data quality characteristics.</p>
<p>Perhaps the most insidious data challenge is drift, the gradual change in data patterns over time that can silently degrade model performance. This phenomenon, known as “data drift”<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a>, affects all three case studies differently. FarmBeats models must adapt to changing seasonal patterns, soil conditions, and climate variations. Waymo’s perception models encounter new traffic patterns, road configurations, and weather conditions that weren’t present in training data. Even AlphaFold, working with fundamental biological structures, faces challenges when applied to protein families that are evolutionarily distant from its training data.</p>
<div class="no-row-height column-margin column-container"><div id="fn41"><p><sup>41</sup>&nbsp;<strong>Data Drift</strong>: The gradual change in the statistical properties of the target variable (what the model is trying to predict) over time, which can degrade model performance if not properly monitored and addressed.</p></div></div><p>Training-serving skew represents one of the most difficult-to-debug production ML failures. Features computed differently between training and serving pipelines cause model performance to degrade despite unchanged code. For example, a training pipeline might compute average transaction amounts using all historical data, while the serving pipeline uses only recent data, creating systematic differences that can reduce model accuracy by 20-40% in production.</p>
</section>
<section id="sec-introduction-modelrelated-challenges-6c1a" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-modelrelated-challenges-6c1a">Model-Related Challenges</h3>
<p>Creating and maintaining the ML models themselves presents another set of challenges. Modern ML models, particularly in deep learning, can be extremely complex. Consider a language model like GPT-3, which has hundreds of billions of parameters that need to be optimized through training processes<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a>. This complexity creates practical challenges: these models require enormous computing power to train and run, making it difficult to deploy them in situations with limited resources, like on mobile phones or IoT devices.</p>
<div class="no-row-height column-margin column-container"><div id="fn42"><p><sup>42</sup>&nbsp;<strong>Backpropagation</strong>: The primary algorithm used to train neural networks, which calculates how each parameter in the network should be adjusted to minimize prediction errors by propagating error gradients backward through the network layers.</p></div><div id="fn43"><p><sup>43</sup>&nbsp;<strong>Transfer Learning</strong>: A machine learning method where a model developed for one task is reused as the starting point for a model on a second task, significantly reducing the amount of training data and computation required.</p></div></div><p>Training these models effectively is itself a significant challenge. Unlike traditional programming where we write explicit instructions, ML models learn from examples<a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a>. This learning process involves many choices: How should we structure the model? How long should we train it? How can we tell if it’s learning the right things? Making these decisions often requires both technical expertise and considerable trial and error. The systematic approaches to these training challenges are explored in detail in <strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>, while the frameworks that support efficient model development are covered in <strong><a href="../core/frameworks/frameworks.html#sec-ai-frameworks">Chapter 5: AI Frameworks</a></strong>.</p>
<p>A particularly important challenge is ensuring that models work well in real-world conditions. A model might perform excellently on its training data but fail when faced with slightly different situations in the real world. This gap between training performance and real-world performance is a central challenge in machine learning, especially for critical applications like autonomous vehicles or medical diagnosis systems.</p>
</section>
<section id="sec-introduction-systemrelated-challenges-fb4f" class="level3">
<h3 class="anchored" data-anchor-id="sec-introduction-systemrelated-challenges-fb4f">System-Related Challenges</h3>
<p>Getting ML systems to work reliably in the real world introduces its own set of challenges. Unlike traditional software that follows fixed rules, ML systems need to handle uncertainty and variability in their inputs and outputs. They also typically need both training systems (for learning from data) and serving systems (for making predictions), each with different requirements and constraints.</p>
<p>Consider a company building a speech recognition system. They need infrastructure to collect and store audio data, systems to train models on this data, and then separate systems to actually process users’ speech in real-time. Each part of this pipeline needs to work reliably and efficiently, and all the parts need to work together seamlessly. The engineering principles for building such robust data pipelines are covered comprehensively in <strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>, while the operational practices for maintaining these systems in production are explored in <strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>.</p>
<p>These systems also need constant monitoring and updating. How do we know if the system is working correctly? How do we update models without interrupting service? How do we handle errors or unexpected inputs? These operational challenges become particularly complex when ML systems are serving millions of users.</p>
</section>
<section id="sec-introduction-ethical-considerations-c579" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-introduction-ethical-considerations-c579">Ethical Considerations</h3>
<p>As ML systems become more prevalent in our daily lives, their broader impacts on society become increasingly important to consider. One major concern is fairness, as ML systems can sometimes learn to make decisions that discriminate against certain groups of people. This often happens unintentionally, as the systems pick up biases present in their training data. For example, a job application screening system might inadvertently learn to favor certain demographics if those groups were historically more likely to be hired.</p>
<p>Another important consideration is transparency. Many modern ML models, particularly deep learning models, work as “black boxes”<a href="#fn44" class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a>. While they can make predictions, it’s often difficult to understand how they arrived at their decisions.</p>
<div class="no-row-height column-margin column-container"><div id="fn44"><p><sup>44</sup>&nbsp;<strong>Black Box</strong>: A system where you can observe the inputs and outputs but cannot see or understand the internal workings, like how a radio receives signals and produces sound without most users understanding the electronics inside. In AI, this opacity becomes problematic when the system makes important decisions affecting people’s lives.</p></div></div><p>This becomes particularly problematic when ML systems are making important decisions about people’s lives, such as in healthcare or financial services.</p>
<p>Privacy is also a major concern. ML systems often need large amounts of data to work effectively, but this data might contain sensitive personal information. How do we balance the need for data with the need to protect individual privacy? How do we ensure that models don’t inadvertently memorize and reveal private information through inference attacks<a href="#fn45" class="footnote-ref" id="fnref45" role="doc-noteref"><sup>45</sup></a>? These challenges aren’t merely technical problems to be solved, but ongoing considerations that shape how we approach ML system design and deployment. The approaches for addressing these critical concerns are covered in <strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong>, <strong><a href="../core/privacy_security/privacy_security.html#sec-security-privacy">Chapter 15: Security & Privacy</a></strong>, and <strong><a href="../core/robust_ai/robust_ai.html#sec-robust-ai">Chapter 14: Robust AI</a></strong>.</p>
<div class="no-row-height column-margin column-container"><div id="fn45"><p><sup>45</sup>&nbsp;<strong>Inference Attack</strong>: A technique where an adversary attempts to extract sensitive information about the training data by making careful queries to a trained model, exploiting patterns the model may have inadvertently memorized during training.</p></div></div><p>This book examines these challenges in detail and presents strategies for addressing them effectively.</p>
<section id="silent-failures-the-hidden-danger" class="level4">
<h4 class="anchored" data-anchor-id="silent-failures-the-hidden-danger">Silent Failures: The Hidden Danger</h4>
<p>Perhaps the most insidious challenge in ML systems is their tendency to fail silently. Unlike traditional software that crashes visibly when broken, ML systems continue operating while their performance quietly degrades. A recommendation system might gradually decline from 85% accuracy to 60% over months without triggering any alerts, silently eroding user experience and business metrics. Similarly, a fraud detection model trained on features computed with 30-day lookback windows but served with 7-day windows due to latency constraints might see false positive rates double from 2% to 4%, causing significant customer friction without any obvious system failures. This degradation often manifests as subtle shifts in prediction quality that remain undetected until significant business impact has already occurred.</p>
<p>This silent failure mode helps explain why industry surveys suggest that a majority of ML models developed in research settings struggle to reach production deployment. Many promising models that perform well in development fail not due to algorithmic limitations, but because these gradual degradation patterns go unnoticed until business impact becomes severe. Production ML systems therefore require comprehensive monitoring across four dimensions: traditional infrastructure metrics (latency, throughput), model performance metrics (accuracy, precision, recall), input data quality metrics (distribution drift detection, schema validation), and business impact metrics (user engagement, revenue correlation). This multi-dimensional monitoring approach helps detect silent failures through early warning signals like data drift detection or prediction distribution monitoring before they cascade into critical business problems.</p>
<div id="quiz-question-sec-introduction-challenges-ml-systems-7167" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.9</strong></summary><div>
<ol type="1">
<li><p>Which of the following is a primary challenge when handling data in machine learning systems?</p>
<ol type="a">
<li>Ensuring the hardware is up-to-date</li>
<li>Implementing a user-friendly interface</li>
<li>Choosing the correct programming language</li>
<li>Maintaining data quality and consistency</li>
</ol></li>
<li><p>True or False: Data drift occurs when the statistical properties of the target variable change over time, potentially degrading model performance.</p></li>
<li><p>How might data drift affect an ML system deployed in a rapidly changing environment, such as during a global pandemic?</p></li>
<li><p>In ML systems, the phenomenon where new data patterns differ from those the system originally learned from is known as ____.</p></li>
<li><p>Consider a scenario where an ML system is used for personalized recommendations in a video streaming service. What challenges might arise as the system scales to handle billions of interactions?</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-challenges-ml-systems-7167" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
</section>
</section>
<section id="sec-introduction-looking-ahead-34a3" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-looking-ahead-34a3">Looking Ahead</h2>
<p>Several significant trends shape the future of machine learning systems. These developments promise to both solve existing challenges and open new possibilities for what ML systems can achieve.</p>
<p>One of the most significant trends is the democratization of AI technology. Just as personal computers transformed computing from specialized mainframes to everyday tools, ML systems are becoming more accessible to developers and organizations of all sizes. Cloud providers now offer pre-trained models and automated ML platforms that reduce the expertise needed to deploy AI solutions. This democratization enables new applications across industries, from small businesses implementing AI for customer service to researchers applying ML to previously intractable problems.</p>
<p>As concerns about computational costs and environmental impact grow, there’s an increasing focus on making ML systems more efficient. Researchers are developing new techniques for training models with less data and computing power. Innovation in specialized hardware, from improved GPUs to custom AI chips, is making ML systems faster and more energy-efficient. These efficiency considerations are explored in <strong><a href="../core/efficient_ai/efficient_ai.html#sec-efficient-ai">Chapter 10: Efficient AI</a></strong> and <strong><a href="../core/sustainable_ai/sustainable_ai.html#sec-sustainable-ai">Chapter 17: Sustainable AI</a></strong>, while the hardware innovations enabling more efficient AI are covered in <strong><a href="../core/hw_acceleration/hw_acceleration.html#sec-ai-acceleration">Chapter 9: AI Acceleration</a></strong>.</p>
<p>Perhaps the most transformative trend is the development of more autonomous ML systems that can adapt and improve themselves. These systems are beginning to handle their own maintenance tasks, such as detecting when they need retraining, automatically finding and correcting errors, and optimizing their own performance. This automation could dramatically reduce the operational overhead of running ML systems while improving their reliability. Such self-managing systems represent an emerging frontier that combines operational excellence with autonomous adaptation capabilities.</p>
<p>While these trends are promising, the field’s limitations require recognition. Creating truly artificial general intelligence remains a distant goal. Current ML systems excel at specific tasks but lack the flexibility and understanding that humans take for granted. Challenges around bias, transparency, and privacy continue to require careful consideration. As ML systems become more prevalent, addressing these limitations while leveraging new capabilities becomes essential. These fundamental challenges and emerging solutions receive detailed treatment in <strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong>, <strong><a href="../core/robust_ai/robust_ai.html#sec-robust-ai">Chapter 14: Robust AI</a></strong>, and <strong><a href="../core/frontiers/frontiers.html#sec-agi-systems">Chapter 21: AGI Systems</a></strong>.</p>
<div id="quiz-question-sec-introduction-looking-ahead-34a3" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.10</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the democratization of AI technology?</p>
<ol type="a">
<li>AI tools and platforms becoming accessible to a wider range of developers and organizations.</li>
<li>AI technology becoming exclusive to large tech companies.</li>
<li>The development of AI systems that require highly specialized expertise.</li>
<li>AI systems being used only in academic research settings.</li>
</ol></li>
<li><p>True or False: The development of more autonomous ML systems will likely reduce the operational overhead of running these systems.</p></li>
<li><p>How might the focus on efficiency in ML systems impact their environmental footprint?</p></li>
<li><p>In what way are specialized hardware developments contributing to the efficiency of ML systems?</p>
<ol type="a">
<li>By increasing the size and complexity of models.</li>
<li>By reducing the need for data preprocessing.</li>
<li>By making ML systems faster and more energy-efficient.</li>
<li>By automating the entire ML lifecycle.</li>
</ol></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-looking-ahead-34a3" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="sec-introduction-book-structure-learning-path-f3ea" class="level2">
<h2 class="anchored" data-anchor-id="sec-introduction-book-structure-learning-path-f3ea">Book Structure and Learning Path</h2>
<p>This book addresses the engineering challenges we’ve explored through a systematic framework organized around five fundamental disciplines that encompass the complete ML systems lifecycle. These disciplines reflect the core engineering capabilities required to bridge the gap between research prototypes and production systems capable of operating at scale.</p>
<p>Building on the three-component foundation, this book organizes ML systems engineering around five interconnected disciplines. As illustrated in <a href="#fig-pillars" class="quarto-xref">Figure&nbsp;7</a>, these five pillars are:</p>
<div id="fig-pillars" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pillars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/book_pillars.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: ML System Lifecycle: Machine learning systems engineering encompasses five interconnected disciplines that address the real-world challenges of building, deploying, and maintaining AI systems at scale. Each pillar represents critical engineering capabilities needed to bridge the gap between research prototypes and production systems."><img src="images/png/book_pillars.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pillars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: <strong>ML System Lifecycle</strong>: Machine learning systems engineering encompasses five interconnected disciplines that address the real-world challenges of building, deploying, and maintaining AI systems at scale. Each pillar represents critical engineering capabilities needed to bridge the gap between research prototypes and production systems.
</figcaption>
</figure>
</div>
<p>The five engineering disciplines illustrated in <a href="#fig-pillars" class="quarto-xref">Figure&nbsp;7</a> address the systematic challenges of ML systems development:</p>
<ul>
<li><p><strong>Data</strong> (<strong><a href="../core/data_engineering/data_engineering.html#sec-data-engineering">Chapter 8: Data Engineering</a></strong>): Engineering robust data pipelines that ensure quality, handle scale, and maintain privacy while providing the foundational infrastructure upon which all ML systems depend.</p></li>
<li><p><strong>Training</strong> (<strong><a href="../core/training/training.html#sec-ai-training">Chapter 6: AI Training</a></strong>): Developing efficient training systems that can manage large datasets and complex models while optimizing computational resource utilization across distributed environments.</p></li>
<li><p><strong>Deployment</strong> (<strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>, <strong><a href="../core/ondevice_learning/ondevice_learning.html#sec-ondevice-learning">Chapter 13: On-Device Learning</a></strong>): Building reliable deployment infrastructure that can serve models at scale, handle failures gracefully, and adapt to evolving requirements in production environments.</p></li>
<li><p><strong>Operations</strong> (<strong><a href="../core/ops/ops.html#sec-ml-operations">Chapter 12: ML Operations</a></strong>, <strong><a href="../core/benchmarking/benchmarking.html#sec-benchmarking-ai">Chapter 7: Benchmarking AI</a></strong>): Creating monitoring and maintenance systems that ensure continued performance, enable early issue detection, and support safe system updates in production.</p></li>
<li><p><strong>Ethics &amp; Governance</strong> (<strong><a href="../core/responsible_ai/responsible_ai.html#sec-responsible-ai">Chapter 16: Responsible AI</a></strong>, <strong><a href="../core/privacy_security/privacy_security.html#sec-security-privacy">Chapter 15: Security & Privacy</a></strong>, <strong><a href="../core/sustainable_ai/sustainable_ai.html#sec-sustainable-ai">Chapter 17: Sustainable AI</a></strong>): Implementing responsible AI practices that address bias, ensure transparency, and protect user privacy throughout the system lifecycle.</p></li>
</ul>
<p>Each pillar represents a critical phase in the lifecycle of ML systems and is composed of foundational elements that build upon each other. This structure ensures a comprehensive understanding of MLSE, from basic principles to advanced applications and ethical considerations.</p>
<p>For more detailed information about the book’s overview, contents, learning outcomes, target audience, prerequisites, and navigation guide (including how to use the cross-reference system that connects topics throughout the book), please refer to the <a href="../../../contents/frontmatter/about/about.html">About the Book</a> section. There, you’ll also find valuable details about our learning community and how to maximize your experience with this resource.</p>
<p>The chapters that follow build systematically on these foundations: <strong><a href="../core/ml_systems/ml_systems.html#sec-ml-systems">Chapter 2: ML Systems</a></strong> explores the architectural principles for different ML deployment scenarios, <strong><a href="../core/dl_primer/dl_primer.html#sec-dl-primer">Chapter 3: Deep Learning Primer</a></strong> and <strong><a href="../core/dnn_architectures/dnn_architectures.html#sec-dnn-architectures">Chapter 4: DNN Architectures</a></strong> provide the algorithmic foundations, while the subsequent sections cover each pillar of the ML systems engineering discipline in detail.</p>


<div id="quiz-question-sec-introduction-book-structure-learning-path-f3ea" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton"><summary><strong>Self-Check: Question 1.11</strong></summary><div>
<ol type="1">
<li><p>Which of the following pillars focuses on the methodologies for AI training, including efficiency and optimization techniques?</p>
<ol type="a">
<li>Data</li>
<li>Operations</li>
<li>Deployment</li>
<li>Training</li>
</ol></li>
<li><p>Explain why the ‘Ethics &amp; Governance’ pillar is crucial in the lifecycle of ML systems.</p></li>
<li><p>Order the following ML system lifecycle pillars as they typically occur: (1) Deployment, (2) Data, (3) Operations, (4) Training.</p></li>
</ol>
<p><a href="#quiz-answer-sec-introduction-book-structure-learning-path-f3ea" class="question-label">See Answers →</a></p>
</div></details>
</div>
</section>
<section id="self-check-answers" class="level2">
<h2 class="anchored" data-anchor-id="self-check-answers">Self-Check Answers</h2>
<div id="quiz-answer-sec-introduction-ai-pervasiveness-8891" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.1</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the role of AI in modern society?</strong></p>
<ol type="a">
<li>AI is primarily used for entertainment purposes.</li>
<li>AI is primarily focused on replacing human jobs.</li>
<li>AI is an emerging technology with limited current applications.</li>
<li>AI is a transformative force impacting multiple domains, including healthcare, transportation, and scientific research.</li>
</ol>
<p><em>Answer</em>: The correct answer is D. AI is a transformative force impacting multiple domains, including healthcare, transportation, and scientific research. This is correct because AI systems are integrated into various sectors, enhancing capabilities and solving complex problems.</p>
<p><em>Learning Objective</em>: Understand the broad impact of AI across different sectors.</p></li>
<li><p><strong>True or False: The AI Revolution is progressing at the same pace as the Industrial Revolution.</strong></p>
<p><em>Answer</em>: False. The AI Revolution is progressing at an unprecedented pace compared to the Industrial Revolution, which unfolded over centuries.</p>
<p><em>Learning Objective</em>: Recognize the rapid pace of AI development compared to historical technological revolutions.</p></li>
<li><p><strong>How does the AI Revolution compare to the Digital Revolution in terms of societal impact?</strong></p>
<p><em>Answer</em>: The AI Revolution, like the Digital Revolution, is fundamentally transforming society by altering how we interact with technology and solve complex problems. However, AI’s impact is more pervasive, influencing diverse fields such as healthcare, transportation, and climate change solutions. This is important because it highlights AI’s potential to redefine human capabilities and address global challenges.</p>
<p><em>Learning Objective</em>: Compare the societal impacts of the AI and Digital Revolutions.</p></li>
<li><p><strong>In what way is AI expected to expand the boundaries of human knowledge?</strong></p>
<ol type="a">
<li>By automating all manual tasks.</li>
<li>By enhancing problem-solving capabilities and accelerating scientific progress.</li>
<li>By replacing the need for human decision-making.</li>
<li>By focusing solely on entertainment and media.</li>
</ol>
<p><em>Answer</em>: The correct answer is B. By enhancing problem-solving capabilities and accelerating scientific progress. This is because AI systems can process vast amounts of data and simulate complex scenarios, leading to new insights and discoveries.</p>
<p><em>Learning Objective</em>: Understand AI’s potential to expand human knowledge and capabilities.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ai-pervasiveness-8891" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ai-ml-basics-fa82" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.2</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the relationship between AI and ML?</strong></p>
<ol type="a">
<li>AI is a subset of ML focused on pattern recognition.</li>
<li>ML focuses on hardware implementation of AI theories.</li>
<li>AI and ML are unrelated fields.</li>
<li>ML is a subset of AI focused on learning from data.</li>
</ol>
<p><em>Answer</em>: The correct answer is D. ML is a subset of AI focused on learning from data. This is correct because machine learning is a methodological approach within AI that involves systems learning from data. Option A is incorrect because AI encompasses broader goals beyond pattern recognition. Option C is incorrect as AI and ML are closely related. Option D is incorrect because ML is not specifically about hardware implementation.</p>
<p><em>Learning Objective</em>: Understand the relationship between AI and ML and their respective roles.</p></li>
<li><p><strong>True or False: Machine Learning systems implement intelligence through predetermined rules.</strong></p>
<p><em>Answer</em>: False. Machine Learning systems do not rely on predetermined rules; instead, they learn patterns from data through computational techniques. This allows them to adapt and improve over time without explicit programming.</p>
<p><em>Learning Objective</em>: Identify the methodological approach of ML in creating intelligent systems.</p></li>
<li><p><strong>How does the development of machine learning reflect fundamental biological learning processes?</strong></p>
<p><em>Answer</em>: Machine learning reflects biological learning by using exposure to numerous examples to develop recognition capabilities, similar to how humans learn. For example, object recognition in ML parallels human visual learning. This is important because it allows ML systems to improve and adapt based on experience, much like natural learning processes.</p>
<p><em>Learning Objective</em>: Analyze the parallels between machine learning and biological learning processes.</p></li>
<li><p><strong>Order the following developments in AI and ML: (1) Paradigm shift from symbolic reasoning to statistical learning, (2) Emergence of machine learning as a scientific discipline, (3) Shift from shallow to deep learning.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Emergence of machine learning as a scientific discipline, (1) Paradigm shift from symbolic reasoning to statistical learning, (3) Shift from shallow to deep learning. This order reflects the historical progression of AI and ML, where machine learning first emerged as a discipline, followed by key paradigm shifts that advanced the field.</p>
<p><em>Learning Objective</em>: Understand the historical progression and paradigm shifts in AI and ML.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ai-ml-basics-fa82" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ai-evolution-8ff4" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.3</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following milestones marked the beginning of the symbolic AI era?</strong></p>
<ol type="a">
<li>The Dartmouth Conference in 1956</li>
<li>The invention of the perceptron by Frank Rosenblatt</li>
<li>The introduction of IBM’s Deep Blue</li>
<li>The release of OpenAI’s GPT-3</li>
</ol>
<p><em>Answer</em>: The correct answer is A. The Dartmouth Conference in 1956. This conference was where the term ‘artificial intelligence’ was first coined, marking the beginning of symbolic AI.</p>
<p><em>Learning Objective</em>: Understand the significance of the Dartmouth Conference in the history of AI.</p></li>
<li><p><strong>Explain the impact of the shift from symbolic AI to statistical learning on the development of AI systems.</strong></p>
<p><em>Answer</em>: The shift from symbolic AI to statistical learning allowed AI systems to learn from data rather than relying on pre-programmed rules. This made AI systems more adaptable and capable of handling complex, real-world problems. For example, statistical learning enabled the development of more robust spam filters. This shift is important because it laid the foundation for modern AI systems that rely heavily on data-driven approaches.</p>
<p><em>Learning Objective</em>: Analyze the impact of transitioning from symbolic AI to statistical learning on AI system development.</p></li>
<li><p><strong>Order the following AI milestones chronologically: (1) ELIZA chatbot, (2) IBM’s Deep Blue, (3) OpenAI’s GPT-3, (4) Perceptron by Frank Rosenblatt.</strong></p>
<p><em>Answer</em>: The correct order is: (4) Perceptron by Frank Rosenblatt, (1) ELIZA chatbot, (2) IBM’s Deep Blue, (3) OpenAI’s GPT-3. This order reflects the chronological progression of key AI milestones from early computational learning algorithms to modern large-scale language models.</p>
<p><em>Learning Objective</em>: Recognize the chronological order of significant AI milestones.</p></li>
<li><p><strong>True or False: The development of deep learning marked a return to rule-based systems similar to those used in symbolic AI.</strong></p>
<p><em>Answer</em>: False. Deep learning represents a departure from rule-based systems, as it relies on learning hierarchical feature representations from data, unlike symbolic AI which used predefined rules.</p>
<p><em>Learning Objective</em>: Distinguish between the characteristics of deep learning and symbolic AI.</p></li>
<li><p><strong>What was a key factor that enabled the transition from shallow to deep learning in AI?</strong></p>
<ol type="a">
<li>Focus on symbolic reasoning</li>
<li>Development of rule-based systems</li>
<li>Introduction of the ELIZA chatbot</li>
<li>Increased availability of large datasets</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Increased availability of large datasets. This factor, along with advances in computational power and new algorithms, enabled the transition to deep learning.</p>
<p><em>Learning Objective</em>: Identify the factors that facilitated the transition from shallow to deep learning in AI.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ai-evolution-8ff4" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-defining-ml-systems-bf7d" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.4</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes a machine learning system according to the textbook’s definition?</strong></p>
<ol type="a">
<li>An integrated system comprising data, algorithms, and computing infrastructure.</li>
<li>A system focused solely on data collection and processing.</li>
<li>A system that only involves learning algorithms and their optimization.</li>
<li>A computing infrastructure that supports model deployment.</li>
</ol>
<p><em>Answer</em>: The correct answer is A. An integrated system comprising data, algorithms, and computing infrastructure. This is correct because the textbook defines a machine learning system as one that integrates these three components to enable learning and inference. Options A, C, and D are incomplete as they focus on only one or two aspects.</p>
<p><em>Learning Objective</em>: Understand the comprehensive definition of a machine learning system as presented in the textbook.</p></li>
<li><p><strong>True or False: The effectiveness of a machine learning system is independent of the interdependencies between its components.</strong></p>
<p><em>Answer</em>: False. This is false because the performance of a machine learning system relies on the coordinated interaction of models, data, and computing infrastructure. Limitations in any one component constrain the capabilities of the others.</p>
<p><em>Learning Objective</em>: Recognize the importance of component interdependencies in the effectiveness of ML systems.</p></li>
<li><p><strong>Explain how the interdependencies between data, algorithms, and computing infrastructure influence the design of a machine learning system.</strong></p>
<p><em>Answer</em>: The interdependencies between data, algorithms, and computing infrastructure influence ML system design by dictating constraints and capabilities. For example, the model architecture affects computational demands and data requirements, while data complexity influences infrastructure needs. In practice, these interdependencies require balancing to optimize performance and feasibility.</p>
<p><em>Learning Objective</em>: Analyze the impact of component interdependencies on ML system design.</p></li>
<li><p><strong>The three core components of a machine learning system are algorithms, data, and ____.</strong></p>
<p><em>Answer</em>: computing infrastructure. This component enables the training and inference processes necessary for the system’s operation.</p>
<p><em>Learning Objective</em>: Recall the core components of a machine learning system.</p></li>
<li><p><strong>In a production ML system, which trade-off must be considered when balancing the three core components?</strong></p>
<ol type="a">
<li>Choosing the simplest algorithm to reduce computational costs.</li>
<li>Maximizing data collection without regard to storage limitations.</li>
<li>Focusing solely on model accuracy without considering inference speed.</li>
<li>Balancing model complexity with available computational resources and data quality.</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Balancing model complexity with available computational resources and data quality. This is important because effective ML system design requires optimizing these interdependencies to ensure feasible and performant systems. Options A, B, and D neglect the need for balance and optimization.</p>
<p><em>Learning Objective</em>: Understand the trade-offs involved in designing a production ML system.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-defining-ml-systems-bf7d" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-lifecycle-ml-systems-6194" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.5</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes a key difference between traditional software systems and machine learning systems?</strong></p>
<ol type="a">
<li>Traditional systems are more data-dependent than ML systems.</li>
<li>Traditional systems do not require version control, while ML systems do.</li>
<li>ML systems have a static lifecycle, unlike traditional systems.</li>
<li>Traditional systems rely on explicit programming logic, while ML systems derive behavior from data patterns.</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Traditional systems rely on explicit programming logic, while ML systems derive behavior from data patterns. This is correct because ML systems use data to drive their behavior, which is a fundamental departure from the code-driven nature of traditional systems. Options B, C, and D are incorrect as they misrepresent the characteristics of traditional and ML systems.</p>
<p><em>Learning Objective</em>: Understand the fundamental differences between traditional and ML systems in terms of behavior derivation.</p></li>
<li><p><strong>True or False: The lifecycle of machine learning systems is more dynamic and requires continuous monitoring compared to traditional software systems.</strong></p>
<p><em>Answer</em>: True. This is true because ML systems depend on data patterns that can change over time, requiring ongoing adaptation and monitoring to maintain performance and relevance.</p>
<p><em>Learning Objective</em>: Recognize the dynamic nature of ML system lifecycles and the need for continuous monitoring.</p></li>
<li><p><strong>How does the shift from code-driven to data-driven behavior in ML systems impact the lifecycle management of these systems?</strong></p>
<p><em>Answer</em>: The shift to data-driven behavior means that ML systems must continuously adapt to changes in data patterns, requiring robust monitoring and feedback loops. For example, a model might need retraining if data distribution changes. This is important because it ensures the system remains accurate and reliable as real-world conditions evolve.</p>
<p><em>Learning Objective</em>: Analyze the implications of data-driven behavior on the lifecycle management of ML systems.</p></li>
<li><p><strong>In a production ML system, what is a potential consequence of failing to monitor data distribution changes?</strong></p>
<ol type="a">
<li>Improved model accuracy</li>
<li>Decreased system performance</li>
<li>Increased system reliability</li>
<li>Reduced need for model retraining</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Decreased system performance. This is correct because changes in data distribution can lead to model drift, negatively impacting performance if not addressed. Options A, C, and D are incorrect as they do not reflect the consequences of unmonitored data changes.</p>
<p><em>Learning Objective</em>: Understand the consequences of failing to monitor data distribution changes in ML systems.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-lifecycle-ml-systems-6194" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ml-systems-wild-8f2f" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.6</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes a TinyML system?</strong></p>
<ol type="a">
<li>A system that processes petabytes of data in cloud data centers.</li>
<li>A system that balances computing resources across multiple tiers.</li>
<li>A system that runs on microcontrollers with limited computing power.</li>
<li>A system that operates within specific business constraints.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. A TinyML system runs on microcontrollers with limited computing power, focusing on low energy consumption and efficient performance. Options A, C, and D describe other types of ML systems.</p>
<p><em>Learning Objective</em>: Understand the characteristics and constraints of TinyML systems.</p></li>
<li><p><strong>Explain the trade-offs involved in deploying ML systems on the edge compared to cloud-based systems.</strong></p>
<p><em>Answer</em>: Edge ML systems reduce latency and bandwidth requirements by processing data closer to the source. However, they face constraints in local computing resources. In contrast, cloud-based systems offer virtually unlimited resources but incur higher latency and operational complexity. For example, an edge system might process video feeds locally to provide real-time analytics, while a cloud system could handle large-scale data aggregation and model training. This is important because choosing the right deployment strategy affects system performance and cost.</p>
<p><em>Learning Objective</em>: Analyze trade-offs between edge and cloud-based ML system deployments.</p></li>
<li><p><strong>True or False: Mobile ML systems prioritize sophisticated capabilities over battery life.</strong></p>
<p><em>Answer</em>: False. Mobile ML systems must balance sophisticated capabilities with battery life and processor limitations to ensure efficient operation on smartphones and tablets.</p>
<p><em>Learning Objective</em>: Understand the constraints and priorities in mobile ML system design.</p></li>
<li><p><strong>In a production system, ____, such as Alexa or Google Assistant, must recognize voice commands using less power than LED bulbs.</strong></p>
<p><em>Answer</em>: smart home devices. These devices are examples of TinyML systems that operate under strict power constraints while providing intelligent features.</p>
<p><em>Learning Objective</em>: Identify examples of TinyML applications and their operational constraints.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ml-systems-wild-8f2f" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-ml-systems-impact-lifecycle-fb60" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.7</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes a key trade-off when choosing between edge and cloud architectures for ML systems?</strong></p>
<ol type="a">
<li>Edge architectures offer unlimited computational power compared to cloud.</li>
<li>Cloud architectures inherently provide better latency than edge systems.</li>
<li>Cloud architectures are always more cost-effective than edge systems.</li>
<li>Edge architectures prioritize low latency and data privacy, while cloud architectures focus on computational power and scalability.</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Edge architectures prioritize low latency and data privacy, while cloud architectures focus on computational power and scalability. Edge systems are designed for fast, local processing, while cloud systems handle intensive computations and large-scale data processing.</p>
<p><em>Learning Objective</em>: Understand the trade-offs between edge and cloud architectures in ML systems.</p></li>
<li><p><strong>Explain how operational complexity increases in distributed ML systems compared to centralized cloud architectures.</strong></p>
<p><em>Answer</em>: Operational complexity increases in distributed ML systems due to the need to manage multiple components across various locations. This includes handling data collection, version control, model deployment, and monitoring across different environments. In contrast, centralized cloud architectures benefit from mature deployment tools and managed services, simplifying operations. Distributed systems require careful orchestration to ensure system health and updates are consistently applied.</p>
<p><em>Learning Objective</em>: Analyze the operational challenges of distributed ML systems.</p></li>
<li><p><strong>In ML systems, the need for real-time sensor data processing often requires ____ architectures to manage bandwidth efficiently.</strong></p>
<p><em>Answer</em>: edge. Edge architectures are designed to process data close to the source, reducing the need for data transfer and managing bandwidth efficiently.</p>
<p><em>Learning Objective</em>: Recognize the architectural requirements for real-time data processing in ML systems.</p></li>
<li><p><strong>What is a primary consideration when designing ML systems for mobile and embedded environments?</strong></p>
<ol type="a">
<li>Maximizing computational power at any cost.</li>
<li>Ensuring the system can handle large-scale data processing.</li>
<li>Minimizing power consumption and optimizing resource usage.</li>
<li>Prioritizing complex model architectures over simplicity.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Minimizing power consumption and optimizing resource usage. Mobile and embedded systems operate under strict resource constraints, where power efficiency and resource optimization are critical for effective operation.</p>
<p><em>Learning Objective</em>: Understand the constraints and design considerations for ML systems in mobile and embedded environments.</p></li>
<li><p><strong>In a production system, how might you balance the trade-offs between computational power and operational costs when choosing an architecture?</strong></p>
<p><em>Answer</em>: Balancing computational power and operational costs involves assessing the specific needs of the application. For latency-sensitive applications, edge architectures might be preferred despite higher initial costs due to lower ongoing data transfer expenses. Conversely, applications requiring significant computational resources might benefit from cloud architectures, which offer scalable resources but require careful cost management. Hybrid approaches can also be considered to optimize both performance and cost.</p>
<p><em>Learning Objective</em>: Evaluate trade-offs in architectural decisions for ML systems based on computational and cost considerations.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-ml-systems-impact-lifecycle-fb60" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-practical-applications-0728" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.8</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the primary goal of the FarmBeats project?</strong></p>
<ol type="a">
<li>To develop a cloud-based system for urban farming</li>
<li>To increase farm productivity and reduce costs using AI and IoT</li>
<li>To replace traditional farming methods with fully automated systems</li>
<li>To create a global database of agricultural data for research</li>
</ol>
<p><em>Answer</em>: The correct answer is B. To increase farm productivity and reduce costs using AI and IoT. This is correct because FarmBeats aims to leverage AI and IoT technologies to enhance agricultural efficiency. Options A, C, and D do not accurately capture the primary goal of FarmBeats.</p>
<p><em>Learning Objective</em>: Understand the primary objectives and goals of the FarmBeats project.</p></li>
<li><p><strong>True or False: FarmBeats relies entirely on cloud connectivity for data processing and decision-making.</strong></p>
<p><em>Answer</em>: False. FarmBeats minimizes reliance on cloud connectivity by using edge computing to process data locally, reducing latency and improving responsiveness in remote environments.</p>
<p><em>Learning Objective</em>: Recognize the role of edge computing in FarmBeats and its implications for data processing.</p></li>
<li><p><strong>Explain how FarmBeats utilizes edge computing to address the challenges of data collection and processing in remote agricultural environments.</strong></p>
<p><em>Answer</em>: FarmBeats uses edge computing to process data locally on IoT devices and edge gateways, reducing the need for constant cloud connectivity. This approach enables real-time decision-making and minimizes latency, which is crucial in remote areas with limited bandwidth. For example, soil moisture data can be analyzed on-site to optimize irrigation without waiting for cloud processing. This is important because it enhances system responsiveness and reliability in challenging environments.</p>
<p><em>Learning Objective</em>: Analyze the use of edge computing in FarmBeats and its benefits for agricultural data management.</p></li>
<li><p><strong>What is a key advantage of using TV white spaces in FarmBeats for data transmission?</strong></p>
<ol type="a">
<li>It extends internet connectivity to remote sensors</li>
<li>It provides high-speed internet access similar to fiber optics</li>
<li>It eliminates the need for any physical sensors</li>
<li>It allows for real-time data processing in the cloud</li>
</ol>
<p><em>Answer</em>: The correct answer is A. It extends internet connectivity to remote sensors. This is correct because TV white spaces are used to provide connectivity in areas where traditional internet infrastructure is unavailable. Options A, C, and D do not accurately describe the advantage of using TV white spaces in FarmBeats.</p>
<p><em>Learning Objective</em>: Understand the role of TV white spaces in extending connectivity for FarmBeats.</p></li>
<li><p><strong>In what ways might the FarmBeats approach be applied to address global challenges in food security and sustainable agriculture?</strong></p>
<p><em>Answer</em>: The FarmBeats approach can enhance food security by increasing crop yields and optimizing resource use through AI-driven insights. It can also promote sustainable agriculture by reducing water usage and minimizing environmental impact. For example, precision irrigation can conserve water while maintaining crop health. This is important because it supports sustainable farming practices and addresses global food production challenges.</p>
<p><em>Learning Objective</em>: Evaluate the potential broader impacts of the FarmBeats approach on global agricultural challenges.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-practical-applications-0728" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-challenges-ml-systems-7167" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.9</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following is a primary challenge when handling data in machine learning systems?</strong></p>
<ol type="a">
<li>Ensuring the hardware is up-to-date</li>
<li>Implementing a user-friendly interface</li>
<li>Choosing the correct programming language</li>
<li>Maintaining data quality and consistency</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Maintaining data quality and consistency. This is correct because real-world data is often messy and inconsistent, requiring significant effort to clean and standardize before use in ML systems. Options A, C, and D are not directly related to data challenges.</p>
<p><em>Learning Objective</em>: Understand the primary data-related challenges in ML systems.</p></li>
<li><p><strong>True or False: Data drift occurs when the statistical properties of the target variable change over time, potentially degrading model performance.</strong></p>
<p><em>Answer</em>: True. This is true because data drift refers to changes in data patterns over time, which can lead to reduced model accuracy if not addressed.</p>
<p><em>Learning Objective</em>: Recognize the concept of data drift and its impact on ML models.</p></li>
<li><p><strong>How might data drift affect an ML system deployed in a rapidly changing environment, such as during a global pandemic?</strong></p>
<p><em>Answer</em>: Data drift in a rapidly changing environment can lead to ML models making inaccurate predictions, as the models are trained on historical data that no longer reflects current patterns. For example, consumer behavior changes during a pandemic can render previous data patterns obsolete, requiring models to be retrained or adapted. This is important because it highlights the need for continuous monitoring and adaptation of ML systems.</p>
<p><em>Learning Objective</em>: Analyze the impact of data drift on ML systems in dynamic environments.</p></li>
<li><p><strong>In ML systems, the phenomenon where new data patterns differ from those the system originally learned from is known as ____. </strong></p>
<p><em>Answer</em>: data drift. This term describes the changes in data patterns over time, which can affect model accuracy if not addressed.</p>
<p><em>Learning Objective</em>: Recall the term for changes in data patterns that affect ML models.</p></li>
<li><p><strong>Consider a scenario where an ML system is used for personalized recommendations in a video streaming service. What challenges might arise as the system scales to handle billions of interactions?</strong></p>
<p><em>Answer</em>: As the system scales, challenges include managing vast amounts of data efficiently, ensuring data quality and consistency across diverse sources, and maintaining system performance. For example, processing billions of interactions requires robust infrastructure to store and analyze data quickly. This is important because it ensures the system can continue to provide accurate recommendations as user data grows.</p>
<p><em>Learning Objective</em>: Evaluate the challenges of scaling ML systems to handle large data volumes.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-challenges-ml-systems-7167" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-looking-ahead-34a3" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.10</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the democratization of AI technology?</strong></p>
<ol type="a">
<li>AI tools and platforms becoming accessible to a wider range of developers and organizations.</li>
<li>AI technology becoming exclusive to large tech companies.</li>
<li>The development of AI systems that require highly specialized expertise.</li>
<li>AI systems being used only in academic research settings.</li>
</ol>
<p><em>Answer</em>: The correct answer is A. AI tools and platforms becoming accessible to a wider range of developers and organizations. This democratization enables more widespread application of AI across various industries. Options A, C, and D do not reflect the trend of increasing accessibility.</p>
<p><em>Learning Objective</em>: Understand the concept of AI democratization and its implications for accessibility.</p></li>
<li><p><strong>True or False: The development of more autonomous ML systems will likely reduce the operational overhead of running these systems.</strong></p>
<p><em>Answer</em>: True. Autonomous ML systems can manage maintenance tasks like retraining and error correction, which reduces the need for manual intervention and lowers operational costs.</p>
<p><em>Learning Objective</em>: Recognize the impact of autonomous ML systems on operational efficiency.</p></li>
<li><p><strong>How might the focus on efficiency in ML systems impact their environmental footprint?</strong></p>
<p><em>Answer</em>: Focusing on efficiency in ML systems can reduce their environmental footprint by minimizing computational costs and energy consumption. For example, using specialized hardware like AI chips can make systems faster and more energy-efficient. This is important because it addresses growing concerns about the environmental impact of large-scale ML deployments.</p>
<p><em>Learning Objective</em>: Analyze the environmental implications of efficiency improvements in ML systems.</p></li>
<li><p><strong>In what way are specialized hardware developments contributing to the efficiency of ML systems?</strong></p>
<ol type="a">
<li>By increasing the size and complexity of models.</li>
<li>By reducing the need for data preprocessing.</li>
<li>By making ML systems faster and more energy-efficient.</li>
<li>By automating the entire ML lifecycle.</li>
</ol>
<p><em>Answer</em>: The correct answer is C. By making ML systems faster and more energy-efficient. Specialized hardware, such as improved GPUs and custom AI chips, enhances processing speed and reduces energy consumption. Options A, B, and D do not specifically address efficiency improvements through hardware.</p>
<p><em>Learning Objective</em>: Understand the role of specialized hardware in improving ML system efficiency.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-looking-ahead-34a3" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>
<div id="quiz-answer-sec-introduction-book-structure-learning-path-f3ea" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1.11</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following pillars focuses on the methodologies for AI training, including efficiency and optimization techniques?</strong></p>
<ol type="a">
<li>Data</li>
<li>Operations</li>
<li>Deployment</li>
<li>Training</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Training. This pillar explores methodologies for AI training, focusing on efficiency, optimization, and acceleration techniques to enhance model performance. Other options focus on different aspects of the ML lifecycle.</p>
<p><em>Learning Objective</em>: Identify the focus of the ‘Training’ pillar in the ML systems lifecycle.</p></li>
<li><p><strong>Explain why the ‘Ethics &amp; Governance’ pillar is crucial in the lifecycle of ML systems.</strong></p>
<p><em>Answer</em>: The ‘Ethics &amp; Governance’ pillar is crucial because it addresses security, privacy, responsible AI practices, and societal implications. For example, it ensures that AI technologies are developed and used in ways that respect user privacy and prevent biases. This is important because ethical considerations are fundamental to gaining public trust and ensuring compliance with regulations.</p>
<p><em>Learning Objective</em>: Understand the importance of the ‘Ethics &amp; Governance’ pillar in ML systems.</p></li>
<li><p><strong>Order the following ML system lifecycle pillars as they typically occur: (1) Deployment, (2) Data, (3) Operations, (4) Training.</strong></p>
<p><em>Answer</em>: The correct order is: (2) Data, (4) Training, (1) Deployment, (3) Operations. Data is first as it involves data engineering and foundational principles, followed by Training which optimizes model performance. Deployment comes next to ensure effective model application, and finally, Operations maintains the system.</p>
<p><em>Learning Objective</em>: Sequence the lifecycle pillars of ML systems in their typical order.</p></li>
</ol>
<p><a href="#quiz-question-sec-introduction-book-structure-learning-path-f3ea" class="answer-label">← Back to Questions</a></p>
</div></details>
</div>

</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="pagination-link" aria-label="SocratiQ AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">SocratiQ AI</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/ml_systems/ml_systems.html" class="pagination-link" aria-label="ML Systems">
        <span class="nav-page-text">ML Systems</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 Harvard University. Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a></p>
</div>   
    <div class="nav-footer-center">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-github" role="img" aria-label="View source on GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/harvard-edge/cs249r_book">
      <i class="bi bi-star" role="img" aria-label="Star this repository">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>