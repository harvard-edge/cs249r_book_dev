<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; ML Systems – Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/dl_primer/dl_primer.html" rel="next">
<link href="../../../contents/core/introduction/introduction.html" rel="prev">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-4a990d8dcb58f517c7c86712b8f2ac7c.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-46f4cc9626f044588a66931b604fc9c8.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-4a990d8dcb58f517c7c86712b8f2ac7c.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-70c99df5108d69e32b22fd3b8f2fd642.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-d83d3dba059e47d7a78a8dca4befe3ea.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-70c99df5108d69e32b22fd3b8f2fd642.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script type="module" src="../../../scripts/ai_menu/dist/bundle.js" defer=""></script>
<script type="module" src="../../../scripts/ai_menu/dist/sqlite3-opfs-async-proxy-B_ImRJXp.js"></script>
<script type="module" src="../../../scripts/ai_menu/dist/sqlite3-worker1-bundler-friendly-CbDNa4by.js"></script>
<script type="module" src="../../../scripts/ai_menu/dist/worker-voUF5YDa.js"></script>
<style>
.callout-resource-slides {
  --color1: #E9F3E3;
  --color2: #55984D;
}
.callout-quiz-question {
  --color1: #E1F3F8;
  --color2: #119EC7;
}
.callout-quiz-answer {
  --color1: #FAEAF1;
  --color2: #980e5a;
}
.callout-resource-videos {
  --color1: #f9f5f0;
  --color2: #8b5e3c;
}
.callout-resource-exercises {
  --color1: #f7f0fa;
  --color2: #815AA4;
}
</style>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="../../../Machine-Learning-Systems.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="../../../Machine-Learning-Systems.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/ml_systems/ml_systems.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">ML Systems</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="ab18bf679d12eff080697991ab97393a" class="alert alert-primary hidden"><i class="bi bi-book quarto-announcement-icon"></i><div class="quarto-announcement-content">
<div id="banner">
<p>🎉 <b>Just Announced:</b> <i>Introduction to Machine Learning Systems</i> will be published by <b>MIT Press</b> in 2026!<br> 💻 Fully open source at <a href="https://mlsysbook.ai">mlsysbook.ai</a><br> 🗒️ <a href="contents/frontmatter/changelog/changelog.html">View the full changelog</a><br> ⭐ Help grow the project: <a href="https://github.com/harvard-edge/cs249r_book">Star on GitHub</a></p>
</div>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Author’s Note</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/about/about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/changelog/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Book Changelog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/acknowledgements/acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/frontmatter/socratiq/socratiq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Foundations</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">ML Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">DL Primer</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dnn_architectures/dnn_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">DNN Architectures</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Design Principles</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">AI Workflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">AI Frameworks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">AI Training</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Efficient AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model Optimizations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Acceleration</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Benchmarking AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Best Practices</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">ML Operations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">On-Device Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Security &amp; Privacy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Responsible AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sustainable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Robust AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Impact and Outlook</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">LABS</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/seeed/grove_vision_ai_v2/grove_vision_ai_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Grove Vision AI V2</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/setup_and_no_code_apps/setup_and_no_code_apps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup and No-Code Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/grove_vision_ai_v2/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/raspi/raspi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models (VLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Shared Labs</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">RESOURCES</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/resources/phd_survival_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PhD Survival Guide</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/backmatter/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#purpose" id="toc-purpose" class="nav-link active" data-scroll-target="#purpose">Purpose</a></li>
  <li><a href="#sec-ml-systems-overview-5d7e" id="toc-sec-ml-systems-overview-5d7e" class="nav-link" data-scroll-target="#sec-ml-systems-overview-5d7e"><span class="header-section-number">2.1</span> Overview</a></li>
  <li><a href="#sec-ml-systems-cloudbased-machine-learning-52c3" id="toc-sec-ml-systems-cloudbased-machine-learning-52c3" class="nav-link" data-scroll-target="#sec-ml-systems-cloudbased-machine-learning-52c3"><span class="header-section-number">2.2</span> Cloud-Based Machine Learning</a>
  <ul>
  <li><a href="#sec-ml-systems-characteristics-1648" id="toc-sec-ml-systems-characteristics-1648" class="nav-link" data-scroll-target="#sec-ml-systems-characteristics-1648"><span class="header-section-number">2.2.1</span> Characteristics</a></li>
  <li><a href="#sec-ml-systems-benefits-981f" id="toc-sec-ml-systems-benefits-981f" class="nav-link" data-scroll-target="#sec-ml-systems-benefits-981f"><span class="header-section-number">2.2.2</span> Benefits</a></li>
  <li><a href="#sec-ml-systems-challenges-6897" id="toc-sec-ml-systems-challenges-6897" class="nav-link" data-scroll-target="#sec-ml-systems-challenges-6897"><span class="header-section-number">2.2.3</span> Challenges</a></li>
  <li><a href="#sec-ml-systems-use-cases-02a3" id="toc-sec-ml-systems-use-cases-02a3" class="nav-link" data-scroll-target="#sec-ml-systems-use-cases-02a3"><span class="header-section-number">2.2.4</span> Use Cases</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-edge-machine-learning-52c5" id="toc-sec-ml-systems-edge-machine-learning-52c5" class="nav-link" data-scroll-target="#sec-ml-systems-edge-machine-learning-52c5"><span class="header-section-number">2.3</span> Edge Machine Learning</a>
  <ul>
  <li><a href="#sec-ml-systems-characteristics-40ab" id="toc-sec-ml-systems-characteristics-40ab" class="nav-link" data-scroll-target="#sec-ml-systems-characteristics-40ab"><span class="header-section-number">2.3.1</span> Characteristics</a></li>
  <li><a href="#sec-ml-systems-benefits-2d74" id="toc-sec-ml-systems-benefits-2d74" class="nav-link" data-scroll-target="#sec-ml-systems-benefits-2d74"><span class="header-section-number">2.3.2</span> Benefits</a></li>
  <li><a href="#sec-ml-systems-challenges-7d58" id="toc-sec-ml-systems-challenges-7d58" class="nav-link" data-scroll-target="#sec-ml-systems-challenges-7d58"><span class="header-section-number">2.3.3</span> Challenges</a></li>
  <li><a href="#sec-ml-systems-use-cases-c403" id="toc-sec-ml-systems-use-cases-c403" class="nav-link" data-scroll-target="#sec-ml-systems-use-cases-c403"><span class="header-section-number">2.3.4</span> Use Cases</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-mobile-machine-learning-dbe8" id="toc-sec-ml-systems-mobile-machine-learning-dbe8" class="nav-link" data-scroll-target="#sec-ml-systems-mobile-machine-learning-dbe8"><span class="header-section-number">2.4</span> Mobile Machine Learning</a>
  <ul>
  <li><a href="#sec-ml-systems-characteristics-c512" id="toc-sec-ml-systems-characteristics-c512" class="nav-link" data-scroll-target="#sec-ml-systems-characteristics-c512"><span class="header-section-number">2.4.1</span> Characteristics</a></li>
  <li><a href="#sec-ml-systems-benefits-de8e" id="toc-sec-ml-systems-benefits-de8e" class="nav-link" data-scroll-target="#sec-ml-systems-benefits-de8e"><span class="header-section-number">2.4.2</span> Benefits</a></li>
  <li><a href="#sec-ml-systems-challenges-de63" id="toc-sec-ml-systems-challenges-de63" class="nav-link" data-scroll-target="#sec-ml-systems-challenges-de63"><span class="header-section-number">2.4.3</span> Challenges</a></li>
  <li><a href="#sec-ml-systems-use-cases-59ec" id="toc-sec-ml-systems-use-cases-59ec" class="nav-link" data-scroll-target="#sec-ml-systems-use-cases-59ec"><span class="header-section-number">2.4.4</span> Use Cases</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-tiny-machine-learning-ccce" id="toc-sec-ml-systems-tiny-machine-learning-ccce" class="nav-link" data-scroll-target="#sec-ml-systems-tiny-machine-learning-ccce"><span class="header-section-number">2.5</span> Tiny Machine Learning</a>
  <ul>
  <li><a href="#sec-ml-systems-characteristics-794b" id="toc-sec-ml-systems-characteristics-794b" class="nav-link" data-scroll-target="#sec-ml-systems-characteristics-794b"><span class="header-section-number">2.5.1</span> Characteristics</a></li>
  <li><a href="#sec-ml-systems-benefits-c373" id="toc-sec-ml-systems-benefits-c373" class="nav-link" data-scroll-target="#sec-ml-systems-benefits-c373"><span class="header-section-number">2.5.2</span> Benefits</a></li>
  <li><a href="#sec-ml-systems-challenges-29ae" id="toc-sec-ml-systems-challenges-29ae" class="nav-link" data-scroll-target="#sec-ml-systems-challenges-29ae"><span class="header-section-number">2.5.3</span> Challenges</a></li>
  <li><a href="#sec-ml-systems-use-cases-3173" id="toc-sec-ml-systems-use-cases-3173" class="nav-link" data-scroll-target="#sec-ml-systems-use-cases-3173"><span class="header-section-number">2.5.4</span> Use Cases</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-hybrid-machine-learning-6d02" id="toc-sec-ml-systems-hybrid-machine-learning-6d02" class="nav-link" data-scroll-target="#sec-ml-systems-hybrid-machine-learning-6d02"><span class="header-section-number">2.6</span> Hybrid Machine Learning</a>
  <ul>
  <li><a href="#sec-ml-systems-design-patterns-0b70" id="toc-sec-ml-systems-design-patterns-0b70" class="nav-link" data-scroll-target="#sec-ml-systems-design-patterns-0b70"><span class="header-section-number">2.6.1</span> Design Patterns</a>
  <ul class="collapse">
  <li><a href="#sec-ml-systems-trainserve-split-33d9" id="toc-sec-ml-systems-trainserve-split-33d9" class="nav-link" data-scroll-target="#sec-ml-systems-trainserve-split-33d9">Train-Serve Split</a></li>
  <li><a href="#sec-ml-systems-hierarchical-processing-d06a" id="toc-sec-ml-systems-hierarchical-processing-d06a" class="nav-link" data-scroll-target="#sec-ml-systems-hierarchical-processing-d06a">Hierarchical Processing</a></li>
  <li><a href="#sec-ml-systems-progressive-deployment-86b2" id="toc-sec-ml-systems-progressive-deployment-86b2" class="nav-link" data-scroll-target="#sec-ml-systems-progressive-deployment-86b2">Progressive Deployment</a></li>
  <li><a href="#sec-ml-systems-federated-learning-37f5" id="toc-sec-ml-systems-federated-learning-37f5" class="nav-link" data-scroll-target="#sec-ml-systems-federated-learning-37f5">Federated Learning</a></li>
  <li><a href="#sec-ml-systems-collaborative-learning-3f3d" id="toc-sec-ml-systems-collaborative-learning-3f3d" class="nav-link" data-scroll-target="#sec-ml-systems-collaborative-learning-3f3d">Collaborative Learning</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-realworld-integration-9e96" id="toc-sec-ml-systems-realworld-integration-9e96" class="nav-link" data-scroll-target="#sec-ml-systems-realworld-integration-9e96"><span class="header-section-number">2.6.2</span> Real-World Integration</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-shared-principles-db13" id="toc-sec-ml-systems-shared-principles-db13" class="nav-link" data-scroll-target="#sec-ml-systems-shared-principles-db13"><span class="header-section-number">2.7</span> Shared Principles</a>
  <ul>
  <li><a href="#sec-ml-systems-implementation-layer-40e0" id="toc-sec-ml-systems-implementation-layer-40e0" class="nav-link" data-scroll-target="#sec-ml-systems-implementation-layer-40e0"><span class="header-section-number">2.7.1</span> Implementation Layer</a></li>
  <li><a href="#sec-ml-systems-system-principles-layer-7ed6" id="toc-sec-ml-systems-system-principles-layer-7ed6" class="nav-link" data-scroll-target="#sec-ml-systems-system-principles-layer-7ed6"><span class="header-section-number">2.7.2</span> System Principles Layer</a></li>
  <li><a href="#sec-ml-systems-system-considerations-layer-c419" id="toc-sec-ml-systems-system-considerations-layer-c419" class="nav-link" data-scroll-target="#sec-ml-systems-system-considerations-layer-c419"><span class="header-section-number">2.7.3</span> System Considerations Layer</a></li>
  <li><a href="#sec-ml-systems-principles-practice-fa6c" id="toc-sec-ml-systems-principles-practice-fa6c" class="nav-link" data-scroll-target="#sec-ml-systems-principles-practice-fa6c"><span class="header-section-number">2.7.4</span> Principles to Practice</a></li>
  </ul></li>
  <li><a href="#sec-ml-systems-system-comparison-0245" id="toc-sec-ml-systems-system-comparison-0245" class="nav-link" data-scroll-target="#sec-ml-systems-system-comparison-0245"><span class="header-section-number">2.8</span> System Comparison</a></li>
  <li><a href="#sec-ml-systems-deployment-decision-framework-cb57" id="toc-sec-ml-systems-deployment-decision-framework-cb57" class="nav-link" data-scroll-target="#sec-ml-systems-deployment-decision-framework-cb57"><span class="header-section-number">2.9</span> Deployment Decision Framework</a></li>
  <li><a href="#sec-ml-systems-conclusion-1102" id="toc-sec-ml-systems-conclusion-1102" class="nav-link" data-scroll-target="#sec-ml-systems-conclusion-1102"><span class="header-section-number">2.10</span> Conclusion</a></li>
  <li><a href="#sec-ml-systems-resources-c1ff" id="toc-sec-ml-systems-resources-c1ff" class="nav-link" data-scroll-target="#sec-ml-systems-resources-c1ff"><span class="header-section-number">2.11</span> Resources</a></li>
  <li><a href="#self-check-answers" id="toc-self-check-answers" class="nav-link" data-scroll-target="#self-check-answers"><span class="header-section-number">2.12</span> Self-Check Answers</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/widget_quiz/contents/core/ml_systems/ml_systems.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/widget_quiz/contents/core/ml_systems/ml_systems.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">ML Systems</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/png/cover_ml_systems.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="DALL·E 3 Prompt: Illustration in a rectangular format depicting the merger of embedded systems with Embedded AI. The left half of the image portrays traditional embedded systems, including microcontrollers and processors, detailed and precise. The right half showcases the world of artificial intelligence, with abstract representations of machine learning models, neurons, and data flow. The two halves are distinctly separated, emphasizing the individual significance of embedded tech and AI, but they come together in harmony at the center."><img src="images/png/cover_ml_systems.png" class="img-fluid figure-img" alt="DALL·E 3 Prompt: Illustration in a rectangular format depicting the merger of embedded systems with Embedded AI. The left half of the image portrays traditional embedded systems, including microcontrollers and processors, detailed and precise. The right half showcases the world of artificial intelligence, with abstract representations of machine learning models, neurons, and data flow. The two halves are distinctly separated, emphasizing the individual significance of embedded tech and AI, but they come together in harmony at the center."></a></p>
<figcaption><em>DALL·E 3 Prompt: Illustration in a rectangular format depicting the merger of embedded systems with Embedded AI. The left half of the image portrays traditional embedded systems, including microcontrollers and processors, detailed and precise. The right half showcases the world of artificial intelligence, with abstract representations of machine learning models, neurons, and data flow. The two halves are distinctly separated, emphasizing the individual significance of embedded tech and AI, but they come together in harmony at the center.</em></figcaption>
</figure>
</div>
<section id="purpose" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="purpose">Purpose</h2>
<p><em>How do the diverse environments where machine learning operates shape the fundamental nature of these systems, and what drives their widespread deployment across computing platforms?</em></p>
<p>The deployment of machine learning systems across varied computing environments reveals essential insights into the relationship between theoretical principles and practical implementation. Each computing environment, from large-scale distributed systems to resource-constrained devices, introduces distinct requirements that influence both system architecture and algorithmic approaches. Understanding these relationships reveals core engineering principles that govern the design of machine learning systems. This understanding provides a foundation for examining how theoretical concepts translate into practical implementations, and how system designs adapt to meet diverse computational, memory, and energy constraints.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Understand the key characteristics and differences between Cloud ML, Edge ML, Mobile ML, and Tiny ML systems.</p></li>
<li><p>Analyze the benefits and challenges associated with each ML paradigm.</p></li>
<li><p>Explore real-world applications and use cases for Cloud ML, Edge ML, Mobile ML, and Tiny ML.</p></li>
<li><p>Compare the performance aspects of each ML approach, including latency, privacy, and resource utilization.</p></li>
<li><p>Examine the evolving landscape of ML systems and potential future developments.</p></li>
</ul>
</div>
</div>
</section>
<section id="sec-ml-systems-overview-5d7e" class="level2 page-columns page-full" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-ml-systems-overview-5d7e"><span class="header-section-number">2.1</span> Overview</h2>
<p>Modern machine learning systems span a spectrum of deployment options, each with its own set of characteristics and use cases. At one end, we have cloud-based ML, which leverages powerful centralized computing resources for complex, data-intensive tasks. Moving along the spectrum, we encounter edge ML, which brings computation closer to the data source for reduced latency and improved privacy. Mobile ML further extends these capabilities to smartphones and tablets, while at the far end, we find Tiny ML, which enables machine learning on extremely low-power devices with severe memory and processing constraints.</p>
<p>This spectrum of deployment can be visualized like Earth’s geological features, each operating at different scales in our computational landscape. Cloud ML systems operate like continents, processing vast amounts of data across interconnected centers; Edge ML exists where these continental powers meet the sea, creating dynamic coastlines where computation flows into local waters; Mobile ML moves through these waters like ocean currents, carrying computing power across the digital seas; and where these currents meet the physical world, TinyML systems rise like islands, each a precise point of intelligence in the vast computational ocean.</p>
<p><a href="#fig-cloud-edge-TinyML-comparison" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> illustrates the spectrum of distributed intelligence across these approaches, providing a visual comparison of their characteristics. We will examine the unique characteristics, advantages, and challenges of each approach, as depicted in the figure. Additionally, we will discuss the emerging trends and technologies that are shaping the future of machine learning deployment, considering how they might influence the balance between these three paradigms.</p>
<div id="fig-cloud-edge-TinyML-comparison" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cloud-edge-TinyML-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb1"><pre class="sourceCode tikz code-with-copy"><code class="sourceCode latex"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}[line cap=round,line join=round,font=<span class="fu">\usefont</span>{T1}{phv}{m}{n}<span class="fu">\small</span>]</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">% Parameters</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">\def\angle</span>{10}        <span class="co">% angle</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">\def\length</span>{18}       <span class="co">% Lengths (cm)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">\def\npoints</span>{5}       <span class="co">% number of poihnts</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">\def\startfrac</span>{0.13}  <span class="co">% start (e.g.. 0.2 = 20%)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">\def\endfrac</span>{0.87}    <span class="co">% end (e.g.. 0.8 = 80%)</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">\draw</span>[line width=1pt, black!70] (0,0) -- ({<span class="fu">\length*</span>cos(<span class="fu">\angle</span>)}, {<span class="fu">\length*</span>sin(<span class="fu">\angle</span>)})coordinate(end);</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a> <span class="co">%</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">\foreach</span> <span class="fu">\i</span> in {0,1,...,<span class="fu">\numexpr\npoints</span>-1} {</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">\pgfmathsetmacro</span>{<span class="fu">\t</span>}{<span class="fu">\startfrac</span> + (<span class="fu">\endfrac</span> - <span class="fu">\startfrac</span>)*<span class="fu">\i</span>/(<span class="fu">\npoints</span>-1)}</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(T<span class="fu">\i</span>)at({<span class="fu">\t*\length*</span>cos(<span class="fu">\angle</span>)}, {<span class="fu">\t*\length*</span>sin(<span class="fu">\angle</span>)});</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span> {</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>pics/gatewey/.style = {</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        code = {</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">\colorlet</span>{red}{white}</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[local bounding box=GAT,scale=0.9, every node/.append style={transform shape}]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">\def\rI</span>{4mm}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="fu">\def\rII</span>{2.8mm}</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">\def\rIII</span>{1.6mm}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red,line width=1.25pt](0,0)--(0,0.38)--(1.2,0.38)--(1.2,0)--cycle;</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red,line width=1.5pt](0.6,0.4)--(0.6,0.9);</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red, line width=1.5pt] (0.6,0.9)+(60:<span class="fu">\rI</span>) arc[start angle=60, end angle=-60, radius=<span class="fu">\rI</span>];</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red, line width=1.5pt] (0.6,0.9)+(50:<span class="fu">\rII</span>) arc[start angle=50, end angle=-50, radius=<span class="fu">\rII</span>];</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red, line width=1.5pt] (0.6,0.9)+(30:<span class="fu">\rIII</span>) arc[start angle=30, end angle=-30, radius=<span class="fu">\rIII</span>];</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a> <span class="fu">\draw</span>[red, line width=1.5pt] (0.6,0.9)+(120:<span class="fu">\rI</span>) arc[start angle=120, end angle=240, radius=<span class="fu">\rI</span>];</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red, line width=1.5pt] (0.6,0.9)+(130:<span class="fu">\rII</span>) arc[start angle=130, end angle=230, radius=<span class="fu">\rII</span>];</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red, line width=1.5pt] (0.6,0.9)+(150:<span class="fu">\rIII</span>) arc[start angle=150, end angle=210, radius=<span class="fu">\rIII</span>];</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="fu">\fill</span>[red](0.6,0.9)circle (1.5pt);</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach\i</span> in{0.15,0.3,0.45,0.6}{</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">\fill</span>[red](<span class="fu">\i</span>,0.19)circle (1.5pt);</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="fu">\fill</span>[red](1,0.19)circle (2pt);</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>}}}</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span> {</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>pics/cloud/.style = {</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        code = {</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="fu">\colorlet</span>{red}{white}</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[local bounding box=CLO,scale=0.6, every node/.append style={transform shape}]</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red,line width=1.5pt](0,0)to[out=170,in=180,distance=11](0.1,0.61)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>to[out=90,in=105,distance=17](1.07,0.71)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>to[out=20,in=75,distance=7](1.48,0.36)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>to[out=350,in=0,distance=7](1.48,0)--(0,0);</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red,line width=1.5pt](0.27,0.71)to[bend left=25](0.49,0.96);</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red,line width=1.5pt](0.67,1.21)to[out=55,in=90,distance=13](1.5,0.96)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>to[out=360,in=30,distance=9](1.68,0.42);</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>}}}</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span> {</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>  pics/server/.style = {</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    code = {</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>      <span class="fu">\colorlet</span>{red}{white}</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>      <span class="kw">\begin</span>{<span class="ex">scope</span>}[anchor=center, transform shape,scale=0.8, every node/.append style={transform shape}]</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        <span class="fu">\draw</span>[red,line width=1.25pt,fill=white](-0.55,-0.5) rectangle (0.55,0.5);</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\i</span> in {-0.25,0,0.25} {</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>                <span class="fu">\draw</span>[cyan,line width=1.25pt]( -0.55,<span class="fu">\i</span>) -- (0.55, <span class="fu">\i</span>);</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        <span class="fu">\foreach</span> <span class="fu">\i</span> in {-0.375, -0.125, 0.125, 0.375} {</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>          <span class="fu">\draw</span>[cyan!50!black!90,line width=1.25pt](-0.45,<span class="fu">\i</span>)--(0,<span class="fu">\i</span>);</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>          <span class="fu">\fill</span>[cyan!50!black!90](0.35,<span class="fu">\i</span>) circle (1.5pt);</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[red,line width=1.75pt](0,-0.53) |- (-0.55,-0.7);</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        <span class="fu">\draw</span>[red,line width=1.75pt](0,-0.53) |- (0.55,-0.7);</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>      <span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span> {</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>pics/cpu/.style = {</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>        code = {</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="fu">\definecolor</span>{CPU}{RGB}{0,120,176}</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="fu">\colorlet</span>{CPU}{white}</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[local bounding box = CPU,scale=0.33, every node/.append style={transform shape}]</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[fill=CPU,minimum width=66, minimum height=66,</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>            rounded corners=2,outer sep=2pt] (C1) {};</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[fill=violet,minimum width=54, minimum height=54] (C2) {};</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="co">%\node[fill=CPU!40,minimum width=44, minimum height=44] (C3) {CPU};</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\x</span>/<span class="fu">\y</span> in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[fill=CPU,minimum width=4, minimum height=15,</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>           inner sep=0pt,anchor=south](GO<span class="fu">\y</span>)at(<span class="ss">$(C1.north west)!</span><span class="sc">\x</span><span class="ss">!(C1.north east)$</span>){};</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\x</span>/<span class="fu">\y</span> in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[fill=CPU,minimum width=4, minimum height=15,</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>           inner sep=0pt,anchor=north](DO<span class="fu">\y</span>)at(<span class="ss">$(C1.south west)!</span><span class="sc">\x</span><span class="ss">!(C1.south east)$</span>){};</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\x</span>/<span class="fu">\y</span> in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[fill=CPU,minimum width=15, minimum height=4,</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>           inner sep=0pt,anchor=east](LE<span class="fu">\y</span>)at(<span class="ss">$(C1.north west)!</span><span class="sc">\x</span><span class="ss">!(C1.south west)$</span>){};</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\x</span>/<span class="fu">\y</span> in {0.11/1,0.26/2,0.41/3,0.56/4,0.71/5,0.85/6}{</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[fill=CPU,minimum width=15, minimum height=4,</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>           inner sep=0pt,anchor=west](DE<span class="fu">\y</span>)at(<span class="ss">$(C1.north east)!</span><span class="sc">\x</span><span class="ss">!(C1.south east)$</span>){};</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>    }  }}</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span> {</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>pics/mobile/.style = {</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>        code = {</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="fu">\colorlet</span>{red}{white}</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[local bounding box=MOB,scale=0.4, every node/.append style={transform shape}]</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[rectangle,draw=red,minimum height=94,minimum width=47,</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>            rounded corners=6,thick,fill=white](R1){};</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[rectangle,draw=red,minimum height=67,minimum width=38,thick,fill=green!69!black!90](R2){};</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[circle,minimum size=8,below= 2pt of R2,inner sep=0pt,thick,fill=green!69!black!90]{};</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[rectangle,fill=green!69!black!90,minimum height=2,minimum width=20,above= 4pt of R2,inner sep=0pt,thick]{};</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a> <span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>     }  }}</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=none,fill=red,circle,minimum size=20mm](GA)at(T2){};</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="fu">\pic</span>[shift={(-0.55,-0.5)}] at (T2) {gatewey};</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=0 of GA]{Gateway};</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=none,fill=violet,circle,minimum size=20mm](CP)at(T0){};</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="fu">\pic</span>[shift={(0,-0)}] at (T0) {cpu};</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=0 of CP,align=center]{Ultra Low Powered<span class="fu">\\</span>Devices and Sensors};</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=none,fill=green!70,,circle,minimum size=20mm](MO)at(T1){};</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a> <span class="fu">\pic</span>[shift={(0,0)}] at (T1) {mobile};</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a> <span class="fu">\node</span>[above=0 of MO,align=center]{Intellignet<span class="fu">\\</span>Device};</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=none,fill=cyan,circle,minimum size=20mm](SE)at(T3){};</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="fu">\pic</span>[shift={(-0.03,0.1)}] at (T3) {server};</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a> <span class="fu">\node</span>[above=0 of SE,align=center]{On Premise<span class="fu">\\</span>Servers};</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=none,fill=brown,circle,minimum size=20mm](CL)at(T4){};</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="fu">\pic</span>[shift={(-0.48,-0.35)}] at (T4) {cloud};</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a> <span class="fu">\node</span>[above=0 of CL,align=center]{Cloud};</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span> (T0) -- (T1) coordinate[pos=0.5] (M1);</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span> (0,0) -- (T0) coordinate[pos=0.25] (M0);</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span> (T3) -- (T4) coordinate[pos=0.5] (M2);</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span> (T4) -- (end) coordinate[pos=0.75] (M3);</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\x</span> in {0,1,2,3}{</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="fu">\fill</span>[OliveLine](M<span class="fu">\x</span>)circle (2.5pt);</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](M0)--++(270:1.6)coordinate(LL1)-|coordinate(LL2)(M2);</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](M0)--++(270:1.1)coordinate(L1)-|coordinate(L2)(M1);</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](M0)--++(270:1.1)-|coordinate(L3)(M2);</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](M0)--++(270:1.1)-|coordinate(L4)(M3);</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[black!70,thick](M0)--(LL1);</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[black!70,thick](M1)--(L2);</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[black!70,thick](M3)--(L4);</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[black!70,thick](M2)--(LL2);</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[latex-latex,line width=1pt,draw=black!60](L1)--node[red,fill=white]{TinyML}(L2);</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[latex-latex,line width=1pt,draw=black!60](L3)--node[fill=white]{Cloud AI}(L4);</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[latex-latex,line width=1pt,draw=black!60]([yshift=4pt]LL1)--node[fill=white,text=black]{Edge AI}([yshift=4pt]LL2);</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="fu">\foreach</span> <span class="fu">\x</span> in {0,1,2,3}{</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="fu">\fill</span>[OliveLine](M<span class="fu">\x</span>)circle (2.5pt);</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=0.35 of LL1,anchor=west,font=<span class="fu">\usefont</span>{T1}{phv}{m}{n}<span class="fu">\footnotesize</span>,black!50]</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>{Source: ABI Research: TinyML};</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[](M0)--++(90:4.2)-|node[pos=0.25]{<span class="fu">\textbf</span>{The Distributed Intelligence Spectrum}}(M3);</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cloud-edge-TinyML-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: Cloud vs.&nbsp;Edge vs.&nbsp;Mobile vs.&nbsp;Tiny ML: The Spectrum of Distributed Intelligence. Source: ABI Research – Tiny ML.
</figcaption>
</figure>
</div>
<p>To better understand the dramatic differences between these ML deployment options, <a href="#tbl-representative-systems" class="quarto-xref">Table&nbsp;<span>2.1</span></a> provides examples of representative hardware platforms for each category. These examples illustrate the vast range of computational resources, power requirements, and cost considerations across the ML systems spectrum. As we explore each paradigm in detail, you can refer back to these concrete examples to better understand the practical implications of each approach.</p>
<div id="tbl-representative-systems" class="hover striped quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-representative-systems-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.1: Representative hardware platforms across the ML systems spectrum, showing typical specifications and capabilities for each category.
</figcaption>
<div aria-describedby="tbl-representative-systems-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table-striped caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 21%">
<col style="width: 9%">
<col style="width: 10%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Category</th>
<th style="text-align: left;">Example Device</th>
<th style="text-align: left;">Processor</th>
<th style="text-align: left;">Memory</th>
<th style="text-align: left;">Storage</th>
<th style="text-align: left;">Power</th>
<th style="text-align: left;">Price Range</th>
<th style="text-align: left;">Example Models/Tasks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cloud ML</td>
<td style="text-align: left;">NVIDIA DGX A100</td>
<td style="text-align: left;">8x NVIDIA A100 GPUs (40 GB/80 GB)</td>
<td style="text-align: left;">1 TB System RAM</td>
<td style="text-align: left;">15 TB NVMe SSD</td>
<td style="text-align: left;">6.5 kW</td>
<td style="text-align: left;">$200 K+</td>
<td style="text-align: left;">Large language models (GPT-3), real-time video processing</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">Google TPU v4 Pod</td>
<td style="text-align: left;">4096 TPU v4 chips</td>
<td style="text-align: left;">128 TB+</td>
<td style="text-align: left;">Networked storage</td>
<td style="text-align: left;">~MW</td>
<td style="text-align: left;">Pay-per-use</td>
<td style="text-align: left;">Training foundation models, large-scale ML research</td>
</tr>
<tr class="odd">
<td>Edge ML</td>
<td style="text-align: left;">NVIDIA Jetson AGX Orin</td>
<td style="text-align: left;">12-core Arm® Cortex®-A78AE, NVIDIA Ampere GPU</td>
<td style="text-align: left;">32 GB LPDDR5</td>
<td style="text-align: left;">64GB eMMC</td>
<td style="text-align: left;">15-60 W</td>
<td style="text-align: left;">$899</td>
<td style="text-align: left;">Computer vision, robotics, autonomous systems</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">Intel NUC 12 Pro</td>
<td style="text-align: left;">Intel Core i7-1260P, Intel Iris Xe</td>
<td style="text-align: left;">32 GB DDR4</td>
<td style="text-align: left;">1 TB SSD</td>
<td style="text-align: left;">28 W</td>
<td style="text-align: left;">$750</td>
<td style="text-align: left;">Edge AI servers, industrial automation</td>
</tr>
<tr class="odd">
<td>Mobile ML</td>
<td style="text-align: left;">iPhone 15 Pro</td>
<td style="text-align: left;">A17 Pro (6-core CPU, 6-core GPU)</td>
<td style="text-align: left;">8 GB RAM</td>
<td style="text-align: left;">128 GB-1 TB</td>
<td style="text-align: left;">3-5 W</td>
<td style="text-align: left;">$999+</td>
<td style="text-align: left;">Face ID, computational photography, voice recognition</td>
</tr>
<tr class="even">
<td>Tiny ML</td>
<td style="text-align: left;">Arduino Nano 33 BLE Sense</td>
<td style="text-align: left;">Arm Cortex-M4 @ 64 MHz</td>
<td style="text-align: left;">256 KB RAM</td>
<td style="text-align: left;">1 MB Flash</td>
<td style="text-align: left;">0.02-0.04 W</td>
<td style="text-align: left;">$35</td>
<td style="text-align: left;">Gesture recognition, voice detection</td>
</tr>
<tr class="odd">
<td></td>
<td style="text-align: left;">ESP32-CAM</td>
<td style="text-align: left;">Dual-core @ 240MHz</td>
<td style="text-align: left;">520 KB RAM</td>
<td style="text-align: left;">4 MB Flash</td>
<td style="text-align: left;">0.05-0.25 W</td>
<td style="text-align: left;">$10</td>
<td style="text-align: left;">Image classification, motion detection</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The evolution of machine learning systems can be seen as a progression from centralized to increasingly distributed and specialized computing paradigms:</p>
<p><strong>Cloud ML</strong>: Initially, ML was predominantly cloud-based. Powerful, scalable servers in data centers are used to train and run large ML models. This approach leverages vast computational resources and storage capacities, enabling the development of complex models trained on massive datasets. Cloud ML excels at tasks requiring extensive processing power, distributed training of large models, and is ideal for applications where real-time responsiveness isn’t critical. Popular platforms like AWS SageMaker, Google Cloud AI, and Azure ML offer flexible, scalable solutions for model development, training, and deployment. Cloud ML can handle models with billions of parameters, training on petabytes of data, but may incur latencies of 100-500 ms for online inference due to network delays.</p>
<p><strong>Edge ML</strong>: As the need for real-time, low-latency processing grew, Edge ML emerged. This paradigm brings inference capabilities closer to the data source, typically on edge devices such as industrial gateways, smart cameras, autonomous vehicles, or IoT hubs. Edge ML reduces latency (often to less than 50 ms), enhances privacy by keeping data local, and can operate with intermittent cloud connectivity. It’s particularly useful for applications requiring quick responses or handling sensitive data in industrial or enterprise settings. Frameworks like NVIDIA Jetson or Google’s Edge TPU enable powerful ML capabilities on edge devices. Edge ML plays a crucial role in IoT ecosystems, enabling real-time decision making and reducing bandwidth usage by processing data locally.</p>
<p><strong>Mobile ML</strong>: Building on edge computing concepts, Mobile ML focuses on leveraging the computational capabilities of smartphones and tablets. This approach enables personalized, responsive applications while reducing reliance on constant network connectivity. Mobile ML offers a balance between the power of edge computing and the ubiquity of personal devices. It utilizes on-device sensors (e.g., cameras, GPS, accelerometers) for unique ML applications. Frameworks like TensorFlow Lite and Core ML allow developers to deploy optimized models on mobile devices, with inference times often under 30 ms for common tasks. Mobile ML enhances privacy by keeping personal data on the device and can operate offline, but must balance model performance with device resource constraints (typically 4-8 GB RAM, 100-200 GB storage).</p>
<p><strong>Tiny ML</strong>: The latest development in this progression is Tiny ML, which enables ML models to run on extremely resource-constrained microcontrollers and small embedded systems. Tiny ML allows for on-device inference without relying on connectivity to the cloud, edge, or even the processing power of mobile devices. This approach is crucial for applications where size, power consumption, and cost are critical factors. Tiny ML devices typically operate with less than 1 MB of RAM and flash memory, consuming only milliwatts of power, enabling battery life of months or years. Applications include wake word detection, gesture recognition, and predictive maintenance in industrial settings. Platforms like Arduino Nano 33 BLE Sense and STM32 microcontrollers, coupled with frameworks like TensorFlow Lite for Microcontrollers, enable ML on these tiny devices. However, Tiny ML requires significant model optimization and quantization to fit within these constraints.</p>
<p>Each of these paradigms has its own strengths and is suited to different use cases:</p>
<ul>
<li>Cloud ML remains essential for tasks requiring massive computational power or large-scale data analysis.</li>
<li>Edge ML is ideal for applications needing low-latency responses or local data processing in industrial or enterprise environments.</li>
<li>Mobile ML is suited for personalized, responsive applications on smartphones and tablets.</li>
<li>Tiny ML enables AI capabilities in small, power-efficient devices, expanding the reach of ML to new domains.</li>
</ul>
<p>This progression reflects a broader trend in computing towards more distributed, localized, and specialized processing. The evolution is driven by the need for faster response times, improved privacy, reduced bandwidth usage, and the ability to operate in environments with limited or no connectivity, while also catering to the specific capabilities and constraints of different types of devices.</p>
<div id="fig-vMLsizes" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-vMLsizes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb2"><pre class="sourceCode tikz code-with-copy"><code class="sourceCode latex"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}[font=<span class="fu">\small\usefont</span>{T1}{phv}{m}{n}]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span>{</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Line/.style={red,line width=1.0pt,text=black},</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  Box/.style={inner xsep=2pt,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    node distance=1.1,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    draw=none,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    line width=0.75pt,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    fill=none,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    text width=22mm,align=flush center,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    minimum width=22mm, minimum height=11mm</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  Box1/.style={Box,node distance=0.25, minimum height=5mm},</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  Box2/.style={Box,node distance=0.45, minimum height=5mm}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box](B0){};</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,right=0 of B0](B1){<span class="fu">\textbf</span>{Cloud AI}<span class="fu">\\</span>(NVIDIA V100)};</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,right=of B1](B2){<span class="fu">\textbf</span>{Mobile AI}<span class="fu">\\</span>(iPhone 11)};</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,right=of B2](B3){<span class="fu">\textbf</span>{Tiny AI}<span class="fu">\\</span>(STM32F746)};</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box, right=of B3](B4){<span class="fu">\textbf</span>{ResNet-50}};</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box, right=0 of B4](B5){<span class="fu">\textbf</span>{MobileNetV2}};</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box, right=0 of B5](B6){<span class="fu">\textbf</span>{MobileNetV2}<span class="fu">\\</span> (int8)};</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co">%%%%</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B0](B20){<span class="fu">\textbf</span>{Memory}};</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B1](B21){16 GB};</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B2](B22){4 GB};</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B3](B23){<span class="fu">\textbf</span>{320 kB}};</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B4](B24){7.2 MB};</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B5](B25){6.8 MB};</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box2,below=of B6](B26){1.7 MB};</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="co">%%%%</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B20](B30){<span class="fu">\textbf</span>{Storage}};</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B21](B31){TB <span class="ss">$</span><span class="sc">\sim</span><span class="ss">$</span> PB};</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B22](B32){&gt; 64 GB};</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B23](B33){<span class="fu">\textbf</span>{1 MB}};</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B24](B34){102 MB};</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B25](B35){13.6 MB};</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B26](B36){3.4 MB};</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co">%%</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(GL)at(<span class="ss">$(B0.north west)+(0,0)$</span>);</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(GD)at(<span class="ss">$(B6.north east)+(0,0)$</span>);</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(DL)at(<span class="ss">$(B30.south west)+(0,0)$</span>);</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(DD)at(<span class="ss">$(B36.south east)+(0,0)$</span>);</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(SL)at(<span class="ss">$(B0.south west)!0.0!(B20.north west)$</span>);</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="fu">\coordinate</span>(SD)at(<span class="ss">$(B6.south east)!0.0!(B26.north east)$</span>);</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex,shorten &gt;=-6pt,shorten &lt;=-6pt](B21)--node[above]{4<span class="ss">$</span><span class="sc">\times</span><span class="ss">$</span>}(B22);</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex,shorten &gt;=-6pt,shorten &lt;=-6pt](B22)--node[above]{3100<span class="ss">$</span><span class="sc">\times</span><span class="ss">$</span>}(B23);</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,latex-latex,shorten &gt;=-9pt,shorten &lt;=-9pt](B23)--</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>node[above](GAG){gap}(B24);</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex,shorten &gt;=-6pt,shorten &lt;=-6pt](B31)--node[above]{1000<span class="ss">$</span><span class="sc">\times</span><span class="ss">$</span>}(B32);</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex,shorten &gt;=-6pt,shorten &lt;=-6pt](B32)--node[above]{6400<span class="ss">$</span><span class="sc">\times</span><span class="ss">$</span>}(B33);</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,latex-latex,shorten &gt;=-9pt,shorten &lt;=-9pt](B33)--</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>node[above](GAD){gap}(B34);</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](GL)-|coordinate(GS)(GAG);</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](DL)-|coordinate(DS)(GAD);</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[red](SL)-|coordinate(SS)(GAD);</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[line width=1.75pt,shorten &gt;=5pt](DL)--(DS);</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[line width=1.75pt,shorten &gt;=5pt](GL)--(GS);</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[line width=1.0pt,shorten &gt;=5pt](SL)--(SS);</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a><span class="co">%%</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[line width=1.75pt,shorten &gt;=5pt](DD)--(DS);</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[line width=1.75pt,shorten &gt;=5pt](GD)--(GS);</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[line width=1.0pt,shorten &gt;=5pt](SD)--(SS);</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=none,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>      anchor=west,yshift=0mm,fill=cyan!10,fit=(GL)(DD)](BB){};</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[single arrow, draw=none, fill=red,inner sep=2pt,</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>      minimum width = 14pt, single arrow head extend=3pt,</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>      minimum height=8mm]at(<span class="ss">$(B1)!0.5!(B2)$</span>) {};</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>      <span class="fu">\node</span>[single arrow, draw=none, fill=red,inner sep=2pt,</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>      minimum width = 14pt, single arrow head extend=3pt,</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>      minimum height=8mm]at(<span class="ss">$(B2)!0.5!(B3)$</span>) {};</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vMLsizes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: From cloud GPUs to microcontrollers: Navigating the memory and storage landscape across computing devices. Source: <span class="citation" data-cites="lin2023tiny">(<a href="../../backmatter/references.html#ref-lin2023tiny" role="doc-biblioref">Lin et al. 2023</a>)</span>
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-lin2023tiny" class="csl-entry" role="listitem">
Lin, Ji, Ligeng Zhu, Wei-Ming Chen, Wei-Chen Wang, and Song Han. 2023. <span>“Tiny Machine Learning: Progress and Futures [Feature].”</span> <em>IEEE Circuits and Systems Magazine</em> 23 (3): 8–34. <a href="https://doi.org/10.1109/mcas.2023.3302182">https://doi.org/10.1109/mcas.2023.3302182</a>.
</div></div></figure>
</div>
<p><a href="#fig-vMLsizes" class="quarto-xref">Figure&nbsp;<span>2.2</span></a> illustrates the key differences between Cloud ML, Edge ML, Mobile ML, and Tiny ML in terms of hardware, latency, connectivity, power requirements, and model complexity. As we move from Cloud to Edge to Tiny ML, we see a dramatic reduction in available resources, which presents significant challenges for deploying sophisticated machine learning models. This resource disparity becomes particularly apparent when attempting to deploy deep learning models on microcontrollers, the primary hardware platform for Tiny ML. These tiny devices have severely constrained memory and storage capacities, which are often insufficient for conventional deep learning models. We will learn to put these things into perspective in this chapter.</p>
</section>
<section id="sec-ml-systems-cloudbased-machine-learning-52c3" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-ml-systems-cloudbased-machine-learning-52c3"><span class="header-section-number">2.2</span> Cloud-Based Machine Learning</h2>
<p>The vast computational demands of modern machine learning often require the scalability and power of centralized cloud infrastructures. Cloud Machine Learning (Cloud ML) handles tasks such as large-scale data processing, collaborative model development, and advanced analytics. Cloud data centers leverage distributed architectures, offering specialized resources to train complex models and support diverse applications, from recommendation systems to natural language processing.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Definition of Cloud ML">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of Cloud ML
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Cloud Machine Learning (Cloud ML)</strong> refers to the deployment of machine learning models on <em>centralized computing infrastructures</em>, such as data centers. These systems operate in the <em>kilowatt to megawatt</em> power range and utilize <em>specialized computing systems</em> to handle <em>large-scale datasets</em> and train <em>complex models</em>. Cloud ML offers <em>scalability</em> and <em>computational capacity</em>, making it well-suited for tasks requiring extensive resources and collaboration. However, it depends on <em>consistent connectivity</em> and may introduce <em>latency</em> for real-time applications.</p>
</div>
</div>
<p><a href="#fig-cloud-ml" class="quarto-xref">Figure&nbsp;<span>2.3</span></a> provides an overview of Cloud ML’s capabilities, which we will discuss in greater detail throughout this section.</p>
<div id="fig-cloud-ml" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cloud-ml-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/cloudml.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2.3: Section overview for Cloud ML."><img src="images/png/cloudml.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cloud-ml-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: Section overview for Cloud ML.
</figcaption>
</figure>
</div>
<div id="sec-sec-ml-systems-cloudbased-machine-learning-52c3" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 1</strong></summary><div>
<ol type="1">
<li><p>Which of the following is a key characteristic of Cloud Machine Learning?</p>
<ol type="a">
<li>Decentralized infrastructure</li>
<li>Limited scalability</li>
<li>Centralized infrastructure</li>
<li>High latency</li>
</ol></li>
<li><p>True or False: Cloud ML eliminates the need for organizations to consider data privacy and security.</p></li>
<li><p>Explain how Cloud ML can be both cost-effective and potentially costly for organizations.</p></li>
<li><p>Cloud ML’s ability to handle large datasets and complex computations makes it particularly suitable for tasks such as ______ and natural language processing.</p></li>
<li><p>Order the following steps in addressing latency challenges in Cloud ML: [Implement robust security measures, Optimize network infrastructure, Minimize data transmission, Design for low latency]</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-cloudbased-machine-learning-52c3-answer">See Answer →</a></p>
</div></details>
</div>
<section id="sec-ml-systems-characteristics-1648" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="sec-ml-systems-characteristics-1648"><span class="header-section-number">2.2.1</span> Characteristics</h3>
<p>One of the key characteristics of Cloud ML is its centralized infrastructure. <a href="#fig-cloudml-example" class="quarto-xref">Figure&nbsp;<span>2.4</span></a> illustrates this concept with an example from Google’s Cloud TPU data center. Cloud service providers offer a <strong>virtual platform</strong> that consists of high-capacity servers, expansive storage solutions, and robust networking architectures, all housed in data centers distributed across the globe. As shown in the figure, these centralized facilities can be massive in scale, housing rows upon rows of specialized hardware. This centralized setup allows for the pooling and efficient management of computational resources, making it easier to scale machine learning projects as needed.</p>
<div id="fig-cloudml-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cloudml-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/cloud_ml_tpu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;2.4: Cloud TPU data center at Google. Source: Google."><img src="images/png/cloud_ml_tpu.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cloudml-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Cloud TPU data center at Google. Source: <a href="https://blog.google/technology/ai/google-gemini-ai/#scalable-efficient">Google.</a>
</figcaption>
</figure>
</div>
<p>Cloud ML excels in its ability to process and analyze massive volumes of data. The centralized infrastructure is designed to handle complex computations and <a href="../../../contents/core/training/training.html">model training</a> tasks that require significant computational power. By leveraging the scalability of the cloud, machine learning models can be trained on vast amounts of data, leading to improved learning capabilities and predictive performance.</p>
<p>Another advantage of Cloud ML is the flexibility it offers in terms of deployment and accessibility. Once a machine learning model is trained and validated, it can be deployed through cloud-based APIs and services, making it accessible to users worldwide. This enables seamless integration of ML capabilities into applications across mobile, web, and IoT platforms, regardless of the end user’s computational resources.</p>
<p>Cloud ML promotes collaboration and resource sharing among teams and organizations. The centralized nature of the cloud infrastructure enables multiple data scientists and engineers to access and work on the same machine learning projects simultaneously. This collaborative approach facilitates knowledge sharing, accelerates the development cycle from experimentation to production, and optimizes resource utilization across teams.</p>
<p>By leveraging the pay-as-you-go pricing model offered by cloud service providers, Cloud ML allows organizations to avoid the upfront capital expenditure associated with building and maintaining dedicated ML infrastructure. The ability to scale resources up during intensive training periods and down during lower demand ensures cost-effectiveness and financial flexibility in managing machine learning projects.</p>
<p>Cloud ML has revolutionized the way machine learning is approached, democratizing access to advanced AI capabilities and making them more accessible, scalable, and efficient. It has enabled organizations of all sizes to harness the power of machine learning without requiring specialized hardware expertise or significant infrastructure investments.</p>
</section>
<section id="sec-ml-systems-benefits-981f" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="sec-ml-systems-benefits-981f"><span class="header-section-number">2.2.2</span> Benefits</h3>
<p>Cloud ML offers several significant benefits that make it a powerful choice for machine learning projects:</p>
<p>One of the key advantages of Cloud ML is its ability to provide vast computational resources. The cloud infrastructure is designed to handle complex algorithms and process large datasets efficiently. This is particularly beneficial for machine learning models that require significant computational power, such as deep learning networks or models trained on massive datasets. By leveraging the cloud’s computational capabilities, organizations can overcome the limitations of local hardware setups and scale their machine learning projects to meet demanding requirements.</p>
<p>Cloud ML offers dynamic scalability, allowing organizations to easily adapt to changing computational needs. As the volume of data grows or the complexity of machine learning models increases, the cloud infrastructure can seamlessly scale up or down to accommodate these changes. This flexibility ensures consistent performance and enables organizations to handle varying workloads without the need for extensive hardware investments. With Cloud ML, resources can be allocated on-demand, providing a cost-effective and efficient solution for managing machine learning projects.</p>
<p>Cloud ML platforms provide access to a wide range of advanced tools and algorithms specifically designed for machine learning. These tools often include pre-built models, AutoML capabilities, and specialized APIs that simplify the development and deployment of machine learning solutions. Developers can leverage these resources to accelerate the building, training, and optimization of sophisticated models. By utilizing the latest advancements in machine learning algorithms and techniques, organizations can implement state-of-the-art solutions without needing to develop them from scratch.</p>
<p>Cloud ML fosters a collaborative environment that enables teams to work together seamlessly. The centralized nature of the cloud infrastructure allows multiple data scientists and engineers to access and contribute to the same machine learning projects simultaneously. This collaborative approach facilitates knowledge sharing, promotes cross-functional collaboration, and accelerates the development and iteration of machine learning models. Teams can easily share code, datasets, and results through version control and project management tools integrated with cloud platforms.</p>
<p>Adopting Cloud ML can be a cost-effective solution for organizations, especially compared to building and maintaining an on-premises machine learning infrastructure. Cloud service providers offer flexible pricing models, such as pay-as-you-go or subscription-based plans, allowing organizations to pay only for the resources they consume. This eliminates the need for upfront capital investments in specialized hardware like GPUs and TPUs, reducing the overall cost of implementing machine learning projects. Additionally, the ability to automatically scale down resources during periods of low utilization ensures organizations only pay for what they actually use.</p>
<p>The benefits of Cloud ML, including its immense computational power, dynamic scalability, access to advanced tools and algorithms, collaborative environment, and cost-effectiveness, make it a compelling choice for organizations looking to harness the potential of machine learning. By leveraging the capabilities of the cloud, organizations can accelerate their machine learning initiatives, drive innovation, and gain a competitive edge in today’s data-driven landscape.</p>
</section>
<section id="sec-ml-systems-challenges-6897" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="sec-ml-systems-challenges-6897"><span class="header-section-number">2.2.3</span> Challenges</h3>
<p>While Cloud ML offers numerous benefits, it also comes with certain challenges that organizations need to consider:</p>
<p>Latency is a primary concern in Cloud ML, particularly for applications requiring real-time responses. The process of transmitting data to centralized cloud servers for processing and then back to applications introduces delays. This can significantly impact time-sensitive scenarios like autonomous vehicles, real-time fraud detection, and industrial control systems where immediate decision-making is crucial. Organizations must implement careful system design to minimize latency and ensure acceptable response times.</p>
<p>Data privacy and security represent critical challenges when centralizing processing and storage in the cloud. Sensitive data transmitted to remote data centers becomes potentially vulnerable to cyber-attacks and unauthorized access. Cloud environments often attract hackers seeking to exploit vulnerabilities in valuable information repositories. Organizations must implement robust security measures including encryption, strict access controls, and continuous monitoring. Additionally, compliance with regulations like GDPR or HIPAA becomes increasingly complex when handling sensitive data in cloud environments.</p>
<p>Cost management becomes increasingly important as data processing requirements grow. Although Cloud ML provides scalability and flexibility, organizations processing large data volumes may experience escalating costs with increased cloud resource consumption. The pay-as-you-go pricing model can quickly accumulate expenses, especially for compute-intensive operations like model training and inference. Effective cloud adoption requires careful monitoring and optimization of usage patterns. Organizations should consider implementing data compression techniques, efficient algorithmic design, and resource allocation optimization to balance cost-effectiveness with performance requirements.</p>
<p>Network dependency presents another significant challenge for Cloud ML implementations. The requirement for stable and reliable internet connectivity means that any disruptions in network availability directly impact system performance. This dependency becomes particularly problematic in environments with limited, unreliable, or expensive network access. Building resilient ML systems requires robust network infrastructure complemented by appropriate failover mechanisms or offline processing capabilities.</p>
<p>Vendor lock-in often emerges as organizations adopt specific tools, APIs, and services from their chosen cloud provider. This dependency can complicate future transitions between providers or platform migrations. Organizations may encounter challenges with portability, interoperability, and cost implications when considering changes to their cloud ML infrastructure. Strategic planning should include careful evaluation of vendor offerings, consideration of long-term goals, and preparation for potential migration scenarios to mitigate lock-in risks.</p>
<p>Addressing these challenges requires thorough planning, thoughtful architectural design, and comprehensive risk mitigation strategies. Organizations must balance Cloud ML benefits against potential challenges based on their specific requirements, data sensitivity concerns, and business objectives. Proactive approaches to these challenges enable organizations to effectively leverage Cloud ML while maintaining data privacy, security, cost-effectiveness, and system reliability.</p>
</section>
<section id="sec-ml-systems-use-cases-02a3" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="sec-ml-systems-use-cases-02a3"><span class="header-section-number">2.2.4</span> Use Cases</h3>
<p>Cloud ML has found widespread adoption across various domains, revolutionizing the way businesses operate and users interact with technology. Let’s explore some notable examples of Cloud ML in action:</p>
<p>Cloud ML plays a crucial role in powering virtual assistants like Siri and Alexa. These systems leverage the immense computational capabilities of the cloud to process and analyze voice inputs in real-time. By harnessing the power of natural language processing and machine learning algorithms, virtual assistants can understand user queries, extract relevant information, and generate intelligent and personalized responses. The cloud’s scalability and processing power enable these assistants to handle a vast number of user interactions simultaneously, providing a seamless and responsive user experience.</p>
<p>Cloud ML forms the backbone of advanced recommendation systems used by platforms like Netflix and Amazon. These systems use the cloud’s ability to process and analyze massive datasets to uncover patterns, preferences, and user behavior. By leveraging collaborative filtering and other machine learning techniques, recommendation systems can offer personalized content or product suggestions tailored to each user’s interests. The cloud’s scalability allows these systems to continuously update and refine their recommendations based on the ever-growing amount of user data, enhancing user engagement and satisfaction.</p>
<p>In the financial industry, Cloud ML has revolutionized fraud detection systems. By leveraging the cloud’s computational power, these systems can analyze vast amounts of transactional data in real-time to identify potential fraudulent activities. Machine learning algorithms trained on historical fraud patterns can detect anomalies and suspicious behavior, enabling financial institutions to take proactive measures to prevent fraud and minimize financial losses. The cloud’s ability to process and store large volumes of data makes it an ideal platform for implementing robust and scalable fraud detection systems.</p>
<p>Cloud ML is deeply integrated into our online experiences, shaping the way we interact with digital platforms. From personalized ads on social media feeds to predictive text features in email services, Cloud ML powers smart algorithms that enhance user engagement and convenience. It enables e-commerce sites to recommend products based on a user’s browsing and purchase history, fine-tunes search engines to deliver accurate and relevant results, and automates the tagging and categorization of photos on platforms like Facebook. By leveraging the cloud’s computational resources, these systems can continuously learn and adapt to user preferences, providing a more intuitive and personalized user experience.</p>
<p>Cloud ML plays a role in bolstering user security by powering anomaly detection systems. These systems continuously monitor user activities and system logs to identify unusual patterns or suspicious behavior. By analyzing vast amounts of data in real-time, Cloud ML algorithms can detect potential cyber threats, such as unauthorized access attempts, malware infections, or data breaches. The cloud’s scalability and processing power enable these systems to handle the increasing complexity and volume of security data, providing a proactive approach to protecting users and systems from potential threats.</p>
</section>
</section>
<section id="sec-ml-systems-edge-machine-learning-52c5" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-ml-systems-edge-machine-learning-52c5"><span class="header-section-number">2.3</span> Edge Machine Learning</h2>
<p>As machine learning applications grow, so does the need for faster, localized decision-making. Edge Machine Learning (Edge ML) shifts computation away from centralized servers, processing data closer to its source. This paradigm is critical for time-sensitive applications, such as autonomous systems, industrial IoT, and smart infrastructure, where minimizing latency and preserving data privacy are paramount. Edge devices, like gateways and IoT hubs, enable these systems to function efficiently while reducing dependence on cloud infrastructures.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Definition of Edge ML">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of Edge ML
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Edge Machine Learning (Edge ML)</strong> describes the deployment of machine learning models at or near the <em>edge of the network</em>. These systems operate in the <em>tens to hundreds of watts</em> range and rely on <em>localized hardware</em> optimized for <em>real-time processing</em>. Edge ML minimizes <em>latency</em> and enhances <em>privacy</em> by processing data locally, but its primary limitation lies in <em>restricted computational resources</em>.</p>
</div>
</div>
<p><a href="#fig-edge-ml" class="quarto-xref">Figure&nbsp;<span>2.5</span></a> provides an overview of this section.</p>
<div id="fig-edge-ml" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edge-ml-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/edgeml.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;2.5: Section overview for Edge ML."><img src="images/png/edgeml.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-edge-ml-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: Section overview for Edge ML.
</figcaption>
</figure>
</div>
<div id="sec-sec-ml-systems-edge-machine-learning-52c5" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 2</strong></summary><div>
<ol type="1">
<li><p>Which of the following is a primary advantage of Edge Machine Learning over Cloud Machine Learning?</p>
<ol type="a">
<li>Higher computational power</li>
<li>Reduced latency</li>
<li>Unlimited data storage</li>
<li>Simplified network management</li>
</ol></li>
<li><p>True or False: Edge ML inherently provides better data privacy compared to Cloud ML.</p></li>
<li><p>Explain one major challenge of deploying Edge ML systems in industrial IoT environments.</p></li>
<li><p>Edge ML is particularly beneficial for applications requiring ______ processing and decision-making.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-edge-machine-learning-52c5-answer">See Answer →</a></p>
</div></details>
</div>
<section id="sec-ml-systems-characteristics-40ab" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="sec-ml-systems-characteristics-40ab"><span class="header-section-number">2.3.1</span> Characteristics</h3>
<p>In Edge ML, data processing happens in a decentralized fashion, as illustrated in <a href="#fig-edgeml-example" class="quarto-xref">Figure&nbsp;<span>2.6</span></a>. Instead of sending data to remote servers, the data is processed locally on devices like smartphones, tablets, or Internet of Things (IoT) devices. The figure showcases various examples of these edge devices, including wearables, industrial sensors, and smart home appliances. This local processing allows devices to make quick decisions based on the data they collect without relying heavily on a central server’s resources.</p>
<div id="fig-edgeml-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edgeml-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/jpg/edge_ml_iot.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;2.6: Edge ML Examples. Source: Edge Impulse."><img src="images/jpg/edge_ml_iot.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-edgeml-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: Edge ML Examples. Source: Edge Impulse.
</figcaption>
</figure>
</div>
<p>Local data storage and computation are key features of Edge ML. This setup ensures that data can be stored and analyzed directly on the devices, thereby maintaining the privacy of the data and reducing the need for constant internet connectivity. Moreover, this approach reduces latency in decision-making processes, as computations occur closer to where data is generated. This proximity not only enhances real-time capabilities but also often results in more efficient resource utilization, as data doesn’t need to travel across networks, saving bandwidth and energy consumption.</p>
</section>
<section id="sec-ml-systems-benefits-2d74" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="sec-ml-systems-benefits-2d74"><span class="header-section-number">2.3.2</span> Benefits</h3>
<p>One of Edge ML’s main advantages is the significant latency reduction compared to Cloud ML. This reduced latency can be a critical benefit in situations where milliseconds count, such as in autonomous vehicles, where quick decision-making can mean the difference between safety and an accident.</p>
<p>Edge ML also offers improved data privacy, as data is primarily stored and processed locally. This minimizes the risk of data breaches that are more common in centralized data storage solutions. Sensitive information can be kept more secure, as it’s not sent over networks that could be intercepted.</p>
<p>Operating closer to the data source means less data must be sent over networks, reducing bandwidth usage. This can result in cost savings and efficiency gains, especially in environments where bandwidth is limited or costly.</p>
</section>
<section id="sec-ml-systems-challenges-7d58" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="sec-ml-systems-challenges-7d58"><span class="header-section-number">2.3.3</span> Challenges</h3>
<p>However, Edge ML has its challenges. One of the main concerns is the limited computational resources compared to cloud-based solutions. Endpoint devices may have a different processing power or storage capacity than cloud servers, limiting the complexity of the machine learning models that can be deployed.</p>
<p>Managing a network of edge nodes can introduce complexity, especially regarding coordination, updates, and maintenance. Ensuring all nodes operate seamlessly and are up-to-date with the latest algorithms and security protocols can be a logistical challenge.</p>
<p>While Edge ML offers enhanced data privacy, edge nodes can sometimes be more vulnerable to physical and cyber-attacks. Developing robust security protocols that protect data at each node without compromising the system’s efficiency remains a significant challenge in deploying Edge ML solutions.</p>
</section>
<section id="sec-ml-systems-use-cases-c403" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="sec-ml-systems-use-cases-c403"><span class="header-section-number">2.3.4</span> Use Cases</h3>
<p>Edge ML has many applications, from autonomous vehicles and smart homes to industrial Internet of Things (IoT). These examples were chosen to highlight scenarios where real-time data processing, reduced latency, and enhanced privacy are not just beneficial but often critical to the operation and success of these technologies. They demonstrate the role that Edge ML can play in driving advancements in various sectors, fostering innovation, and paving the way for more intelligent, responsive, and adaptive systems.</p>
<p>Autonomous vehicles stand as a prime example of Edge ML’s potential. These vehicles rely heavily on real-time data processing to navigate and make decisions. Localized machine learning models assist in quickly analyzing data from various sensors to make immediate driving decisions, ensuring safety and smooth operation.</p>
<p>Edge ML plays a crucial role in efficiently managing various systems in smart homes and buildings, from lighting and heating to security. By processing data locally, these systems can operate more responsively and harmoniously with the occupants’ habits and preferences, creating a more comfortable living environment.</p>
<p>The Industrial IoT leverages Edge ML to monitor and control complex industrial processes. Here, machine learning models can analyze data from numerous sensors in real-time, enabling predictive maintenance, optimizing operations, and enhancing safety measures. This revolution in industrial automation and efficiency is transforming manufacturing and production across various sectors.</p>
<p>The applicability of Edge ML is vast and not limited to these examples. Various other sectors, including healthcare, agriculture, and urban planning, are exploring and integrating Edge ML to develop innovative solutions responsive to real-world needs and challenges, heralding a new era of smart, interconnected systems.</p>
</section>
</section>
<section id="sec-ml-systems-mobile-machine-learning-dbe8" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-ml-systems-mobile-machine-learning-dbe8"><span class="header-section-number">2.4</span> Mobile Machine Learning</h2>
<p>Machine learning is increasingly being integrated into portable devices like smartphones and tablets, empowering users with real-time, personalized capabilities. Mobile Machine Learning (Mobile ML) supports applications like voice recognition, computational photography, and health monitoring, all while maintaining data privacy through on-device computation. These battery-powered devices are optimized for responsiveness and can operate offline, making them indispensable in everyday consumer technologies.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Definition of Mobile ML">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of Mobile ML
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Mobile Machine Learning (Mobile ML)</strong> enables machine learning models to run directly on <em>portable, battery-powered devices</em> like smartphones and tablets. Operating within the <em>single-digit to tens of watts</em> range, Mobile ML leverages <em>on-device computation</em> to provide <em>personalized and responsive applications</em>. This paradigm preserves <em>privacy</em> and ensures <em>offline functionality</em>, though it must balance <em>performance</em> with <em>battery and storage limitations</em>.</p>
</div>
</div>
<div id="sec-sec-ml-systems-mobile-machine-learning-dbe8" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 3</strong></summary><div>
<ol type="1">
<li><p>What is a key advantage of Mobile ML compared to Cloud ML?</p>
<ol type="a">
<li>Higher computational power</li>
<li>Enhanced data privacy</li>
<li>Unlimited storage capacity</li>
<li>Constant internet connectivity</li>
</ol></li>
<li><p>True or False: Mobile ML applications can operate offline, making them less dependent on network conditions.</p></li>
<li><p>Explain one major challenge developers face when implementing Mobile ML on battery-powered devices.</p></li>
<li><p>Mobile ML utilizes specialized hardware such as ______ to efficiently execute ML models on devices.</p></li>
<li><p>How does Mobile ML enhance the user experience on smartphones?</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-mobile-machine-learning-dbe8-answer">See Answer →</a></p>
</div></details>
</div>
<section id="sec-ml-systems-characteristics-c512" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="sec-ml-systems-characteristics-c512"><span class="header-section-number">2.4.1</span> Characteristics</h3>
<p>Mobile ML utilizes the processing power of mobile devices’ System-on-Chip (SoC) architectures, including specialized Neural Processing Units (NPUs) and AI accelerators. This enables efficient execution of ML models directly on the device, allowing for real-time processing of data from device sensors like cameras, microphones, and motion sensors without constant cloud connectivity.</p>
<p>Mobile ML is supported by specialized frameworks and tools designed specifically for mobile deployment, such as TensorFlow Lite for Android devices and Core ML for iOS devices. These frameworks are optimized for mobile hardware and provide efficient model compression and quantization techniques to ensure smooth performance within mobile resource constraints.</p>
</section>
<section id="sec-ml-systems-benefits-de8e" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="sec-ml-systems-benefits-de8e"><span class="header-section-number">2.4.2</span> Benefits</h3>
<p>Mobile ML enables real-time processing of data directly on mobile devices, eliminating the need for constant server communication. This results in faster response times for applications requiring immediate feedback, such as real-time translation, face detection, or gesture recognition.</p>
<p>By processing data locally on the device, Mobile ML helps maintain user privacy. Sensitive information doesn’t need to leave the device, reducing the risk of data breaches and addressing privacy concerns, particularly important for applications handling personal data.</p>
<p>Mobile ML applications can function without constant internet connectivity, making them reliable in areas with poor network coverage or when users are offline. This ensures consistent performance and user experience regardless of network conditions.</p>
</section>
<section id="sec-ml-systems-challenges-de63" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="sec-ml-systems-challenges-de63"><span class="header-section-number">2.4.3</span> Challenges</h3>
<p>Despite modern mobile devices being powerful, they still face resource constraints compared to cloud servers. Mobile ML must operate within limited RAM, storage, and processing power, requiring careful optimization of models and efficient resource management.</p>
<p>ML operations can be computationally intensive, potentially impacting device battery life. Developers must balance model complexity and performance with power consumption to ensure reasonable battery life for users.</p>
<p>Mobile devices have limited storage space, necessitating careful consideration of model size. This often requires model compression and quantization techniques, which can affect model accuracy and performance.</p>
</section>
<section id="sec-ml-systems-use-cases-59ec" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="sec-ml-systems-use-cases-59ec"><span class="header-section-number">2.4.4</span> Use Cases</h3>
<p>Mobile ML has revolutionized how we use cameras on mobile devices, enabling sophisticated computer vision applications that process visual data in real-time. Modern smartphone cameras now incorporate ML models that can detect faces, analyze scenes, and apply complex filters instantaneously. These models work directly on the camera feed to enable features like portrait mode photography, where ML algorithms separate foreground subjects from backgrounds. Document scanning applications use ML to detect paper edges, correct perspective, and enhance text readability, while augmented reality applications use ML-powered object detection to accurately place virtual objects in the real world.</p>
<p>Natural language processing on mobile devices has transformed how we interact with our phones and communicate with others. Speech recognition models run directly on device, enabling voice assistants to respond quickly to commands even without internet connectivity. Real-time translation applications can now translate conversations and text without sending data to the cloud, preserving privacy and working reliably regardless of network conditions. Mobile keyboards have become increasingly intelligent, using ML to predict not just the next word but entire phrases based on the user’s writing style and context, while maintaining all learning and personalization locally on the device.</p>
<p>Mobile ML has enabled smartphones and tablets to become sophisticated health monitoring devices. Through clever use of existing sensors combined with ML models, mobile devices can now track physical activity, analyze sleep patterns, and monitor vital signs. For example, cameras can measure heart rate by detecting subtle color changes in the user’s skin, while accelerometers and ML models work together to recognize specific exercises and analyze workout form. These applications process sensitive health data directly on the device, ensuring privacy while providing users with real-time feedback and personalized health insights.</p>
<p>Perhaps the most pervasive but least visible application of Mobile ML lies in how it personalizes and enhances the overall user experience. ML models continuously analyze how users interact with their devices to optimize everything from battery usage to interface layouts. These models learn individual usage patterns to predict which apps users are likely to open next, preload content they might want to see, and adjust system settings like screen brightness and audio levels based on environmental conditions and user preferences. This creates a deeply personalized experience that adapts to each user’s needs while maintaining privacy by keeping all learning and adaptation on the device itself.</p>
<p>These applications demonstrate how Mobile ML bridges the gap between cloud-based solutions and edge computing, providing efficient, privacy-conscious, and user-friendly machine learning capabilities on personal mobile devices. The continuous advancement in mobile hardware capabilities and optimization techniques continues to expand the possibilities for Mobile ML applications.</p>
</section>
</section>
<section id="sec-ml-systems-tiny-machine-learning-ccce" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="sec-ml-systems-tiny-machine-learning-ccce"><span class="header-section-number">2.5</span> Tiny Machine Learning</h2>
<p>Tiny Machine Learning (Tiny ML) brings intelligence to the smallest devices, from microcontrollers to embedded sensors, enabling real-time computation in resource-constrained environments. These systems power applications such as predictive maintenance, environmental monitoring, and simple gesture recognition. Tiny ML devices are optimized for energy efficiency, often running for months or years on limited power sources, such as coin-cell batteries, while delivering actionable insights in remote or disconnected environments.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Definition of Tiny ML">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of Tiny ML
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Tiny Machine Learning (Tiny ML)</strong> refers to the execution of machine learning models on <em>ultra-constrained devices</em>, such as microcontrollers and sensors. These devices operate in the <em>milliwatt to sub-watt</em> power range, prioritizing <em>energy efficiency</em> and <em>compactness</em>. Tiny ML enables <em>localized decision-making</em> in resource-constrained environments, excelling in applications where <em>extended operation on limited power sources</em> is required. However, it is limited by <em>severely restricted computational resources</em>.</p>
</div>
</div>
<p><a href="#fig-tiny-ml" class="quarto-xref">Figure&nbsp;<span>2.7</span></a> encapsulates the key aspects of Tiny ML discussed in this section.</p>
<div id="fig-tiny-ml" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tiny-ml-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/tinyml.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;2.7: Section overview for Tiny ML."><img src="images/png/tinyml.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tiny-ml-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.7: Section overview for Tiny ML.
</figcaption>
</figure>
</div>
<div id="sec-sec-ml-systems-tiny-machine-learning-ccce" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 4</strong></summary><div>
<ol type="1">
<li><p>Which of the following is a primary benefit of using Tiny ML in resource-constrained environments?</p>
<ol type="a">
<li>Reduced computational accuracy</li>
<li>Increased data transmission costs</li>
<li>Ultra-low latency and enhanced data security</li>
<li>Dependence on external servers</li>
</ol></li>
<li><p>Explain why energy efficiency is critical for Tiny ML applications and how it is achieved.</p></li>
<li><p>True or False: Tiny ML devices can operate effectively without any need for model optimization or compression.</p></li>
<li><p>Tiny ML is particularly beneficial for applications requiring ______ decision-making in environments with limited connectivity.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-tiny-machine-learning-ccce-answer">See Answer →</a></p>
</div></details>
</div>
<section id="sec-ml-systems-characteristics-794b" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="sec-ml-systems-characteristics-794b"><span class="header-section-number">2.5.1</span> Characteristics</h3>
<p>In Tiny ML, the focus, much like in Mobile ML, is on on-device machine learning. This means that machine learning models are deployed and trained on the device, eliminating the need for external servers or cloud infrastructures. This allows Tiny ML to enable intelligent decision-making right where the data is generated, making real-time insights and actions possible, even in settings where connectivity is limited or unavailable.</p>
<p>Tiny ML excels in low-power and resource-constrained settings. These environments require highly optimized solutions that function within the available resources. <a href="#fig-TinyML-example" class="quarto-xref">Figure&nbsp;<span>2.8</span></a> showcases an example Tiny ML device kit, illustrating the compact nature of these systems. These devices can typically fit in the palm of your hand or, in some cases, are even as small as a fingernail. Tiny ML meets the need for efficiency through specialized algorithms and models designed to deliver decent performance while consuming minimal energy, thus ensuring extended operational periods, even in battery-powered devices like those shown.</p>
<div id="fig-TinyML-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-TinyML-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/jpg/tiny_ml.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;2.8: Examples of Tiny ML device kits. Source: Widening Access to Applied Machine Learning with Tiny ML."><img src="images/jpg/tiny_ml.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-TinyML-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.8: Examples of Tiny ML device kits. Source: <a href="https://arxiv.org/pdf/2106.04008.pdf">Widening Access to Applied Machine Learning with Tiny ML.</a>
</figcaption>
</figure>
</div>
</section>
<section id="sec-ml-systems-benefits-c373" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="sec-ml-systems-benefits-c373"><span class="header-section-number">2.5.2</span> Benefits</h3>
<p>One of the standout benefits of Tiny ML is its ability to offer ultra-low latency. Since computation occurs directly on the device, the time required to send data to external servers and receive a response is eliminated. This is crucial in applications requiring immediate decision-making, enabling quick responses to changing conditions.</p>
<p>Tiny ML inherently enhances data security. Because data processing and analysis happen on the device, the risk of data interception during transmission is virtually eliminated. This localized approach to data management ensures that sensitive information stays on the device, strengthening user data security.</p>
<p>Tiny ML operates within an energy-efficient framework, a necessity given its resource-constrained environments. By employing lean algorithms and optimized computational methods, Tiny ML ensures that devices can execute complex tasks without rapidly depleting battery life, making it a sustainable option for long-term deployments.</p>
</section>
<section id="sec-ml-systems-challenges-29ae" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3" class="anchored" data-anchor-id="sec-ml-systems-challenges-29ae"><span class="header-section-number">2.5.3</span> Challenges</h3>
<p>However, the shift to Tiny ML comes with its set of hurdles. The primary limitation is the devices’ constrained computational capabilities. The need to operate within such limits means that deployed models must be simplified, which could affect the accuracy and sophistication of the solutions.</p>
<p>Tiny ML also introduces a complicated development cycle. Crafting lightweight and effective models demands a deep understanding of machine learning principles and expertise in embedded systems. This complexity calls for a collaborative development approach, where multi-domain expertise is essential for success.</p>
<p>A central challenge in Tiny ML is model optimization and compression. Creating machine learning models that can operate effectively within the limited memory and computational power of microcontrollers requires innovative approaches to model design. Developers often face the challenge of striking a delicate balance and optimizing models to maintain effectiveness while fitting within stringent resource constraints.</p>
</section>
<section id="sec-ml-systems-use-cases-3173" class="level3" data-number="2.5.4">
<h3 data-number="2.5.4" class="anchored" data-anchor-id="sec-ml-systems-use-cases-3173"><span class="header-section-number">2.5.4</span> Use Cases</h3>
<p>In wearables, Tiny ML opens the door to smarter, more responsive gadgets. From fitness trackers offering real-time workout feedback to smart glasses processing visual data on the fly, Tiny ML transforms how we engage with wearable tech, delivering personalized experiences directly from the device.</p>
<p>In industrial settings, Tiny ML plays a significant role in predictive maintenance. By deploying Tiny ML algorithms on sensors that monitor equipment health, companies can preemptively identify potential issues, reducing downtime and preventing costly breakdowns. On-site data analysis ensures quick responses, potentially stopping minor issues from becoming major problems.</p>
<p>Tiny ML can be employed to create anomaly detection models that identify unusual data patterns. For instance, a smart factory could use Tiny ML to monitor industrial processes and spot anomalies, helping prevent accidents and improve product quality. Similarly, a security company could use Tiny ML to monitor network traffic for unusual patterns, aiding in detecting and preventing cyber-attacks. Tiny ML could monitor patient data for anomalies in healthcare, aiding early disease detection and better patient treatment.</p>
<p>In environmental monitoring, Tiny ML enables real-time data analysis from various field-deployed sensors. These could range from city air quality monitoring to wildlife tracking in protected areas. Through Tiny ML, data can be processed locally, allowing for quick responses to changing conditions and providing a nuanced understanding of environmental patterns, crucial for informed decision-making.</p>
<p>In summary, Tiny ML serves as a trailblazer in the evolution of machine learning, fostering innovation across various fields by bringing intelligence directly to the edge. Its potential to transform our interaction with technology and the world is immense, promising a future where devices are connected, intelligent, and capable of making real-time decisions and responses.</p>
</section>
</section>
<section id="sec-ml-systems-hybrid-machine-learning-6d02" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="sec-ml-systems-hybrid-machine-learning-6d02"><span class="header-section-number">2.6</span> Hybrid Machine Learning</h2>
<p>The increasingly complex demands of modern applications often require a blend of machine learning approaches. Hybrid Machine Learning (Hybrid ML) combines the computational power of the cloud, the efficiency of edge and mobile devices, and the compact capabilities of Tiny ML. This approach enables architects to create systems that balance performance, privacy, and resource efficiency, addressing real-world challenges with innovative, distributed solutions.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Definition of Hybrid ML">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definition of Hybrid ML
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Hybrid Machine Learning (Hybrid ML)</strong> refers to the integration of multiple ML paradigms, such as Cloud, Edge, Mobile, and Tiny ML, to form a unified, distributed system. These systems leverage the <em>complementary strengths</em> of each paradigm while addressing their <em>individual limitations</em>. Hybrid ML supports <em>scalability, adaptability,</em> and <em>privacy-preserving capabilities,</em> enabling sophisticated ML applications for diverse scenarios. By combining centralized and decentralized computing, Hybrid ML facilitates efficient resource utilization while meeting the demands of complex real-world requirements.</p>
</div>
</div>
<div id="sec-sec-ml-systems-hybrid-machine-learning-6d02" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 5</strong></summary><div>
<ol type="1">
<li><p>Which design pattern in Hybrid ML involves training models in the cloud and deploying them for inference on edge, mobile, or tiny devices?</p>
<ol type="a">
<li>Hierarchical Processing</li>
<li>Train-Serve Split</li>
<li>Federated Learning</li>
<li>Collaborative Learning</li>
</ol></li>
<li><p>Explain how the Hierarchical Processing pattern benefits smart city applications.</p></li>
<li><p>In the context of Hybrid ML, ______ learning involves devices sharing model updates rather than raw data to maintain privacy while improving a global model.</p></li>
<li><p>Order the following steps in a Progressive Deployment strategy: [Optimize model for edge devices, Train model in the cloud, Deploy model to mobile devices, Compress model for tiny sensors]</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-hybrid-machine-learning-6d02-answer">See Answer →</a></p>
</div></details>
</div>
<section id="sec-ml-systems-design-patterns-0b70" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="sec-ml-systems-design-patterns-0b70"><span class="header-section-number">2.6.1</span> Design Patterns</h3>
<p>Design patterns in Hybrid ML represent reusable solutions to common challenges faced when integrating multiple ML paradigms (cloud, edge, mobile, and tiny). These patterns guide system architects in combining the strengths of different approaches, including the computational power of the cloud and the efficiency of edge devices, while mitigating their individual limitations. By following these patterns, architects can address key trade-offs in performance, latency, privacy, and resource efficiency.</p>
<p>Hybrid ML design patterns serve as blueprints, enabling the creation of scalable, efficient, and adaptive systems tailored to diverse real-world applications. Each pattern reflects a specific strategy for organizing and deploying ML workloads across different tiers of a distributed system, ensuring optimal use of available resources while meeting application-specific requirements.</p>
<section id="sec-ml-systems-trainserve-split-33d9" class="level4">
<h4 class="anchored" data-anchor-id="sec-ml-systems-trainserve-split-33d9">Train-Serve Split</h4>
<p>One of the most common hybrid patterns is the train-serve split, where model training occurs in the cloud but inference happens on edge, mobile, or tiny devices. This pattern takes advantage of the cloud’s vast computational resources for the training phase while benefiting from the low latency and privacy advantages of on-device inference. For example, smart home devices often use models trained on large datasets in the cloud but run inference locally to ensure quick response times and protect user privacy. In practice, this might involve training models on powerful systems like the NVIDIA DGX A100, leveraging its 8 A100 GPUs and terabyte-scale memory, before deploying optimized versions to edge devices like the NVIDIA Jetson AGX Orin for efficient inference. Similarly, mobile vision models for computational photography are typically trained on powerful cloud infrastructure but deployed to run efficiently on phone hardware.</p>
</section>
<section id="sec-ml-systems-hierarchical-processing-d06a" class="level4">
<h4 class="anchored" data-anchor-id="sec-ml-systems-hierarchical-processing-d06a">Hierarchical Processing</h4>
<p>Hierarchical processing creates a multi-tier system where data and intelligence flow between different levels of the ML stack. In industrial IoT applications, tiny sensors might perform basic anomaly detection, edge devices aggregate and analyze data from multiple sensors, and cloud systems handle complex analytics and model updates. For instance, we might see ESP32-CAM devices performing basic image classification at the sensor level with their minimal 520 KB RAM, feeding data up to Jetson AGX Orin devices for more sophisticated computer vision tasks, and ultimately connecting to cloud infrastructure for complex analytics and model updates.</p>
<p>This hierarchy allows each tier to handle tasks appropriate to its capabilities. Tiny ML devices handle immediate, simple decisions; edge devices manage local coordination; and cloud systems tackle complex analytics and learning tasks. Smart city installations often use this pattern, with street-level sensors feeding data to neighborhood-level edge processors, which in turn connect to city-wide cloud analytics.</p>
</section>
<section id="sec-ml-systems-progressive-deployment-86b2" class="level4">
<h4 class="anchored" data-anchor-id="sec-ml-systems-progressive-deployment-86b2">Progressive Deployment</h4>
<p>Progressive deployment strategies adapt models for different computational tiers, creating a cascade of increasingly lightweight versions. A model might start as a large, complex version in the cloud, then be progressively compressed and optimized for edge servers, mobile devices, and finally tiny sensors. Voice assistant systems often employ this pattern, where full natural language processing runs in the cloud, while simplified wake-word detection runs on-device. This allows the system to balance capability and resource constraints across the ML stack.</p>
</section>
<section id="sec-ml-systems-federated-learning-37f5" class="level4">
<h4 class="anchored" data-anchor-id="sec-ml-systems-federated-learning-37f5">Federated Learning</h4>
<p>Federated learning represents a sophisticated hybrid approach where model training is distributed across many edge or mobile devices while maintaining privacy. Devices learn from local data and share model updates, rather than raw data, with cloud servers that aggregate these updates into an improved global model. This pattern is particularly powerful for applications like keyboard prediction on mobile devices or healthcare analytics, where privacy is paramount but benefits from collective learning are valuable. The cloud coordinates the learning process without directly accessing sensitive data, while devices benefit from the collective intelligence of the network.</p>
</section>
<section id="sec-ml-systems-collaborative-learning-3f3d" class="level4">
<h4 class="anchored" data-anchor-id="sec-ml-systems-collaborative-learning-3f3d">Collaborative Learning</h4>
<p>Collaborative learning enables peer-to-peer learning between devices at the same tier, often complementing hierarchical structures. Autonomous vehicle fleets, for example, might share learning about road conditions or traffic patterns directly between vehicles while also communicating with cloud infrastructure. This horizontal collaboration allows systems to share time-sensitive information and learn from each other’s experiences without always routing through central servers.</p>
</section>
</section>
<section id="sec-ml-systems-realworld-integration-9e96" class="level3" data-number="2.6.2">
<h3 data-number="2.6.2" class="anchored" data-anchor-id="sec-ml-systems-realworld-integration-9e96"><span class="header-section-number">2.6.2</span> Real-World Integration</h3>
<p>Design patterns establish a foundation for organizing and optimizing ML workloads across distributed systems. However, the practical application of these patterns often requires combining multiple paradigms into integrated workflows. Thus, in practice, ML systems rarely operate in isolation. Instead, they form interconnected networks where each paradigm, including Cloud, Edge, Mobile, and Tiny ML, plays a specific role while communicating with other parts of the system. These interconnected networks follow integration patterns that assign specific roles to Cloud, Edge, Mobile, and Tiny ML systems based on their unique strengths and limitations. Recall that cloud systems excel at training and analytics but require significant infrastructure. Edge systems provide local processing power and reduced latency. Mobile devices offer personal computing capabilities and user interaction. Tiny ML enables intelligence in the smallest devices and sensors.</p>
<p><a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a> illustrates these key interactions through specific connection types: “Deploy” paths show how models flow from cloud training to various devices, “Data” and “Results” show information flow from sensors through processing stages, “Analyze” shows how processed information reaches cloud analytics, and “Sync” demonstrates device coordination. Notice how data generally flows upward from sensors through processing layers to cloud analytics, while model deployments flow downward from cloud training to various inference points. The interactions aren’t strictly hierarchical. Mobile devices might communicate directly with both cloud services and tiny sensors, while edge systems can assist mobile devices with complex processing tasks.</p>
<div id="fig-hybrid" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hybrid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb3"><pre class="sourceCode tikz code-with-copy"><code class="sourceCode latex"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}[font=<span class="fu">\small\usefont</span>{T1}{phv}{m}{n}]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span>{</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>Line/.style={line width=1.0pt,black!50,text=black},</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  Box/.style={inner xsep=2pt,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    node distance=0.6,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    draw=GreenLine, line width=0.75pt,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    fill=GreenL,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    text width=20mm,align=flush center,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    minimum width=20mm, minimum height=9mm</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>   Text/.style={inner xsep=2pt,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    draw=none, line width=0.75pt,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    fill=TextColor,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    font=<span class="fu">\footnotesize\usefont</span>{T1}{phv}{m}{n},</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    align=flush center,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    minimum width=7mm, minimum height=5mm</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,fill=RedL,draw=RedLine](G2){Training};</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,fill=none,draw=none,below =1.75 of G2](A){};</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.75, left=of A](B2){Inference};</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.75,left=of B2,fill=cyan!20,draw=BlueLine](B1){Inference};</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.75, right=of A,fill=orange!20,draw=OrangeLine](B3){Inference};</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.5, below=of B1,fill=cyan!20,draw=BlueLine](1DB1){Processing};</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.5, below=of B3,fill=orange!20,draw=OrangeLine](1DB3){Processing};</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[](1DB3)-|coordinate(S)(G2);</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.5,fill=RedL,draw=RedLine]at(S)(1DB2){Analytics};</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="fu">\path</span>[](G2)-|coordinate(SS)(B2);</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box](G1)at(SS){Sensors};</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=4mm,inner ysep=6mm,anchor= west,</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>       yshift=1mm,fill=BackColor,fit=(G1)(B2),line width=0.75pt](BB2){};</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=3pt of  BB2.north,anchor=north]{TinyML};</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=4mm,inner ysep=6mm,anchor= west,</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>       yshift=1mm,fill=BackColor,fit=(G2)(1DB2),line width=0.75pt](BB2){};</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=3pt of  BB2.north,anchor=north]{Cloud ML};</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](G1.west)--++(180:0.9)|-node[Text,pos=0.1]{Data}(B2);</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](G2)--++(270:0.9)-|node[Text,pos=0.66]{Deploy}(B1);</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](G2)--++(270:0.9)-|node[Text,pos=0.66]{Deploy}(B2);</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](G2)--++(270:0.9)-|node[Text,pos=0.66]{Deploy}(B3);</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B1)--node[Text,pos=0.5]{Results}(1DB1);</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B2)|-node[Text,pos=0.75]{Results}(1DB1.10);</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B1.330)--++(270:0.9)-|node[Text,pos=0.2]{Assist}(B3.220);</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B2.east)--node[Text,pos=0.5]{Sync}++(0:4.8)|-(1DB3.170);</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](1DB1.350)--node[Text,pos=0.75]{Results}(1DB2.190);</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](1DB3.190)--node[Text,pos=0.50]{Data}(1DB2.350);</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B3.290)--node[Text,pos=0.5]{Results}(1DB3.70);</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=4mm,inner ysep=6mm,anchor= west,</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>      yshift=-1mm,fill=BackColor,fit=(B1)(1DB1),line width=0.75pt](BB2){};</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=3pt of  BB2.south,anchor=south]{Edge ML};</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=4mm,inner ysep=6mm,anchor= west,</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>      yshift=-1mm,fill=BackColor,fit=(B3)(1DB3),line width=0.75pt](BB2){};</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=3pt of  BB2.south,anchor=south]{Mobile ML};</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hybrid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.9: Example interaction patterns between ML paradigms, showing data flows, model deployment, and processing relationships across Cloud, Edge, Mobile, and Tiny ML systems.
</figcaption>
</figure>
</div>
<p>To understand how these labeled interactions manifest in real applications, let’s explore several common scenarios using <a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a>:</p>
<ul>
<li><p><strong>Model Deployment Scenario</strong>: A company develops a computer vision model for defect detection. Following the “Deploy” paths shown in <a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a>, the cloud-trained model is distributed to edge servers in factories, quality control tablets on the production floor, and tiny cameras embedded in the production line. This showcases how a single ML solution can be distributed across different computational tiers for optimal performance.</p></li>
<li><p><strong>Data Flow and Analysis Scenario</strong>: In a smart agriculture system, soil sensors (Tiny ML) collect moisture and nutrient data, following the “Data” path to Tiny ML inference. The “Results” flow to edge processors in local stations, which process this information and use the “Analyze” path to send insights to the cloud for farm-wide analytics, while also sharing results with farmers’ mobile apps. This demonstrates the hierarchical flow shown in <a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a> from sensors through processing to cloud analytics.</p></li>
<li><p><strong>Edge-Mobile Assistance Scenario</strong>: When a mobile app needs to perform complex image processing that exceeds the phone’s capabilities, it utilizes the “Assist” connection shown in <a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a>. The edge system helps process the heavier computational tasks, sending back results to enhance the mobile app’s performance. This shows how different ML tiers can cooperate to handle demanding tasks.</p></li>
<li><p><strong>Tiny ML-Mobile Integration Scenario</strong>: A fitness tracker uses Tiny ML to continuously monitor activity patterns and vital signs. Using the “Sync” pathway shown in <a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a>, it synchronizes this processed data with the user’s smartphone, which combines it with other health data before sending consolidated updates via the “Analyze” path to the cloud for long-term health analysis. This illustrates the common pattern of tiny devices using mobile devices as gateways to larger networks.</p></li>
<li><p><strong>Multi-Layer Processing Scenario</strong>: In a smart retail environment, tiny sensors monitor inventory levels, using “Data” and “Results” paths to send inference results to both edge systems for immediate stock management and mobile devices for staff notifications. Following the “Analyze” path, the edge systems process this data alongside other store metrics, while the cloud analyzes trends across all store locations. This demonstrates how the interactions shown in <a href="#fig-hybrid" class="quarto-xref">Figure&nbsp;<span>2.9</span></a> enable ML tiers to work together in a complete solution.</p></li>
</ul>
<p>These real-world patterns demonstrate how different ML paradigms naturally complement each other in practice. While each approach has its own strengths, their true power emerges when they work together as an integrated system. By understanding these patterns, system architects can better design solutions that effectively leverage the capabilities of each ML tier while managing their respective constraints.</p>
</section>
</section>
<section id="sec-ml-systems-shared-principles-db13" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="sec-ml-systems-shared-principles-db13"><span class="header-section-number">2.7</span> Shared Principles</h2>
<p>The design and integration patterns illustrate how ML paradigms, such as Cloud, Edge, Mobile, and Tiny, interact to address real-world challenges. While each paradigm is tailored to specific roles, their interactions reveal recurring principles that guide effective system design. These shared principles provide a unifying framework for understanding both individual ML paradigms and their hybrid combinations. As we explore these principles, a deeper system design perspective emerges, showing how different ML implementations, which are optimized for distinct contexts, converge around core concepts. This convergence forms the foundation for systematically understanding ML systems, despite their diversity and breadth.</p>
<p><a href="#fig-ml-systems-convergence" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> illustrates this convergence, highlighting the relationships that underpin practical system design and implementation. Grasping these principles is invaluable not only for working with individual ML systems but also for developing hybrid solutions that leverage their strengths, mitigate their limitations, and create cohesive, efficient ML workflows.</p>
<div id="fig-ml-systems-convergence" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml-systems-convergence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb4"><pre class="sourceCode tikz code-with-copy"><code class="sourceCode latex"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}[font=<span class="fu">\small\usefont</span>{T1}{phv}{m}{n}]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span>{</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Line/.style={line width=1.0pt,black!50,text=black},</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  Box/.style={inner xsep=2pt,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    node distance=0.6,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    draw=GreenLine, line width=0.75pt,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    fill=GreenL,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    text width=30mm,align=flush center,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    minimum width=30mm, minimum height=13mm</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  Box1/.style={inner xsep=2pt,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    node distance=0.8,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    draw=BlueLine, line width=0.75pt,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    fill=BlueL,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    text width=36mm,align=flush center,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    minimum width=40mm, minimum height=13mm</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[anchor=west]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box](B1){Cloud ML Data Centers Training at Scale};</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,right=of B1](B2){Edge ML Local Processing Inference Focus};</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,right=of B2](B3){Mobile ML Personal DevicesUser Applications};</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box, right=of B3](B4){TinyML Embedded Systems Resource Constrained};</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>      anchor=west,yshift=2mm,fill=BackColor,</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>      fit=(B1)(B2)(B3)(B4),line width=0.75pt](BB){};</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=11pt of  BB.north east,anchor=east]{ML System Implementations};</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[shift={(0.4,-2.8)}, anchor=west]</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1](2B1){Data Pipeline Collection -- Processing -- Deployment};</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,right=of 2B1](2B2){Resource Management Compute -- Memory -- Energy -- Network};</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,right=of 2B2](2B3){System Architecture Models -- Hardware -- Software};</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>      anchor= west,yshift=-1mm,fill=BackColor,fit=(2B1)(2B2)(2B3),line width=0.75pt](BB2){};</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=8pt of  BB2.south east,anchor=east]{Core System Principles};</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[shift={(0.4,-6.0)}, anchor=west]</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1, fill=VioletL,draw=VioletLine](3B1){Optimization <span class="fu">\&amp;</span> Efficiency Model -- Hardware -- Energy};</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,right=of 3B1, fill=VioletL,draw=VioletLine](3B2){Operational Aspects Deployment -- Monitoring -- Updates};</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,right=of 3B2, fill=VioletL,draw=VioletLine](3B3){Trustworthy AI Security -- Privacy -- Reliability};</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=5mm,inner ysep=5mm,minimum width=170mm,</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>       anchor= west,yshift=-1mm,fill=BackColor,fit=(3B1)(3B2)(3B3),line width=0.75pt](BB3){};</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=8pt of  BB3.south east,anchor=east]{System Considerations};</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](B1.south)--++(270:0.75)-|(2B1);</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](B2.south)--++(270:0.75)-|(2B1);</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](B3.south)--++(270:0.75)-|(2B1);</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](B4.south)--++(270:0.75)-|(2B1);</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](B2.south)--++(270:0.75)-|(2B2);</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](B3.south)--++(270:0.75)-|(2B3);</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](2B1.south)--++(270:0.95)-|(3B1);</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](2B2.south)--++(270:0.95)-|(3B1);</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](2B3.south)--++(270:0.95)-|(3B1);</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](2B2.south)--++(270:0.95)-|(3B2);</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[-latex,Line](2B3.south)--++(270:0.95)-|(3B3);</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml-systems-convergence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.10: Core principles converge across different ML system implementations, from cloud to tiny deployments, sharing common foundations in data pipelines, resource management, and system architecture.
</figcaption>
</figure>
</div>
<p>The figure shows three key layers that help us understand how ML systems relate to each other. At the top, we see the diverse implementations that we have explored throughout this chapter. Cloud ML operates in data centers, focusing on training at scale with vast computational resources. Edge ML emphasizes local processing with inference capabilities closer to data sources. Mobile ML leverages personal devices for user-centric applications. Tiny ML brings intelligence to highly constrained embedded systems and sensors.</p>
<p>Despite their distinct characteristics, the arrows in the figure show how all these implementations connect to the same core system principles. This reflects an important reality in ML systems, even though they may operate at dramatically different scales, from cloud systems processing petabytes to tiny devices handling kilobytes, they all must solve similar fundamental challenges in terms of:</p>
<ul>
<li>Managing data pipelines from collection through processing to deployment</li>
<li>Balancing resource utilization across compute, memory, energy, and network</li>
<li>Implementing system architectures that effectively integrate models, hardware, and software</li>
</ul>
<p>These core principles then lead to shared system considerations around optimization, operations, and trustworthiness. This progression helps explain why techniques developed for one scale of ML system often transfer effectively to others. The underlying problems, efficiently processing data, managing resources, and ensuring reliable operation, remain consistent even as the specific solutions vary based on scale and context.</p>
<p>Understanding this convergence becomes particularly valuable as we move towards hybrid ML systems. When we recognize that different ML implementations share fundamental principles, combining them effectively becomes more intuitive. We can better appreciate why, for example, a cloud-trained model can be effectively deployed to edge devices, or why mobile and tiny ML systems can complement each other in IoT applications.</p>
<div id="sec-sec-ml-systems-shared-principles-db13" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 6</strong></summary><div>
<ol type="1">
<li><p>Which of the following best describes the significance of shared principles in ML systems?</p>
<ol type="a">
<li>They allow for the development of specialized hardware for each ML paradigm.</li>
<li>They facilitate the integration of different ML paradigms into cohesive workflows.</li>
<li>They eliminate the need for optimization in ML systems.</li>
<li>They restrict ML systems to operate only in cloud environments.</li>
</ol></li>
<li><p>Explain how the convergence of core principles across different ML implementations aids in the development of hybrid systems.</p></li>
<li><p>In ML systems, managing data pipelines involves handling information flow from collection through ______ to final deployment.</p></li>
<li><p>True or False: The principles of resource management are unique to each ML paradigm and do not overlap.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-shared-principles-db13-answer">See Answer →</a></p>
</div></details>
</div>
<section id="sec-ml-systems-implementation-layer-40e0" class="level3" data-number="2.7.1">
<h3 data-number="2.7.1" class="anchored" data-anchor-id="sec-ml-systems-implementation-layer-40e0"><span class="header-section-number">2.7.1</span> Implementation Layer</h3>
<p>The top layer of <a href="#fig-ml-systems-convergence" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> represents the diverse landscape of ML systems we’ve explored throughout this chapter. Each implementation addresses specific needs and operational contexts, yet all contribute to the broader ecosystem of ML deployment options.</p>
<p>Cloud ML, centered in data centers, provides the foundation for large-scale training and complex model serving. With access to vast computational resources like the NVIDIA DGX A100 systems we saw in <a href="#tbl-representative-systems" class="quarto-xref">Table&nbsp;<span>2.1</span></a>, cloud implementations excel at handling massive datasets and training sophisticated models. This makes them particularly suited for tasks requiring extensive computational power, such as training foundation models or processing large-scale analytics.</p>
<p>Edge ML shifts the focus to local processing, prioritizing inference capabilities closer to data sources. Using devices like the NVIDIA Jetson AGX Orin, edge implementations balance computational power with reduced latency and improved privacy. This approach proves especially valuable in scenarios requiring quick decisions based on local data, such as industrial automation or real-time video analytics.</p>
<p>Mobile ML leverages the capabilities of personal devices, particularly smartphones and tablets. With specialized hardware like Apple’s A17 Pro chip, mobile implementations enable sophisticated ML capabilities while maintaining user privacy and providing offline functionality. This paradigm has revolutionized applications from computational photography to on-device speech recognition.</p>
<p>Tiny ML represents the frontier of embedded ML, bringing intelligence to highly constrained devices. Operating on microcontrollers like the Arduino Nano 33 BLE Sense, tiny implementations must carefully balance functionality with severe resource constraints. Despite these limitations, Tiny ML enables ML capabilities in scenarios where power efficiency and size constraints are paramount.</p>
</section>
<section id="sec-ml-systems-system-principles-layer-7ed6" class="level3" data-number="2.7.2">
<h3 data-number="2.7.2" class="anchored" data-anchor-id="sec-ml-systems-system-principles-layer-7ed6"><span class="header-section-number">2.7.2</span> System Principles Layer</h3>
<p>The middle layer reveals the fundamental principles that unite all ML systems, regardless of their implementation scale. These core principles remain consistent even as their specific manifestations vary dramatically across different deployments.</p>
<p>Data Pipeline principles govern how systems handle information flow, from initial collection through processing to final deployment. In cloud systems, this might mean processing petabytes of data through distributed pipelines. For tiny systems, it could involve carefully managing sensor data streams within limited memory. Despite these scale differences, all systems must address the same fundamental challenges of data ingestion, transformation, and utilization.</p>
<p>Resource Management emerges as a universal challenge across all implementations. Whether managing thousands of GPUs in a data center or optimizing battery life on a microcontroller, all systems must balance competing demands for computation, memory, energy, and network resources. The quantities involved may differ by orders of magnitude, but the core principles of resource allocation and optimization remain remarkably consistent.</p>
<p>System Architecture principles guide how ML systems integrate models, hardware, and software components. Cloud architectures might focus on distributed computing and scalability, while tiny systems emphasize efficient memory mapping and interrupt handling. Yet all must solve fundamental problems of component integration, data flow optimization, and processing coordination.</p>
</section>
<section id="sec-ml-systems-system-considerations-layer-c419" class="level3" data-number="2.7.3">
<h3 data-number="2.7.3" class="anchored" data-anchor-id="sec-ml-systems-system-considerations-layer-c419"><span class="header-section-number">2.7.3</span> System Considerations Layer</h3>
<p>The bottom layer of <a href="#fig-ml-systems-convergence" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> illustrates how fundamental principles manifest in practical system-wide considerations. These considerations span all ML implementations, though their specific challenges and solutions vary based on scale and context.</p>
<p><strong>Optimization and Efficiency</strong> shape how ML systems balance performance with resource utilization. In cloud environments, this often means optimizing model training across GPU clusters while managing energy consumption in data centers. Edge systems focus on reducing model size and accelerating inference without compromising accuracy. Mobile implementations must balance model performance with battery life and thermal constraints. Tiny ML pushes optimization to its limits, requiring extensive model compression and quantization to fit within severely constrained environments. Despite these different emphases, all implementations grapple with the core challenge of maximizing performance within their available resources.</p>
<p><strong>Operational Aspects</strong> affect how ML systems are deployed, monitored, and maintained in production environments. Cloud systems must handle continuous deployment across distributed infrastructure while monitoring model performance at scale. Edge implementations need robust update mechanisms and health monitoring across potentially thousands of devices. Mobile systems require seamless app updates and performance monitoring without disrupting user experience. Tiny ML faces unique challenges in deploying updates to embedded devices while ensuring continuous operation. Across all scales, the fundamental problems of deployment, monitoring, and maintenance remain consistent, even as solutions vary.</p>
<p><strong>Trustworthy AI</strong> considerations ensure ML systems operate reliably, securely, and with appropriate privacy protections. Cloud implementations must secure massive amounts of data while ensuring model predictions remain reliable at scale. Edge systems need to protect local data processing while maintaining model accuracy in diverse environments. Mobile ML must preserve user privacy while delivering consistent performance. Tiny ML systems, despite their size, must still ensure secure operation and reliable inference. These trustworthiness considerations cut across all implementations, reflecting the critical importance of building ML systems that users can depend on.</p>
<p>The progression through these layers, from diverse implementations through core principles to shared considerations, reveals why ML systems can be studied as a unified field despite their apparent differences. While specific solutions may vary dramatically based on scale and context, the fundamental challenges remain remarkably consistent. This understanding becomes particularly valuable as we move toward increasingly sophisticated hybrid systems that combine multiple implementation approaches.</p>
<p>The convergence of fundamental principles across ML implementations helps explain why hybrid approaches work so effectively in practice. As we saw in our discussion of hybrid ML, different implementations naturally complement each other precisely because they share these core foundations. Whether we’re looking at train-serve splits that leverage cloud resources for training and edge devices for inference, or hierarchical processing that combines Tiny ML sensors with edge aggregation and cloud analytics, the shared principles enable seamless integration across scales.</p>
</section>
<section id="sec-ml-systems-principles-practice-fa6c" class="level3" data-number="2.7.4">
<h3 data-number="2.7.4" class="anchored" data-anchor-id="sec-ml-systems-principles-practice-fa6c"><span class="header-section-number">2.7.4</span> Principles to Practice</h3>
<p>This convergence also suggests why techniques and insights often transfer well between different scales of ML systems. A deep understanding of data pipelines in cloud environments can inform how we structure data flow in embedded systems. Resource management strategies developed for mobile devices might inspire new approaches to cloud optimization. System architecture patterns that prove effective at one scale often adapt surprisingly well to others.</p>
<p>Understanding these fundamental principles and shared considerations provides a foundation for comparing different ML implementations more effectively. While each approach has its distinct characteristics and optimal use cases, they all build upon the same core elements. As we move into our detailed comparison in the next section, keeping these shared foundations in mind will help us better appreciate both the differences and similarities between various ML system implementations.</p>
</section>
</section>
<section id="sec-ml-systems-system-comparison-0245" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="sec-ml-systems-system-comparison-0245"><span class="header-section-number">2.8</span> System Comparison</h2>
<p>Building on the shared principles explored earlier, we can synthesize our understanding by examining how the various ML system approaches compare across different dimensions. This synthesis highlights the trade-offs system designers often face when choosing deployment options and how these decisions align with core principles like resource management, data pipelines, and system architecture.</p>
<p>The relationship between computational resources and deployment location forms one of the most fundamental comparisons across ML systems. As we move from cloud deployments to tiny devices, we observe a dramatic reduction in available computing power, storage, and energy consumption. Cloud ML systems, with their data center infrastructure, can leverage virtually unlimited resources, processing data at the scale of petabytes and training models with billions of parameters. Edge ML systems, while more constrained, still offer significant computational capability through specialized hardware like edge GPUs and neural processing units. Mobile ML represents a middle ground, balancing computational power with energy efficiency on devices like smartphones and tablets. At the far end of the spectrum, TinyML operates under severe resource constraints, often limited to kilobytes of memory and milliwatts of power consumption.</p>
<div id="tbl-big_vs_tiny" class="hover striped quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-big_vs_tiny-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.2: Comparison of feature aspects across Cloud ML, Edge ML, and Tiny ML.
</figcaption>
<div aria-describedby="tbl-big_vs_tiny-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table-striped caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspect</th>
<th style="text-align: left;">Cloud ML</th>
<th style="text-align: left;">Edge ML</th>
<th style="text-align: left;">Mobile ML</th>
<th style="text-align: left;">Tiny ML</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Performance</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Processing Location</td>
<td style="text-align: left;">Centralized cloud servers (Data Centers)</td>
<td style="text-align: left;">Local edge devices (gateways, servers)</td>
<td style="text-align: left;">Smartphones and tablets</td>
<td style="text-align: left;">Ultra-low-power microcontrollers and embedded systems</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Latency</td>
<td style="text-align: left;">High (100 ms-1000 ms+)</td>
<td style="text-align: left;">Moderate (10-100 ms)</td>
<td style="text-align: left;">Low-Moderate (5-50 ms)</td>
<td style="text-align: left;">Very Low (1-10 ms)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Compute Power</td>
<td style="text-align: left;">Very High (Multiple GPUs/TPUs)</td>
<td style="text-align: left;">High (Edge GPUs)</td>
<td style="text-align: left;">Moderate (Mobile NPUs/GPUs)</td>
<td style="text-align: left;">Very Low (MCU/tiny processors)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Storage Capacity</td>
<td style="text-align: left;">Unlimited (petabytes+)</td>
<td style="text-align: left;">Large (terabytes)</td>
<td style="text-align: left;">Moderate (gigabytes)</td>
<td style="text-align: left;">Very Limited (kilobytes-megabytes)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Energy Consumption</td>
<td style="text-align: left;">Very High (kW-MW range)</td>
<td style="text-align: left;">High (100 s W)</td>
<td style="text-align: left;">Moderate (1-10 W)</td>
<td style="text-align: left;">Very Low (mW range)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Scalability</td>
<td style="text-align: left;">Excellent (virtually unlimited)</td>
<td style="text-align: left;">Good (limited by edge hardware)</td>
<td style="text-align: left;">Moderate (per-device scaling)</td>
<td style="text-align: left;">Limited (fixed hardware)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Operational</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Data Privacy</td>
<td style="text-align: left;">Basic-Moderate (Data leaves device)</td>
<td style="text-align: left;">High (Data stays in local network)</td>
<td style="text-align: left;">High (Data stays on phone)</td>
<td style="text-align: left;">Very High (Data never leaves sensor)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Connectivity Required</td>
<td style="text-align: left;">Constant high-bandwidth</td>
<td style="text-align: left;">Intermittent</td>
<td style="text-align: left;">Optional</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Offline Capability</td>
<td style="text-align: left;">None</td>
<td style="text-align: left;">Good</td>
<td style="text-align: left;">Excellent</td>
<td style="text-align: left;">Complete</td>
</tr>
<tr class="even">
<td style="text-align: left;">Real-time Processing</td>
<td style="text-align: left;">Dependent on network</td>
<td style="text-align: left;">Good</td>
<td style="text-align: left;">Very Good</td>
<td style="text-align: left;">Excellent</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Deployment</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Cost</td>
<td style="text-align: left;">High ($1000s+/month)</td>
<td style="text-align: left;">Moderate ($100s-1000s)</td>
<td style="text-align: left;">Low ($0-10s)</td>
<td style="text-align: left;">Very Low ($1-10s)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Hardware Requirements</td>
<td style="text-align: left;">Cloud infrastructure</td>
<td style="text-align: left;">Edge servers/gateways</td>
<td style="text-align: left;">Modern smartphones</td>
<td style="text-align: left;">MCUs/embedded systems</td>
</tr>
<tr class="even">
<td style="text-align: left;">Development Complexity</td>
<td style="text-align: left;">High (cloud expertise needed)</td>
<td style="text-align: left;">Moderate-High (edge+networking)</td>
<td style="text-align: left;">Moderate (mobile SDKs)</td>
<td style="text-align: left;">High (embedded expertise)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deployment Speed</td>
<td style="text-align: left;">Fast</td>
<td style="text-align: left;">Moderate</td>
<td style="text-align: left;">Fast</td>
<td style="text-align: left;">Slow</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The operational characteristics of these systems reveal another important dimension of comparison. <a href="#tbl-big_vs_tiny" class="quarto-xref">Table&nbsp;<span>2.2</span></a> organizes these characteristics into logical groupings, highlighting performance, operational considerations, costs, and development aspects. For instance, latency shows a clear gradient: cloud systems typically incur delays of 100-1000 ms due to network communication, while edge systems reduce this to 10-100 ms by processing data locally. Mobile ML achieves even lower latencies of 5-50 ms for many tasks, and TinyML systems can respond in 1-10 ms for simple inferences. Similarly, privacy and data handling improve progressively as computation shifts closer to the data source, with TinyML offering the strongest guarantees by keeping data entirely local to the device.</p>
<p>The table is designed to provide a high-level view of how these paradigms differ across key dimensions, making it easier to understand the trade-offs and select the most appropriate approach for specific deployment needs.</p>
<p>To complement the details presented in <a href="#tbl-big_vs_tiny" class="quarto-xref">Table&nbsp;<span>2.2</span></a>, radar plots are presented below. These visualizations highlight two critical dimensions: performance characteristics and operational characteristics. The performance characteristics plot in <a href="#fig-perf_char" class="quarto-xref">Figure&nbsp;<span>2.11</span></a> focuses on latency, compute power, energy consumption, and scalability. As discussed earlier, Cloud ML demands exceptional compute power and demonstrates good scalability, making it ideal for large-scale tasks requiring extensive resources. Tiny ML, in contrast, excels in latency and energy efficiency due to its lightweight and localized processing, suitable for low-power, real-time scenarios. Edge ML and Mobile ML strike a balance, offering moderate scalability and efficiency for a variety of applications.</p>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-perf_char" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-perf_char-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/perf_char.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;2.11: Performance characteristics."><img src="images/png/perf_char.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-perf_char-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.11: Performance characteristics.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-op_char" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-op_char-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/png/op_char.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;2.12: Operational characteristics."><img src="images/png/op_char.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-op_char-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.12: Operational characteristics.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>The operational characteristics plot in <a href="#fig-op_char" class="quarto-xref">Figure&nbsp;<span>2.12</span></a> emphasizes data privacy, connectivity independence, offline capability, and real-time processing. Tiny ML emerges as a highly independent and private paradigm, excelling in offline functionality and real-time responsiveness. In contrast, Cloud ML relies on centralized infrastructure and constant connectivity, which can be a limitation in scenarios demanding autonomy or low-latency decision-making.</p>
<p>Development complexity and deployment considerations also vary significantly across these paradigms. Cloud ML benefits from mature development tools and frameworks but requires expertise in cloud infrastructure. Edge ML demands knowledge of both ML and networking protocols, while Mobile ML developers must understand mobile-specific optimizations and platform constraints. TinyML development, though targeting simpler devices, often requires specialized knowledge of embedded systems and careful optimization to work within severe resource constraints.</p>
<p>Cost structures differ markedly as well. Cloud ML typically involves ongoing operational costs for computation and storage, often running into thousands of dollars monthly for large-scale deployments. Edge ML requires significant upfront investment in edge devices but may reduce ongoing costs. Mobile ML leverages existing consumer devices, minimizing additional hardware costs, while TinyML solutions can be deployed for just a few dollars per device, though development costs may be higher.</p>
<p>These comparisons reveal that each paradigm has distinct advantages and limitations. Cloud ML excels at complex, data-intensive tasks but requires constant connectivity. Edge ML offers a balance of computational power and local processing. Mobile ML provides personalized intelligence on ubiquitous devices. TinyML enables ML in previously inaccessible contexts but requires careful optimization. Understanding these trade-offs is crucial for selecting the appropriate deployment strategy for specific applications and constraints.</p>
<div id="sec-sec-ml-systems-system-comparison-0245" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 7</strong></summary><div>
<ol type="1">
<li><p>Which ML system paradigm is best suited for applications requiring minimal latency and high data privacy?</p>
<ol type="a">
<li>Cloud ML</li>
<li>Edge ML</li>
<li>Mobile ML</li>
<li>Tiny ML</li>
</ol></li>
<li><p>Explain why Mobile ML represents a middle ground between Cloud ML and Tiny ML in terms of computational power and energy efficiency.</p></li>
<li><p>True or False: Cloud ML systems offer the best offline capabilities among all ML paradigms.</p></li>
<li><p>The trade-off between compute power and ______ is a key consideration when comparing different ML system paradigms.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-system-comparison-0245-answer">See Answer →</a></p>
</div></details>
</div>
</section>
<section id="sec-ml-systems-deployment-decision-framework-cb57" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="sec-ml-systems-deployment-decision-framework-cb57"><span class="header-section-number">2.9</span> Deployment Decision Framework</h2>
<p>We have examined the diverse paradigms of machine learning systems, including Cloud ML, Edge ML, Mobile ML, and Tiny ML, each with its own characteristics, trade-offs, and use cases. Selecting an optimal deployment strategy requires careful consideration of multiple factors.</p>
<div id="fig-mlsys-playbook-flowchart" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-env="figure" data-fig-pos="!t">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mlsys-playbook-flowchart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb5"><pre class="sourceCode tikz code-with-copy"><code class="sourceCode latex"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">\resizebox</span>{.75<span class="fu">\textwidth</span>}{!}{<span class="co">%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}[font=<span class="fu">\small\usefont</span>{T1}{phv}{m}{n},line width=0.75pt]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">\tikzset</span>{</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  Line/.style={line width=1.0pt,black!50,text=black},</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  Box/.style={inner xsep=2pt,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    draw=GreenLine, line width=0.65pt,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    fill=GreenL,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    text width=25mm,align=flush center,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    minimum width=25mm, minimum height=9mm</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  Box1/.style={inner xsep=2pt,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    node distance=0.5,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    draw=BlueLine, line width=0.65pt,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    fill=BlueL,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    text width=33mm,align=flush center,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    minimum width=33mm, minimum height=9mm</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  Text/.style={inner xsep=2pt,</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    draw=none, line width=0.75pt,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    fill=TextColor,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    font=<span class="fu">\footnotesize\usefont</span>{T1}{phv}{m}{n},</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    align=flush center,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    minimum width=7mm, minimum height=5mm</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box, rounded corners=12pt,fill=magenta!20](B1){Start};</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1,below=of B1](B2){Is privacy critical?};</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below left=0.15 and 1 of B2](B3){Cloud Processing Allowed};</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below right=0.15 and 1 of B2](B4){Local Processing Preferred};</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B1)--(B2);</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B2)-|node[Text,pos=0.2]{No}(B3);</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B2)-|node[Text,pos=0.2]{Yes}(B4);</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=12mm,inner ysep=4mm,yshift=0mm,</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>       fill=BackColor,fit=(B1)(B3)(B4),line width=0.75pt](BB){};</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=11pt of BB.north east,anchor=east]{Layer: Privacy};</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[shift={(0,-4.8)}]</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1](2B1){Is low latency required (<span class="ss">$&lt;$</span>10 ms)?};</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below left=0.15 and 1 of 2B1](2B2){Latency Tolerant};</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below right=0.15 and 1 of 2B1](2B3){Tiny or Edge ML};</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](2B1)-|node[Text,pos=0.2]{No}(2B2);</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](2B1)-|node[Text,pos=0.2]{Yes}(2B3);</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=12mm,inner ysep=4mm,yshift=0mm,</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>       fill=BackColor,fit=(2B1)(2B2)(2B3),line width=0.75pt](BB1){};</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=11pt of BB1.north east,anchor=east]{Layer: Performance};</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B3)--++(270:1.15)-|(2B1.110);</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](B4)--++(270:1.15)-|(2B1.70);</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[shift={(0,-8.4)}]</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1](3B1){Does the model require significant compute?};</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below left=0.15 and 1 of 3B1](3B2){Heavy Compute};</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below right=0.15 and 1 of 3B1](3B3){Lightweight Processing};</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](3B1)-|node[Text,pos=0.2]{Yes}(3B2);</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](3B1)-|node[Text,pos=0.2]{No}(3B3);</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=1mm,</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>       fill=BackColor,fit=(3B1)(3B2)(3B3),line width=0.75pt](BB2){};</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=11pt of BB2.north east,anchor=east]{Layer: Compute Needs};</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](2B2)--++(270:1.15)-|(3B1.110);</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](2B3)--++(270:1.15)-|(3B1.70);</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a><span class="co">%4</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[shift={(0,-12.0)}]</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box1](4B1){Are there strict cost constraints?};</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below left=0.15 and 1 of 4B1](4B2){Flexible Budget};</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,below right=0.15 and 1 of 4B1](4B3){Low-Cost Options};</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](4B1)-|node[Text,pos=0.2]{No}(4B2);</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](4B1)-|node[Text,pos=0.2]{Yes}(4B3);</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=1mm,</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>       fill=BackColor,fit=(4B1)(4B2)(4B3),line width=0.75pt](BB3){};</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[below=11pt of  BB3.north east,anchor=east]{Layer: Cost};</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](3B2)--++(270:1.15)-|(4B1.110);</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](3B3)--++(270:1.15)-|(4B1.70);</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a><span class="co">%5</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a><span class="kw">\begin</span>{<span class="ex">scope</span>}[shift={(-0.45,-14.8)},anchor=north east]</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,fill=magenta!20,rounded corners=12pt,text width=18mm,</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>       minimum width=17mm](5B1){Cloud ML};</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.0,fill=magenta!20,rounded corners=12pt,left=of 5B1,text width=18mm,</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>       minimum width=17mm](5B2){Edge ML};</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.0,fill=magenta!20, rounded corners=12pt,right=of 5B1,text width=18mm,</span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>       minimum width=17mm](5B3){Mobile ML};</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[Box,node distance=1.0,fill=magenta!20, rounded corners=12pt,right=of 5B3,text width=18mm,</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>       minimum width=17mm](5B4){Tiny ML};</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a><span class="co">%</span></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a><span class="fu">\scoped</span>[on background layer]</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[draw=BackLine,inner xsep=12mm,inner ysep=5mm,yshift=-1mm,</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>       fill=BackColor,fit=(5B1)(5B2)(5B4),line width=0.75pt](BB4){};</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a><span class="fu">\node</span>[above=8pt of BB4.south east,anchor=east]{Layer: Deployment Options};</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">scope</span>}</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](4B3)-|(5B3);</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](4B3)--++(270:1.1)-|(5B4);</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](4B2)--++(270:1.1)-|(5B1);</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a><span class="fu">\draw</span>[Line,-latex](3B2.west)--++(180:0.5)|-(5B2);</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mlsys-playbook-flowchart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.13: A decision flowchart for selecting the most suitable ML deployment paradigm.
</figcaption>
</figure>
</div>
<p>To facilitate this decision-making process, we present a structured framework in <a href="#fig-mlsys-playbook-flowchart" class="quarto-xref">Figure&nbsp;<span>2.13</span></a>. This framework distills the chapter’s key insights into a systematic approach for determining the most suitable deployment paradigm based on specific requirements and constraints.</p>
<p>The framework is organized into five fundamental layers of consideration:</p>
<ul>
<li><p><strong>Privacy</strong>: Determines whether processing can occur in the cloud or must remain local to safeguard sensitive data.</p></li>
<li><p><strong>Latency</strong>: Evaluates the required decision-making speed, particularly for real-time or near-real-time processing needs.</p></li>
<li><p><strong>Reliability</strong>: Assesses network stability and its impact on deployment feasibility.</p></li>
<li><p><strong>Compute Needs</strong>: Identifies whether high-performance infrastructure is required or if lightweight processing suffices.</p></li>
<li><p><strong>Cost and Energy Efficiency</strong>: Balances resource availability with financial and energy constraints, particularly crucial for low-power or budget-sensitive applications.</p></li>
</ul>
<p>As designers progress through these layers, each decision point narrows the viable options, ultimately guiding them toward one of the four deployment paradigms. This systematic approach proves valuable across various scenarios. For instance, privacy-sensitive healthcare applications might prioritize local processing over cloud solutions, while high-performance recommendation engines typically favor cloud infrastructure. Similarly, applications requiring real-time responses often gravitate toward edge or mobile-based deployment.</p>
<p>While not exhaustive, this framework provides a practical roadmap for navigating deployment decisions. By following this structured approach, system designers can evaluate trade-offs and align their deployment choices with technical, financial, and operational priorities, even as they address the unique challenges of each application.</p>
<div id="sec-sec-ml-systems-deployment-decision-framework-cb57" class="callout callout-quiz-question">
<details class="callout-quiz-question fbx-default closebutton" open=""><summary><strong>Self-Check: Question 8</strong></summary><div>
<ol type="1">
<li><p>Which layer of the deployment decision framework determines whether processing can occur in the cloud or must remain local?</p>
<ol type="a">
<li>Latency</li>
<li>Privacy</li>
<li>Compute Needs</li>
<li>Cost and Energy Efficiency</li>
</ol></li>
<li><p>Explain why applications requiring real-time responses might favor edge or mobile-based deployment over cloud solutions.</p></li>
<li><p>True or False: High-performance recommendation engines typically prioritize mobile-based deployment due to their need for significant compute resources.</p></li>
<li><p>In the deployment decision framework, the ______ layer assesses network stability and its impact on deployment feasibility.</p></li>
<li><p>Order the following layers of the deployment decision framework: [Latency, Privacy, Cost and Energy Efficiency, Compute Needs, Reliability]</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-deployment-decision-framework-cb57-answer">See Answer →</a></p>
</div></details>
</div>
</section>
<section id="sec-ml-systems-conclusion-1102" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="sec-ml-systems-conclusion-1102"><span class="header-section-number">2.10</span> Conclusion</h2>
<p>This chapter has explored the diverse landscape of machine learning systems, highlighting their unique characteristics, benefits, challenges, and applications. Cloud ML leverages immense computational resources, excelling in large-scale data processing and model training but facing limitations such as latency and privacy concerns. Edge ML bridges this gap by enabling localized processing, reducing latency, and enhancing privacy. Mobile ML builds on these strengths, harnessing the ubiquity of smartphones to provide responsive, user-centric applications. At the smallest scale, Tiny ML extends the reach of machine learning to resource-constrained devices, opening new domains of application.</p>
<p>Together, these paradigms reflect an ongoing progression in machine learning, moving from centralized systems in the cloud to increasingly distributed and specialized deployments across edge, mobile, and tiny devices. This evolution marks a shift toward systems that are finely tuned to specific deployment contexts, balancing computational power, energy efficiency, and real-time responsiveness. As these paradigms mature, hybrid approaches are emerging, blending their strengths to unlock new possibilities—from cloud-based training paired with edge inference to federated learning and hierarchical processing.</p>
<p>Despite their variety, ML systems can be distilled into a core set of unifying principles that span resource management, data pipelines, and system architecture. These principles provide a structured framework for understanding and designing ML systems at any scale. By focusing on these shared fundamentals and mastering their design and optimization, we can navigate the complexity of the ML landscape with clarity and confidence. As we continue to advance, these principles will act as a compass, guiding our exploration and innovation within the ever-evolving field of machine learning systems. Regardless of how diverse or complex these systems become, a strong grasp of these foundational concepts will remain essential to unlocking their full potential.</p>
</section>
<section id="sec-ml-systems-resources-c1ff" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="sec-ml-systems-resources-c1ff"><span class="header-section-number">2.11</span> Resources</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slides
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1Lgrn7bddHYxyrOmk0JfSVmEBimRePqI7WSliUKRPK9E/edit?resourcekey=0-c5JvfDeqHIdV9A5RMAMAyw#slide=id.g94db9f9f78_0_8">Embedded Systems Overview.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1hDCFcOrZ08kZPhY4DA3gVikGUo47HwNyvqNrLW-t-Tg/edit?resourcekey=0-J6ix5AYvZMGbFFOa7ae4Hw#slide=id.g94db9f9f78_0_8">Embedded Computer Hardware.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1rnWh9XC6iCKSx_hQd4xq2iIDlpc-GkBQw_GjzlP5mQc/edit#slide=id.g94db9f9f78_0_8">Embedded I/O.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1TApZn9xxPWCRY-D-soJ8YOSsfysnccR5UjOyspzeTuU/edit?resourcekey=0-BRWIyCKPLNQFnIfG0fJJ9A#slide=id.g94db9f9f78_0_8">Embedded systems software.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/17wgAfoF24Rcx7uPrbau0c8FyzXIUWbe48qGGBOXXT-g/edit?resourcekey=0-Uv29DvmF7gYzKdOoRtn0vw#slide=id.g94db9f9f78_0_8">Embedded ML software.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1FOUQ9dbe3l_qTa2AnroSbOz0ykuCz5cbTNO77tvFxEs/edit?usp=drive_link">Embedded Inference.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1jwAZz3UOoJTR8PY6Wa34FxijpoDc9gBM/edit?usp=drive_link&amp;ouid=102419556060649178683&amp;rtpof=true&amp;sd=true">Tiny ML on Microcontrollers.</a></p></li>
<li><p>Tiny ML as a Service (Tiny MLaaS):</p></li>
</ul>
<p>—<a href="https://docs.google.com/presentation/d/1O7bxb36SnexfDI3iE_p0C8JI_VYXAL8cyAx3JKDfeUo/edit?usp=drive_link">Tiny MLaaS: Introduction.</a></p>
<p>—<a href="https://docs.google.com/presentation/d/1ZUUHtTbKlzeTwVteQMSztscQmdmMxT1A24pBKSys7g0/edit#slide=id.g94db9f9f78_0_2">Tiny MLaaS: Design Overview.</a></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Videos
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><em>Coming soon.</em></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercises
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><em>Coming soon.</em></li>
</ul>
</div>
</div>
</div>


</section>
<section id="self-check-answers" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="self-check-answers"><span class="header-section-number">2.12</span> Self-Check Answers</h2>
<div id="sec-sec-ml-systems-cloudbased-machine-learning-52c3-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 1</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following is a key characteristic of Cloud Machine Learning?</strong></p>
<ol type="a">
<li>Decentralized infrastructure</li>
<li>Limited scalability</li>
<li>Centralized infrastructure</li>
<li>High latency</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Cloud Machine Learning is characterized by its centralized infrastructure, which allows for the pooling and efficient management of computational resources, making it easier to scale machine learning projects as needed.</p>
<p><em>Learning Objective</em>: Understand the core characteristics of Cloud ML and how they enable scalable ML operations.</p></li>
<li><p><strong>True or False: Cloud ML eliminates the need for organizations to consider data privacy and security.</strong></p>
<p><em>Answer</em>: False. While Cloud ML offers significant computational advantages, it also introduces challenges related to data privacy and security, as sensitive data transmitted to remote data centers can be vulnerable to cyber-attacks.</p>
<p><em>Learning Objective</em>: Recognize the data privacy and security challenges associated with Cloud ML.</p></li>
<li><p><strong>Explain how Cloud ML can be both cost-effective and potentially costly for organizations.</strong></p>
<p><em>Answer</em>: Cloud ML is cost-effective due to its pay-as-you-go pricing model, which eliminates the need for upfront capital investments in hardware. However, it can become costly if not managed properly, as the pay-as-you-go model can lead to escalating expenses with increased resource consumption during intensive operations.</p>
<p><em>Learning Objective</em>: Analyze the cost implications of adopting Cloud ML and the importance of managing cloud resources effectively.</p></li>
<li><p><strong>Cloud ML’s ability to handle large datasets and complex computations makes it particularly suitable for tasks such as ______ and natural language processing.</strong></p>
<p><em>Answer</em>: recommendation systems. Cloud ML’s computational power and scalability make it ideal for tasks that require processing large datasets and performing complex computations, such as recommendation systems and natural language processing.</p>
<p><em>Learning Objective</em>: Identify specific applications that benefit from Cloud ML’s capabilities.</p></li>
<li><p><strong>Order the following steps in addressing latency challenges in Cloud ML: [Implement robust security measures, Optimize network infrastructure, Minimize data transmission, Design for low latency]</strong></p>
<p><em>Answer</em>: 1. Design for low latency: Consider latency in the system design phase to ensure fast response times. 2. Minimize data transmission: Reduce the amount of data that needs to be sent to the cloud to lower latency. 3. Optimize network infrastructure: Ensure a robust and fast network to support low-latency applications. 4. Implement robust security measures: Protect data without introducing significant delays.</p>
<p><em>Learning Objective</em>: Understand the steps involved in mitigating latency challenges in Cloud ML systems.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-cloudbased-machine-learning-52c3">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-edge-machine-learning-52c5-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 2</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following is a primary advantage of Edge Machine Learning over Cloud Machine Learning?</strong></p>
<ol type="a">
<li>Higher computational power</li>
<li>Reduced latency</li>
<li>Unlimited data storage</li>
<li>Simplified network management</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Reduced latency is a primary advantage of Edge ML, as it allows for faster decision-making by processing data closer to its source, which is crucial for time-sensitive applications.</p>
<p><em>Learning Objective</em>: Understand the key advantages of Edge ML compared to Cloud ML.</p></li>
<li><p><strong>True or False: Edge ML inherently provides better data privacy compared to Cloud ML.</strong></p>
<p><em>Answer</em>: True. Edge ML processes and stores data locally, minimizing the risk of data breaches associated with transmitting data over networks to centralized servers.</p>
<p><em>Learning Objective</em>: Recognize the privacy benefits of Edge ML and how it contrasts with cloud-based solutions.</p></li>
<li><p><strong>Explain one major challenge of deploying Edge ML systems in industrial IoT environments.</strong></p>
<p><em>Answer</em>: One major challenge is managing the limited computational resources of edge devices, which can restrict the complexity of machine learning models that can be deployed. This limitation requires careful optimization to ensure efficient processing and decision-making.</p>
<p><em>Learning Objective</em>: Analyze the challenges of deploying Edge ML in resource-constrained environments.</p></li>
<li><p><strong>Edge ML is particularly beneficial for applications requiring ______ processing and decision-making.</strong></p>
<p><em>Answer</em>: real-time. Real-time processing is crucial for applications like autonomous vehicles and industrial IoT, where timely decision-making is essential for safety and efficiency.</p>
<p><em>Learning Objective</em>: Recall the specific scenarios where Edge ML’s real-time processing capabilities are advantageous.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-edge-machine-learning-52c5">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-mobile-machine-learning-dbe8-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 3</strong></summary><div>
<ol type="1">
<li><p><strong>What is a key advantage of Mobile ML compared to Cloud ML?</strong></p>
<ol type="a">
<li>Higher computational power</li>
<li>Enhanced data privacy</li>
<li>Unlimited storage capacity</li>
<li>Constant internet connectivity</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Mobile ML enhances data privacy by processing data locally on the device, reducing the need to transmit sensitive information to the cloud.</p>
<p><em>Learning Objective</em>: Understand the privacy benefits of Mobile ML.</p></li>
<li><p><strong>True or False: Mobile ML applications can operate offline, making them less dependent on network conditions.</strong></p>
<p><em>Answer</em>: True. Mobile ML applications are designed to function without constant internet connectivity, ensuring reliable performance even in areas with poor network coverage.</p>
<p><em>Learning Objective</em>: Recognize the offline capabilities of Mobile ML applications.</p></li>
<li><p><strong>Explain one major challenge developers face when implementing Mobile ML on battery-powered devices.</strong></p>
<p><em>Answer</em>: One major challenge is balancing model complexity with power consumption. Mobile ML must operate within limited battery life, requiring developers to optimize models to ensure efficient power usage without compromising performance.</p>
<p><em>Learning Objective</em>: Analyze the tradeoffs involved in optimizing Mobile ML for battery-powered devices.</p></li>
<li><p><strong>Mobile ML utilizes specialized hardware such as ______ to efficiently execute ML models on devices.</strong></p>
<p><em>Answer</em>: Neural Processing Units (NPUs). NPUs are designed to accelerate AI and ML computations, enabling efficient on-device processing.</p>
<p><em>Learning Objective</em>: Recall the specialized hardware used in Mobile ML.</p></li>
<li><p><strong>How does Mobile ML enhance the user experience on smartphones?</strong></p>
<p><em>Answer</em>: Mobile ML personalizes the user experience by learning individual usage patterns, optimizing battery usage, preloading content, and adjusting settings based on user preferences and environmental conditions, all while maintaining privacy by keeping data processing on the device.</p>
<p><em>Learning Objective</em>: Evaluate the impact of Mobile ML on user experience and personalization.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-mobile-machine-learning-dbe8">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-tiny-machine-learning-ccce-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 4</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following is a primary benefit of using Tiny ML in resource-constrained environments?</strong></p>
<ol type="a">
<li>Reduced computational accuracy</li>
<li>Increased data transmission costs</li>
<li>Ultra-low latency and enhanced data security</li>
<li>Dependence on external servers</li>
</ol>
<p><em>Answer</em>: The correct answer is C. Ultra-low latency and enhanced data security are primary benefits of Tiny ML because computation occurs directly on the device, reducing response time and minimizing data transmission risks.</p>
<p><em>Learning Objective</em>: Understand the benefits of Tiny ML in terms of latency and data security.</p></li>
<li><p><strong>Explain why energy efficiency is critical for Tiny ML applications and how it is achieved.</strong></p>
<p><em>Answer</em>: Energy efficiency is critical for Tiny ML applications because these devices often operate on limited power sources, like coin-cell batteries, in remote or disconnected environments. It is achieved through specialized algorithms and models designed to perform tasks with minimal energy consumption, ensuring extended operational periods.</p>
<p><em>Learning Objective</em>: Explain the importance of energy efficiency in Tiny ML and how it is achieved.</p></li>
<li><p><strong>True or False: Tiny ML devices can operate effectively without any need for model optimization or compression.</strong></p>
<p><em>Answer</em>: False. Tiny ML devices require model optimization and compression to operate effectively due to their limited memory and computational power. These optimizations are necessary to ensure models fit within resource constraints while maintaining effectiveness.</p>
<p><em>Learning Objective</em>: Recognize the necessity of model optimization in Tiny ML systems.</p></li>
<li><p><strong>Tiny ML is particularly beneficial for applications requiring ______ decision-making in environments with limited connectivity.</strong></p>
<p><em>Answer</em>: localized. Tiny ML enables localized decision-making by processing data directly on the device, which is crucial in environments where connectivity is limited or unavailable.</p>
<p><em>Learning Objective</em>: Identify the applications where Tiny ML is particularly beneficial.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-tiny-machine-learning-ccce">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-hybrid-machine-learning-6d02-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 5</strong></summary><div>
<ol type="1">
<li><p><strong>Which design pattern in Hybrid ML involves training models in the cloud and deploying them for inference on edge, mobile, or tiny devices?</strong></p>
<ol type="a">
<li>Hierarchical Processing</li>
<li>Train-Serve Split</li>
<li>Federated Learning</li>
<li>Collaborative Learning</li>
</ol>
<p><em>Answer</em>: The correct answer is B. The Train-Serve Split pattern involves training models in the cloud and deploying them for inference on edge, mobile, or tiny devices, leveraging cloud computational power for training and local inference for low latency and privacy.</p>
<p><em>Learning Objective</em>: Understand the Train-Serve Split pattern in Hybrid ML and its system-level implications.</p></li>
<li><p><strong>Explain how the Hierarchical Processing pattern benefits smart city applications.</strong></p>
<p><em>Answer</em>: Hierarchical Processing in smart city applications allows different tiers of devices to handle tasks suited to their capabilities. Street-level sensors perform immediate data collection, edge processors manage local data aggregation, and cloud systems conduct complex analytics. This ensures efficient use of resources and timely data processing across the city.</p>
<p><em>Learning Objective</em>: Analyze the application of Hierarchical Processing in real-world scenarios, specifically smart cities.</p></li>
<li><p><strong>In the context of Hybrid ML, ______ learning involves devices sharing model updates rather than raw data to maintain privacy while improving a global model.</strong></p>
<p><em>Answer</em>: federated. Federated learning involves devices sharing model updates rather than raw data, allowing for privacy-preserving model improvements across a network.</p>
<p><em>Learning Objective</em>: Recall the concept of federated learning and its privacy-preserving benefits in Hybrid ML systems.</p></li>
<li><p><strong>Order the following steps in a Progressive Deployment strategy: [Optimize model for edge devices, Train model in the cloud, Deploy model to mobile devices, Compress model for tiny sensors]</strong></p>
<p><em>Answer</em>: 1. Train model in the cloud, 2. Optimize model for edge devices, 3. Deploy model to mobile devices, 4. Compress model for tiny sensors. Progressive Deployment starts with a complex model in the cloud, which is then optimized and compressed for deployment across various computational tiers.</p>
<p><em>Learning Objective</em>: Understand the sequence of steps in the Progressive Deployment strategy within Hybrid ML systems.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-hybrid-machine-learning-6d02">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-shared-principles-db13-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 6</strong></summary><div>
<ol type="1">
<li><p><strong>Which of the following best describes the significance of shared principles in ML systems?</strong></p>
<ol type="a">
<li>They allow for the development of specialized hardware for each ML paradigm.</li>
<li>They facilitate the integration of different ML paradigms into cohesive workflows.</li>
<li>They eliminate the need for optimization in ML systems.</li>
<li>They restrict ML systems to operate only in cloud environments.</li>
</ol>
<p><em>Answer</em>: The correct answer is B. Shared principles facilitate the integration of different ML paradigms into cohesive workflows by providing a common framework that guides system design across various implementations.</p>
<p><em>Learning Objective</em>: Understand the role of shared principles in integrating different ML paradigms.</p></li>
<li><p><strong>Explain how the convergence of core principles across different ML implementations aids in the development of hybrid systems.</strong></p>
<p><em>Answer</em>: The convergence of core principles across ML implementations aids in the development of hybrid systems by providing a unified framework that ensures compatibility and seamless integration. This allows different ML paradigms to complement each other effectively, leveraging their strengths while mitigating limitations.</p>
<p><em>Learning Objective</em>: Analyze how shared principles enable the development of hybrid ML systems.</p></li>
<li><p><strong>In ML systems, managing data pipelines involves handling information flow from collection through ______ to final deployment.</strong></p>
<p><em>Answer</em>: processing. Managing data pipelines involves handling information flow from collection through processing to final deployment, addressing challenges of data ingestion, transformation, and utilization.</p>
<p><em>Learning Objective</em>: Recall the stages involved in managing data pipelines in ML systems.</p></li>
<li><p><strong>True or False: The principles of resource management are unique to each ML paradigm and do not overlap.</strong></p>
<p><em>Answer</em>: False. The principles of resource management are consistent across different ML paradigms, involving the balance of computation, memory, energy, and network resources, though the specific implementations may vary.</p>
<p><em>Learning Objective</em>: Understand the consistency of resource management principles across ML paradigms.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-shared-principles-db13">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-system-comparison-0245-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 7</strong></summary><div>
<ol type="1">
<li><p><strong>Which ML system paradigm is best suited for applications requiring minimal latency and high data privacy?</strong></p>
<ol type="a">
<li>Cloud ML</li>
<li>Edge ML</li>
<li>Mobile ML</li>
<li>Tiny ML</li>
</ol>
<p><em>Answer</em>: The correct answer is D. Tiny ML. Tiny ML is best suited for applications requiring minimal latency and high data privacy because it processes data locally on ultra-low-power devices, ensuring that data never leaves the sensor.</p>
<p><em>Learning Objective</em>: Understand the strengths of Tiny ML in terms of latency and data privacy.</p></li>
<li><p><strong>Explain why Mobile ML represents a middle ground between Cloud ML and Tiny ML in terms of computational power and energy efficiency.</strong></p>
<p><em>Answer</em>: Mobile ML represents a middle ground because it balances computational power and energy efficiency by using devices like smartphones and tablets, which have moderate processing capabilities and are optimized for energy-efficient operations compared to cloud and tiny devices.</p>
<p><em>Learning Objective</em>: Analyze the trade-offs of Mobile ML in terms of computational power and energy efficiency.</p></li>
<li><p><strong>True or False: Cloud ML systems offer the best offline capabilities among all ML paradigms.</strong></p>
<p><em>Answer</em>: False. Cloud ML systems do not offer offline capabilities as they rely on constant high-bandwidth connectivity to function effectively, unlike Edge ML, Mobile ML, and Tiny ML which can operate offline.</p>
<p><em>Learning Objective</em>: Identify the limitations of Cloud ML in terms of offline capabilities.</p></li>
<li><p><strong>The trade-off between compute power and ______ is a key consideration when comparing different ML system paradigms.</strong></p>
<p><em>Answer</em>: energy efficiency. The trade-off between compute power and energy efficiency is a key consideration when comparing different ML system paradigms, as higher compute power often comes with increased energy consumption.</p>
<p><em>Learning Objective</em>: Understand the trade-off between compute power and energy efficiency across ML systems.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-system-comparison-0245">↩︎ Back to Question</a></p>
</div></details>
</div>
<div id="sec-sec-ml-systems-deployment-decision-framework-cb57-answer" class="callout callout-quiz-answer">
<details class="callout-quiz-answer fbx-answer closebutton"><summary><strong>Self-Check: Answer 8</strong></summary><div>
<ol type="1">
<li><p><strong>Which layer of the deployment decision framework determines whether processing can occur in the cloud or must remain local?</strong></p>
<ol type="a">
<li>Latency</li>
<li>Privacy</li>
<li>Compute Needs</li>
<li>Cost and Energy Efficiency</li>
</ol>
<p><em>Answer</em>: The correct answer is B. The Privacy layer determines whether processing can occur in the cloud or must remain local to safeguard sensitive data.</p>
<p><em>Learning Objective</em>: Understand the role of the Privacy layer in the deployment decision framework.</p></li>
<li><p><strong>Explain why applications requiring real-time responses might favor edge or mobile-based deployment over cloud solutions.</strong></p>
<p><em>Answer</em>: Applications requiring real-time responses favor edge or mobile-based deployment because these paradigms reduce latency by processing data closer to the source, avoiding the delays associated with data transmission to and from the cloud.</p>
<p><em>Learning Objective</em>: Analyze the trade-offs between different deployment paradigms for real-time applications.</p></li>
<li><p><strong>True or False: High-performance recommendation engines typically prioritize mobile-based deployment due to their need for significant compute resources.</strong></p>
<p><em>Answer</em>: False. High-performance recommendation engines typically favor cloud infrastructure due to the availability of significant compute resources required for processing large amounts of data.</p>
<p><em>Learning Objective</em>: Challenge misconceptions about deployment paradigms and compute needs.</p></li>
<li><p><strong>In the deployment decision framework, the ______ layer assesses network stability and its impact on deployment feasibility.</strong></p>
<p><em>Answer</em>: Reliability. The Reliability layer assesses network stability and its impact on deployment feasibility.</p>
<p><em>Learning Objective</em>: Recall the role of the Reliability layer in the deployment decision framework.</p></li>
<li><p><strong>Order the following layers of the deployment decision framework: [Latency, Privacy, Cost and Energy Efficiency, Compute Needs, Reliability]</strong></p>
<p><em>Answer</em>: 1. Privacy, 2. Latency, 3. Reliability, 4. Compute Needs, 5. Cost and Energy Efficiency. This order reflects the logical progression from determining processing location to evaluating resource constraints.</p>
<p><em>Learning Objective</em>: Understand the structured approach of the deployment decision framework.</p></li>
</ol>
<p><a href="#sec-sec-ml-systems-deployment-decision-framework-cb57">↩︎ Back to Question</a></p>
</div></details>
</div>

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "harvard-edge/cs249r_book";
    script.dataset.repoId = "R_kgDOKQSOaw";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOKQSOa84CZ8Ry";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/introduction/introduction.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/dl_primer/dl_primer.html" class="pagination-link" aria-label="DL Primer">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">DL Primer</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Written, edited and curated by Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/widget_quiz/contents/core/ml_systems/ml_systems.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/widget_quiz/contents/core/ml_systems/ml_systems.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>